doc	unit1_toks	unit2_toks	unit1_txt	unit2_txt	s1_toks	s2_toks	unit1_sent	unit2_sent	dir	orig_label	label
nlpabs102_Chi	1-6	7-21	针对 维吾尔 语零 指代 现象 ,	提出 采用 栈式 降噪 自编码 的 深度 学习 机制 进行 维吾尔 语零 指代 消解 。	1-21	1-21	针对 维吾尔 语零 指代 现象 , 提出 采用 栈式 降噪 自编码 的 深度 学习 机制 进行 维吾尔 语零 指代 消解 。	针对 维吾尔 语零 指代 现象 , 提出 采用 栈式 降噪 自编码 的 深度 学习 机制 进行 维吾尔 语零 指代 消解 。	1>2	bg-general	bg-general
nlpabs102_Chi	7-21	22-31	提出 采用 栈式 降噪 自编码 的 深度 学习 机制 进行 维吾尔 语零 指代 消解 。	首先 由 大 规模 无 标注 维吾尔 语 语料 训练	1-21	22-124	针对 维吾尔 语零 指代 现象 , 提出 采用 栈式 降噪 自编码 的 深度 学习 机制 进行 维吾尔 语零 指代 消解 。	首先 由 大 规模 无 标注 维吾尔 语 语料 训练 得到 富含 语义 和 句法 信息 的 词 嵌入 表示 , 将 其 作 为 候选 先行 语 和 缺省 零代 词 的 语义 特征 ; 其次 根据 维吾尔 语 语言 特点 , 抽取 14 项 针对 零 指代 消解 任务 的 手工 设计 特征 ; 然后 融合 word embedding 特征 和 14 项 hand-crafted 特征 作 为 栈式 降噪 自编 码 的 输入 , 最后 经过 无 监督 逐层 贪婪 的 预训练 和 有 监督 的 微调 过程 , 使用 sof tmax 进行 分类 完成 维吾尔 语 零 指代 消解 任务 。	1<2	elab-process_step	elab-process_step
nlpabs102_Chi	22-31	32-42	首先 由 大 规模 无 标注 维吾尔 语 语料 训练	得到 富含 语义 和 句法 信息 的 词 嵌入 表示 ,	22-124	22-124	首先 由 大 规模 无 标注 维吾尔 语 语料 训练 得到 富含 语义 和 句法 信息 的 词 嵌入 表示 , 将 其 作 为 候选 先行 语 和 缺省 零代 词 的 语义 特征 ; 其次 根据 维吾尔 语 语言 特点 , 抽取 14 项 针对 零 指代 消解 任务 的 手工 设计 特征 ; 然后 融合 word embedding 特征 和 14 项 hand-crafted 特征 作 为 栈式 降噪 自编 码 的 输入 , 最后 经过 无 监督 逐层 贪婪 的 预训练 和 有 监督 的 微调 过程 , 使用 sof tmax 进行 分类 完成 维吾尔 语 零 指代 消解 任务 。	首先 由 大 规模 无 标注 维吾尔 语 语料 训练 得到 富含 语义 和 句法 信息 的 词 嵌入 表示 , 将 其 作 为 候选 先行 语 和 缺省 零代 词 的 语义 特征 ; 其次 根据 维吾尔 语 语言 特点 , 抽取 14 项 针对 零 指代 消解 任务 的 手工 设计 特征 ; 然后 融合 word embedding 特征 和 14 项 hand-crafted 特征 作 为 栈式 降噪 自编 码 的 输入 , 最后 经过 无 监督 逐层 贪婪 的 预训练 和 有 监督 的 微调 过程 , 使用 sof tmax 进行 分类 完成 维吾尔 语 零 指代 消解 任务 。	1<2	enablement	enablement
nlpabs102_Chi	32-42	43-57	得到 富含 语义 和 句法 信息 的 词 嵌入 表示 ,	将 其 作 为 候选 先行 语 和 缺省 零代 词 的 语义 特征 ;	22-124	22-124	首先 由 大 规模 无 标注 维吾尔 语 语料 训练 得到 富含 语义 和 句法 信息 的 词 嵌入 表示 , 将 其 作 为 候选 先行 语 和 缺省 零代 词 的 语义 特征 ; 其次 根据 维吾尔 语 语言 特点 , 抽取 14 项 针对 零 指代 消解 任务 的 手工 设计 特征 ; 然后 融合 word embedding 特征 和 14 项 hand-crafted 特征 作 为 栈式 降噪 自编 码 的 输入 , 最后 经过 无 监督 逐层 贪婪 的 预训练 和 有 监督 的 微调 过程 , 使用 sof tmax 进行 分类 完成 维吾尔 语 零 指代 消解 任务 。	首先 由 大 规模 无 标注 维吾尔 语 语料 训练 得到 富含 语义 和 句法 信息 的 词 嵌入 表示 , 将 其 作 为 候选 先行 语 和 缺省 零代 词 的 语义 特征 ; 其次 根据 维吾尔 语 语言 特点 , 抽取 14 项 针对 零 指代 消解 任务 的 手工 设计 特征 ; 然后 融合 word embedding 特征 和 14 项 hand-crafted 特征 作 为 栈式 降噪 自编 码 的 输入 , 最后 经过 无 监督 逐层 贪婪 的 预训练 和 有 监督 的 微调 过程 , 使用 sof tmax 进行 分类 完成 维吾尔 语 零 指代 消解 任务 。	1<2	elab-addition	elab-addition
nlpabs102_Chi	58-64	65-77	其次 根据 维吾尔 语 语言 特点 ,	抽取 14 项 针对 零 指代 消解 任务 的 手工 设计 特征 ;	22-124	22-124	首先 由 大 规模 无 标注 维吾尔 语 语料 训练 得到 富含 语义 和 句法 信息 的 词 嵌入 表示 , 将 其 作 为 候选 先行 语 和 缺省 零代 词 的 语义 特征 ; 其次 根据 维吾尔 语 语言 特点 , 抽取 14 项 针对 零 指代 消解 任务 的 手工 设计 特征 ; 然后 融合 word embedding 特征 和 14 项 hand-crafted 特征 作 为 栈式 降噪 自编 码 的 输入 , 最后 经过 无 监督 逐层 贪婪 的 预训练 和 有 监督 的 微调 过程 , 使用 sof tmax 进行 分类 完成 维吾尔 语 零 指代 消解 任务 。	首先 由 大 规模 无 标注 维吾尔 语 语料 训练 得到 富含 语义 和 句法 信息 的 词 嵌入 表示 , 将 其 作 为 候选 先行 语 和 缺省 零代 词 的 语义 特征 ; 其次 根据 维吾尔 语 语言 特点 , 抽取 14 项 针对 零 指代 消解 任务 的 手工 设计 特征 ; 然后 融合 word embedding 特征 和 14 项 hand-crafted 特征 作 为 栈式 降噪 自编 码 的 输入 , 最后 经过 无 监督 逐层 贪婪 的 预训练 和 有 监督 的 微调 过程 , 使用 sof tmax 进行 分类 完成 维吾尔 语 零 指代 消解 任务 。	1>2	bg-general	bg-general
nlpabs102_Chi	22-31	65-77	首先 由 大 规模 无 标注 维吾尔 语 语料 训练	抽取 14 项 针对 零 指代 消解 任务 的 手工 设计 特征 ;	22-124	22-124	首先 由 大 规模 无 标注 维吾尔 语 语料 训练 得到 富含 语义 和 句法 信息 的 词 嵌入 表示 , 将 其 作 为 候选 先行 语 和 缺省 零代 词 的 语义 特征 ; 其次 根据 维吾尔 语 语言 特点 , 抽取 14 项 针对 零 指代 消解 任务 的 手工 设计 特征 ; 然后 融合 word embedding 特征 和 14 项 hand-crafted 特征 作 为 栈式 降噪 自编 码 的 输入 , 最后 经过 无 监督 逐层 贪婪 的 预训练 和 有 监督 的 微调 过程 , 使用 sof tmax 进行 分类 完成 维吾尔 语 零 指代 消解 任务 。	首先 由 大 规模 无 标注 维吾尔 语 语料 训练 得到 富含 语义 和 句法 信息 的 词 嵌入 表示 , 将 其 作 为 候选 先行 语 和 缺省 零代 词 的 语义 特征 ; 其次 根据 维吾尔 语 语言 特点 , 抽取 14 项 针对 零 指代 消解 任务 的 手工 设计 特征 ; 然后 融合 word embedding 特征 和 14 项 hand-crafted 特征 作 为 栈式 降噪 自编 码 的 输入 , 最后 经过 无 监督 逐层 贪婪 的 预训练 和 有 监督 的 微调 过程 , 使用 sof tmax 进行 分类 完成 维吾尔 语 零 指代 消解 任务 。	1<2	joint	joint
nlpabs102_Chi	65-77	78-96	抽取 14 项 针对 零 指代 消解 任务 的 手工 设计 特征 ;	然后 融合 word embedding 特征 和 14 项 hand-crafted 特征 作 为 栈式 降噪 自编 码 的 输入 ,	22-124	22-124	首先 由 大 规模 无 标注 维吾尔 语 语料 训练 得到 富含 语义 和 句法 信息 的 词 嵌入 表示 , 将 其 作 为 候选 先行 语 和 缺省 零代 词 的 语义 特征 ; 其次 根据 维吾尔 语 语言 特点 , 抽取 14 项 针对 零 指代 消解 任务 的 手工 设计 特征 ; 然后 融合 word embedding 特征 和 14 项 hand-crafted 特征 作 为 栈式 降噪 自编 码 的 输入 , 最后 经过 无 监督 逐层 贪婪 的 预训练 和 有 监督 的 微调 过程 , 使用 sof tmax 进行 分类 完成 维吾尔 语 零 指代 消解 任务 。	首先 由 大 规模 无 标注 维吾尔 语 语料 训练 得到 富含 语义 和 句法 信息 的 词 嵌入 表示 , 将 其 作 为 候选 先行 语 和 缺省 零代 词 的 语义 特征 ; 其次 根据 维吾尔 语 语言 特点 , 抽取 14 项 针对 零 指代 消解 任务 的 手工 设计 特征 ; 然后 融合 word embedding 特征 和 14 项 hand-crafted 特征 作 为 栈式 降噪 自编 码 的 输入 , 最后 经过 无 监督 逐层 贪婪 的 预训练 和 有 监督 的 微调 过程 , 使用 sof tmax 进行 分类 完成 维吾尔 语 零 指代 消解 任务 。	1<2	joint	joint
nlpabs102_Chi	78-96	97-111	然后 融合 word embedding 特征 和 14 项 hand-crafted 特征 作 为 栈式 降噪 自编 码 的 输入 ,	最后 经过 无 监督 逐层 贪婪 的 预训练 和 有 监督 的 微调 过程 ,	22-124	22-124	首先 由 大 规模 无 标注 维吾尔 语 语料 训练 得到 富含 语义 和 句法 信息 的 词 嵌入 表示 , 将 其 作 为 候选 先行 语 和 缺省 零代 词 的 语义 特征 ; 其次 根据 维吾尔 语 语言 特点 , 抽取 14 项 针对 零 指代 消解 任务 的 手工 设计 特征 ; 然后 融合 word embedding 特征 和 14 项 hand-crafted 特征 作 为 栈式 降噪 自编 码 的 输入 , 最后 经过 无 监督 逐层 贪婪 的 预训练 和 有 监督 的 微调 过程 , 使用 sof tmax 进行 分类 完成 维吾尔 语 零 指代 消解 任务 。	首先 由 大 规模 无 标注 维吾尔 语 语料 训练 得到 富含 语义 和 句法 信息 的 词 嵌入 表示 , 将 其 作 为 候选 先行 语 和 缺省 零代 词 的 语义 特征 ; 其次 根据 维吾尔 语 语言 特点 , 抽取 14 项 针对 零 指代 消解 任务 的 手工 设计 特征 ; 然后 融合 word embedding 特征 和 14 项 hand-crafted 特征 作 为 栈式 降噪 自编 码 的 输入 , 最后 经过 无 监督 逐层 贪婪 的 预训练 和 有 监督 的 微调 过程 , 使用 sof tmax 进行 分类 完成 维吾尔 语 零 指代 消解 任务 。	1<2	joint	joint
nlpabs102_Chi	97-111	112-124	最后 经过 无 监督 逐层 贪婪 的 预训练 和 有 监督 的 微调 过程 ,	使用 sof tmax 进行 分类 完成 维吾尔 语 零 指代 消解 任务 。	22-124	22-124	首先 由 大 规模 无 标注 维吾尔 语 语料 训练 得到 富含 语义 和 句法 信息 的 词 嵌入 表示 , 将 其 作 为 候选 先行 语 和 缺省 零代 词 的 语义 特征 ; 其次 根据 维吾尔 语 语言 特点 , 抽取 14 项 针对 零 指代 消解 任务 的 手工 设计 特征 ; 然后 融合 word embedding 特征 和 14 项 hand-crafted 特征 作 为 栈式 降噪 自编 码 的 输入 , 最后 经过 无 监督 逐层 贪婪 的 预训练 和 有 监督 的 微调 过程 , 使用 sof tmax 进行 分类 完成 维吾尔 语 零 指代 消解 任务 。	首先 由 大 规模 无 标注 维吾尔 语 语料 训练 得到 富含 语义 和 句法 信息 的 词 嵌入 表示 , 将 其 作 为 候选 先行 语 和 缺省 零代 词 的 语义 特征 ; 其次 根据 维吾尔 语 语言 特点 , 抽取 14 项 针对 零 指代 消解 任务 的 手工 设计 特征 ; 然后 融合 word embedding 特征 和 14 项 hand-crafted 特征 作 为 栈式 降噪 自编 码 的 输入 , 最后 经过 无 监督 逐层 贪婪 的 预训练 和 有 监督 的 微调 过程 , 使用 sof tmax 进行 分类 完成 维吾尔 语 零 指代 消解 任务 。	1<2	joint	joint
nlpabs102_Chi	125-128	148-163	实验 结果 表明 ,	栈式 降噪 自编 码 的 F值 分 别提 高 了 4.450% 、 10.032% 和 8.140% ,	125-192	125-192	实验 结果 表明 , 与 传统 栈式 自编 码 、 浅层 机器 学习 的 支持 向量 机 和 人工 神经 网络 相比 , 栈式 降噪 自编 码 的 F值 分 别提 高 了 4.450% 、 10.032% 和 8.140% , 实验 结果 验证 了 该 方法 的 有效 性 及 栈式 降噪 自编 码 在 任务 中 具备 挖掘 高 层 面 鲁棒 性 语义 特征 的 优势 。	实验 结果 表明 , 与 传统 栈式 自编 码 、 浅层 机器 学习 的 支持 向量 机 和 人工 神经 网络 相比 , 栈式 降噪 自编 码 的 F值 分 别提 高 了 4.450% 、 10.032% 和 8.140% , 实验 结果 验证 了 该 方法 的 有效 性 及 栈式 降噪 自编 码 在 任务 中 具备 挖掘 高 层 面 鲁棒 性 语义 特征 的 优势 。	1>2	attribution	attribution
nlpabs102_Chi	129-147	148-163	与 传统 栈式 自编 码 、 浅层 机器 学习 的 支持 向量 机 和 人工 神经 网络 相比 ,	栈式 降噪 自编 码 的 F值 分 别提 高 了 4.450% 、 10.032% 和 8.140% ,	125-192	125-192	实验 结果 表明 , 与 传统 栈式 自编 码 、 浅层 机器 学习 的 支持 向量 机 和 人工 神经 网络 相比 , 栈式 降噪 自编 码 的 F值 分 别提 高 了 4.450% 、 10.032% 和 8.140% , 实验 结果 验证 了 该 方法 的 有效 性 及 栈式 降噪 自编 码 在 任务 中 具备 挖掘 高 层 面 鲁棒 性 语义 特征 的 优势 。	实验 结果 表明 , 与 传统 栈式 自编 码 、 浅层 机器 学习 的 支持 向量 机 和 人工 神经 网络 相比 , 栈式 降噪 自编 码 的 F值 分 别提 高 了 4.450% 、 10.032% 和 8.140% , 实验 结果 验证 了 该 方法 的 有效 性 及 栈式 降噪 自编 码 在 任务 中 具备 挖掘 高 层 面 鲁棒 性 语义 特征 的 优势 。	1>2	comparison	comparison
nlpabs102_Chi	7-21	148-163	提出 采用 栈式 降噪 自编码 的 深度 学习 机制 进行 维吾尔 语零 指代 消解 。	栈式 降噪 自编 码 的 F值 分 别提 高 了 4.450% 、 10.032% 和 8.140% ,	1-21	125-192	针对 维吾尔 语零 指代 现象 , 提出 采用 栈式 降噪 自编码 的 深度 学习 机制 进行 维吾尔 语零 指代 消解 。	实验 结果 表明 , 与 传统 栈式 自编 码 、 浅层 机器 学习 的 支持 向量 机 和 人工 神经 网络 相比 , 栈式 降噪 自编 码 的 F值 分 别提 高 了 4.450% 、 10.032% 和 8.140% , 实验 结果 验证 了 该 方法 的 有效 性 及 栈式 降噪 自编 码 在 任务 中 具备 挖掘 高 层 面 鲁棒 性 语义 特征 的 优势 。	1<2	evaluation	evaluation
nlpabs102_Chi	148-163	164-192	栈式 降噪 自编 码 的 F值 分 别提 高 了 4.450% 、 10.032% 和 8.140% ,	实验 结果 验证 了 该 方法 的 有效 性 及 栈式 降噪 自编 码 在 任务 中 具备 挖掘 高 层 面 鲁棒 性 语义 特征 的 优势 。	125-192	125-192	实验 结果 表明 , 与 传统 栈式 自编 码 、 浅层 机器 学习 的 支持 向量 机 和 人工 神经 网络 相比 , 栈式 降噪 自编 码 的 F值 分 别提 高 了 4.450% 、 10.032% 和 8.140% , 实验 结果 验证 了 该 方法 的 有效 性 及 栈式 降噪 自编 码 在 任务 中 具备 挖掘 高 层 面 鲁棒 性 语义 特征 的 优势 。	实验 结果 表明 , 与 传统 栈式 自编 码 、 浅层 机器 学习 的 支持 向量 机 和 人工 神经 网络 相比 , 栈式 降噪 自编 码 的 F值 分 别提 高 了 4.450% 、 10.032% 和 8.140% , 实验 结果 验证 了 该 方法 的 有效 性 及 栈式 降噪 自编 码 在 任务 中 具备 挖掘 高 层 面 鲁棒 性 语义 特征 的 优势 。	1<2	elab-addition	elab-addition
nlpabs109_Chi	1-24	25-62	该文 将 行业 政策 形式 化 为 一 个 由 微观 、 中观 和 宏观 政策 血缘 网络 构成 的 复杂 网络 体系 。	分别 通过 改进 的 基 于 语义 的 政策 词语 相似 度 计算 方法 、 依 存句 分析 和 基 于 向量 空间 模型 的 方法 构建 了 微观 、 中观 及 宏观 的 政策 血缘 网络 。	1-24	25-62	该文 将 行业 政策 形式 化 为 一 个 由 微观 、 中观 和 宏观 政策 血缘 网络 构成 的 复杂 网络 体系 。	分别 通过 改进 的 基 于 语义 的 政策 词语 相似 度 计算 方法 、 依 存句 分析 和 基 于 向量 空间 模型 的 方法 构建 了 微观 、 中观 及 宏观 的 政策 血缘 网络 。	1<2	elab-addition	elab-addition
nlpabs109_Chi	63-67	68-81	在 此 基础 上 ,	该文 对 政策 血缘 网络 进行 了 层次 结构 演化 和 碎片 清理 ,	63-101	63-101	在 此 基础 上 , 该文 对 政策 血缘 网络 进行 了 层次 结构 演化 和 碎片 清理 , 构建 了 政策 血缘 森林 并 提出 基 于 政策 血缘 森林 的 政策 碎片 化 预防 的 方法 。	在 此 基础 上 , 该文 对 政策 血缘 网络 进行 了 层次 结构 演化 和 碎片 清理 , 构建 了 政策 血缘 森林 并 提出 基 于 政策 血缘 森林 的 政策 碎片 化 预防 的 方法 。	1>2	bg-general	bg-general
nlpabs109_Chi	25-62	68-81	分别 通过 改进 的 基 于 语义 的 政策 词语 相似 度 计算 方法 、 依 存句 分析 和 基 于 向量 空间 模型 的 方法 构建 了 微观 、 中观 及 宏观 的 政策 血缘 网络 。	该文 对 政策 血缘 网络 进行 了 层次 结构 演化 和 碎片 清理 ,	25-62	63-101	分别 通过 改进 的 基 于 语义 的 政策 词语 相似 度 计算 方法 、 依 存句 分析 和 基 于 向量 空间 模型 的 方法 构建 了 微观 、 中观 及 宏观 的 政策 血缘 网络 。	在 此 基础 上 , 该文 对 政策 血缘 网络 进行 了 层次 结构 演化 和 碎片 清理 , 构建 了 政策 血缘 森林 并 提出 基 于 政策 血缘 森林 的 政策 碎片 化 预防 的 方法 。	1<2	progression	progression
nlpabs109_Chi	68-81	82-101	该文 对 政策 血缘 网络 进行 了 层次 结构 演化 和 碎片 清理 ,	构建 了 政策 血缘 森林 并 提出 基 于 政策 血缘 森林 的 政策 碎片 化 预防 的 方法 。	63-101	63-101	在 此 基础 上 , 该文 对 政策 血缘 网络 进行 了 层次 结构 演化 和 碎片 清理 , 构建 了 政策 血缘 森林 并 提出 基 于 政策 血缘 森林 的 政策 碎片 化 预防 的 方法 。	在 此 基础 上 , 该文 对 政策 血缘 网络 进行 了 层次 结构 演化 和 碎片 清理 , 构建 了 政策 血缘 森林 并 提出 基 于 政策 血缘 森林 的 政策 碎片 化 预防 的 方法 。	1<2	joint	joint
nlpabs109_Chi	102-105	106-120	实验 结果 表明 ,	该文 所 提出 的 方法 能 有效 地 解决 政策 碎片 化 等 问题 。	102-120	102-120	实验 结果 表明 , 该文 所 提出 的 方法 能 有效 地 解决 政策 碎片 化 等 问题 。	实验 结果 表明 , 该文 所 提出 的 方法 能 有效 地 解决 政策 碎片 化 等 问题 。	1>2	attribution	attribution
nlpabs109_Chi	1-24	106-120	该文 将 行业 政策 形式 化 为 一 个 由 微观 、 中观 和 宏观 政策 血缘 网络 构成 的 复杂 网络 体系 。	该文 所 提出 的 方法 能 有效 地 解决 政策 碎片 化 等 问题 。	1-24	102-120	该文 将 行业 政策 形式 化 为 一 个 由 微观 、 中观 和 宏观 政策 血缘 网络 构成 的 复杂 网络 体系 。	实验 结果 表明 , 该文 所 提出 的 方法 能 有效 地 解决 政策 碎片 化 等 问题 。	1<2	evaluation	evaluation
nlpabs17_Chi	1-12	48-72	朝鲜 语 词性 标注 是 朝鲜 语 信息 处理 的 基础 ,	该文 提出 了 一 种 在 seq2seq 模型 的 基础 上 融合 朝鲜 语 字母 信息 的 朝鲜 语 形态 素原 形 恢复 方法 ;	1-26	27-95	朝鲜 语 词性 标注 是 朝鲜 语 信息 处理 的 基础 , 其 结果 直接 影响 后 续 朝 鲜语 自然 语言 处理 的 效果 。	首先 为了 解决 朝鲜 语 词性 标注 中 遇到 的 形态 素 实际 写法 与 原形 不 一致 的 问题 , 该文 提出 了 一 种 在 seq2seq 模型 的 基础 上 融合 朝鲜 语 字母 信息 的 朝鲜 语 形态 素原 形 恢复 方法 ; 其次 , 在 恢复 形态 素 原 形 的 基础 上 , 利用 LSTM-CRF 模型 完成 朝鲜 语 分写 及 词性 标注 。	1>2	bg-general	bg-general
nlpabs17_Chi	1-12	13-26	朝鲜 语 词性 标注 是 朝鲜 语 信息 处理 的 基础 ,	其 结果 直接 影响 后 续 朝 鲜语 自然 语言 处理 的 效果 。	1-26	1-26	朝鲜 语 词性 标注 是 朝鲜 语 信息 处理 的 基础 , 其 结果 直接 影响 后 续 朝 鲜语 自然 语言 处理 的 效果 。	朝鲜 语 词性 标注 是 朝鲜 语 信息 处理 的 基础 , 其 结果 直接 影响 后 续 朝 鲜语 自然 语言 处理 的 效果 。	1<2	elab-addition	elab-addition
nlpabs17_Chi	27-47	48-72	首先 为了 解决 朝鲜 语 词性 标注 中 遇到 的 形态 素 实际 写法 与 原形 不 一致 的 问题 ,	该文 提出 了 一 种 在 seq2seq 模型 的 基础 上 融合 朝鲜 语 字母 信息 的 朝鲜 语 形态 素原 形 恢复 方法 ;	27-95	27-95	首先 为了 解决 朝鲜 语 词性 标注 中 遇到 的 形态 素 实际 写法 与 原形 不 一致 的 问题 , 该文 提出 了 一 种 在 seq2seq 模型 的 基础 上 融合 朝鲜 语 字母 信息 的 朝鲜 语 形态 素原 形 恢复 方法 ; 其次 , 在 恢复 形态 素 原 形 的 基础 上 , 利用 LSTM-CRF 模型 完成 朝鲜 语 分写 及 词性 标注 。	首先 为了 解决 朝鲜 语 词性 标注 中 遇到 的 形态 素 实际 写法 与 原形 不 一致 的 问题 , 该文 提出 了 一 种 在 seq2seq 模型 的 基础 上 融合 朝鲜 语 字母 信息 的 朝鲜 语 形态 素原 形 恢复 方法 ; 其次 , 在 恢复 形态 素 原 形 的 基础 上 , 利用 LSTM-CRF 模型 完成 朝鲜 语 分写 及 词性 标注 。	1>2	bg-goal	bg-goal
nlpabs17_Chi	73-84	85-95	其次 , 在 恢复 形态 素 原 形 的 基础 上 ,	利用 LSTM-CRF 模型 完成 朝鲜 语 分写 及 词性 标注 。	27-95	27-95	首先 为了 解决 朝鲜 语 词性 标注 中 遇到 的 形态 素 实际 写法 与 原形 不 一致 的 问题 , 该文 提出 了 一 种 在 seq2seq 模型 的 基础 上 融合 朝鲜 语 字母 信息 的 朝鲜 语 形态 素原 形 恢复 方法 ; 其次 , 在 恢复 形态 素 原 形 的 基础 上 , 利用 LSTM-CRF 模型 完成 朝鲜 语 分写 及 词性 标注 。	首先 为了 解决 朝鲜 语 词性 标注 中 遇到 的 形态 素 实际 写法 与 原形 不 一致 的 问题 , 该文 提出 了 一 种 在 seq2seq 模型 的 基础 上 融合 朝鲜 语 字母 信息 的 朝鲜 语 形态 素原 形 恢复 方法 ; 其次 , 在 恢复 形态 素 原 形 的 基础 上 , 利用 LSTM-CRF 模型 完成 朝鲜 语 分写 及 词性 标注 。	1>2	bg-general	bg-general
nlpabs17_Chi	48-72	85-95	该文 提出 了 一 种 在 seq2seq 模型 的 基础 上 融合 朝鲜 语 字母 信息 的 朝鲜 语 形态 素原 形 恢复 方法 ;	利用 LSTM-CRF 模型 完成 朝鲜 语 分写 及 词性 标注 。	27-95	27-95	首先 为了 解决 朝鲜 语 词性 标注 中 遇到 的 形态 素 实际 写法 与 原形 不 一致 的 问题 , 该文 提出 了 一 种 在 seq2seq 模型 的 基础 上 融合 朝鲜 语 字母 信息 的 朝鲜 语 形态 素原 形 恢复 方法 ; 其次 , 在 恢复 形态 素 原 形 的 基础 上 , 利用 LSTM-CRF 模型 完成 朝鲜 语 分写 及 词性 标注 。	首先 为了 解决 朝鲜 语 词性 标注 中 遇到 的 形态 素 实际 写法 与 原形 不 一致 的 问题 , 该文 提出 了 一 种 在 seq2seq 模型 的 基础 上 融合 朝鲜 语 字母 信息 的 朝鲜 语 形态 素原 形 恢复 方法 ; 其次 , 在 恢复 形态 素 原 形 的 基础 上 , 利用 LSTM-CRF 模型 完成 朝鲜 语 分写 及 词性 标注 。	1<2	joint	joint
nlpabs17_Chi	96-99	100-110	实验 结果 表明 ,	该文 提出 的 方法 词性 标注 F1 值 为 94.75% ,	96-115	96-115	实验 结果 表明 , 该文 提出 的 方法 词性 标注 F1 值 为 94.75% , 优 于 其他 方法 。	实验 结果 表明 , 该文 提出 的 方法 词性 标注 F1 值 为 94.75% , 优 于 其他 方法 。	1>2	attribution	attribution
nlpabs17_Chi	48-72	100-110	该文 提出 了 一 种 在 seq2seq 模型 的 基础 上 融合 朝鲜 语 字母 信息 的 朝鲜 语 形态 素原 形 恢复 方法 ;	该文 提出 的 方法 词性 标注 F1 值 为 94.75% ,	27-95	96-115	首先 为了 解决 朝鲜 语 词性 标注 中 遇到 的 形态 素 实际 写法 与 原形 不 一致 的 问题 , 该文 提出 了 一 种 在 seq2seq 模型 的 基础 上 融合 朝鲜 语 字母 信息 的 朝鲜 语 形态 素原 形 恢复 方法 ; 其次 , 在 恢复 形态 素 原 形 的 基础 上 , 利用 LSTM-CRF 模型 完成 朝鲜 语 分写 及 词性 标注 。	实验 结果 表明 , 该文 提出 的 方法 词性 标注 F1 值 为 94.75% , 优 于 其他 方法 。	1<2	evaluation	evaluation
nlpabs17_Chi	100-110	111-115	该文 提出 的 方法 词性 标注 F1 值 为 94.75% ,	优 于 其他 方法 。	96-115	96-115	实验 结果 表明 , 该文 提出 的 方法 词性 标注 F1 值 为 94.75% , 优 于 其他 方法 。	实验 结果 表明 , 该文 提出 的 方法 词性 标注 F1 值 为 94.75% , 优 于 其他 方法 。	1<2	elab-addition	elab-addition
nlpabs26_Chi	1-36	37-57	交互 式 机器 翻译 ( Interactive Machine Translation , IMT ) 是 一 种 通过 机器 翻译 系统 与 译员 之间 的 相互 作用 指导 计算 机 解码 并 改善 输出 译文 质量 的 技术 。	目前 主流 的 IMT 方法 使用 译员 确定 的 前缀 作 为 唯一 约束 指导 解码 , 交互 方式 受限 ,	1-36	37-61	交互 式 机器 翻译 ( Interactive Machine Translation , IMT ) 是 一 种 通过 机器 翻译 系统 与 译员 之间 的 相互 作用 指导 计算 机 解码 并 改善 输出 译文 质量 的 技术 。	目前 主流 的 IMT 方法 使用 译员 确定 的 前缀 作 为 唯一 约束 指导 解码 , 交互 方式 受限 , 交互 效率 低 。	1>2	bg-general	bg-general
nlpabs26_Chi	37-57	62-77	目前 主流 的 IMT 方法 使用 译员 确定 的 前缀 作 为 唯一 约束 指导 解码 , 交互 方式 受限 ,	该文 从 交互 方式 和 解码 算法 两 个 方面 对 IMT 方法 进行 改进 。	37-61	62-77	目前 主流 的 IMT 方法 使用 译员 确定 的 前缀 作 为 唯一 约束 指导 解码 , 交互 方式 受限 , 交互 效率 低 。	该文 从 交互 方式 和 解码 算法 两 个 方面 对 IMT 方法 进行 改进 。	1>2	bg-goal	bg-goal
nlpabs26_Chi	37-57	58-61	目前 主流 的 IMT 方法 使用 译员 确定 的 前缀 作 为 唯一 约束 指导 解码 , 交互 方式 受限 ,	交互 效率 低 。	37-61	37-61	目前 主流 的 IMT 方法 使用 译员 确定 的 前缀 作 为 唯一 约束 指导 解码 , 交互 方式 受限 , 交互 效率 低 。	目前 主流 的 IMT 方法 使用 译员 确定 的 前缀 作 为 唯一 约束 指导 解码 , 交互 方式 受限 , 交互 效率 低 。	1<2	joint	joint
nlpabs26_Chi	62-77	78-99	该文 从 交互 方式 和 解码 算法 两 个 方面 对 IMT 方法 进行 改进 。	在 交互 方式 方面 , 允许 译员 译前 从 短语 译项 列表 中 为 源 语 言 短语 选择 正确 译项 。	62-77	78-99	该文 从 交互 方式 和 解码 算法 两 个 方面 对 IMT 方法 进行 改进 。	在 交互 方式 方面 , 允许 译员 译前 从 短语 译项 列表 中 为 源 语 言 短语 选择 正确 译项 。	1<2	elab-aspect	elab-aspect
nlpabs26_Chi	78-99	100-114	在 交互 方式 方面 , 允许 译员 译前 从 短语 译项 列表 中 为 源 语 言 短语 选择 正确 译项 。	该文 还 提出 了 基 于 短 语 表 的 多样 性 排序 算法 ,	78-99	100-144	在 交互 方式 方面 , 允许 译员 译前 从 短语 译项 列表 中 为 源 语 言 短语 选择 正确 译项 。	该文 还 提出 了 基 于 短 语 表 的 多样 性 排序 算法 , 来 提高 短 语候 选译项 的 多样 性 , 并 根据 译员 的 翻译 认知 过程 设计 交互界 面 , 改善 译员 在 翻译 过程 中 的 用户 体验 。	1<2	elab-addition	elab-addition
nlpabs26_Chi	100-114	115-123	该文 还 提出 了 基 于 短 语 表 的 多样 性 排序 算法 ,	来 提高 短 语候 选译项 的 多样 性 ,	100-144	100-144	该文 还 提出 了 基 于 短 语 表 的 多样 性 排序 算法 , 来 提高 短 语候 选译项 的 多样 性 , 并 根据 译员 的 翻译 认知 过程 设计 交互界 面 , 改善 译员 在 翻译 过程 中 的 用户 体验 。	该文 还 提出 了 基 于 短 语 表 的 多样 性 排序 算法 , 来 提高 短 语候 选译项 的 多样 性 , 并 根据 译员 的 翻译 认知 过程 设计 交互界 面 , 改善 译员 在 翻译 过程 中 的 用户 体验 。	1<2	enablement	enablement
nlpabs26_Chi	115-123	124-134	来 提高 短 语候 选译项 的 多样 性 ,	并 根据 译员 的 翻译 认知 过程 设计 交互界 面 ,	100-144	100-144	该文 还 提出 了 基 于 短 语 表 的 多样 性 排序 算法 , 来 提高 短 语候 选译项 的 多样 性 , 并 根据 译员 的 翻译 认知 过程 设计 交互界 面 , 改善 译员 在 翻译 过程 中 的 用户 体验 。	该文 还 提出 了 基 于 短 语 表 的 多样 性 排序 算法 , 来 提高 短 语候 选译项 的 多样 性 , 并 根据 译员 的 翻译 认知 过程 设计 交互界 面 , 改善 译员 在 翻译 过程 中 的 用户 体验 。	1<2	joint	joint
nlpabs26_Chi	124-134	135-144	并 根据 译员 的 翻译 认知 过程 设计 交互界 面 ,	改善 译员 在 翻译 过程 中 的 用户 体验 。	100-144	100-144	该文 还 提出 了 基 于 短 语 表 的 多样 性 排序 算法 , 来 提高 短 语候 选译项 的 多样 性 , 并 根据 译员 的 翻译 认知 过程 设计 交互界 面 , 改善 译员 在 翻译 过程 中 的 用户 体验 。	该文 还 提出 了 基 于 短 语 表 的 多样 性 排序 算法 , 来 提高 短 语候 选译项 的 多样 性 , 并 根据 译员 的 翻译 认知 过程 设计 交互界 面 , 改善 译员 在 翻译 过程 中 的 用户 体验 。	1<2	elab-addition	elab-addition
nlpabs26_Chi	62-77	145-165	该文 从 交互 方式 和 解码 算法 两 个 方面 对 IMT 方法 进行 改进 。	在 解码 算法 方面 , 将 双 语 短语 与 前缀 一同 作 为 约束 参 与 指导 解码 过程 ,	62-77	145-175	该文 从 交互 方式 和 解码 算法 两 个 方面 对 IMT 方法 进行 改进 。	在 解码 算法 方面 , 将 双 语 短语 与 前缀 一同 作 为 约束 参 与 指导 解码 过程 , 提高 翻译 假设 评价 和 过滤 的 准确 性 。	1<2	elab-aspect	elab-aspect
nlpabs26_Chi	145-165	166-175	在 解码 算法 方面 , 将 双 语 短语 与 前缀 一同 作 为 约束 参 与 指导 解码 过程 ,	提高 翻译 假设 评价 和 过滤 的 准确 性 。	145-175	145-175	在 解码 算法 方面 , 将 双 语 短语 与 前缀 一同 作 为 约束 参 与 指导 解码 过程 , 提高 翻译 假设 评价 和 过滤 的 准确 性 。	在 解码 算法 方面 , 将 双 语 短语 与 前缀 一同 作 为 约束 参 与 指导 解码 过程 , 提高 翻译 假设 评价 和 过滤 的 准确 性 。	1<2	elab-addition	elab-addition
nlpabs26_Chi	62-77	176-187	该文 从 交互 方式 和 解码 算法 两 个 方面 对 IMT 方法 进行 改进 。	在 LDC 汉 英 平行 语料 上 进行 了 人工 评测 ,	62-77	176-212	该文 从 交互 方式 和 解码 算法 两 个 方面 对 IMT 方法 进行 改进 。	在 LDC 汉 英 平行 语料 上 进行 了 人工 评测 , 实验 结果 表明 该 方法 较 传统 的 IMT 方法 能够 减轻 译员 的 认知 负担 , 减少 翻译 时间 , 提升 翻译 效率 。	1<2	evaluation	evaluation
nlpabs26_Chi	188-190	191-204	实验 结果 表明	该 方法 较 传统 的 IMT 方法 能够 减轻 译员 的 认知 负担 ,	176-212	176-212	在 LDC 汉 英 平行 语料 上 进行 了 人工 评测 , 实验 结果 表明 该 方法 较 传统 的 IMT 方法 能够 减轻 译员 的 认知 负担 , 减少 翻译 时间 , 提升 翻译 效率 。	在 LDC 汉 英 平行 语料 上 进行 了 人工 评测 , 实验 结果 表明 该 方法 较 传统 的 IMT 方法 能够 减轻 译员 的 认知 负担 , 减少 翻译 时间 , 提升 翻译 效率 。	1>2	attribution	attribution
nlpabs26_Chi	176-187	191-204	在 LDC 汉 英 平行 语料 上 进行 了 人工 评测 ,	该 方法 较 传统 的 IMT 方法 能够 减轻 译员 的 认知 负担 ,	176-212	176-212	在 LDC 汉 英 平行 语料 上 进行 了 人工 评测 , 实验 结果 表明 该 方法 较 传统 的 IMT 方法 能够 减轻 译员 的 认知 负担 , 减少 翻译 时间 , 提升 翻译 效率 。	在 LDC 汉 英 平行 语料 上 进行 了 人工 评测 , 实验 结果 表明 该 方法 较 传统 的 IMT 方法 能够 减轻 译员 的 认知 负担 , 减少 翻译 时间 , 提升 翻译 效率 。	1<2	elab-addition	elab-addition
nlpabs26_Chi	191-204	205-208	该 方法 较 传统 的 IMT 方法 能够 减轻 译员 的 认知 负担 ,	减少 翻译 时间 ,	176-212	176-212	在 LDC 汉 英 平行 语料 上 进行 了 人工 评测 , 实验 结果 表明 该 方法 较 传统 的 IMT 方法 能够 减轻 译员 的 认知 负担 , 减少 翻译 时间 , 提升 翻译 效率 。	在 LDC 汉 英 平行 语料 上 进行 了 人工 评测 , 实验 结果 表明 该 方法 较 传统 的 IMT 方法 能够 减轻 译员 的 认知 负担 , 减少 翻译 时间 , 提升 翻译 效率 。	1<2	joint	joint
nlpabs26_Chi	191-204	209-212	该 方法 较 传统 的 IMT 方法 能够 减轻 译员 的 认知 负担 ,	提升 翻译 效率 。	176-212	176-212	在 LDC 汉 英 平行 语料 上 进行 了 人工 评测 , 实验 结果 表明 该 方法 较 传统 的 IMT 方法 能够 减轻 译员 的 认知 负担 , 减少 翻译 时间 , 提升 翻译 效率 。	在 LDC 汉 英 平行 语料 上 进行 了 人工 评测 , 实验 结果 表明 该 方法 较 传统 的 IMT 方法 能够 减轻 译员 的 认知 负担 , 减少 翻译 时间 , 提升 翻译 效率 。	1<2	joint	joint
nlpabs29_Chi	1-9	10-29	为 了提 高蒙 古 语 语音 识别 性能 ,	该文 首先 将 时延 神经 网络 融合 前 馈型 序列 记忆 网络 应用 于 蒙古 语语音 识别 任务 中 ,	1-88	1-88	为 了提 高蒙 古 语 语音 识别 性能 , 该文 首先 将 时延 神经 网络 融合 前 馈型 序列 记忆 网络 应用 于 蒙古 语语音 识别 任务 中 , 通过 对长 序列语 音帧 建模 来 充分 挖掘 上 下文 相关 信息 ; 此外 研究 了 前 馈型 序列 记忆 网络 “ 记忆 ” 模块 中 历史 信息 和 未来 信息 长度 对 模型 的 影响 ; 最后 分析 了 融合 的 网络 结构 中 隐藏 层 个数 及 隐藏 层节 点数 对 声学 模型 性能 的 影响 。	为 了提 高蒙 古 语 语音 识别 性能 , 该文 首先 将 时延 神经 网络 融合 前 馈型 序列 记忆 网络 应用 于 蒙古 语语音 识别 任务 中 , 通过 对长 序列语 音帧 建模 来 充分 挖掘 上 下文 相关 信息 ; 此外 研究 了 前 馈型 序列 记忆 网络 “ 记忆 ” 模块 中 历史 信息 和 未来 信息 长度 对 模型 的 影响 ; 最后 分析 了 融合 的 网络 结构 中 隐藏 层 个数 及 隐藏 层节 点数 对 声学 模型 性能 的 影响 。	1>2	bg-goal	bg-goal
nlpabs29_Chi	10-29	30-34	该文 首先 将 时延 神经 网络 融合 前 馈型 序列 记忆 网络 应用 于 蒙古 语语音 识别 任务 中 ,	通过 对长 序列语 音帧 建模	1-88	1-88	为 了提 高蒙 古 语 语音 识别 性能 , 该文 首先 将 时延 神经 网络 融合 前 馈型 序列 记忆 网络 应用 于 蒙古 语语音 识别 任务 中 , 通过 对长 序列语 音帧 建模 来 充分 挖掘 上 下文 相关 信息 ; 此外 研究 了 前 馈型 序列 记忆 网络 “ 记忆 ” 模块 中 历史 信息 和 未来 信息 长度 对 模型 的 影响 ; 最后 分析 了 融合 的 网络 结构 中 隐藏 层 个数 及 隐藏 层节 点数 对 声学 模型 性能 的 影响 。	为 了提 高蒙 古 语 语音 识别 性能 , 该文 首先 将 时延 神经 网络 融合 前 馈型 序列 记忆 网络 应用 于 蒙古 语语音 识别 任务 中 , 通过 对长 序列语 音帧 建模 来 充分 挖掘 上 下文 相关 信息 ; 此外 研究 了 前 馈型 序列 记忆 网络 “ 记忆 ” 模块 中 历史 信息 和 未来 信息 长度 对 模型 的 影响 ; 最后 分析 了 融合 的 网络 结构 中 隐藏 层 个数 及 隐藏 层节 点数 对 声学 模型 性能 的 影响 。	1<2	elab-addition	elab-addition
nlpabs29_Chi	30-34	35-42	通过 对长 序列语 音帧 建模	来 充分 挖掘 上 下文 相关 信息 ;	1-88	1-88	为 了提 高蒙 古 语 语音 识别 性能 , 该文 首先 将 时延 神经 网络 融合 前 馈型 序列 记忆 网络 应用 于 蒙古 语语音 识别 任务 中 , 通过 对长 序列语 音帧 建模 来 充分 挖掘 上 下文 相关 信息 ; 此外 研究 了 前 馈型 序列 记忆 网络 “ 记忆 ” 模块 中 历史 信息 和 未来 信息 长度 对 模型 的 影响 ; 最后 分析 了 融合 的 网络 结构 中 隐藏 层 个数 及 隐藏 层节 点数 对 声学 模型 性能 的 影响 。	为 了提 高蒙 古 语 语音 识别 性能 , 该文 首先 将 时延 神经 网络 融合 前 馈型 序列 记忆 网络 应用 于 蒙古 语语音 识别 任务 中 , 通过 对长 序列语 音帧 建模 来 充分 挖掘 上 下文 相关 信息 ; 此外 研究 了 前 馈型 序列 记忆 网络 “ 记忆 ” 模块 中 历史 信息 和 未来 信息 长度 对 模型 的 影响 ; 最后 分析 了 融合 的 网络 结构 中 隐藏 层 个数 及 隐藏 层节 点数 对 声学 模型 性能 的 影响 。	1<2	enablement	enablement
nlpabs29_Chi	10-29	43-66	该文 首先 将 时延 神经 网络 融合 前 馈型 序列 记忆 网络 应用 于 蒙古 语语音 识别 任务 中 ,	此外 研究 了 前 馈型 序列 记忆 网络 “ 记忆 ” 模块 中 历史 信息 和 未来 信息 长度 对 模型 的 影响 ;	1-88	1-88	为 了提 高蒙 古 语 语音 识别 性能 , 该文 首先 将 时延 神经 网络 融合 前 馈型 序列 记忆 网络 应用 于 蒙古 语语音 识别 任务 中 , 通过 对长 序列语 音帧 建模 来 充分 挖掘 上 下文 相关 信息 ; 此外 研究 了 前 馈型 序列 记忆 网络 “ 记忆 ” 模块 中 历史 信息 和 未来 信息 长度 对 模型 的 影响 ; 最后 分析 了 融合 的 网络 结构 中 隐藏 层 个数 及 隐藏 层节 点数 对 声学 模型 性能 的 影响 。	为 了提 高蒙 古 语 语音 识别 性能 , 该文 首先 将 时延 神经 网络 融合 前 馈型 序列 记忆 网络 应用 于 蒙古 语语音 识别 任务 中 , 通过 对长 序列语 音帧 建模 来 充分 挖掘 上 下文 相关 信息 ; 此外 研究 了 前 馈型 序列 记忆 网络 “ 记忆 ” 模块 中 历史 信息 和 未来 信息 长度 对 模型 的 影响 ; 最后 分析 了 融合 的 网络 结构 中 隐藏 层 个数 及 隐藏 层节 点数 对 声学 模型 性能 的 影响 。	1<2	joint	joint
nlpabs29_Chi	10-29	67-88	该文 首先 将 时延 神经 网络 融合 前 馈型 序列 记忆 网络 应用 于 蒙古 语语音 识别 任务 中 ,	最后 分析 了 融合 的 网络 结构 中 隐藏 层 个数 及 隐藏 层节 点数 对 声学 模型 性能 的 影响 。	1-88	1-88	为 了提 高蒙 古 语 语音 识别 性能 , 该文 首先 将 时延 神经 网络 融合 前 馈型 序列 记忆 网络 应用 于 蒙古 语语音 识别 任务 中 , 通过 对长 序列语 音帧 建模 来 充分 挖掘 上 下文 相关 信息 ; 此外 研究 了 前 馈型 序列 记忆 网络 “ 记忆 ” 模块 中 历史 信息 和 未来 信息 长度 对 模型 的 影响 ; 最后 分析 了 融合 的 网络 结构 中 隐藏 层 个数 及 隐藏 层节 点数 对 声学 模型 性能 的 影响 。	为 了提 高蒙 古 语 语音 识别 性能 , 该文 首先 将 时延 神经 网络 融合 前 馈型 序列 记忆 网络 应用 于 蒙古 语语音 识别 任务 中 , 通过 对长 序列语 音帧 建模 来 充分 挖掘 上 下文 相关 信息 ; 此外 研究 了 前 馈型 序列 记忆 网络 “ 记忆 ” 模块 中 历史 信息 和 未来 信息 长度 对 模型 的 影响 ; 最后 分析 了 融合 的 网络 结构 中 隐藏 层 个数 及 隐藏 层节 点数 对 声学 模型 性能 的 影响 。	1<2	joint	joint
nlpabs29_Chi	89-92	93-120	实验 结果 表明 ,	时延 神经 网络 融合 前馈 型 序列 记忆 网络 相比 深度 神经 网络 、 时延 神经 网络 和 前馈 型 序列 记忆 网络 具有 更好 的 性能 ,	89-133	89-133	实验 结果 表明 , 时延 神经 网络 融合 前馈 型 序列 记忆 网络 相比 深度 神经 网络 、 时延 神经 网络 和 前馈 型 序列 记忆 网络 具有 更好 的 性能 , 单词 错误 率 与 基线 深度 神经 网络 模型 相比 降低 22.2% 。	实验 结果 表明 , 时延 神经 网络 融合 前馈 型 序列 记忆 网络 相比 深度 神经 网络 、 时延 神经 网络 和 前馈 型 序列 记忆 网络 具有 更好 的 性能 , 单词 错误 率 与 基线 深度 神经 网络 模型 相比 降低 22.2% 。	1>2	attribution	attribution
nlpabs29_Chi	10-29	93-120	该文 首先 将 时延 神经 网络 融合 前 馈型 序列 记忆 网络 应用 于 蒙古 语语音 识别 任务 中 ,	时延 神经 网络 融合 前馈 型 序列 记忆 网络 相比 深度 神经 网络 、 时延 神经 网络 和 前馈 型 序列 记忆 网络 具有 更好 的 性能 ,	1-88	89-133	为 了提 高蒙 古 语 语音 识别 性能 , 该文 首先 将 时延 神经 网络 融合 前 馈型 序列 记忆 网络 应用 于 蒙古 语语音 识别 任务 中 , 通过 对长 序列语 音帧 建模 来 充分 挖掘 上 下文 相关 信息 ; 此外 研究 了 前 馈型 序列 记忆 网络 “ 记忆 ” 模块 中 历史 信息 和 未来 信息 长度 对 模型 的 影响 ; 最后 分析 了 融合 的 网络 结构 中 隐藏 层 个数 及 隐藏 层节 点数 对 声学 模型 性能 的 影响 。	实验 结果 表明 , 时延 神经 网络 融合 前馈 型 序列 记忆 网络 相比 深度 神经 网络 、 时延 神经 网络 和 前馈 型 序列 记忆 网络 具有 更好 的 性能 , 单词 错误 率 与 基线 深度 神经 网络 模型 相比 降低 22.2% 。	1<2	evaluation	evaluation
nlpabs29_Chi	93-120	121-133	时延 神经 网络 融合 前馈 型 序列 记忆 网络 相比 深度 神经 网络 、 时延 神经 网络 和 前馈 型 序列 记忆 网络 具有 更好 的 性能 ,	单词 错误 率 与 基线 深度 神经 网络 模型 相比 降低 22.2% 。	89-133	89-133	实验 结果 表明 , 时延 神经 网络 融合 前馈 型 序列 记忆 网络 相比 深度 神经 网络 、 时延 神经 网络 和 前馈 型 序列 记忆 网络 具有 更好 的 性能 , 单词 错误 率 与 基线 深度 神经 网络 模型 相比 降低 22.2% 。	实验 结果 表明 , 时延 神经 网络 融合 前馈 型 序列 记忆 网络 相比 深度 神经 网络 、 时延 神经 网络 和 前馈 型 序列 记忆 网络 具有 更好 的 性能 , 单词 错误 率 与 基线 深度 神经 网络 模型 相比 降低 22.2% 。	1<2	exp-evidence	exp-evidence
nlpabs38_Chi	1-12	59-74	推荐 系统 的 冷 启动 问题 是 近期 的 研究 热点 ,	该 文面 向 微博 网络 , 提出 了 系统 的 用户 活跃 性 判定 方法 ,	1-25	59-80	推荐 系统 的 冷 启动 问题 是 近期 的 研究 热点 , 而 用户 的 活跃 性 判定 是 冷 启动 问题 的 基础 。	该 文面 向 微博 网络 , 提出 了 系统 的 用户 活跃 性 判定 方法 , 创新 性 主要 体现 在 :	1>2	bg-goal	bg-goal
nlpabs38_Chi	1-12	13-25	推荐 系统 的 冷 启动 问题 是 近期 的 研究 热点 ,	而 用户 的 活跃 性 判定 是 冷 启动 问题 的 基础 。	1-25	1-25	推荐 系统 的 冷 启动 问题 是 近期 的 研究 热点 , 而 用户 的 活跃 性 判定 是 冷 启动 问题 的 基础 。	推荐 系统 的 冷 启动 问题 是 近期 的 研究 热点 , 而 用户 的 活跃 性 判定 是 冷 启动 问题 的 基础 。	1<2	elab-addition	elab-addition
nlpabs38_Chi	26-36	37-45	已 有 方法 在 判定 用户 的 活跃 性 时 ,	单纯 地 考虑 了 用户 发表 信息 量 ,	26-58	26-58	已 有 方法 在 判定 用户 的 活跃 性 时 , 单纯 地 考虑 了 用户 发表 信息 量 , 对 社交 媒体 的 社交 关系 及 行为 等 特征 利用 不够 。	已 有 方法 在 判定 用户 的 活跃 性 时 , 单纯 地 考虑 了 用户 发表 信息 量 , 对 社交 媒体 的 社交 关系 及 行为 等 特征 利用 不够 。	1>2	temporal	temporal
nlpabs38_Chi	13-25	37-45	而 用户 的 活跃 性 判定 是 冷 启动 问题 的 基础 。	单纯 地 考虑 了 用户 发表 信息 量 ,	1-25	26-58	推荐 系统 的 冷 启动 问题 是 近期 的 研究 热点 , 而 用户 的 活跃 性 判定 是 冷 启动 问题 的 基础 。	已 有 方法 在 判定 用户 的 活跃 性 时 , 单纯 地 考虑 了 用户 发表 信息 量 , 对 社交 媒体 的 社交 关系 及 行为 等 特征 利用 不够 。	1<2	elab-addition	elab-addition
nlpabs38_Chi	37-45	46-58	单纯 地 考虑 了 用户 发表 信息 量 ,	对 社交 媒体 的 社交 关系 及 行为 等 特征 利用 不够 。	26-58	26-58	已 有 方法 在 判定 用户 的 活跃 性 时 , 单纯 地 考虑 了 用户 发表 信息 量 , 对 社交 媒体 的 社交 关系 及 行为 等 特征 利用 不够 。	已 有 方法 在 判定 用户 的 活跃 性 时 , 单纯 地 考虑 了 用户 发表 信息 量 , 对 社交 媒体 的 社交 关系 及 行为 等 特征 利用 不够 。	1<2	elab-addition	elab-addition
nlpabs38_Chi	59-74	75-80	该 文面 向 微博 网络 , 提出 了 系统 的 用户 活跃 性 判定 方法 ,	创新 性 主要 体现 在 :	59-80	59-80	该 文面 向 微博 网络 , 提出 了 系统 的 用户 活跃 性 判定 方法 , 创新 性 主要 体现 在 :	该 文面 向 微博 网络 , 提出 了 系统 的 用户 活跃 性 判定 方法 , 创新 性 主要 体现 在 :	1<2	elab-addition	elab-addition
nlpabs38_Chi	75-80	81-96	创新 性 主要 体现 在 :	( 1 ) 提出 了 微博 网络 影响 用户 活跃 性 的 四 类 指标 ,	59-80	81-156	该 文面 向 微博 网络 , 提出 了 系统 的 用户 活跃 性 判定 方法 , 创新 性 主要 体现 在 :	( 1 ) 提出 了 微博 网络 影响 用户 活跃 性 的 四 类 指标 , 包括 用户 背景 、 社交 关系 、 发表 内容 质量 及 社交 行为 , 避免 了 仅仅 使 用 用户 发表 信息 数量 判定 用户 是否 活跃 的 粗糙 方式 ; ( 2 ) 提出 了 用户 活跃 性 判定 流程 , 提出 了 基 于 四 类 指标 的 用户 与 用户 集 的 差异 度 计算 模型 。	1<2	elab-enumember	elab-enumember
nlpabs38_Chi	81-96	97-110	( 1 ) 提出 了 微博 网络 影响 用户 活跃 性 的 四 类 指标 ,	包括 用户 背景 、 社交 关系 、 发表 内容 质量 及 社交 行为 ,	81-156	81-156	( 1 ) 提出 了 微博 网络 影响 用户 活跃 性 的 四 类 指标 , 包括 用户 背景 、 社交 关系 、 发表 内容 质量 及 社交 行为 , 避免 了 仅仅 使 用 用户 发表 信息 数量 判定 用户 是否 活跃 的 粗糙 方式 ; ( 2 ) 提出 了 用户 活跃 性 判定 流程 , 提出 了 基 于 四 类 指标 的 用户 与 用户 集 的 差异 度 计算 模型 。	( 1 ) 提出 了 微博 网络 影响 用户 活跃 性 的 四 类 指标 , 包括 用户 背景 、 社交 关系 、 发表 内容 质量 及 社交 行为 , 避免 了 仅仅 使 用 用户 发表 信息 数量 判定 用户 是否 活跃 的 粗糙 方式 ; ( 2 ) 提出 了 用户 活跃 性 判定 流程 , 提出 了 基 于 四 类 指标 的 用户 与 用户 集 的 差异 度 计算 模型 。	1<2	elab-enumember	elab-enumember
nlpabs38_Chi	97-110	111-127	包括 用户 背景 、 社交 关系 、 发表 内容 质量 及 社交 行为 ,	避免 了 仅仅 使 用 用户 发表 信息 数量 判定 用户 是否 活跃 的 粗糙 方式 ;	81-156	81-156	( 1 ) 提出 了 微博 网络 影响 用户 活跃 性 的 四 类 指标 , 包括 用户 背景 、 社交 关系 、 发表 内容 质量 及 社交 行为 , 避免 了 仅仅 使 用 用户 发表 信息 数量 判定 用户 是否 活跃 的 粗糙 方式 ; ( 2 ) 提出 了 用户 活跃 性 判定 流程 , 提出 了 基 于 四 类 指标 的 用户 与 用户 集 的 差异 度 计算 模型 。	( 1 ) 提出 了 微博 网络 影响 用户 活跃 性 的 四 类 指标 , 包括 用户 背景 、 社交 关系 、 发表 内容 质量 及 社交 行为 , 避免 了 仅仅 使 用 用户 发表 信息 数量 判定 用户 是否 活跃 的 粗糙 方式 ; ( 2 ) 提出 了 用户 活跃 性 判定 流程 , 提出 了 基 于 四 类 指标 的 用户 与 用户 集 的 差异 度 计算 模型 。	1<2	enablement	enablement
nlpabs38_Chi	81-96	128-138	( 1 ) 提出 了 微博 网络 影响 用户 活跃 性 的 四 类 指标 ,	( 2 ) 提出 了 用户 活跃 性 判定 流程 ,	81-156	81-156	( 1 ) 提出 了 微博 网络 影响 用户 活跃 性 的 四 类 指标 , 包括 用户 背景 、 社交 关系 、 发表 内容 质量 及 社交 行为 , 避免 了 仅仅 使 用 用户 发表 信息 数量 判定 用户 是否 活跃 的 粗糙 方式 ; ( 2 ) 提出 了 用户 活跃 性 判定 流程 , 提出 了 基 于 四 类 指标 的 用户 与 用户 集 的 差异 度 计算 模型 。	( 1 ) 提出 了 微博 网络 影响 用户 活跃 性 的 四 类 指标 , 包括 用户 背景 、 社交 关系 、 发表 内容 质量 及 社交 行为 , 避免 了 仅仅 使 用 用户 发表 信息 数量 判定 用户 是否 活跃 的 粗糙 方式 ; ( 2 ) 提出 了 用户 活跃 性 判定 流程 , 提出 了 基 于 四 类 指标 的 用户 与 用户 集 的 差异 度 计算 模型 。	1<2	joint	joint
nlpabs38_Chi	128-138	139-156	( 2 ) 提出 了 用户 活跃 性 判定 流程 ,	提出 了 基 于 四 类 指标 的 用户 与 用户 集 的 差异 度 计算 模型 。	81-156	81-156	( 1 ) 提出 了 微博 网络 影响 用户 活跃 性 的 四 类 指标 , 包括 用户 背景 、 社交 关系 、 发表 内容 质量 及 社交 行为 , 避免 了 仅仅 使 用 用户 发表 信息 数量 判定 用户 是否 活跃 的 粗糙 方式 ; ( 2 ) 提出 了 用户 活跃 性 判定 流程 , 提出 了 基 于 四 类 指标 的 用户 与 用户 集 的 差异 度 计算 模型 。	( 1 ) 提出 了 微博 网络 影响 用户 活跃 性 的 四 类 指标 , 包括 用户 背景 、 社交 关系 、 发表 内容 质量 及 社交 行为 , 避免 了 仅仅 使 用 用户 发表 信息 数量 判定 用户 是否 活跃 的 粗糙 方式 ; ( 2 ) 提出 了 用户 活跃 性 判定 流程 , 提出 了 基 于 四 类 指标 的 用户 与 用户 集 的 差异 度 计算 模型 。	1<2	elab-addition	elab-addition
nlpabs38_Chi	59-74	157-162	该 文面 向 微博 网络 , 提出 了 系统 的 用户 活跃 性 判定 方法 ,	以 新浪 微博 为 例 ,	59-80	157-209	该 文面 向 微博 网络 , 提出 了 系统 的 用户 活跃 性 判定 方法 , 创新 性 主要 体现 在 :	以 新浪 微博 为 例 , 选取 了 学术 研究 、 企业 管理 、 教育 、 文化 、 军事 五 个 领域 的 900 个 用户 作 为 测试 集 , 使用 准确 率 P 、 召回 率 R 及 F 值 为 评价 指标 , 进行 了 实验 分析 和 比较 。	1<2	evaluation	evaluation
nlpabs38_Chi	157-162	163-187	以 新浪 微博 为 例 ,	选取 了 学术 研究 、 企业 管理 、 教育 、 文化 、 军事 五 个 领域 的 900 个 用户 作 为 测试 集 ,	157-209	157-209	以 新浪 微博 为 例 , 选取 了 学术 研究 、 企业 管理 、 教育 、 文化 、 军事 五 个 领域 的 900 个 用户 作 为 测试 集 , 使用 准确 率 P 、 召回 率 R 及 F 值 为 评价 指标 , 进行 了 实验 分析 和 比较 。	以 新浪 微博 为 例 , 选取 了 学术 研究 、 企业 管理 、 教育 、 文化 、 军事 五 个 领域 的 900 个 用户 作 为 测试 集 , 使用 准确 率 P 、 召回 率 R 及 F 值 为 评价 指标 , 进行 了 实验 分析 和 比较 。	1<2	elab-addition	elab-addition
nlpabs38_Chi	163-187	188-202	选取 了 学术 研究 、 企业 管理 、 教育 、 文化 、 军事 五 个 领域 的 900 个 用户 作 为 测试 集 ,	使用 准确 率 P 、 召回 率 R 及 F 值 为 评价 指标 ,	157-209	157-209	以 新浪 微博 为 例 , 选取 了 学术 研究 、 企业 管理 、 教育 、 文化 、 军事 五 个 领域 的 900 个 用户 作 为 测试 集 , 使用 准确 率 P 、 召回 率 R 及 F 值 为 评价 指标 , 进行 了 实验 分析 和 比较 。	以 新浪 微博 为 例 , 选取 了 学术 研究 、 企业 管理 、 教育 、 文化 、 军事 五 个 领域 的 900 个 用户 作 为 测试 集 , 使用 准确 率 P 、 召回 率 R 及 F 值 为 评价 指标 , 进行 了 实验 分析 和 比较 。	1<2	elab-addition	elab-addition
nlpabs38_Chi	188-202	203-209	使用 准确 率 P 、 召回 率 R 及 F 值 为 评价 指标 ,	进行 了 实验 分析 和 比较 。	157-209	157-209	以 新浪 微博 为 例 , 选取 了 学术 研究 、 企业 管理 、 教育 、 文化 、 军事 五 个 领域 的 900 个 用户 作 为 测试 集 , 使用 准确 率 P 、 召回 率 R 及 F 值 为 评价 指标 , 进行 了 实验 分析 和 比较 。	以 新浪 微博 为 例 , 选取 了 学术 研究 、 企业 管理 、 教育 、 文化 、 军事 五 个 领域 的 900 个 用户 作 为 测试 集 , 使用 准确 率 P 、 召回 率 R 及 F 值 为 评价 指标 , 进行 了 实验 分析 和 比较 。	1<2	elab-addition	elab-addition
nlpabs38_Chi	210-212	213-245	结果 显示 ,	该文 所 提用 户 活跃 性 判定 方法 的 准确 率 P 、 召回 率 R 、 F 值 比 传统 的 判定 方法 分别 提高 了 21% 、 13% 和 16% ,	210-286	210-286	结果 显示 , 该文 所 提用 户 活跃 性 判定 方法 的 准确 率 P 、 召回 率 R 、 F 值 比 传统 的 判定 方法 分别 提高 了 21% 、 13% 和 16% , 将 该 文 所 提 方法 用 于 用户 推荐 , 得到 的 P 、 R 和 F 值 比 最新 的 方法 分别 提高 了 5% 、 2% 和 3% , 验证 了 所 提 方法 的 有效 性 。	结果 显示 , 该文 所 提用 户 活跃 性 判定 方法 的 准确 率 P 、 召回 率 R 、 F 值 比 传统 的 判定 方法 分别 提高 了 21% 、 13% 和 16% , 将 该 文 所 提 方法 用 于 用户 推荐 , 得到 的 P 、 R 和 F 值 比 最新 的 方法 分别 提高 了 5% 、 2% 和 3% , 验证 了 所 提 方法 的 有效 性 。	1>2	attribution	attribution
nlpabs38_Chi	157-162	213-245	以 新浪 微博 为 例 ,	该文 所 提用 户 活跃 性 判定 方法 的 准确 率 P 、 召回 率 R 、 F 值 比 传统 的 判定 方法 分别 提高 了 21% 、 13% 和 16% ,	157-209	210-286	以 新浪 微博 为 例 , 选取 了 学术 研究 、 企业 管理 、 教育 、 文化 、 军事 五 个 领域 的 900 个 用户 作 为 测试 集 , 使用 准确 率 P 、 召回 率 R 及 F 值 为 评价 指标 , 进行 了 实验 分析 和 比较 。	结果 显示 , 该文 所 提用 户 活跃 性 判定 方法 的 准确 率 P 、 召回 率 R 、 F 值 比 传统 的 判定 方法 分别 提高 了 21% 、 13% 和 16% , 将 该 文 所 提 方法 用 于 用户 推荐 , 得到 的 P 、 R 和 F 值 比 最新 的 方法 分别 提高 了 5% 、 2% 和 3% , 验证 了 所 提 方法 的 有效 性 。	1<2	elab-addition	elab-addition
nlpabs38_Chi	213-245	246-256	该文 所 提用 户 活跃 性 判定 方法 的 准确 率 P 、 召回 率 R 、 F 值 比 传统 的 判定 方法 分别 提高 了 21% 、 13% 和 16% ,	将 该 文 所 提 方法 用 于 用户 推荐 ,	210-286	210-286	结果 显示 , 该文 所 提用 户 活跃 性 判定 方法 的 准确 率 P 、 召回 率 R 、 F 值 比 传统 的 判定 方法 分别 提高 了 21% 、 13% 和 16% , 将 该 文 所 提 方法 用 于 用户 推荐 , 得到 的 P 、 R 和 F 值 比 最新 的 方法 分别 提高 了 5% 、 2% 和 3% , 验证 了 所 提 方法 的 有效 性 。	结果 显示 , 该文 所 提用 户 活跃 性 判定 方法 的 准确 率 P 、 召回 率 R 、 F 值 比 传统 的 判定 方法 分别 提高 了 21% 、 13% 和 16% , 将 该 文 所 提 方法 用 于 用户 推荐 , 得到 的 P 、 R 和 F 值 比 最新 的 方法 分别 提高 了 5% 、 2% 和 3% , 验证 了 所 提 方法 的 有效 性 。	1<2	joint	joint
nlpabs38_Chi	246-256	257-277	将 该 文 所 提 方法 用 于 用户 推荐 ,	得到 的 P 、 R 和 F 值 比 最新 的 方法 分别 提高 了 5% 、 2% 和 3% ,	210-286	210-286	结果 显示 , 该文 所 提用 户 活跃 性 判定 方法 的 准确 率 P 、 召回 率 R 、 F 值 比 传统 的 判定 方法 分别 提高 了 21% 、 13% 和 16% , 将 该 文 所 提 方法 用 于 用户 推荐 , 得到 的 P 、 R 和 F 值 比 最新 的 方法 分别 提高 了 5% 、 2% 和 3% , 验证 了 所 提 方法 的 有效 性 。	结果 显示 , 该文 所 提用 户 活跃 性 判定 方法 的 准确 率 P 、 召回 率 R 、 F 值 比 传统 的 判定 方法 分别 提高 了 21% 、 13% 和 16% , 将 该 文 所 提 方法 用 于 用户 推荐 , 得到 的 P 、 R 和 F 值 比 最新 的 方法 分别 提高 了 5% 、 2% 和 3% , 验证 了 所 提 方法 的 有效 性 。	1<2	elab-addition	elab-addition
nlpabs38_Chi	257-277	278-286	得到 的 P 、 R 和 F 值 比 最新 的 方法 分别 提高 了 5% 、 2% 和 3% ,	验证 了 所 提 方法 的 有效 性 。	210-286	210-286	结果 显示 , 该文 所 提用 户 活跃 性 判定 方法 的 准确 率 P 、 召回 率 R 、 F 值 比 传统 的 判定 方法 分别 提高 了 21% 、 13% 和 16% , 将 该 文 所 提 方法 用 于 用户 推荐 , 得到 的 P 、 R 和 F 值 比 最新 的 方法 分别 提高 了 5% 、 2% 和 3% , 验证 了 所 提 方法 的 有效 性 。	结果 显示 , 该文 所 提用 户 活跃 性 判定 方法 的 准确 率 P 、 召回 率 R 、 F 值 比 传统 的 判定 方法 分别 提高 了 21% 、 13% 和 16% , 将 该 文 所 提 方法 用 于 用户 推荐 , 得到 的 P 、 R 和 F 值 比 最新 的 方法 分别 提高 了 5% 、 2% 和 3% , 验证 了 所 提 方法 的 有效 性 。	1<2	elab-addition	elab-addition
nlpabs39_Chi	1-11	12-19	该 文针 对 中 文 网络 评论 情感 分类 任务 ,	提出 了 一 种 集成 学习 框架 。	1-19	1-19	该 文针 对 中 文 网络 评论 情感 分类 任务 , 提出 了 一 种 集成 学习 框架 。	该 文针 对 中 文 网络 评论 情感 分类 任务 , 提出 了 一 种 集成 学习 框架 。	1>2	bg-general	bg-general
nlpabs39_Chi	20-30	31-49	首先 针对 中 文 网络 评论 复杂 多样 的 特点 ,	采用 词性 组合 模式 、 频繁 词 序列 模式 和 保序 子 矩阵 模式 作 为 输入 特征 。	20-49	20-49	首先 针对 中 文 网络 评论 复杂 多样 的 特点 , 采用 词性 组合 模式 、 频繁 词 序列 模式 和 保序 子 矩阵 模式 作 为 输入 特征 。	首先 针对 中 文 网络 评论 复杂 多样 的 特点 , 采用 词性 组合 模式 、 频繁 词 序列 模式 和 保序 子 矩阵 模式 作 为 输入 特征 。	1>2	bg-general	bg-general
nlpabs39_Chi	12-19	31-49	提出 了 一 种 集成 学习 框架 。	采用 词性 组合 模式 、 频繁 词 序列 模式 和 保序 子 矩阵 模式 作 为 输入 特征 。	1-19	20-49	该 文针 对 中 文 网络 评论 情感 分类 任务 , 提出 了 一 种 集成 学习 框架 。	首先 针对 中 文 网络 评论 复杂 多样 的 特点 , 采用 词性 组合 模式 、 频繁 词 序列 模式 和 保序 子 矩阵 模式 作 为 输入 特征 。	1<2	elab-process_step	elab-process_step
nlpabs39_Chi	31-49	50-61	采用 词性 组合 模式 、 频繁 词 序列 模式 和 保序 子 矩阵 模式 作 为 输入 特征 。	然后 采用 基 于 信息 增益 的 随 机 子 空间 算法	20-49	50-76	首先 针对 中 文 网络 评论 复杂 多样 的 特点 , 采用 词性 组合 模式 、 频繁 词 序列 模式 和 保序 子 矩阵 模式 作 为 输入 特征 。	然后 采用 基 于 信息 增益 的 随 机 子 空间 算法 解决 文本 特征 繁多 的 问题 , 同时 提高 基分 类器 的 分类 性能 。	1<2	joint	joint
nlpabs39_Chi	50-61	62-68	然后 采用 基 于 信息 增益 的 随 机 子 空间 算法	解决 文本 特征 繁多 的 问题 ,	50-76	50-76	然后 采用 基 于 信息 增益 的 随 机 子 空间 算法 解决 文本 特征 繁多 的 问题 , 同时 提高 基分 类器 的 分类 性能 。	然后 采用 基 于 信息 增益 的 随 机 子 空间 算法 解决 文本 特征 繁多 的 问题 , 同时 提高 基分 类器 的 分类 性能 。	1<2	enablement	enablement
nlpabs39_Chi	62-68	69-76	解决 文本 特征 繁多 的 问题 ,	同时 提高 基分 类器 的 分类 性能 。	50-76	50-76	然后 采用 基 于 信息 增益 的 随 机 子 空间 算法 解决 文本 特征 繁多 的 问题 , 同时 提高 基分 类器 的 分类 性能 。	然后 采用 基 于 信息 增益 的 随 机 子 空间 算法 解决 文本 特征 繁多 的 问题 , 同时 提高 基分 类器 的 分类 性能 。	1<2	joint	joint
nlpabs39_Chi	50-61	77-85	然后 采用 基 于 信息 增益 的 随 机 子 空间 算法	最后 基 于 产品 属性 构造 基分 类器 算法	50-76	77-104	然后 采用 基 于 信息 增益 的 随 机 子 空间 算法 解决 文本 特征 繁多 的 问题 , 同时 提高 基分 类器 的 分类 性能 。	最后 基 于 产品 属性 构造 基分 类器 算法 综合 评论 文本 中 每个 属性 的 情感 信息 , 进而 判别 评论 的 句子 级 情感 倾向 。	1<2	joint	joint
nlpabs39_Chi	77-85	86-95	最后 基 于 产品 属性 构造 基分 类器 算法	综合 评论 文本 中 每个 属性 的 情感 信息 ,	77-104	77-104	最后 基 于 产品 属性 构造 基分 类器 算法 综合 评论 文本 中 每个 属性 的 情感 信息 , 进而 判别 评论 的 句子 级 情感 倾向 。	最后 基 于 产品 属性 构造 基分 类器 算法 综合 评论 文本 中 每个 属性 的 情感 信息 , 进而 判别 评论 的 句子 级 情感 倾向 。	1<2	enablement	enablement
nlpabs39_Chi	86-95	96-104	综合 评论 文本 中 每个 属性 的 情感 信息 ,	进而 判别 评论 的 句子 级 情感 倾向 。	77-104	77-104	最后 基 于 产品 属性 构造 基分 类器 算法 综合 评论 文本 中 每个 属性 的 情感 信息 , 进而 判别 评论 的 句子 级 情感 倾向 。	最后 基 于 产品 属性 构造 基分 类器 算法 综合 评论 文本 中 每个 属性 的 情感 信息 , 进而 判别 评论 的 句子 级 情感 倾向 。	1<2	elab-addition	elab-addition
nlpabs39_Chi	105-108	109-123	实验 结果 表明 了	该 框架 在 中 文 网络 评论 情感 分类 任务 上 的 有效 性 ,	105-136	105-136	实验 结果 表明 了 该 框架 在 中 文 网络 评论 情感 分类 任务 上 的 有效 性 , 特别 是 在 Logistic Regression 分类 算法 上 准确 率 达到 90.3% 。	实验 结果 表明 了 该 框架 在 中 文 网络 评论 情感 分类 任务 上 的 有效 性 , 特别 是 在 Logistic Regression 分类 算法 上 准确 率 达到 90.3% 。	1>2	attribution	attribution
nlpabs39_Chi	12-19	109-123	提出 了 一 种 集成 学习 框架 。	该 框架 在 中 文 网络 评论 情感 分类 任务 上 的 有效 性 ,	1-19	105-136	该 文针 对 中 文 网络 评论 情感 分类 任务 , 提出 了 一 种 集成 学习 框架 。	实验 结果 表明 了 该 框架 在 中 文 网络 评论 情感 分类 任务 上 的 有效 性 , 特别 是 在 Logistic Regression 分类 算法 上 准确 率 达到 90.3% 。	1<2	evaluation	evaluation
nlpabs39_Chi	109-123	124-136	该 框架 在 中 文 网络 评论 情感 分类 任务 上 的 有效 性 ,	特别 是 在 Logistic Regression 分类 算法 上 准确 率 达到 90.3% 。	105-136	105-136	实验 结果 表明 了 该 框架 在 中 文 网络 评论 情感 分类 任务 上 的 有效 性 , 特别 是 在 Logistic Regression 分类 算法 上 准确 率 达到 90.3% 。	实验 结果 表明 了 该 框架 在 中 文 网络 评论 情感 分类 任务 上 的 有效 性 , 特别 是 在 Logistic Regression 分类 算法 上 准确 率 达到 90.3% 。	1<2	elab-addition	elab-addition
nlpabs3_Chi	1-14	15-28	﻿主题 模型 在 自然 语言 处理 领域 受到 了 越来越 多 的 关注 。	在 该 领域 中 , 主题 可以 看成 是 词项 的 概率 分布 。	1-14	15-28	﻿主题 模型 在 自然 语言 处理 领域 受到 了 越来越 多 的 关注 。	在 该 领域 中 , 主题 可以 看成 是 词项 的 概率 分布 。	1>2	bg-general	bg-general
nlpabs3_Chi	15-28	29-46	在 该 领域 中 , 主题 可以 看成 是 词项 的 概率 分布 。	主题 模型 通过 词项 在 文档 级 的 共现 信息 抽取 出 语义 相关 的 主题 集合 ,	15-28	29-68	在 该 领域 中 , 主题 可以 看成 是 词项 的 概率 分布 。	主题 模型 通过 词项 在 文档 级 的 共现 信息 抽取 出 语义 相关 的 主题 集合 , 并 能够 将 词项 空间 中 的 文档 变换 到 主题 空间 , 得到 文档 在 低维 空间 中 的 表达 。	1<2	elab-addition	elab-addition
nlpabs3_Chi	29-46	47-59	主题 模型 通过 词项 在 文档 级 的 共现 信息 抽取 出 语义 相关 的 主题 集合 ,	并 能够 将 词项 空间 中 的 文档 变换 到 主题 空间 ,	29-68	29-68	主题 模型 通过 词项 在 文档 级 的 共现 信息 抽取 出 语义 相关 的 主题 集合 , 并 能够 将 词项 空间 中 的 文档 变换 到 主题 空间 , 得到 文档 在 低维 空间 中 的 表达 。	主题 模型 通过 词项 在 文档 级 的 共现 信息 抽取 出 语义 相关 的 主题 集合 , 并 能够 将 词项 空间 中 的 文档 变换 到 主题 空间 , 得到 文档 在 低维 空间 中 的 表达 。	1<2	joint	joint
nlpabs3_Chi	47-59	60-68	并 能够 将 词项 空间 中 的 文档 变换 到 主题 空间 ,	得到 文档 在 低维 空间 中 的 表达 。	29-68	29-68	主题 模型 通过 词项 在 文档 级 的 共现 信息 抽取 出 语义 相关 的 主题 集合 , 并 能够 将 词项 空间 中 的 文档 变换 到 主题 空间 , 得到 文档 在 低维 空间 中 的 表达 。	主题 模型 通过 词项 在 文档 级 的 共现 信息 抽取 出 语义 相关 的 主题 集合 , 并 能够 将 词项 空间 中 的 文档 变换 到 主题 空间 , 得到 文档 在 低维 空间 中 的 表达 。	1<2	enablement	enablement
nlpabs3_Chi	69-79	80-103	作者 从 主题 模型 的 起源 隐性 语义 索引 出发 ,	对 概率 隐性 语义 索引 以及 LDA 等 在 主题 模型 发展 中 的 重要 阶段 性 工作 进行 了 介绍 和 分析 ,	69-112	69-112	作者 从 主题 模型 的 起源 隐性 语义 索引 出发 , 对 概率 隐性 语义 索引 以及 LDA 等 在 主题 模型 发展 中 的 重要 阶段 性 工作 进行 了 介绍 和 分析 , 着重 描述 这些 工作 之间 的 关联 性 。	作者 从 主题 模型 的 起源 隐性 语义 索引 出发 , 对 概率 隐性 语义 索引 以及 LDA 等 在 主题 模型 发展 中 的 重要 阶段 性 工作 进行 了 介绍 和 分析 , 着重 描述 这些 工作 之间 的 关联 性 。	1>2	bg-general	bg-general
nlpabs3_Chi	15-28	80-103	在 该 领域 中 , 主题 可以 看成 是 词项 的 概率 分布 。	对 概率 隐性 语义 索引 以及 LDA 等 在 主题 模型 发展 中 的 重要 阶段 性 工作 进行 了 介绍 和 分析 ,	15-28	69-112	在 该 领域 中 , 主题 可以 看成 是 词项 的 概率 分布 。	作者 从 主题 模型 的 起源 隐性 语义 索引 出发 , 对 概率 隐性 语义 索引 以及 LDA 等 在 主题 模型 发展 中 的 重要 阶段 性 工作 进行 了 介绍 和 分析 , 着重 描述 这些 工作 之间 的 关联 性 。	1<2	elab-addition	elab-addition
nlpabs3_Chi	80-103	104-112	对 概率 隐性 语义 索引 以及 LDA 等 在 主题 模型 发展 中 的 重要 阶段 性 工作 进行 了 介绍 和 分析 ,	着重 描述 这些 工作 之间 的 关联 性 。	69-112	69-112	作者 从 主题 模型 的 起源 隐性 语义 索引 出发 , 对 概率 隐性 语义 索引 以及 LDA 等 在 主题 模型 发展 中 的 重要 阶段 性 工作 进行 了 介绍 和 分析 , 着重 描述 这些 工作 之间 的 关联 性 。	作者 从 主题 模型 的 起源 隐性 语义 索引 出发 , 对 概率 隐性 语义 索引 以及 LDA 等 在 主题 模型 发展 中 的 重要 阶段 性 工作 进行 了 介绍 和 分析 , 着重 描述 这些 工作 之间 的 关联 性 。	1<2	elab-addition	elab-addition
nlpabs3_Chi	80-103	113-132	对 概率 隐性 语义 索引 以及 LDA 等 在 主题 模型 发展 中 的 重要 阶段 性 工作 进行 了 介绍 和 分析 ,	LDA 作 为 一 个 概率 生成 模型 , 很 容易 被 扩展 成 其它 形式 的 概率 模型 。	69-112	113-132	作者 从 主题 模型 的 起源 隐性 语义 索引 出发 , 对 概率 隐性 语义 索引 以及 LDA 等 在 主题 模型 发展 中 的 重要 阶段 性 工作 进行 了 介绍 和 分析 , 着重 描述 这些 工作 之间 的 关联 性 。	LDA 作 为 一 个 概率 生成 模型 , 很 容易 被 扩展 成 其它 形式 的 概率 模型 。	1<2	elab-addition	elab-addition
nlpabs3_Chi	113-132	133-146	LDA 作 为 一 个 概率 生成 模型 , 很 容易 被 扩展 成 其它 形式 的 概率 模型 。	作者 对 由 LDA 派生 出 的 各种 模型 作 了 粗略 分类 ,	113-132	133-157	LDA 作 为 一 个 概率 生成 模型 , 很 容易 被 扩展 成 其它 形式 的 概率 模型 。	作者 对 由 LDA 派生 出 的 各种 模型 作 了 粗略 分类 , 并 选择 了 各类 的 代表 性 模型 简单 介绍 。	1<2	elab-addition	elab-addition
nlpabs3_Chi	133-146	147-157	作者 对 由 LDA 派生 出 的 各种 模型 作 了 粗略 分类 ,	并 选择 了 各类 的 代表 性 模型 简单 介绍 。	133-157	133-157	作者 对 由 LDA 派生 出 的 各种 模型 作 了 粗略 分类 , 并 选择 了 各类 的 代表 性 模型 简单 介绍 。	作者 对 由 LDA 派生 出 的 各种 模型 作 了 粗略 分类 , 并 选择 了 各类 的 代表 性 模型 简单 介绍 。	1<2	joint	joint
nlpabs3_Chi	15-28	158-183	在 该 领域 中 , 主题 可以 看成 是 词项 的 概率 分布 。	主题 模型 中 最 重要 的 两 组 参数 分别 是 各 主题 下 的 词项 概率 分布 和 各 文档 的 主题 概率 分布 ，	15-28	158-216	在 该 领域 中 , 主题 可以 看成 是 词项 的 概率 分布 。	主题 模型 中 最 重要 的 两 组 参数 分别 是 各 主题 下 的 词项 概率 分布 和 各 文档 的 主题 概率 分布 ， 作者 对 期望 最大 化算 法 在 主题 模型 参数 估计 中 的 使用 进行 了 分析 , 这 有助 于 更 深刻 理解 主题 模型 发展 中 各项 工作 的 联系 .	1<2	elab-addition	elab-addition
nlpabs3_Chi	158-183	184-201	主题 模型 中 最 重要 的 两 组 参数 分别 是 各 主题 下 的 词项 概率 分布 和 各 文档 的 主题 概率 分布 ，	作者 对 期望 最大 化算 法 在 主题 模型 参数 估计 中 的 使用 进行 了 分析 ,	158-216	158-216	主题 模型 中 最 重要 的 两 组 参数 分别 是 各 主题 下 的 词项 概率 分布 和 各 文档 的 主题 概率 分布 ， 作者 对 期望 最大 化算 法 在 主题 模型 参数 估计 中 的 使用 进行 了 分析 , 这 有助 于 更 深刻 理解 主题 模型 发展 中 各项 工作 的 联系 .	主题 模型 中 最 重要 的 两 组 参数 分别 是 各 主题 下 的 词项 概率 分布 和 各 文档 的 主题 概率 分布 ， 作者 对 期望 最大 化算 法 在 主题 模型 参数 估计 中 的 使用 进行 了 分析 , 这 有助 于 更 深刻 理解 主题 模型 发展 中 各项 工作 的 联系 .	1<2	elab-addition	elab-addition
nlpabs3_Chi	184-201	202-216	作者 对 期望 最大 化算 法 在 主题 模型 参数 估计 中 的 使用 进行 了 分析 ,	这 有助 于 更 深刻 理解 主题 模型 发展 中 各项 工作 的 联系 .	158-216	158-216	主题 模型 中 最 重要 的 两 组 参数 分别 是 各 主题 下 的 词项 概率 分布 和 各 文档 的 主题 概率 分布 ， 作者 对 期望 最大 化算 法 在 主题 模型 参数 估计 中 的 使用 进行 了 分析 , 这 有助 于 更 深刻 理解 主题 模型 发展 中 各项 工作 的 联系 .	主题 模型 中 最 重要 的 两 组 参数 分别 是 各 主题 下 的 词项 概率 分布 和 各 文档 的 主题 概率 分布 ， 作者 对 期望 最大 化算 法 在 主题 模型 参数 估计 中 的 使用 进行 了 分析 , 这 有助 于 更 深刻 理解 主题 模型 发展 中 各项 工作 的 联系 .	1<2	enablement	enablement
nlpabs40_Chi	1-11	81-103	情感 分类 任务 需要 捕获 文本 中 的 情感 特征 ,	该文 提出 一 种 基 于 词 注意力 的 卷积 神经 网络 模型 ( word attention-based convolutional neural networks , WACNN ) 。	1-22	70-103	情感 分类 任务 需要 捕获 文本 中 的 情感 特征 , 利用 重要 的 局部 特征 构建 文本 的 特征 表示 。	基 于 目前 运用 非常 成功 的 注意 力 模型 , 该文 提出 一 种 基 于 词 注意力 的 卷积 神经 网络 模型 ( word attention-based convolutional neural networks , WACNN ) 。	1>2	bg-general	bg-general
nlpabs40_Chi	1-11	12-16	情感 分类 任务 需要 捕获 文本 中 的 情感 特征 ,	利用 重要 的 局部 特征	1-22	1-22	情感 分类 任务 需要 捕获 文本 中 的 情感 特征 , 利用 重要 的 局部 特征 构建 文本 的 特征 表示 。	情感 分类 任务 需要 捕获 文本 中 的 情感 特征 , 利用 重要 的 局部 特征 构建 文本 的 特征 表示 。	1<2	elab-addition	elab-addition
nlpabs40_Chi	12-16	17-22	利用 重要 的 局部 特征	构建 文本 的 特征 表示 。	1-22	1-22	情感 分类 任务 需要 捕获 文本 中 的 情感 特征 , 利用 重要 的 局部 特征 构建 文本 的 特征 表示 。	情感 分类 任务 需要 捕获 文本 中 的 情感 特征 , 利用 重要 的 局部 特征 构建 文本 的 特征 表示 。	1<2	enablement	enablement
nlpabs40_Chi	23-42	43-58	卷积 神经 网络 ( convolutional neural networks , CNN ) 已经 被 证明 拥有 出色 的 特征 学习 能力 ,	但是 该 模型 无法 判别 输入 文本 中 特征 词 与 情感 的 相关 性 ,	23-69	23-69	卷积 神经 网络 ( convolutional neural networks , CNN ) 已经 被 证明 拥有 出色 的 特征 学习 能力 , 但是 该 模型 无法 判别 输入 文本 中 特征 词 与 情感 的 相关 性 , 卷积 层 缺乏 对 单 一 词 特征 的 提取 。	卷积 神经 网络 ( convolutional neural networks , CNN ) 已经 被 证明 拥有 出色 的 特征 学习 能力 , 但是 该 模型 无法 判别 输入 文本 中 特征 词 与 情感 的 相关 性 , 卷积 层 缺乏 对 单 一 词 特征 的 提取 。	1>2	contrast	contrast
nlpabs40_Chi	1-11	43-58	情感 分类 任务 需要 捕获 文本 中 的 情感 特征 ,	但是 该 模型 无法 判别 输入 文本 中 特征 词 与 情感 的 相关 性 ,	1-22	23-69	情感 分类 任务 需要 捕获 文本 中 的 情感 特征 , 利用 重要 的 局部 特征 构建 文本 的 特征 表示 。	卷积 神经 网络 ( convolutional neural networks , CNN ) 已经 被 证明 拥有 出色 的 特征 学习 能力 , 但是 该 模型 无法 判别 输入 文本 中 特征 词 与 情感 的 相关 性 , 卷积 层 缺乏 对 单 一 词 特征 的 提取 。	1<2	elab-addition	elab-addition
nlpabs40_Chi	43-58	59-69	但是 该 模型 无法 判别 输入 文本 中 特征 词 与 情感 的 相关 性 ,	卷积 层 缺乏 对 单 一 词 特征 的 提取 。	23-69	23-69	卷积 神经 网络 ( convolutional neural networks , CNN ) 已经 被 证明 拥有 出色 的 特征 学习 能力 , 但是 该 模型 无法 判别 输入 文本 中 特征 词 与 情感 的 相关 性 , 卷积 层 缺乏 对 单 一 词 特征 的 提取 。	卷积 神经 网络 ( convolutional neural networks , CNN ) 已经 被 证明 拥有 出色 的 特征 学习 能力 , 但是 该 模型 无法 判别 输入 文本 中 特征 词 与 情感 的 相关 性 , 卷积 层 缺乏 对 单 一 词 特征 的 提取 。	1<2	elab-addition	elab-addition
nlpabs40_Chi	70-80	81-103	基 于 目前 运用 非常 成功 的 注意 力 模型 ,	该文 提出 一 种 基 于 词 注意力 的 卷积 神经 网络 模型 ( word attention-based convolutional neural networks , WACNN ) 。	70-103	70-103	基 于 目前 运用 非常 成功 的 注意 力 模型 , 该文 提出 一 种 基 于 词 注意力 的 卷积 神经 网络 模型 ( word attention-based convolutional neural networks , WACNN ) 。	基 于 目前 运用 非常 成功 的 注意 力 模型 , 该文 提出 一 种 基 于 词 注意力 的 卷积 神经 网络 模型 ( word attention-based convolutional neural networks , WACNN ) 。	1>2	bg-general	bg-general
nlpabs40_Chi	81-103	104-120	该文 提出 一 种 基 于 词 注意力 的 卷积 神经 网络 模型 ( word attention-based convolutional neural networks , WACNN ) 。	相比 于 卷积 神经 网络 , 该 模型 以 篇章 的 文本 信息 作 为 输入 ,	70-103	104-210	基 于 目前 运用 非常 成功 的 注意 力 模型 , 该文 提出 一 种 基 于 词 注意力 的 卷积 神经 网络 模型 ( word attention-based convolutional neural networks , WACNN ) 。	相比 于 卷积 神经 网络 , 该 模型 以 篇章 的 文本 信息 作 为 输入 , 首先 在 词 嵌入 层 之后 增加 注意 力 机制 层 , 获取 重要 的 局部 特征 词 , 使 模型 有 选择 地 进行 特征 提取 ; 然后 在 卷积 层 中 增加 大小 为 1 的 卷积 核 , 提取 单 一 词 的 特征 ; 最后 该 方法 对 输入 文本 进行 适当 的 文本 填充 , 保证 每个 词 都 存在 上下文 信息 , 使 模型 有效 提取 到 每个 词 的 n-grams 局部 特征 , 避免 卷积 处理 过程 中 局部 信息 的 丢失 。	1<2	elab-addition	elab-addition
nlpabs40_Chi	104-120	121-132	相比 于 卷积 神经 网络 , 该 模型 以 篇章 的 文本 信息 作 为 输入 ,	首先 在 词 嵌入 层 之后 增加 注意 力 机制 层 ,	104-210	104-210	相比 于 卷积 神经 网络 , 该 模型 以 篇章 的 文本 信息 作 为 输入 , 首先 在 词 嵌入 层 之后 增加 注意 力 机制 层 , 获取 重要 的 局部 特征 词 , 使 模型 有 选择 地 进行 特征 提取 ; 然后 在 卷积 层 中 增加 大小 为 1 的 卷积 核 , 提取 单 一 词 的 特征 ; 最后 该 方法 对 输入 文本 进行 适当 的 文本 填充 , 保证 每个 词 都 存在 上下文 信息 , 使 模型 有效 提取 到 每个 词 的 n-grams 局部 特征 , 避免 卷积 处理 过程 中 局部 信息 的 丢失 。	相比 于 卷积 神经 网络 , 该 模型 以 篇章 的 文本 信息 作 为 输入 , 首先 在 词 嵌入 层 之后 增加 注意 力 机制 层 , 获取 重要 的 局部 特征 词 , 使 模型 有 选择 地 进行 特征 提取 ; 然后 在 卷积 层 中 增加 大小 为 1 的 卷积 核 , 提取 单 一 词 的 特征 ; 最后 该 方法 对 输入 文本 进行 适当 的 文本 填充 , 保证 每个 词 都 存在 上下文 信息 , 使 模型 有效 提取 到 每个 词 的 n-grams 局部 特征 , 避免 卷积 处理 过程 中 局部 信息 的 丢失 。	1<2	elab-process_step	elab-process_step
nlpabs40_Chi	121-132	133-139	首先 在 词 嵌入 层 之后 增加 注意 力 机制 层 ,	获取 重要 的 局部 特征 词 ,	104-210	104-210	相比 于 卷积 神经 网络 , 该 模型 以 篇章 的 文本 信息 作 为 输入 , 首先 在 词 嵌入 层 之后 增加 注意 力 机制 层 , 获取 重要 的 局部 特征 词 , 使 模型 有 选择 地 进行 特征 提取 ; 然后 在 卷积 层 中 增加 大小 为 1 的 卷积 核 , 提取 单 一 词 的 特征 ; 最后 该 方法 对 输入 文本 进行 适当 的 文本 填充 , 保证 每个 词 都 存在 上下文 信息 , 使 模型 有效 提取 到 每个 词 的 n-grams 局部 特征 , 避免 卷积 处理 过程 中 局部 信息 的 丢失 。	相比 于 卷积 神经 网络 , 该 模型 以 篇章 的 文本 信息 作 为 输入 , 首先 在 词 嵌入 层 之后 增加 注意 力 机制 层 , 获取 重要 的 局部 特征 词 , 使 模型 有 选择 地 进行 特征 提取 ; 然后 在 卷积 层 中 增加 大小 为 1 的 卷积 核 , 提取 单 一 词 的 特征 ; 最后 该 方法 对 输入 文本 进行 适当 的 文本 填充 , 保证 每个 词 都 存在 上下文 信息 , 使 模型 有效 提取 到 每个 词 的 n-grams 局部 特征 , 避免 卷积 处理 过程 中 局部 信息 的 丢失 。	1<2	enablement	enablement
nlpabs40_Chi	133-139	140-148	获取 重要 的 局部 特征 词 ,	使 模型 有 选择 地 进行 特征 提取 ;	104-210	104-210	相比 于 卷积 神经 网络 , 该 模型 以 篇章 的 文本 信息 作 为 输入 , 首先 在 词 嵌入 层 之后 增加 注意 力 机制 层 , 获取 重要 的 局部 特征 词 , 使 模型 有 选择 地 进行 特征 提取 ; 然后 在 卷积 层 中 增加 大小 为 1 的 卷积 核 , 提取 单 一 词 的 特征 ; 最后 该 方法 对 输入 文本 进行 适当 的 文本 填充 , 保证 每个 词 都 存在 上下文 信息 , 使 模型 有效 提取 到 每个 词 的 n-grams 局部 特征 , 避免 卷积 处理 过程 中 局部 信息 的 丢失 。	相比 于 卷积 神经 网络 , 该 模型 以 篇章 的 文本 信息 作 为 输入 , 首先 在 词 嵌入 层 之后 增加 注意 力 机制 层 , 获取 重要 的 局部 特征 词 , 使 模型 有 选择 地 进行 特征 提取 ; 然后 在 卷积 层 中 增加 大小 为 1 的 卷积 核 , 提取 单 一 词 的 特征 ; 最后 该 方法 对 输入 文本 进行 适当 的 文本 填充 , 保证 每个 词 都 存在 上下文 信息 , 使 模型 有效 提取 到 每个 词 的 n-grams 局部 特征 , 避免 卷积 处理 过程 中 局部 信息 的 丢失 。	1<2	enablement	enablement
nlpabs40_Chi	121-132	149-161	首先 在 词 嵌入 层 之后 增加 注意 力 机制 层 ,	然后 在 卷积 层 中 增加 大小 为 1 的 卷积 核 ,	104-210	104-210	相比 于 卷积 神经 网络 , 该 模型 以 篇章 的 文本 信息 作 为 输入 , 首先 在 词 嵌入 层 之后 增加 注意 力 机制 层 , 获取 重要 的 局部 特征 词 , 使 模型 有 选择 地 进行 特征 提取 ; 然后 在 卷积 层 中 增加 大小 为 1 的 卷积 核 , 提取 单 一 词 的 特征 ; 最后 该 方法 对 输入 文本 进行 适当 的 文本 填充 , 保证 每个 词 都 存在 上下文 信息 , 使 模型 有效 提取 到 每个 词 的 n-grams 局部 特征 , 避免 卷积 处理 过程 中 局部 信息 的 丢失 。	相比 于 卷积 神经 网络 , 该 模型 以 篇章 的 文本 信息 作 为 输入 , 首先 在 词 嵌入 层 之后 增加 注意 力 机制 层 , 获取 重要 的 局部 特征 词 , 使 模型 有 选择 地 进行 特征 提取 ; 然后 在 卷积 层 中 增加 大小 为 1 的 卷积 核 , 提取 单 一 词 的 特征 ; 最后 该 方法 对 输入 文本 进行 适当 的 文本 填充 , 保证 每个 词 都 存在 上下文 信息 , 使 模型 有效 提取 到 每个 词 的 n-grams 局部 特征 , 避免 卷积 处理 过程 中 局部 信息 的 丢失 。	1<2	joint	joint
nlpabs40_Chi	149-161	162-168	然后 在 卷积 层 中 增加 大小 为 1 的 卷积 核 ,	提取 单 一 词 的 特征 ;	104-210	104-210	相比 于 卷积 神经 网络 , 该 模型 以 篇章 的 文本 信息 作 为 输入 , 首先 在 词 嵌入 层 之后 增加 注意 力 机制 层 , 获取 重要 的 局部 特征 词 , 使 模型 有 选择 地 进行 特征 提取 ; 然后 在 卷积 层 中 增加 大小 为 1 的 卷积 核 , 提取 单 一 词 的 特征 ; 最后 该 方法 对 输入 文本 进行 适当 的 文本 填充 , 保证 每个 词 都 存在 上下文 信息 , 使 模型 有效 提取 到 每个 词 的 n-grams 局部 特征 , 避免 卷积 处理 过程 中 局部 信息 的 丢失 。	相比 于 卷积 神经 网络 , 该 模型 以 篇章 的 文本 信息 作 为 输入 , 首先 在 词 嵌入 层 之后 增加 注意 力 机制 层 , 获取 重要 的 局部 特征 词 , 使 模型 有 选择 地 进行 特征 提取 ; 然后 在 卷积 层 中 增加 大小 为 1 的 卷积 核 , 提取 单 一 词 的 特征 ; 最后 该 方法 对 输入 文本 进行 适当 的 文本 填充 , 保证 每个 词 都 存在 上下文 信息 , 使 模型 有效 提取 到 每个 词 的 n-grams 局部 特征 , 避免 卷积 处理 过程 中 局部 信息 的 丢失 。	1<2	enablement	enablement
nlpabs40_Chi	149-161	169-180	然后 在 卷积 层 中 增加 大小 为 1 的 卷积 核 ,	最后 该 方法 对 输入 文本 进行 适当 的 文本 填充 ,	104-210	104-210	相比 于 卷积 神经 网络 , 该 模型 以 篇章 的 文本 信息 作 为 输入 , 首先 在 词 嵌入 层 之后 增加 注意 力 机制 层 , 获取 重要 的 局部 特征 词 , 使 模型 有 选择 地 进行 特征 提取 ; 然后 在 卷积 层 中 增加 大小 为 1 的 卷积 核 , 提取 单 一 词 的 特征 ; 最后 该 方法 对 输入 文本 进行 适当 的 文本 填充 , 保证 每个 词 都 存在 上下文 信息 , 使 模型 有效 提取 到 每个 词 的 n-grams 局部 特征 , 避免 卷积 处理 过程 中 局部 信息 的 丢失 。	相比 于 卷积 神经 网络 , 该 模型 以 篇章 的 文本 信息 作 为 输入 , 首先 在 词 嵌入 层 之后 增加 注意 力 机制 层 , 获取 重要 的 局部 特征 词 , 使 模型 有 选择 地 进行 特征 提取 ; 然后 在 卷积 层 中 增加 大小 为 1 的 卷积 核 , 提取 单 一 词 的 特征 ; 最后 该 方法 对 输入 文本 进行 适当 的 文本 填充 , 保证 每个 词 都 存在 上下文 信息 , 使 模型 有效 提取 到 每个 词 的 n-grams 局部 特征 , 避免 卷积 处理 过程 中 局部 信息 的 丢失 。	1<2	joint	joint
nlpabs40_Chi	169-180	181-188	最后 该 方法 对 输入 文本 进行 适当 的 文本 填充 ,	保证 每个 词 都 存在 上下文 信息 ,	104-210	104-210	相比 于 卷积 神经 网络 , 该 模型 以 篇章 的 文本 信息 作 为 输入 , 首先 在 词 嵌入 层 之后 增加 注意 力 机制 层 , 获取 重要 的 局部 特征 词 , 使 模型 有 选择 地 进行 特征 提取 ; 然后 在 卷积 层 中 增加 大小 为 1 的 卷积 核 , 提取 单 一 词 的 特征 ; 最后 该 方法 对 输入 文本 进行 适当 的 文本 填充 , 保证 每个 词 都 存在 上下文 信息 , 使 模型 有效 提取 到 每个 词 的 n-grams 局部 特征 , 避免 卷积 处理 过程 中 局部 信息 的 丢失 。	相比 于 卷积 神经 网络 , 该 模型 以 篇章 的 文本 信息 作 为 输入 , 首先 在 词 嵌入 层 之后 增加 注意 力 机制 层 , 获取 重要 的 局部 特征 词 , 使 模型 有 选择 地 进行 特征 提取 ; 然后 在 卷积 层 中 增加 大小 为 1 的 卷积 核 , 提取 单 一 词 的 特征 ; 最后 该 方法 对 输入 文本 进行 适当 的 文本 填充 , 保证 每个 词 都 存在 上下文 信息 , 使 模型 有效 提取 到 每个 词 的 n-grams 局部 特征 , 避免 卷积 处理 过程 中 局部 信息 的 丢失 。	1<2	enablement	enablement
nlpabs40_Chi	181-188	189-200	保证 每个 词 都 存在 上下文 信息 ,	使 模型 有效 提取 到 每个 词 的 n-grams 局部 特征 ,	104-210	104-210	相比 于 卷积 神经 网络 , 该 模型 以 篇章 的 文本 信息 作 为 输入 , 首先 在 词 嵌入 层 之后 增加 注意 力 机制 层 , 获取 重要 的 局部 特征 词 , 使 模型 有 选择 地 进行 特征 提取 ; 然后 在 卷积 层 中 增加 大小 为 1 的 卷积 核 , 提取 单 一 词 的 特征 ; 最后 该 方法 对 输入 文本 进行 适当 的 文本 填充 , 保证 每个 词 都 存在 上下文 信息 , 使 模型 有效 提取 到 每个 词 的 n-grams 局部 特征 , 避免 卷积 处理 过程 中 局部 信息 的 丢失 。	相比 于 卷积 神经 网络 , 该 模型 以 篇章 的 文本 信息 作 为 输入 , 首先 在 词 嵌入 层 之后 增加 注意 力 机制 层 , 获取 重要 的 局部 特征 词 , 使 模型 有 选择 地 进行 特征 提取 ; 然后 在 卷积 层 中 增加 大小 为 1 的 卷积 核 , 提取 单 一 词 的 特征 ; 最后 该 方法 对 输入 文本 进行 适当 的 文本 填充 , 保证 每个 词 都 存在 上下文 信息 , 使 模型 有效 提取 到 每个 词 的 n-grams 局部 特征 , 避免 卷积 处理 过程 中 局部 信息 的 丢失 。	1<2	enablement	enablement
nlpabs40_Chi	189-200	201-210	使 模型 有效 提取 到 每个 词 的 n-grams 局部 特征 ,	避免 卷积 处理 过程 中 局部 信息 的 丢失 。	104-210	104-210	相比 于 卷积 神经 网络 , 该 模型 以 篇章 的 文本 信息 作 为 输入 , 首先 在 词 嵌入 层 之后 增加 注意 力 机制 层 , 获取 重要 的 局部 特征 词 , 使 模型 有 选择 地 进行 特征 提取 ; 然后 在 卷积 层 中 增加 大小 为 1 的 卷积 核 , 提取 单 一 词 的 特征 ; 最后 该 方法 对 输入 文本 进行 适当 的 文本 填充 , 保证 每个 词 都 存在 上下文 信息 , 使 模型 有效 提取 到 每个 词 的 n-grams 局部 特征 , 避免 卷积 处理 过程 中 局部 信息 的 丢失 。	相比 于 卷积 神经 网络 , 该 模型 以 篇章 的 文本 信息 作 为 输入 , 首先 在 词 嵌入 层 之后 增加 注意 力 机制 层 , 获取 重要 的 局部 特征 词 , 使 模型 有 选择 地 进行 特征 提取 ; 然后 在 卷积 层 中 增加 大小 为 1 的 卷积 核 , 提取 单 一 词 的 特征 ; 最后 该 方法 对 输入 文本 进行 适当 的 文本 填充 , 保证 每个 词 都 存在 上下文 信息 , 使 模型 有效 提取 到 每个 词 的 n-grams 局部 特征 , 避免 卷积 处理 过程 中 局部 信息 的 丢失 。	1<2	enablement	enablement
nlpabs40_Chi	81-103	211-221	该文 提出 一 种 基 于 词 注意力 的 卷积 神经 网络 模型 ( word attention-based convolutional neural networks , WACNN ) 。	该 模型 在 MR5K 和 CR 数据 集上 进行 验证 ,	70-103	211-244	基 于 目前 运用 非常 成功 的 注意 力 模型 , 该文 提出 一 种 基 于 词 注意力 的 卷积 神经 网络 模型 ( word attention-based convolutional neural networks , WACNN ) 。	该 模型 在 MR5K 和 CR 数据 集上 进行 验证 , 较 普通 卷积 神经 网络 和 传统 机器 学习 方法 , 在 准确 率 上 分别 取得 0.5% 和 2% 的 提升 。	1<2	evaluation	evaluation
nlpabs40_Chi	211-221	222-244	该 模型 在 MR5K 和 CR 数据 集上 进行 验证 ,	较 普通 卷积 神经 网络 和 传统 机器 学习 方法 , 在 准确 率 上 分别 取得 0.5% 和 2% 的 提升 。	211-244	211-244	该 模型 在 MR5K 和 CR 数据 集上 进行 验证 , 较 普通 卷积 神经 网络 和 传统 机器 学习 方法 , 在 准确 率 上 分别 取得 0.5% 和 2% 的 提升 。	该 模型 在 MR5K 和 CR 数据 集上 进行 验证 , 较 普通 卷积 神经 网络 和 传统 机器 学习 方法 , 在 准确 率 上 分别 取得 0.5% 和 2% 的 提升 。	1<2	elab-addition	elab-addition
nlpabs41_Chi	1-15	79-96	实际 的 网络 化 数据 往往 包含 多 种 类型 的 对象 和 关系 ,	提出 了 一 个 新 的 社团 发现 算法 框架 HCD ( heterogeneou s community detection ) 。	1-41	68-96	实际 的 网络 化 数据 往往 包含 多 种 类型 的 对象 和 关系 , 采用 异质 信息 网络 可以 更好 地 对 其 建模 , 因 此 异质 信息 网络 分析 逐渐 成 为 数据 挖掘 的 研究 热点 。	该文 研究 异质 信息 网络 中 的 社团 发现 问题 , 提出 了 一 个 新 的 社团 发现 算法 框架 HCD ( heterogeneou s community detection ) 。	1>2	bg-general	bg-general
nlpabs41_Chi	1-15	16-26	实际 的 网络 化 数据 往往 包含 多 种 类型 的 对象 和 关系 ,	采用 异质 信息 网络 可以 更好 地 对 其 建模 ,	1-41	1-41	实际 的 网络 化 数据 往往 包含 多 种 类型 的 对象 和 关系 , 采用 异质 信息 网络 可以 更好 地 对 其 建模 , 因 此 异质 信息 网络 分析 逐渐 成 为 数据 挖掘 的 研究 热点 。	实际 的 网络 化 数据 往往 包含 多 种 类型 的 对象 和 关系 , 采用 异质 信息 网络 可以 更好 地 对 其 建模 , 因 此 异质 信息 网络 分析 逐渐 成 为 数据 挖掘 的 研究 热点 。	1<2	elab-addition	elab-addition
nlpabs41_Chi	16-26	27-41	采用 异质 信息 网络 可以 更好 地 对 其 建模 ,	因 此 异质 信息 网络 分析 逐渐 成 为 数据 挖掘 的 研究 热点 。	1-41	1-41	实际 的 网络 化 数据 往往 包含 多 种 类型 的 对象 和 关系 , 采用 异质 信息 网络 可以 更好 地 对 其 建模 , 因 此 异质 信息 网络 分析 逐渐 成 为 数据 挖掘 的 研究 热点 。	实际 的 网络 化 数据 往往 包含 多 种 类型 的 对象 和 关系 , 采用 异质 信息 网络 可以 更好 地 对 其 建模 , 因 此 异质 信息 网络 分析 逐渐 成 为 数据 挖掘 的 研究 热点 。	1<2	result	result
nlpabs41_Chi	42-54	55-67	虽然 同质 信息 网络 中 的 社团 发现 已经 被 深入 研究 ,	但是 异质 信息 网络 中 的 社团 发现 还 很少 被 研究 。	42-67	42-67	虽然 同质 信息 网络 中 的 社团 发现 已经 被 深入 研究 , 但是 异质 信息 网络 中 的 社团 发现 还 很少 被 研究 。	虽然 同质 信息 网络 中 的 社团 发现 已经 被 深入 研究 , 但是 异质 信息 网络 中 的 社团 发现 还 很少 被 研究 。	1>2	contrast	contrast
nlpabs41_Chi	16-26	55-67	采用 异质 信息 网络 可以 更好 地 对 其 建模 ,	但是 异质 信息 网络 中 的 社团 发现 还 很少 被 研究 。	1-41	42-67	实际 的 网络 化 数据 往往 包含 多 种 类型 的 对象 和 关系 , 采用 异质 信息 网络 可以 更好 地 对 其 建模 , 因 此 异质 信息 网络 分析 逐渐 成 为 数据 挖掘 的 研究 热点 。	虽然 同质 信息 网络 中 的 社团 发现 已经 被 深入 研究 , 但是 异质 信息 网络 中 的 社团 发现 还 很少 被 研究 。	1<2	elab-addition	elab-addition
nlpabs41_Chi	68-78	79-96	该文 研究 异质 信息 网络 中 的 社团 发现 问题 ,	提出 了 一 个 新 的 社团 发现 算法 框架 HCD ( heterogeneou s community detection ) 。	68-96	68-96	该文 研究 异质 信息 网络 中 的 社团 发现 问题 , 提出 了 一 个 新 的 社团 发现 算法 框架 HCD ( heterogeneou s community detection ) 。	该文 研究 异质 信息 网络 中 的 社团 发现 问题 , 提出 了 一 个 新 的 社团 发现 算法 框架 HCD ( heterogeneou s community detection ) 。	1>2	bg-general	bg-general
nlpabs41_Chi	79-96	97-104	提出 了 一 个 新 的 社团 发现 算法 框架 HCD ( heterogeneou s community detection ) 。	该 框架 由 两 部 分 组成 :	68-96	97-127	该文 研究 异质 信息 网络 中 的 社团 发现 问题 , 提出 了 一 个 新 的 社团 发现 算法 框架 HCD ( heterogeneou s community detection ) 。	该 框架 由 两 部 分 组成 : 基 于 单 条 元 路径 的 社团 发现 算法 HCD_sgl 和 融合 多 条 元 路径 的 社团 发现 算法 HCD_all 。	1<2	elab-addition	elab-addition
nlpabs41_Chi	97-104	105-127	该 框架 由 两 部 分 组成 :	基 于 单 条 元 路径 的 社团 发现 算法 HCD_sgl 和 融合 多 条 元 路径 的 社团 发现 算法 HCD_all 。	97-127	97-127	该 框架 由 两 部 分 组成 : 基 于 单 条 元 路径 的 社团 发现 算法 HCD_sgl 和 融合 多 条 元 路径 的 社团 发现 算法 HCD_all 。	该 框架 由 两 部 分 组成 : 基 于 单 条 元 路径 的 社团 发现 算法 HCD_sgl 和 融合 多 条 元 路径 的 社团 发现 算法 HCD_all 。	1<2	elab-enumember	elab-enumember
nlpabs41_Chi	105-127	128-141	基 于 单 条 元 路径 的 社团 发现 算法 HCD_sgl 和 融合 多 条 元 路径 的 社团 发现 算法 HCD_all 。	HCD_sgl 首先 确定 在 给定 元 路径 下 所有 节点 的 初始 标签 ,	97-127	128-175	该 框架 由 两 部 分 组成 : 基 于 单 条 元 路径 的 社团 发现 算法 HCD_sgl 和 融合 多 条 元 路径 的 社团 发现 算法 HCD_all 。	HCD_sgl 首先 确定 在 给定 元 路径 下 所有 节点 的 初始 标签 , 再 利用 改进 的 标签 传递 算法 进行 最终 的 社团 发现 ; HCD_all 是 在 HCD_sgl 的 基础 上 将 基 于 多 条 元 路径 的 社团 发现 结果 进行 融合 。	1<2	elab-addition	elab-addition
nlpabs41_Chi	128-141	142-148	HCD_sgl 首先 确定 在 给定 元 路径 下 所有 节点 的 初始 标签 ,	再 利用 改进 的 标签 传递 算法	128-175	128-175	HCD_sgl 首先 确定 在 给定 元 路径 下 所有 节点 的 初始 标签 , 再 利用 改进 的 标签 传递 算法 进行 最终 的 社团 发现 ; HCD_all 是 在 HCD_sgl 的 基础 上 将 基 于 多 条 元 路径 的 社团 发现 结果 进行 融合 。	HCD_sgl 首先 确定 在 给定 元 路径 下 所有 节点 的 初始 标签 , 再 利用 改进 的 标签 传递 算法 进行 最终 的 社团 发现 ; HCD_all 是 在 HCD_sgl 的 基础 上 将 基 于 多 条 元 路径 的 社团 发现 结果 进行 融合 。	1<2	progression	progression
nlpabs41_Chi	142-148	149-154	再 利用 改进 的 标签 传递 算法	进行 最终 的 社团 发现 ;	128-175	128-175	HCD_sgl 首先 确定 在 给定 元 路径 下 所有 节点 的 初始 标签 , 再 利用 改进 的 标签 传递 算法 进行 最终 的 社团 发现 ; HCD_all 是 在 HCD_sgl 的 基础 上 将 基 于 多 条 元 路径 的 社团 发现 结果 进行 融合 。	HCD_sgl 首先 确定 在 给定 元 路径 下 所有 节点 的 初始 标签 , 再 利用 改进 的 标签 传递 算法 进行 最终 的 社团 发现 ; HCD_all 是 在 HCD_sgl 的 基础 上 将 基 于 多 条 元 路径 的 社团 发现 结果 进行 融合 。	1<2	enablement	enablement
nlpabs41_Chi	128-141	155-175	HCD_sgl 首先 确定 在 给定 元 路径 下 所有 节点 的 初始 标签 ,	HCD_all 是 在 HCD_sgl 的 基础 上 将 基 于 多 条 元 路径 的 社团 发现 结果 进行 融合 。	128-175	128-175	HCD_sgl 首先 确定 在 给定 元 路径 下 所有 节点 的 初始 标签 , 再 利用 改进 的 标签 传递 算法 进行 最终 的 社团 发现 ; HCD_all 是 在 HCD_sgl 的 基础 上 将 基 于 多 条 元 路径 的 社团 发现 结果 进行 融合 。	HCD_sgl 首先 确定 在 给定 元 路径 下 所有 节点 的 初始 标签 , 再 利用 改进 的 标签 传递 算法 进行 最终 的 社团 发现 ; HCD_all 是 在 HCD_sgl 的 基础 上 将 基 于 多 条 元 路径 的 社团 发现 结果 进行 融合 。	1<2	joint	joint
nlpabs41_Chi	79-96	176-195	提出 了 一 个 新 的 社团 发现 算法 框架 HCD ( heterogeneou s community detection ) 。	通过 在 真实 数据 集 和 人工 数据 集 上 的 实验 验证 了 HCD 算法 的 有效 性 。	68-96	176-195	该文 研究 异质 信息 网络 中 的 社团 发现 问题 , 提出 了 一 个 新 的 社团 发现 算法 框架 HCD ( heterogeneou s community detection ) 。	通过 在 真实 数据 集 和 人工 数据 集 上 的 实验 验证 了 HCD 算法 的 有效 性 。	1<2	evaluation	evaluation
nlpabs42_Chi	1-8	9-21	随 着 认知 计算 的 飞速 发展 ,	通用 知识 图谱 的 自动 构 建取 得 了 极大 的 进步 ,	1-36	1-36	随 着 认知 计算 的 飞速 发展 , 通用 知识 图谱 的 自动 构 建取 得 了 极大 的 进步 , 但 在 垂直 领域 由于 缺乏 本体 等 语义 信息 , 导致 进展 缓慢 。	随 着 认知 计算 的 飞速 发展 , 通用 知识 图谱 的 自动 构 建取 得 了 极大 的 进步 , 但 在 垂直 领域 由于 缺乏 本体 等 语义 信息 , 导致 进展 缓慢 。	1>2	bg-general	bg-general
nlpabs42_Chi	9-21	81-86	通用 知识 图谱 的 自动 构 建取 得 了 极大 的 进步 ,	该文 提出 两 个 假设 ,	1-36	81-122	随 着 认知 计算 的 飞速 发展 , 通用 知识 图谱 的 自动 构 建取 得 了 极大 的 进步 , 但 在 垂直 领域 由于 缺乏 本体 等 语义 信息 , 导致 进展 缓慢 。	该文 提出 两 个 假设 , 利用 假设 可以 从 叙词 表 内部 结构 中 提取 实体 类型 和 关系 类型 , 进而 设计 了 一 种 基 于 叙词 表 的 领域 知识 图谱 初始 种子 集自 动生 成算 法 。	1>2	bg-general	bg-general
nlpabs42_Chi	9-21	22-32	通用 知识 图谱 的 自动 构 建取 得 了 极大 的 进步 ,	但 在 垂直 领域 由于 缺乏 本体 等 语义 信息 ,	1-36	1-36	随 着 认知 计算 的 飞速 发展 , 通用 知识 图谱 的 自动 构 建取 得 了 极大 的 进步 , 但 在 垂直 领域 由于 缺乏 本体 等 语义 信息 , 导致 进展 缓慢 。	随 着 认知 计算 的 飞速 发展 , 通用 知识 图谱 的 自动 构 建取 得 了 极大 的 进步 , 但 在 垂直 领域 由于 缺乏 本体 等 语义 信息 , 导致 进展 缓慢 。	1<2	contrast	contrast
nlpabs42_Chi	22-32	33-36	但 在 垂直 领域 由于 缺乏 本体 等 语义 信息 ,	导致 进展 缓慢 。	1-36	1-36	随 着 认知 计算 的 飞速 发展 , 通用 知识 图谱 的 自动 构 建取 得 了 极大 的 进步 , 但 在 垂直 领域 由于 缺乏 本体 等 语义 信息 , 导致 进展 缓慢 。	随 着 认知 计算 的 飞速 发展 , 通用 知识 图谱 的 自动 构 建取 得 了 极大 的 进步 , 但 在 垂直 领域 由于 缺乏 本体 等 语义 信息 , 导致 进展 缓慢 。	1<2	result	result
nlpabs42_Chi	9-21	37-45	通用 知识 图谱 的 自动 构 建取 得 了 极大 的 进步 ,	叙 词 表 广泛 分布 于 各个 专业 领域	1-36	37-80	随 着 认知 计算 的 飞速 发展 , 通用 知识 图谱 的 自动 构 建取 得 了 极大 的 进步 , 但 在 垂直 领域 由于 缺乏 本体 等 语义 信息 , 导致 进展 缓慢 。	叙 词 表 广泛 分布 于 各个 专业 领域 且 蕴藏 着 丰富 的 语义 信息 , 如 能 对 这些 语义 信息 进行 合理 的 提取 和 利用 , 必然 能 在 一定 程度 上 帮助 领域 知识 图谱 的 自动 构建 。	1<2	joint	joint
nlpabs42_Chi	37-45	46-53	叙 词 表 广泛 分布 于 各个 专业 领域	且 蕴藏 着 丰富 的 语义 信息 ,	37-80	37-80	叙 词 表 广泛 分布 于 各个 专业 领域 且 蕴藏 着 丰富 的 语义 信息 , 如 能 对 这些 语义 信息 进行 合理 的 提取 和 利用 , 必然 能 在 一定 程度 上 帮助 领域 知识 图谱 的 自动 构建 。	叙 词 表 广泛 分布 于 各个 专业 领域 且 蕴藏 着 丰富 的 语义 信息 , 如 能 对 这些 语义 信息 进行 合理 的 提取 和 利用 , 必然 能 在 一定 程度 上 帮助 领域 知识 图谱 的 自动 构建 。	1<2	joint	joint
nlpabs42_Chi	54-66	67-80	如 能 对 这些 语义 信息 进行 合理 的 提取 和 利用 ,	必然 能 在 一定 程度 上 帮助 领域 知识 图谱 的 自动 构建 。	37-80	37-80	叙 词 表 广泛 分布 于 各个 专业 领域 且 蕴藏 着 丰富 的 语义 信息 , 如 能 对 这些 语义 信息 进行 合理 的 提取 和 利用 , 必然 能 在 一定 程度 上 帮助 领域 知识 图谱 的 自动 构建 。	叙 词 表 广泛 分布 于 各个 专业 领域 且 蕴藏 着 丰富 的 语义 信息 , 如 能 对 这些 语义 信息 进行 合理 的 提取 和 利用 , 必然 能 在 一定 程度 上 帮助 领域 知识 图谱 的 自动 构建 。	1>2	condition	condition
nlpabs42_Chi	46-53	67-80	且 蕴藏 着 丰富 的 语义 信息 ,	必然 能 在 一定 程度 上 帮助 领域 知识 图谱 的 自动 构建 。	37-80	37-80	叙 词 表 广泛 分布 于 各个 专业 领域 且 蕴藏 着 丰富 的 语义 信息 , 如 能 对 这些 语义 信息 进行 合理 的 提取 和 利用 , 必然 能 在 一定 程度 上 帮助 领域 知识 图谱 的 自动 构建 。	叙 词 表 广泛 分布 于 各个 专业 领域 且 蕴藏 着 丰富 的 语义 信息 , 如 能 对 这些 语义 信息 进行 合理 的 提取 和 利用 , 必然 能 在 一定 程度 上 帮助 领域 知识 图谱 的 自动 构建 。	1<2	elab-addition	elab-addition
nlpabs42_Chi	81-86	87-102	该文 提出 两 个 假设 ,	利用 假设 可以 从 叙词 表 内部 结构 中 提取 实体 类型 和 关系 类型 ,	81-122	81-122	该文 提出 两 个 假设 , 利用 假设 可以 从 叙词 表 内部 结构 中 提取 实体 类型 和 关系 类型 , 进而 设计 了 一 种 基 于 叙词 表 的 领域 知识 图谱 初始 种子 集自 动生 成算 法 。	该文 提出 两 个 假设 , 利用 假设 可以 从 叙词 表 内部 结构 中 提取 实体 类型 和 关系 类型 , 进而 设计 了 一 种 基 于 叙词 表 的 领域 知识 图谱 初始 种子 集自 动生 成算 法 。	1<2	elab-addition	elab-addition
nlpabs42_Chi	87-102	103-122	利用 假设 可以 从 叙词 表 内部 结构 中 提取 实体 类型 和 关系 类型 ,	进而 设计 了 一 种 基 于 叙词 表 的 领域 知识 图谱 初始 种子 集自 动生 成算 法 。	81-122	81-122	该文 提出 两 个 假设 , 利用 假设 可以 从 叙词 表 内部 结构 中 提取 实体 类型 和 关系 类型 , 进而 设计 了 一 种 基 于 叙词 表 的 领域 知识 图谱 初始 种子 集自 动生 成算 法 。	该文 提出 两 个 假设 , 利用 假设 可以 从 叙词 表 内部 结构 中 提取 实体 类型 和 关系 类型 , 进而 设计 了 一 种 基 于 叙词 表 的 领域 知识 图谱 初始 种子 集自 动生 成算 法 。	1<2	enablement	enablement
nlpabs42_Chi	81-86	123-137	该文 提出 两 个 假设 ,	最后 , 以 地质 领域 和 林业 领域 的 叙词 表作 为 实验 对象 ,	81-122	123-187	该文 提出 两 个 假设 , 利用 假设 可以 从 叙词 表 内部 结构 中 提取 实体 类型 和 关系 类型 , 进而 设计 了 一 种 基 于 叙词 表 的 领域 知识 图谱 初始 种子 集自 动生 成算 法 。	最后 , 以 地质 领域 和 林业 领域 的 叙词 表作 为 实验 对象 , 采用 Bootstrapping 算法 , 利用 由 叙词 表 自 动 生成 的 初始 种子 集 进行 抽取 工作 , 通过 对 抽取 到 的 结果 进行 分析 , 结果 表明 利用 叙词 表 得 到 的 初始 种子 集 可以 取得 同 人 工设计 种子 比较 接近 的 效果 。	1<2	evaluation	evaluation
nlpabs42_Chi	123-137	138-141	最后 , 以 地质 领域 和 林业 领域 的 叙词 表作 为 实验 对象 ,	采用 Bootstrapping 算法 ,	123-187	123-187	最后 , 以 地质 领域 和 林业 领域 的 叙词 表作 为 实验 对象 , 采用 Bootstrapping 算法 , 利用 由 叙词 表 自 动 生成 的 初始 种子 集 进行 抽取 工作 , 通过 对 抽取 到 的 结果 进行 分析 , 结果 表明 利用 叙词 表 得 到 的 初始 种子 集 可以 取得 同 人 工设计 种子 比较 接近 的 效果 。	最后 , 以 地质 领域 和 林业 领域 的 叙词 表作 为 实验 对象 , 采用 Bootstrapping 算法 , 利用 由 叙词 表 自 动 生成 的 初始 种子 集 进行 抽取 工作 , 通过 对 抽取 到 的 结果 进行 分析 , 结果 表明 利用 叙词 表 得 到 的 初始 种子 集 可以 取得 同 人 工设计 种子 比较 接近 的 效果 。	1<2	elab-addition	elab-addition
nlpabs42_Chi	138-141	142-152	采用 Bootstrapping 算法 ,	利用 由 叙词 表 自 动 生成 的 初始 种子 集	123-187	123-187	最后 , 以 地质 领域 和 林业 领域 的 叙词 表作 为 实验 对象 , 采用 Bootstrapping 算法 , 利用 由 叙词 表 自 动 生成 的 初始 种子 集 进行 抽取 工作 , 通过 对 抽取 到 的 结果 进行 分析 , 结果 表明 利用 叙词 表 得 到 的 初始 种子 集 可以 取得 同 人 工设计 种子 比较 接近 的 效果 。	最后 , 以 地质 领域 和 林业 领域 的 叙词 表作 为 实验 对象 , 采用 Bootstrapping 算法 , 利用 由 叙词 表 自 动 生成 的 初始 种子 集 进行 抽取 工作 , 通过 对 抽取 到 的 结果 进行 分析 , 结果 表明 利用 叙词 表 得 到 的 初始 种子 集 可以 取得 同 人 工设计 种子 比较 接近 的 效果 。	1<2	joint	joint
nlpabs42_Chi	138-141	153-156	采用 Bootstrapping 算法 ,	进行 抽取 工作 ,	123-187	123-187	最后 , 以 地质 领域 和 林业 领域 的 叙词 表作 为 实验 对象 , 采用 Bootstrapping 算法 , 利用 由 叙词 表 自 动 生成 的 初始 种子 集 进行 抽取 工作 , 通过 对 抽取 到 的 结果 进行 分析 , 结果 表明 利用 叙词 表 得 到 的 初始 种子 集 可以 取得 同 人 工设计 种子 比较 接近 的 效果 。	最后 , 以 地质 领域 和 林业 领域 的 叙词 表作 为 实验 对象 , 采用 Bootstrapping 算法 , 利用 由 叙词 表 自 动 生成 的 初始 种子 集 进行 抽取 工作 , 通过 对 抽取 到 的 结果 进行 分析 , 结果 表明 利用 叙词 表 得 到 的 初始 种子 集 可以 取得 同 人 工设计 种子 比较 接近 的 效果 。	1<2	enablement	enablement
nlpabs42_Chi	153-156	157-165	进行 抽取 工作 ,	通过 对 抽取 到 的 结果 进行 分析 ,	123-187	123-187	最后 , 以 地质 领域 和 林业 领域 的 叙词 表作 为 实验 对象 , 采用 Bootstrapping 算法 , 利用 由 叙词 表 自 动 生成 的 初始 种子 集 进行 抽取 工作 , 通过 对 抽取 到 的 结果 进行 分析 , 结果 表明 利用 叙词 表 得 到 的 初始 种子 集 可以 取得 同 人 工设计 种子 比较 接近 的 效果 。	最后 , 以 地质 领域 和 林业 领域 的 叙词 表作 为 实验 对象 , 采用 Bootstrapping 算法 , 利用 由 叙词 表 自 动 生成 的 初始 种子 集 进行 抽取 工作 , 通过 对 抽取 到 的 结果 进行 分析 , 结果 表明 利用 叙词 表 得 到 的 初始 种子 集 可以 取得 同 人 工设计 种子 比较 接近 的 效果 。	1<2	elab-addition	elab-addition
nlpabs42_Chi	166-167	168-187	结果 表明	利用 叙词 表 得 到 的 初始 种子 集 可以 取得 同 人 工设计 种子 比较 接近 的 效果 。	123-187	123-187	最后 , 以 地质 领域 和 林业 领域 的 叙词 表作 为 实验 对象 , 采用 Bootstrapping 算法 , 利用 由 叙词 表 自 动 生成 的 初始 种子 集 进行 抽取 工作 , 通过 对 抽取 到 的 结果 进行 分析 , 结果 表明 利用 叙词 表 得 到 的 初始 种子 集 可以 取得 同 人 工设计 种子 比较 接近 的 效果 。	最后 , 以 地质 领域 和 林业 领域 的 叙词 表作 为 实验 对象 , 采用 Bootstrapping 算法 , 利用 由 叙词 表 自 动 生成 的 初始 种子 集 进行 抽取 工作 , 通过 对 抽取 到 的 结果 进行 分析 , 结果 表明 利用 叙词 表 得 到 的 初始 种子 集 可以 取得 同 人 工设计 种子 比较 接近 的 效果 。	1>2	attribution	attribution
nlpabs42_Chi	157-165	168-187	通过 对 抽取 到 的 结果 进行 分析 ,	利用 叙词 表 得 到 的 初始 种子 集 可以 取得 同 人 工设计 种子 比较 接近 的 效果 。	123-187	123-187	最后 , 以 地质 领域 和 林业 领域 的 叙词 表作 为 实验 对象 , 采用 Bootstrapping 算法 , 利用 由 叙词 表 自 动 生成 的 初始 种子 集 进行 抽取 工作 , 通过 对 抽取 到 的 结果 进行 分析 , 结果 表明 利用 叙词 表 得 到 的 初始 种子 集 可以 取得 同 人 工设计 种子 比较 接近 的 效果 。	最后 , 以 地质 领域 和 林业 领域 的 叙词 表作 为 实验 对象 , 采用 Bootstrapping 算法 , 利用 由 叙词 表 自 动 生成 的 初始 种子 集 进行 抽取 工作 , 通过 对 抽取 到 的 结果 进行 分析 , 结果 表明 利用 叙词 表 得 到 的 初始 种子 集 可以 取得 同 人 工设计 种子 比较 接近 的 效果 。	1<2	elab-addition	elab-addition
nlpabs42_Chi	81-86	188-215	该文 提出 两 个 假设 ,	此外 , 所 提 模型 具有 通用 性 , 为 叙词 表 在 构建 领域 知识 图谱 中 的 应用 提供 了 一 种 新 的 思路 。	81-122	188-215	该文 提出 两 个 假设 , 利用 假设 可以 从 叙词 表 内部 结构 中 提取 实体 类型 和 关系 类型 , 进而 设计 了 一 种 基 于 叙词 表 的 领域 知识 图谱 初始 种子 集自 动生 成算 法 。	此外 , 所 提 模型 具有 通用 性 , 为 叙词 表 在 构建 领域 知识 图谱 中 的 应用 提供 了 一 种 新 的 思路 。	1<2	elab-addition	elab-addition
nlpabs43_Chi	1-28	63-74	目前 的 语境 向量 模型 在 对 语义 空间 建模 的 时候 , 没有 考虑 到 同 一 个 词 的 不同 词性 具有 不同 的 含义 ,	提出 了 一 种 加入 词性 特征 的 语境 向量 模型 ,	1-58	59-114	目前 的 语境 向量 模型 在 对 语义 空间 建模 的 时候 , 没有 考虑 到 同 一 个 词 的 不同 词性 具有 不同 的 含义 , 将 它们 看作 同 一 个 点 进行 建模 , 导致 得到 的 语境 向量 质量 不高 , 使用 这 种 语境 向量 计算 语境 相似 度 效果 不好 。	针对 该类 问题 , 提出 了 一 种 加入 词性 特征 的 语境 向量 模型 , 加入 词性 后 , 可以 将 原本 用 语义 空间 中 一 个 点 表示 的 几 个 语义 区分 出来 , 得到 质量 更好 的 语境 向量 和 语境 相似 度 , 进而 得到 更好 的 消歧 效果 。	1>2	bg-goal	bg-goal
nlpabs43_Chi	1-28	29-38	目前 的 语境 向量 模型 在 对 语义 空间 建模 的 时候 , 没有 考虑 到 同 一 个 词 的 不同 词性 具有 不同 的 含义 ,	将 它们 看作 同 一 个 点 进行 建模 ,	1-58	1-58	目前 的 语境 向量 模型 在 对 语义 空间 建模 的 时候 , 没有 考虑 到 同 一 个 词 的 不同 词性 具有 不同 的 含义 , 将 它们 看作 同 一 个 点 进行 建模 , 导致 得到 的 语境 向量 质量 不高 , 使用 这 种 语境 向量 计算 语境 相似 度 效果 不好 。	目前 的 语境 向量 模型 在 对 语义 空间 建模 的 时候 , 没有 考虑 到 同 一 个 词 的 不同 词性 具有 不同 的 含义 , 将 它们 看作 同 一 个 点 进行 建模 , 导致 得到 的 语境 向量 质量 不高 , 使用 这 种 语境 向量 计算 语境 相似 度 效果 不好 。	1<2	elab-addition	elab-addition
nlpabs43_Chi	29-38	39-46	将 它们 看作 同 一 个 点 进行 建模 ,	导致 得到 的 语境 向量 质量 不高 ,	1-58	1-58	目前 的 语境 向量 模型 在 对 语义 空间 建模 的 时候 , 没有 考虑 到 同 一 个 词 的 不同 词性 具有 不同 的 含义 , 将 它们 看作 同 一 个 点 进行 建模 , 导致 得到 的 语境 向量 质量 不高 , 使用 这 种 语境 向量 计算 语境 相似 度 效果 不好 。	目前 的 语境 向量 模型 在 对 语义 空间 建模 的 时候 , 没有 考虑 到 同 一 个 词 的 不同 词性 具有 不同 的 含义 , 将 它们 看作 同 一 个 点 进行 建模 , 导致 得到 的 语境 向量 质量 不高 , 使用 这 种 语境 向量 计算 语境 相似 度 效果 不好 。	1<2	result	result
nlpabs43_Chi	39-46	47-58	导致 得到 的 语境 向量 质量 不高 ,	使用 这 种 语境 向量 计算 语境 相似 度 效果 不好 。	1-58	1-58	目前 的 语境 向量 模型 在 对 语义 空间 建模 的 时候 , 没有 考虑 到 同 一 个 词 的 不同 词性 具有 不同 的 含义 , 将 它们 看作 同 一 个 点 进行 建模 , 导致 得到 的 语境 向量 质量 不高 , 使用 这 种 语境 向量 计算 语境 相似 度 效果 不好 。	目前 的 语境 向量 模型 在 对 语义 空间 建模 的 时候 , 没有 考虑 到 同 一 个 词 的 不同 词性 具有 不同 的 含义 , 将 它们 看作 同 一 个 点 进行 建模 , 导致 得到 的 语境 向量 质量 不高 , 使用 这 种 语境 向量 计算 语境 相似 度 效果 不好 。	1<2	elab-addition	elab-addition
nlpabs43_Chi	59-62	63-74	针对 该类 问题 ,	提出 了 一 种 加入 词性 特征 的 语境 向量 模型 ,	59-114	59-114	针对 该类 问题 , 提出 了 一 种 加入 词性 特征 的 语境 向量 模型 , 加入 词性 后 , 可以 将 原本 用 语义 空间 中 一 个 点 表示 的 几 个 语义 区分 出来 , 得到 质量 更好 的 语境 向量 和 语境 相似 度 , 进而 得到 更好 的 消歧 效果 。	针对 该类 问题 , 提出 了 一 种 加入 词性 特征 的 语境 向量 模型 , 加入 词性 后 , 可以 将 原本 用 语义 空间 中 一 个 点 表示 的 几 个 语义 区分 出来 , 得到 质量 更好 的 语境 向量 和 语境 相似 度 , 进而 得到 更好 的 消歧 效果 。	1>2	bg-general	bg-general
nlpabs43_Chi	75-78	79-96	加入 词性 后 ,	可以 将 原本 用 语义 空间 中 一 个 点 表示 的 几 个 语义 区分 出来 ,	59-114	59-114	针对 该类 问题 , 提出 了 一 种 加入 词性 特征 的 语境 向量 模型 , 加入 词性 后 , 可以 将 原本 用 语义 空间 中 一 个 点 表示 的 几 个 语义 区分 出来 , 得到 质量 更好 的 语境 向量 和 语境 相似 度 , 进而 得到 更好 的 消歧 效果 。	针对 该类 问题 , 提出 了 一 种 加入 词性 特征 的 语境 向量 模型 , 加入 词性 后 , 可以 将 原本 用 语义 空间 中 一 个 点 表示 的 几 个 语义 区分 出来 , 得到 质量 更好 的 语境 向量 和 语境 相似 度 , 进而 得到 更好 的 消歧 效果 。	1>2	temporal	temporal
nlpabs43_Chi	63-74	79-96	提出 了 一 种 加入 词性 特征 的 语境 向量 模型 ,	可以 将 原本 用 语义 空间 中 一 个 点 表示 的 几 个 语义 区分 出来 ,	59-114	59-114	针对 该类 问题 , 提出 了 一 种 加入 词性 特征 的 语境 向量 模型 , 加入 词性 后 , 可以 将 原本 用 语义 空间 中 一 个 点 表示 的 几 个 语义 区分 出来 , 得到 质量 更好 的 语境 向量 和 语境 相似 度 , 进而 得到 更好 的 消歧 效果 。	针对 该类 问题 , 提出 了 一 种 加入 词性 特征 的 语境 向量 模型 , 加入 词性 后 , 可以 将 原本 用 语义 空间 中 一 个 点 表示 的 几 个 语义 区分 出来 , 得到 质量 更好 的 语境 向量 和 语境 相似 度 , 进而 得到 更好 的 消歧 效果 。	1<2	elab-addition	elab-addition
nlpabs43_Chi	79-96	97-107	可以 将 原本 用 语义 空间 中 一 个 点 表示 的 几 个 语义 区分 出来 ,	得到 质量 更好 的 语境 向量 和 语境 相似 度 ,	59-114	59-114	针对 该类 问题 , 提出 了 一 种 加入 词性 特征 的 语境 向量 模型 , 加入 词性 后 , 可以 将 原本 用 语义 空间 中 一 个 点 表示 的 几 个 语义 区分 出来 , 得到 质量 更好 的 语境 向量 和 语境 相似 度 , 进而 得到 更好 的 消歧 效果 。	针对 该类 问题 , 提出 了 一 种 加入 词性 特征 的 语境 向量 模型 , 加入 词性 后 , 可以 将 原本 用 语义 空间 中 一 个 点 表示 的 几 个 语义 区分 出来 , 得到 质量 更好 的 语境 向量 和 语境 相似 度 , 进而 得到 更好 的 消歧 效果 。	1<2	enablement	enablement
nlpabs43_Chi	97-107	108-114	得到 质量 更好 的 语境 向量 和 语境 相似 度 ,	进而 得到 更好 的 消歧 效果 。	59-114	59-114	针对 该类 问题 , 提出 了 一 种 加入 词性 特征 的 语境 向量 模型 , 加入 词性 后 , 可以 将 原本 用 语义 空间 中 一 个 点 表示 的 几 个 语义 区分 出来 , 得到 质量 更好 的 语境 向量 和 语境 相似 度 , 进而 得到 更好 的 消歧 效果 。	针对 该类 问题 , 提出 了 一 种 加入 词性 特征 的 语境 向量 模型 , 加入 词性 后 , 可以 将 原本 用 语义 空间 中 一 个 点 表示 的 几 个 语义 区分 出来 , 得到 质量 更好 的 语境 向量 和 语境 相似 度 , 进而 得到 更好 的 消歧 效果 。	1<2	progression	progression
nlpabs43_Chi	115-118	119-130	实验 结果 表明 ,	这 种 建模 方式 可以 有效 区分 不同 词性 的 语义 ,	115-178	115-178	实验 结果 表明 , 这 种 建模 方式 可以 有效 区分 不同 词性 的 语义 , 在 2004 年 的 Senseval -3 测试 集 上 进行 测试 , 准确 率 达到 了 75.3% , 并 在 Sem Eval-13 和 Sem Eval -15 公开 测试 集 上 进行 了 测试 , 消歧 效果 相比 未 引入 词性 特征 的 模型 均 得到 了 提升 。	实验 结果 表明 , 这 种 建模 方式 可以 有效 区分 不同 词性 的 语义 , 在 2004 年 的 Senseval -3 测试 集 上 进行 测试 , 准确 率 达到 了 75.3% , 并 在 Sem Eval-13 和 Sem Eval -15 公开 测试 集 上 进行 了 测试 , 消歧 效果 相比 未 引入 词性 特征 的 模型 均 得到 了 提升 。	1>2	elab-addition	elab-addition
nlpabs43_Chi	63-74	119-130	提出 了 一 种 加入 词性 特征 的 语境 向量 模型 ,	这 种 建模 方式 可以 有效 区分 不同 词性 的 语义 ,	59-114	115-178	针对 该类 问题 , 提出 了 一 种 加入 词性 特征 的 语境 向量 模型 , 加入 词性 后 , 可以 将 原本 用 语义 空间 中 一 个 点 表示 的 几 个 语义 区分 出来 , 得到 质量 更好 的 语境 向量 和 语境 相似 度 , 进而 得到 更好 的 消歧 效果 。	实验 结果 表明 , 这 种 建模 方式 可以 有效 区分 不同 词性 的 语义 , 在 2004 年 的 Senseval -3 测试 集 上 进行 测试 , 准确 率 达到 了 75.3% , 并 在 Sem Eval-13 和 Sem Eval -15 公开 测试 集 上 进行 了 测试 , 消歧 效果 相比 未 引入 词性 特征 的 模型 均 得到 了 提升 。	1<2	evaluation	evaluation
nlpabs43_Chi	119-130	131-142	这 种 建模 方式 可以 有效 区分 不同 词性 的 语义 ,	在 2004 年 的 Senseval -3 测试 集 上 进行 测试 ,	115-178	115-178	实验 结果 表明 , 这 种 建模 方式 可以 有效 区分 不同 词性 的 语义 , 在 2004 年 的 Senseval -3 测试 集 上 进行 测试 , 准确 率 达到 了 75.3% , 并 在 Sem Eval-13 和 Sem Eval -15 公开 测试 集 上 进行 了 测试 , 消歧 效果 相比 未 引入 词性 特征 的 模型 均 得到 了 提升 。	实验 结果 表明 , 这 种 建模 方式 可以 有效 区分 不同 词性 的 语义 , 在 2004 年 的 Senseval -3 测试 集 上 进行 测试 , 准确 率 达到 了 75.3% , 并 在 Sem Eval-13 和 Sem Eval -15 公开 测试 集 上 进行 了 测试 , 消歧 效果 相比 未 引入 词性 特征 的 模型 均 得到 了 提升 。	1<2	elab-addition	elab-addition
nlpabs43_Chi	131-142	143-148	在 2004 年 的 Senseval -3 测试 集 上 进行 测试 ,	准确 率 达到 了 75.3% ,	115-178	115-178	实验 结果 表明 , 这 种 建模 方式 可以 有效 区分 不同 词性 的 语义 , 在 2004 年 的 Senseval -3 测试 集 上 进行 测试 , 准确 率 达到 了 75.3% , 并 在 Sem Eval-13 和 Sem Eval -15 公开 测试 集 上 进行 了 测试 , 消歧 效果 相比 未 引入 词性 特征 的 模型 均 得到 了 提升 。	实验 结果 表明 , 这 种 建模 方式 可以 有效 区分 不同 词性 的 语义 , 在 2004 年 的 Senseval -3 测试 集 上 进行 测试 , 准确 率 达到 了 75.3% , 并 在 Sem Eval-13 和 Sem Eval -15 公开 测试 集 上 进行 了 测试 , 消歧 效果 相比 未 引入 词性 特征 的 模型 均 得到 了 提升 。	1<2	elab-addition	elab-addition
nlpabs43_Chi	143-148	149-164	准确 率 达到 了 75.3% ,	并 在 Sem Eval-13 和 Sem Eval -15 公开 测试 集 上 进行 了 测试 ,	115-178	115-178	实验 结果 表明 , 这 种 建模 方式 可以 有效 区分 不同 词性 的 语义 , 在 2004 年 的 Senseval -3 测试 集 上 进行 测试 , 准确 率 达到 了 75.3% , 并 在 Sem Eval-13 和 Sem Eval -15 公开 测试 集 上 进行 了 测试 , 消歧 效果 相比 未 引入 词性 特征 的 模型 均 得到 了 提升 。	实验 结果 表明 , 这 种 建模 方式 可以 有效 区分 不同 词性 的 语义 , 在 2004 年 的 Senseval -3 测试 集 上 进行 测试 , 准确 率 达到 了 75.3% , 并 在 Sem Eval-13 和 Sem Eval -15 公开 测试 集 上 进行 了 测试 , 消歧 效果 相比 未 引入 词性 特征 的 模型 均 得到 了 提升 。	1<2	joint	joint
nlpabs43_Chi	119-130	165-178	这 种 建模 方式 可以 有效 区分 不同 词性 的 语义 ,	消歧 效果 相比 未 引入 词性 特征 的 模型 均 得到 了 提升 。	115-178	115-178	实验 结果 表明 , 这 种 建模 方式 可以 有效 区分 不同 词性 的 语义 , 在 2004 年 的 Senseval -3 测试 集 上 进行 测试 , 准确 率 达到 了 75.3% , 并 在 Sem Eval-13 和 Sem Eval -15 公开 测试 集 上 进行 了 测试 , 消歧 效果 相比 未 引入 词性 特征 的 模型 均 得到 了 提升 。	实验 结果 表明 , 这 种 建模 方式 可以 有效 区分 不同 词性 的 语义 , 在 2004 年 的 Senseval -3 测试 集 上 进行 测试 , 准确 率 达到 了 75.3% , 并 在 Sem Eval-13 和 Sem Eval -15 公开 测试 集 上 进行 了 测试 , 消歧 效果 相比 未 引入 词性 特征 的 模型 均 得到 了 提升 。	1<2	summary	summary
nlpabs44_Chi	1-13	64-75	嵌套 命名 实体 含有 丰富 的 实体 和 实体 间 语义 关系 ,	构建 了 两 个 中 文 嵌套 命名 实体 语料 库 。	1-21	49-75	嵌套 命名 实体 含有 丰富 的 实体 和 实体 间 语义 关系 , 有助 于 提高 信息 抽取 的 效率 。	该文 在 已 有 命名 实体 语料 的 基础 上 采用 半 自动 化 方法 构建 了 两 个 中 文 嵌套 命名 实体 语料 库 。	1>2	bg-general	bg-general
nlpabs44_Chi	1-13	14-21	嵌套 命名 实体 含有 丰富 的 实体 和 实体 间 语义 关系 ,	有助 于 提高 信息 抽取 的 效率 。	1-21	1-21	嵌套 命名 实体 含有 丰富 的 实体 和 实体 间 语义 关系 , 有助 于 提高 信息 抽取 的 效率 。	嵌套 命名 实体 含有 丰富 的 实体 和 实体 间 语义 关系 , 有助 于 提高 信息 抽取 的 效率 。	1<2	elab-addition	elab-addition
nlpabs44_Chi	14-21	22-35	有助 于 提高 信息 抽取 的 效率 。	由于 缺少 统一 的 标准 中 文嵌 套 命 名 实体 语料 库 ,	1-21	22-48	嵌套 命名 实体 含有 丰富 的 实体 和 实体 间 语义 关系 , 有助 于 提高 信息 抽取 的 效率 。	由于 缺少 统一 的 标准 中 文嵌 套 命 名 实体 语料 库 , 目前 中 文 嵌套 命名 实体 的 研究 工作 难 于 比较 。	1<2	elab-addition	elab-addition
nlpabs44_Chi	22-35	36-48	由于 缺少 统一 的 标准 中 文嵌 套 命 名 实体 语料 库 ,	目前 中 文 嵌套 命名 实体 的 研究 工作 难 于 比较 。	22-48	22-48	由于 缺少 统一 的 标准 中 文嵌 套 命 名 实体 语料 库 , 目前 中 文 嵌套 命名 实体 的 研究 工作 难 于 比较 。	由于 缺少 统一 的 标准 中 文嵌 套 命 名 实体 语料 库 , 目前 中 文 嵌套 命名 实体 的 研究 工作 难 于 比较 。	1<2	elab-addition	elab-addition
nlpabs44_Chi	49-58	64-75	该文 在 已 有 命名 实体 语料 的 基础 上	构建 了 两 个 中 文 嵌套 命名 实体 语料 库 。	49-75	49-75	该文 在 已 有 命名 实体 语料 的 基础 上 采用 半 自动 化 方法 构建 了 两 个 中 文 嵌套 命名 实体 语料 库 。	该文 在 已 有 命名 实体 语料 的 基础 上 采用 半 自动 化 方法 构建 了 两 个 中 文 嵌套 命名 实体 语料 库 。	1>2	bg-general	bg-general
nlpabs44_Chi	59-63	64-75	采用 半 自动 化 方法	构建 了 两 个 中 文 嵌套 命名 实体 语料 库 。	49-75	49-75	该文 在 已 有 命名 实体 语料 的 基础 上 采用 半 自动 化 方法 构建 了 两 个 中 文 嵌套 命名 实体 语料 库 。	该文 在 已 有 命名 实体 语料 的 基础 上 采用 半 自动 化 方法 构建 了 两 个 中 文 嵌套 命名 实体 语料 库 。	1>2	manner-means	manner-means
nlpabs44_Chi	64-75	76-87	构建 了 两 个 中 文 嵌套 命名 实体 语料 库 。	首先 利用 已有 中 文命名 实体 语料 库 中 的 标注 信息	49-75	76-128	该文 在 已 有 命名 实体 语料 的 基础 上 采用 半 自动 化 方法 构建 了 两 个 中 文 嵌套 命名 实体 语料 库 。	首先 利用 已有 中 文命名 实体 语料 库 中 的 标注 信息 自动 地 构造 出 尽 可能多 的 嵌套 命名 实体 , 然后 再 进行 手工 调整 以 满足 对 中 文 嵌套 实体 的 标注 要求 , 从而 构建 高 质量 的 中 文 嵌套 命 名实体 识别 语料 库 。	1<2	elab-process_step	elab-process_step
nlpabs44_Chi	76-87	88-98	首先 利用 已有 中 文命名 实体 语料 库 中 的 标注 信息	自动 地 构造 出 尽 可能多 的 嵌套 命名 实体 ,	76-128	76-128	首先 利用 已有 中 文命名 实体 语料 库 中 的 标注 信息 自动 地 构造 出 尽 可能多 的 嵌套 命名 实体 , 然后 再 进行 手工 调整 以 满足 对 中 文 嵌套 实体 的 标注 要求 , 从而 构建 高 质量 的 中 文 嵌套 命 名实体 识别 语料 库 。	首先 利用 已有 中 文命名 实体 语料 库 中 的 标注 信息 自动 地 构造 出 尽 可能多 的 嵌套 命名 实体 , 然后 再 进行 手工 调整 以 满足 对 中 文 嵌套 实体 的 标注 要求 , 从而 构建 高 质量 的 中 文 嵌套 命 名实体 识别 语料 库 。	1<2	elab-addition	elab-addition
nlpabs44_Chi	76-87	99-103	首先 利用 已有 中 文命名 实体 语料 库 中 的 标注 信息	然后 再 进行 手工 调整	76-128	76-128	首先 利用 已有 中 文命名 实体 语料 库 中 的 标注 信息 自动 地 构造 出 尽 可能多 的 嵌套 命名 实体 , 然后 再 进行 手工 调整 以 满足 对 中 文 嵌套 实体 的 标注 要求 , 从而 构建 高 质量 的 中 文 嵌套 命 名实体 识别 语料 库 。	首先 利用 已有 中 文命名 实体 语料 库 中 的 标注 信息 自动 地 构造 出 尽 可能多 的 嵌套 命名 实体 , 然后 再 进行 手工 调整 以 满足 对 中 文 嵌套 实体 的 标注 要求 , 从而 构建 高 质量 的 中 文 嵌套 命 名实体 识别 语料 库 。	1<2	joint	joint
nlpabs44_Chi	99-103	104-114	然后 再 进行 手工 调整	以 满足 对 中 文 嵌套 实体 的 标注 要求 ,	76-128	76-128	首先 利用 已有 中 文命名 实体 语料 库 中 的 标注 信息 自动 地 构造 出 尽 可能多 的 嵌套 命名 实体 , 然后 再 进行 手工 调整 以 满足 对 中 文 嵌套 实体 的 标注 要求 , 从而 构建 高 质量 的 中 文 嵌套 命 名实体 识别 语料 库 。	首先 利用 已有 中 文命名 实体 语料 库 中 的 标注 信息 自动 地 构造 出 尽 可能多 的 嵌套 命名 实体 , 然后 再 进行 手工 调整 以 满足 对 中 文 嵌套 实体 的 标注 要求 , 从而 构建 高 质量 的 中 文 嵌套 命 名实体 识别 语料 库 。	1<2	enablement	enablement
nlpabs44_Chi	104-114	115-128	以 满足 对 中 文 嵌套 实体 的 标注 要求 ,	从而 构建 高 质量 的 中 文 嵌套 命 名实体 识别 语料 库 。	76-128	76-128	首先 利用 已有 中 文命名 实体 语料 库 中 的 标注 信息 自动 地 构造 出 尽 可能多 的 嵌套 命名 实体 , 然后 再 进行 手工 调整 以 满足 对 中 文 嵌套 实体 的 标注 要求 , 从而 构建 高 质量 的 中 文 嵌套 命 名实体 识别 语料 库 。	首先 利用 已有 中 文命名 实体 语料 库 中 的 标注 信息 自动 地 构造 出 尽 可能多 的 嵌套 命名 实体 , 然后 再 进行 手工 调整 以 满足 对 中 文 嵌套 实体 的 标注 要求 , 从而 构建 高 质量 的 中 文 嵌套 命 名实体 识别 语料 库 。	1<2	elab-addition	elab-addition
nlpabs44_Chi	129-141	142-155	语料 内 和 跨 语料 嵌套 实体 识别 的 初步 实验 表明 ,	中 文 嵌套 命名 实体 识别 仍是 一 个 比较 困难 的 问题 ,	129-161	129-161	语料 内 和 跨 语料 嵌套 实体 识别 的 初步 实验 表明 , 中 文 嵌套 命名 实体 识别 仍是 一 个 比较 困难 的 问题 , 需要 进 一 步 研究 。	语料 内 和 跨 语料 嵌套 实体 识别 的 初步 实验 表明 , 中 文 嵌套 命名 实体 识别 仍是 一 个 比较 困难 的 问题 , 需要 进 一 步 研究 。	1>2	attribution	attribution
nlpabs44_Chi	64-75	142-155	构建 了 两 个 中 文 嵌套 命名 实体 语料 库 。	中 文 嵌套 命名 实体 识别 仍是 一 个 比较 困难 的 问题 ,	49-75	129-161	该文 在 已 有 命名 实体 语料 的 基础 上 采用 半 自动 化 方法 构建 了 两 个 中 文 嵌套 命名 实体 语料 库 。	语料 内 和 跨 语料 嵌套 实体 识别 的 初步 实验 表明 , 中 文 嵌套 命名 实体 识别 仍是 一 个 比较 困难 的 问题 , 需要 进 一 步 研究 。	1<2	elab-addition	elab-addition
nlpabs44_Chi	142-155	156-161	中 文 嵌套 命名 实体 识别 仍是 一 个 比较 困难 的 问题 ,	需要 进 一 步 研究 。	129-161	129-161	语料 内 和 跨 语料 嵌套 实体 识别 的 初步 实验 表明 , 中 文 嵌套 命名 实体 识别 仍是 一 个 比较 困难 的 问题 , 需要 进 一 步 研究 。	语料 内 和 跨 语料 嵌套 实体 识别 的 初步 实验 表明 , 中 文 嵌套 命名 实体 识别 仍是 一 个 比较 困难 的 问题 , 需要 进 一 步 研究 。	1<2	elab-addition	elab-addition
nlpabs45_Chi	1-24	54-73	韩 汉 双 语 语料 库 短语 对 齐 对 于 基 于 实例 的 韩 汉 机器 翻译 系统 具有 重要 意义 ,	提出 了 基 于 词对 齐 位置 信息 的 韩 汉 双 语 语料 库 名词 短 语对齐 方法 。	1-73	1-73	韩 汉 双 语 语料 库 短语 对 齐 对 于 基 于 实例 的 韩 汉 机器 翻译 系统 具有 重要 意义 , 该文 从 韩国 语 名词 短语 结构 特点 出发 , 在 基 于 统计 和 基 于 词典 的 词对 齐 方法 进行 试验 分析 的 基础 上 , 提出 了 基 于 词对 齐 位置 信息 的 韩 汉 双 语 语料 库 名词 短 语对齐 方法 。	韩 汉 双 语 语料 库 短语 对 齐 对 于 基 于 实例 的 韩 汉 机器 翻译 系统 具有 重要 意义 , 该文 从 韩国 语 名词 短语 结构 特点 出发 , 在 基 于 统计 和 基 于 词典 的 词对 齐 方法 进行 试验 分析 的 基础 上 , 提出 了 基 于 词对 齐 位置 信息 的 韩 汉 双 语 语料 库 名词 短 语对齐 方法 。	1>2	bg-general	bg-general
nlpabs45_Chi	25-34	54-73	该文 从 韩国 语 名词 短语 结构 特点 出发 ,	提出 了 基 于 词对 齐 位置 信息 的 韩 汉 双 语 语料 库 名词 短 语对齐 方法 。	1-73	1-73	韩 汉 双 语 语料 库 短语 对 齐 对 于 基 于 实例 的 韩 汉 机器 翻译 系统 具有 重要 意义 , 该文 从 韩国 语 名词 短语 结构 特点 出发 , 在 基 于 统计 和 基 于 词典 的 词对 齐 方法 进行 试验 分析 的 基础 上 , 提出 了 基 于 词对 齐 位置 信息 的 韩 汉 双 语 语料 库 名词 短 语对齐 方法 。	韩 汉 双 语 语料 库 短语 对 齐 对 于 基 于 实例 的 韩 汉 机器 翻译 系统 具有 重要 意义 , 该文 从 韩国 语 名词 短语 结构 特点 出发 , 在 基 于 统计 和 基 于 词典 的 词对 齐 方法 进行 试验 分析 的 基础 上 , 提出 了 基 于 词对 齐 位置 信息 的 韩 汉 双 语 语料 库 名词 短 语对齐 方法 。	1>2	bg-general	bg-general
nlpabs45_Chi	25-34	35-53	该文 从 韩国 语 名词 短语 结构 特点 出发 ,	在 基 于 统计 和 基 于 词典 的 词对 齐 方法 进行 试验 分析 的 基础 上 ,	1-73	1-73	韩 汉 双 语 语料 库 短语 对 齐 对 于 基 于 实例 的 韩 汉 机器 翻译 系统 具有 重要 意义 , 该文 从 韩国 语 名词 短语 结构 特点 出发 , 在 基 于 统计 和 基 于 词典 的 词对 齐 方法 进行 试验 分析 的 基础 上 , 提出 了 基 于 词对 齐 位置 信息 的 韩 汉 双 语 语料 库 名词 短 语对齐 方法 。	韩 汉 双 语 语料 库 短语 对 齐 对 于 基 于 实例 的 韩 汉 机器 翻译 系统 具有 重要 意义 , 该文 从 韩国 语 名词 短语 结构 特点 出发 , 在 基 于 统计 和 基 于 词典 的 词对 齐 方法 进行 试验 分析 的 基础 上 , 提出 了 基 于 词对 齐 位置 信息 的 韩 汉 双 语 语料 库 名词 短 语对齐 方法 。	1<2	joint	joint
nlpabs45_Chi	74-81	82-89	该 方法 通过 基 于 统计 的 方法	获得 词 对 齐 位 置 信息 ,	74-145	74-145	该 方法 通过 基 于 统计 的 方法 获得 词 对 齐 位 置 信息 , 在 此 基础 上 利用 基 于 词典 方法 的 相似 度 计算 进行 词 对 齐 校 正 ; 根据 以上 结果 , 该文 通过 韩国 语 名词 短语 左右边 界 规则 抽取 名词 短语 及 其 汉 语 译文 , 利 用 关联 度 度量 方法 进行 过滤 , 实现 名词 短语 对齐 。	该 方法 通过 基 于 统计 的 方法 获得 词 对 齐 位 置 信息 , 在 此 基础 上 利用 基 于 词典 方法 的 相似 度 计算 进行 词 对 齐 校 正 ; 根据 以上 结果 , 该文 通过 韩国 语 名词 短语 左右边 界 规则 抽取 名词 短语 及 其 汉 语 译文 , 利 用 关联 度 度量 方法 进行 过滤 , 实现 名词 短语 对齐 。	1>2	manner-means	manner-means
nlpabs45_Chi	54-73	82-89	提出 了 基 于 词对 齐 位置 信息 的 韩 汉 双 语 语料 库 名词 短 语对齐 方法 。	获得 词 对 齐 位 置 信息 ,	1-73	74-145	韩 汉 双 语 语料 库 短语 对 齐 对 于 基 于 实例 的 韩 汉 机器 翻译 系统 具有 重要 意义 , 该文 从 韩国 语 名词 短语 结构 特点 出发 , 在 基 于 统计 和 基 于 词典 的 词对 齐 方法 进行 试验 分析 的 基础 上 , 提出 了 基 于 词对 齐 位置 信息 的 韩 汉 双 语 语料 库 名词 短 语对齐 方法 。	该 方法 通过 基 于 统计 的 方法 获得 词 对 齐 位 置 信息 , 在 此 基础 上 利用 基 于 词典 方法 的 相似 度 计算 进行 词 对 齐 校 正 ; 根据 以上 结果 , 该文 通过 韩国 语 名词 短语 左右边 界 规则 抽取 名词 短语 及 其 汉 语 译文 , 利 用 关联 度 度量 方法 进行 过滤 , 实现 名词 短语 对齐 。	1<2	elab-process_step	elab-process_step
nlpabs45_Chi	90-102	103-109	在 此 基础 上 利用 基 于 词典 方法 的 相似 度 计算	进行 词 对 齐 校 正 ;	74-145	74-145	该 方法 通过 基 于 统计 的 方法 获得 词 对 齐 位 置 信息 , 在 此 基础 上 利用 基 于 词典 方法 的 相似 度 计算 进行 词 对 齐 校 正 ; 根据 以上 结果 , 该文 通过 韩国 语 名词 短语 左右边 界 规则 抽取 名词 短语 及 其 汉 语 译文 , 利 用 关联 度 度量 方法 进行 过滤 , 实现 名词 短语 对齐 。	该 方法 通过 基 于 统计 的 方法 获得 词 对 齐 位 置 信息 , 在 此 基础 上 利用 基 于 词典 方法 的 相似 度 计算 进行 词 对 齐 校 正 ; 根据 以上 结果 , 该文 通过 韩国 语 名词 短语 左右边 界 规则 抽取 名词 短语 及 其 汉 语 译文 , 利 用 关联 度 度量 方法 进行 过滤 , 实现 名词 短语 对齐 。	1>2	manner-means	manner-means
nlpabs45_Chi	82-89	103-109	获得 词 对 齐 位 置 信息 ,	进行 词 对 齐 校 正 ;	74-145	74-145	该 方法 通过 基 于 统计 的 方法 获得 词 对 齐 位 置 信息 , 在 此 基础 上 利用 基 于 词典 方法 的 相似 度 计算 进行 词 对 齐 校 正 ; 根据 以上 结果 , 该文 通过 韩国 语 名词 短语 左右边 界 规则 抽取 名词 短语 及 其 汉 语 译文 , 利 用 关联 度 度量 方法 进行 过滤 , 实现 名词 短语 对齐 。	该 方法 通过 基 于 统计 的 方法 获得 词 对 齐 位 置 信息 , 在 此 基础 上 利用 基 于 词典 方法 的 相似 度 计算 进行 词 对 齐 校 正 ; 根据 以上 结果 , 该文 通过 韩国 语 名词 短语 左右边 界 规则 抽取 名词 短语 及 其 汉 语 译文 , 利 用 关联 度 度量 方法 进行 过滤 , 实现 名词 短语 对齐 。	1<2	joint	joint
nlpabs45_Chi	110-113	114-131	根据 以上 结果 ,	该文 通过 韩国 语 名词 短语 左右边 界 规则 抽取 名词 短语 及 其 汉 语 译文 ,	74-145	74-145	该 方法 通过 基 于 统计 的 方法 获得 词 对 齐 位 置 信息 , 在 此 基础 上 利用 基 于 词典 方法 的 相似 度 计算 进行 词 对 齐 校 正 ; 根据 以上 结果 , 该文 通过 韩国 语 名词 短语 左右边 界 规则 抽取 名词 短语 及 其 汉 语 译文 , 利 用 关联 度 度量 方法 进行 过滤 , 实现 名词 短语 对齐 。	该 方法 通过 基 于 统计 的 方法 获得 词 对 齐 位 置 信息 , 在 此 基础 上 利用 基 于 词典 方法 的 相似 度 计算 进行 词 对 齐 校 正 ; 根据 以上 结果 , 该文 通过 韩国 语 名词 短语 左右边 界 规则 抽取 名词 短语 及 其 汉 语 译文 , 利 用 关联 度 度量 方法 进行 过滤 , 实现 名词 短语 对齐 。	1>2	bg-general	bg-general
nlpabs45_Chi	103-109	114-131	进行 词 对 齐 校 正 ;	该文 通过 韩国 语 名词 短语 左右边 界 规则 抽取 名词 短语 及 其 汉 语 译文 ,	74-145	74-145	该 方法 通过 基 于 统计 的 方法 获得 词 对 齐 位 置 信息 , 在 此 基础 上 利用 基 于 词典 方法 的 相似 度 计算 进行 词 对 齐 校 正 ; 根据 以上 结果 , 该文 通过 韩国 语 名词 短语 左右边 界 规则 抽取 名词 短语 及 其 汉 语 译文 , 利 用 关联 度 度量 方法 进行 过滤 , 实现 名词 短语 对齐 。	该 方法 通过 基 于 统计 的 方法 获得 词 对 齐 位 置 信息 , 在 此 基础 上 利用 基 于 词典 方法 的 相似 度 计算 进行 词 对 齐 校 正 ; 根据 以上 结果 , 该文 通过 韩国 语 名词 短语 左右边 界 规则 抽取 名词 短语 及 其 汉 语 译文 , 利 用 关联 度 度量 方法 进行 过滤 , 实现 名词 短语 对齐 。	1<2	joint	joint
nlpabs45_Chi	132-137	138-140	利 用 关联 度 度量 方法	进行 过滤 ,	74-145	74-145	该 方法 通过 基 于 统计 的 方法 获得 词 对 齐 位 置 信息 , 在 此 基础 上 利用 基 于 词典 方法 的 相似 度 计算 进行 词 对 齐 校 正 ; 根据 以上 结果 , 该文 通过 韩国 语 名词 短语 左右边 界 规则 抽取 名词 短语 及 其 汉 语 译文 , 利 用 关联 度 度量 方法 进行 过滤 , 实现 名词 短语 对齐 。	该 方法 通过 基 于 统计 的 方法 获得 词 对 齐 位 置 信息 , 在 此 基础 上 利用 基 于 词典 方法 的 相似 度 计算 进行 词 对 齐 校 正 ; 根据 以上 结果 , 该文 通过 韩国 语 名词 短语 左右边 界 规则 抽取 名词 短语 及 其 汉 语 译文 , 利 用 关联 度 度量 方法 进行 过滤 , 实现 名词 短语 对齐 。	1>2	bg-general	bg-general
nlpabs45_Chi	114-131	138-140	该文 通过 韩国 语 名词 短语 左右边 界 规则 抽取 名词 短语 及 其 汉 语 译文 ,	进行 过滤 ,	74-145	74-145	该 方法 通过 基 于 统计 的 方法 获得 词 对 齐 位 置 信息 , 在 此 基础 上 利用 基 于 词典 方法 的 相似 度 计算 进行 词 对 齐 校 正 ; 根据 以上 结果 , 该文 通过 韩国 语 名词 短语 左右边 界 规则 抽取 名词 短语 及 其 汉 语 译文 , 利 用 关联 度 度量 方法 进行 过滤 , 实现 名词 短语 对齐 。	该 方法 通过 基 于 统计 的 方法 获得 词 对 齐 位 置 信息 , 在 此 基础 上 利用 基 于 词典 方法 的 相似 度 计算 进行 词 对 齐 校 正 ; 根据 以上 结果 , 该文 通过 韩国 语 名词 短语 左右边 界 规则 抽取 名词 短语 及 其 汉 语 译文 , 利 用 关联 度 度量 方法 进行 过滤 , 实现 名词 短语 对齐 。	1<2	joint	joint
nlpabs45_Chi	138-140	141-145	进行 过滤 ,	实现 名词 短语 对齐 。	74-145	74-145	该 方法 通过 基 于 统计 的 方法 获得 词 对 齐 位 置 信息 , 在 此 基础 上 利用 基 于 词典 方法 的 相似 度 计算 进行 词 对 齐 校 正 ; 根据 以上 结果 , 该文 通过 韩国 语 名词 短语 左右边 界 规则 抽取 名词 短语 及 其 汉 语 译文 , 利 用 关联 度 度量 方法 进行 过滤 , 实现 名词 短语 对齐 。	该 方法 通过 基 于 统计 的 方法 获得 词 对 齐 位 置 信息 , 在 此 基础 上 利用 基 于 词典 方法 的 相似 度 计算 进行 词 对 齐 校 正 ; 根据 以上 结果 , 该文 通过 韩国 语 名词 短语 左右边 界 规则 抽取 名词 短语 及 其 汉 语 译文 , 利 用 关联 度 度量 方法 进行 过滤 , 实现 名词 短语 对齐 。	1<2	elab-addition	elab-addition
nlpabs45_Chi	146-149	150-167	实验 结果 表明 ,	在 较大 规模 语料 库 情况 下 , 该 方法 取得 了 较好 的 短语 对齐 结果 。	146-167	146-167	实验 结果 表明 , 在 较大 规模 语料 库 情况 下 , 该 方法 取得 了 较好 的 短语 对齐 结果 。	实验 结果 表明 , 在 较大 规模 语料 库 情况 下 , 该 方法 取得 了 较好 的 短语 对齐 结果 。	1>2	attribution	attribution
nlpabs45_Chi	54-73	150-167	提出 了 基 于 词对 齐 位置 信息 的 韩 汉 双 语 语料 库 名词 短 语对齐 方法 。	在 较大 规模 语料 库 情况 下 , 该 方法 取得 了 较好 的 短语 对齐 结果 。	1-73	146-167	韩 汉 双 语 语料 库 短语 对 齐 对 于 基 于 实例 的 韩 汉 机器 翻译 系统 具有 重要 意义 , 该文 从 韩国 语 名词 短语 结构 特点 出发 , 在 基 于 统计 和 基 于 词典 的 词对 齐 方法 进行 试验 分析 的 基础 上 , 提出 了 基 于 词对 齐 位置 信息 的 韩 汉 双 语 语料 库 名词 短 语对齐 方法 。	实验 结果 表明 , 在 较大 规模 语料 库 情况 下 , 该 方法 取得 了 较好 的 短语 对齐 结果 。	1<2	evaluation	evaluation
nlpabs46_Chi	1-14	25-40	目前 中 文 情感 分析 的 主要 资源 以 情感 词典 为 主 ,	该文 主要 研究 如何 从 大 规模 文本 语料 中 自动 获取 实体 情感 知识 。	1-24	25-40	目前 中 文 情感 分析 的 主要 资源 以 情感 词典 为 主 , 缺乏 针对 实体 或 属性 的 情感 知识 资源 。	该文 主要 研究 如何 从 大 规模 文本 语料 中 自动 获取 实体 情感 知识 。	1>2	bg-goal	bg-goal
nlpabs46_Chi	1-14	15-24	目前 中 文 情感 分析 的 主要 资源 以 情感 词典 为 主 ,	缺乏 针对 实体 或 属性 的 情感 知识 资源 。	1-24	1-24	目前 中 文 情感 分析 的 主要 资源 以 情感 词典 为 主 , 缺乏 针对 实体 或 属性 的 情感 知识 资源 。	目前 中 文 情感 分析 的 主要 资源 以 情感 词典 为 主 , 缺乏 针对 实体 或 属性 的 情感 知识 资源 。	1<2	elab-addition	elab-addition
nlpabs46_Chi	25-40	41-50	该文 主要 研究 如何 从 大 规模 文本 语料 中 自动 获取 实体 情感 知识 。	在 该 文 方法 中 , 用 情感 表达 组合	25-40	41-56	该文 主要 研究 如何 从 大 规模 文本 语料 中 自动 获取 实体 情感 知识 。	在 该 文 方法 中 , 用 情感 表达 组合 来 表示 实体 情感 知识 。	1<2	elab-addition	elab-addition
nlpabs46_Chi	41-50	51-56	在 该 文 方法 中 , 用 情感 表达 组合	来 表示 实体 情感 知识 。	41-56	41-56	在 该 文 方法 中 , 用 情感 表达 组合 来 表示 实体 情感 知识 。	在 该 文 方法 中 , 用 情感 表达 组合 来 表示 实体 情感 知识 。	1<2	enablement	enablement
nlpabs46_Chi	25-40	57-74	该文 主要 研究 如何 从 大 规模 文本 语料 中 自动 获取 实体 情感 知识 。	首先 , 基 于 二 部 图 排序 算法 对 情感 表达 组合 候选 集合 进行 排序 。	25-40	57-74	该文 主要 研究 如何 从 大 规模 文本 语料 中 自动 获取 实体 情感 知识 。	首先 , 基 于 二 部 图 排序 算法 对 情感 表达 组合 候选 集合 进行 排序 。	1<2	elab-process_step	elab-process_step
nlpabs46_Chi	57-74	75-87	首先 , 基 于 二 部 图 排序 算法 对 情感 表达 组合 候选 集合 进行 排序 。	然后 , 提出 了 一 种 基 于 语义 相似 的 提炼 算法	57-74	75-96	首先 , 基 于 二 部 图 排序 算法 对 情感 表达 组合 候选 集合 进行 排序 。	然后 , 提出 了 一 种 基 于 语义 相似 的 提炼 算法 对于 排序 靠后 的 表达 组合 进行 选择 。	1<2	joint	joint
nlpabs46_Chi	75-87	88-96	然后 , 提出 了 一 种 基 于 语义 相似 的 提炼 算法	对于 排序 靠后 的 表达 组合 进行 选择 。	75-96	75-96	然后 , 提出 了 一 种 基 于 语义 相似 的 提炼 算法 对于 排序 靠后 的 表达 组合 进行 选择 。	然后 , 提出 了 一 种 基 于 语义 相似 的 提炼 算法 对于 排序 靠后 的 表达 组合 进行 选择 。	1<2	enablement	enablement
nlpabs46_Chi	97-102	103-113	在 提炼 选择 过程 中 ,	充分 考虑 实体 之间 和 情感 词 之间 的 约束 。	97-113	97-113	在 提炼 选择 过程 中 , 充分 考虑 实体 之间 和 情感 词 之间 的 约束 。	在 提炼 选择 过程 中 , 充分 考虑 实体 之间 和 情感 词 之间 的 约束 。	1>2	temporal	temporal
nlpabs46_Chi	75-87	103-113	然后 , 提出 了 一 种 基 于 语义 相似 的 提炼 算法	充分 考虑 实体 之间 和 情感 词 之间 的 约束 。	75-96	97-113	然后 , 提出 了 一 种 基 于 语义 相似 的 提炼 算法 对于 排序 靠后 的 表达 组合 进行 选择 。	在 提炼 选择 过程 中 , 充分 考虑 实体 之间 和 情感 词 之间 的 约束 。	1<2	elab-addition	elab-addition
nlpabs46_Chi	103-113	114-129	充分 考虑 实体 之间 和 情感 词 之间 的 约束 。	最后 , 该文 在 三 种 大 规模 不同 领域 的 语料 上 进行 实验 ,	97-113	114-134	在 提炼 选择 过程 中 , 充分 考虑 实体 之间 和 情感 词 之间 的 约束 。	最后 , 该文 在 三 种 大 规模 不同 领域 的 语料 上 进行 实验 , 并 进行 人工 评价 。	1<2	joint	joint
nlpabs46_Chi	114-129	130-134	最后 , 该文 在 三 种 大 规模 不同 领域 的 语料 上 进行 实验 ,	并 进行 人工 评价 。	114-134	114-134	最后 , 该文 在 三 种 大 规模 不同 领域 的 语料 上 进行 实验 , 并 进行 人工 评价 。	最后 , 该文 在 三 种 大 规模 不同 领域 的 语料 上 进行 实验 , 并 进行 人工 评价 。	1<2	joint	joint
nlpabs46_Chi	135-138	139-157	评价 结果 表明 ,	从 三 个 领域 数据 集上 获取 的 实体 情感 表达 组合 正确 率 均 高 于 90% 。	135-157	135-157	评价 结果 表明 , 从 三 个 领域 数据 集上 获取 的 实体 情感 表达 组合 正确 率 均 高 于 90% 。	评价 结果 表明 , 从 三 个 领域 数据 集上 获取 的 实体 情感 表达 组合 正确 率 均 高 于 90% 。	1>2	attribution	attribution
nlpabs46_Chi	25-40	139-157	该文 主要 研究 如何 从 大 规模 文本 语料 中 自动 获取 实体 情感 知识 。	从 三 个 领域 数据 集上 获取 的 实体 情感 表达 组合 正确 率 均 高 于 90% 。	25-40	135-157	该文 主要 研究 如何 从 大 规模 文本 语料 中 自动 获取 实体 情感 知识 。	评价 结果 表明 , 从 三 个 领域 数据 集上 获取 的 实体 情感 表达 组合 正确 率 均 高 于 90% 。	1<2	evaluation	evaluation
nlpabs46_Chi	25-40	158-169	该文 主要 研究 如何 从 大 规模 文本 语料 中 自动 获取 实体 情感 知识 。	最终 我们 获得 了 一 个 大 规模 情感 知识 词典 ,	25-40	158-178	该文 主要 研究 如何 从 大 规模 文本 语料 中 自动 获取 实体 情感 知识 。	最终 我们 获得 了 一 个 大 规模 情感 知识 词典 , 包括 约 30万 对 的 情感 表达 组合 。	1<2	elab-addition	elab-addition
nlpabs46_Chi	158-169	170-178	最终 我们 获得 了 一 个 大 规模 情感 知识 词典 ,	包括 约 30万 对 的 情感 表达 组合 。	158-178	158-178	最终 我们 获得 了 一 个 大 规模 情感 知识 词典 , 包括 约 30万 对 的 情感 表达 组合 。	最终 我们 获得 了 一 个 大 规模 情感 知识 词典 , 包括 约 30万 对 的 情感 表达 组合 。	1<2	elab-addition	elab-addition
nlpabs48_Chi	1-20	143-175	神经 机器 翻译 ( NMT ) 是 近 两 年 刚 出现 的 一 种 新型 机器 翻译 方法 ,	因 此 , 该文 的 研究 内容 主要 是 探索 批 、 dropout 和 打乱 这 三 个 因素 在 训练 神经 机器 翻译 模型 中 对 模型 翻译 质量 的 影响 ,	1-28	143-233	神经 机器 翻译 ( NMT ) 是 近 两 年 刚 出现 的 一 种 新型 机器 翻译 方法 , 是 一 种 端到端 的 翻译 模型 。	因 此 , 该文 的 研究 内容 主要 是 探索 批 、 dropout 和 打乱 这 三 个 因素 在 训练 神经 机器 翻译 模型 中 对 模型 翻译 质量 的 影响 , 并 得出 以下 三 条 结论 : 一 是 批 的 大 小将 影响 神经 机器 翻译 ( NMT ) 模型 的 收敛 速度 , 二 是 dropout 可以 提升 神经 机器 翻译 模型 的 性能 , 三 是 数据 打乱 可以 在 一定 程度 上 提升 神经 机器 翻译 ( NMT ) 系统 的 翻译 质量 。	1>2	bg-goal	bg-goal
nlpabs48_Chi	1-20	21-28	神经 机器 翻译 ( NMT ) 是 近 两 年 刚 出现 的 一 种 新型 机器 翻译 方法 ,	是 一 种 端到端 的 翻译 模型 。	1-28	1-28	神经 机器 翻译 ( NMT ) 是 近 两 年 刚 出现 的 一 种 新型 机器 翻译 方法 , 是 一 种 端到端 的 翻译 模型 。	神经 机器 翻译 ( NMT ) 是 近 两 年 刚 出现 的 一 种 新型 机器 翻译 方法 , 是 一 种 端到端 的 翻译 模型 。	1<2	elab-addition	elab-addition
nlpabs48_Chi	1-20	29-39	神经 机器 翻译 ( NMT ) 是 近 两 年 刚 出现 的 一 种 新型 机器 翻译 方法 ,	目前 , 影响 NMT 模型 效果 的 因素 有 很多 ,	1-28	29-142	神经 机器 翻译 ( NMT ) 是 近 两 年 刚 出现 的 一 种 新型 机器 翻译 方法 , 是 一 种 端到端 的 翻译 模型 。	目前 , 影响 NMT 模型 效果 的 因素 有 很多 , 其一 , 当 训练 语料 规模 较大 时 , 梯度 下降 更新 方法 会 对 机器 的 内存 要求 很高 , 因 此 大多 研究 工作 中 采用 随机 梯度 下降 ( SGD ) 的 方法 来 更新 模型 的 训练 参数 , 即 每 输入 一定 数量 ( 批 : batch ) 的 训练 样例 , 就 利用 局部 的 训练 样例 更新 一 次 模型 参数 ; 其二 , 参数 dropout 可以 防止 系统 训练 时 出现 过 拟合 , 提高 系统 泛化 能力 ; 其三 , 数据 打乱 ( shuffle ) 也 对 翻译 结果 有 着 重要 影响 。	1<2	elab-addition	elab-addition
nlpabs48_Chi	29-39	40-60	目前 , 影响 NMT 模型 效果 的 因素 有 很多 ,	其一 , 当 训练 语料 规模 较大 时 , 梯度 下降 更新 方法 会 对 机器 的 内存 要求 很高 ,	29-142	29-142	目前 , 影响 NMT 模型 效果 的 因素 有 很多 , 其一 , 当 训练 语料 规模 较大 时 , 梯度 下降 更新 方法 会 对 机器 的 内存 要求 很高 , 因 此 大多 研究 工作 中 采用 随机 梯度 下降 ( SGD ) 的 方法 来 更新 模型 的 训练 参数 , 即 每 输入 一定 数量 ( 批 : batch ) 的 训练 样例 , 就 利用 局部 的 训练 样例 更新 一 次 模型 参数 ; 其二 , 参数 dropout 可以 防止 系统 训练 时 出现 过 拟合 , 提高 系统 泛化 能力 ; 其三 , 数据 打乱 ( shuffle ) 也 对 翻译 结果 有 着 重要 影响 。	目前 , 影响 NMT 模型 效果 的 因素 有 很多 , 其一 , 当 训练 语料 规模 较大 时 , 梯度 下降 更新 方法 会 对 机器 的 内存 要求 很高 , 因 此 大多 研究 工作 中 采用 随机 梯度 下降 ( SGD ) 的 方法 来 更新 模型 的 训练 参数 , 即 每 输入 一定 数量 ( 批 : batch ) 的 训练 样例 , 就 利用 局部 的 训练 样例 更新 一 次 模型 参数 ; 其二 , 参数 dropout 可以 防止 系统 训练 时 出现 过 拟合 , 提高 系统 泛化 能力 ; 其三 , 数据 打乱 ( shuffle ) 也 对 翻译 结果 有 着 重要 影响 。	1<2	elab-enumember	elab-enumember
nlpabs48_Chi	40-60	61-75	其一 , 当 训练 语料 规模 较大 时 , 梯度 下降 更新 方法 会 对 机器 的 内存 要求 很高 ,	因 此 大多 研究 工作 中 采用 随机 梯度 下降 ( SGD ) 的 方法	29-142	29-142	目前 , 影响 NMT 模型 效果 的 因素 有 很多 , 其一 , 当 训练 语料 规模 较大 时 , 梯度 下降 更新 方法 会 对 机器 的 内存 要求 很高 , 因 此 大多 研究 工作 中 采用 随机 梯度 下降 ( SGD ) 的 方法 来 更新 模型 的 训练 参数 , 即 每 输入 一定 数量 ( 批 : batch ) 的 训练 样例 , 就 利用 局部 的 训练 样例 更新 一 次 模型 参数 ; 其二 , 参数 dropout 可以 防止 系统 训练 时 出现 过 拟合 , 提高 系统 泛化 能力 ; 其三 , 数据 打乱 ( shuffle ) 也 对 翻译 结果 有 着 重要 影响 。	目前 , 影响 NMT 模型 效果 的 因素 有 很多 , 其一 , 当 训练 语料 规模 较大 时 , 梯度 下降 更新 方法 会 对 机器 的 内存 要求 很高 , 因 此 大多 研究 工作 中 采用 随机 梯度 下降 ( SGD ) 的 方法 来 更新 模型 的 训练 参数 , 即 每 输入 一定 数量 ( 批 : batch ) 的 训练 样例 , 就 利用 局部 的 训练 样例 更新 一 次 模型 参数 ; 其二 , 参数 dropout 可以 防止 系统 训练 时 出现 过 拟合 , 提高 系统 泛化 能力 ; 其三 , 数据 打乱 ( shuffle ) 也 对 翻译 结果 有 着 重要 影响 。	1<2	result	result
nlpabs48_Chi	61-75	76-82	因 此 大多 研究 工作 中 采用 随机 梯度 下降 ( SGD ) 的 方法	来 更新 模型 的 训练 参数 ,	29-142	29-142	目前 , 影响 NMT 模型 效果 的 因素 有 很多 , 其一 , 当 训练 语料 规模 较大 时 , 梯度 下降 更新 方法 会 对 机器 的 内存 要求 很高 , 因 此 大多 研究 工作 中 采用 随机 梯度 下降 ( SGD ) 的 方法 来 更新 模型 的 训练 参数 , 即 每 输入 一定 数量 ( 批 : batch ) 的 训练 样例 , 就 利用 局部 的 训练 样例 更新 一 次 模型 参数 ; 其二 , 参数 dropout 可以 防止 系统 训练 时 出现 过 拟合 , 提高 系统 泛化 能力 ; 其三 , 数据 打乱 ( shuffle ) 也 对 翻译 结果 有 着 重要 影响 。	目前 , 影响 NMT 模型 效果 的 因素 有 很多 , 其一 , 当 训练 语料 规模 较大 时 , 梯度 下降 更新 方法 会 对 机器 的 内存 要求 很高 , 因 此 大多 研究 工作 中 采用 随机 梯度 下降 ( SGD ) 的 方法 来 更新 模型 的 训练 参数 , 即 每 输入 一定 数量 ( 批 : batch ) 的 训练 样例 , 就 利用 局部 的 训练 样例 更新 一 次 模型 参数 ; 其二 , 参数 dropout 可以 防止 系统 训练 时 出现 过 拟合 , 提高 系统 泛化 能力 ; 其三 , 数据 打乱 ( shuffle ) 也 对 翻译 结果 有 着 重要 影响 。	1<2	enablement	enablement
nlpabs48_Chi	61-75	83-96	因 此 大多 研究 工作 中 采用 随机 梯度 下降 ( SGD ) 的 方法	即 每 输入 一定 数量 ( 批 : batch ) 的 训练 样例 ,	29-142	29-142	目前 , 影响 NMT 模型 效果 的 因素 有 很多 , 其一 , 当 训练 语料 规模 较大 时 , 梯度 下降 更新 方法 会 对 机器 的 内存 要求 很高 , 因 此 大多 研究 工作 中 采用 随机 梯度 下降 ( SGD ) 的 方法 来 更新 模型 的 训练 参数 , 即 每 输入 一定 数量 ( 批 : batch ) 的 训练 样例 , 就 利用 局部 的 训练 样例 更新 一 次 模型 参数 ; 其二 , 参数 dropout 可以 防止 系统 训练 时 出现 过 拟合 , 提高 系统 泛化 能力 ; 其三 , 数据 打乱 ( shuffle ) 也 对 翻译 结果 有 着 重要 影响 。	目前 , 影响 NMT 模型 效果 的 因素 有 很多 , 其一 , 当 训练 语料 规模 较大 时 , 梯度 下降 更新 方法 会 对 机器 的 内存 要求 很高 , 因 此 大多 研究 工作 中 采用 随机 梯度 下降 ( SGD ) 的 方法 来 更新 模型 的 训练 参数 , 即 每 输入 一定 数量 ( 批 : batch ) 的 训练 样例 , 就 利用 局部 的 训练 样例 更新 一 次 模型 参数 ; 其二 , 参数 dropout 可以 防止 系统 训练 时 出现 过 拟合 , 提高 系统 泛化 能力 ; 其三 , 数据 打乱 ( shuffle ) 也 对 翻译 结果 有 着 重要 影响 。	1<2	elab-addition	elab-addition
nlpabs48_Chi	83-96	97-108	即 每 输入 一定 数量 ( 批 : batch ) 的 训练 样例 ,	就 利用 局部 的 训练 样例 更新 一 次 模型 参数 ;	29-142	29-142	目前 , 影响 NMT 模型 效果 的 因素 有 很多 , 其一 , 当 训练 语料 规模 较大 时 , 梯度 下降 更新 方法 会 对 机器 的 内存 要求 很高 , 因 此 大多 研究 工作 中 采用 随机 梯度 下降 ( SGD ) 的 方法 来 更新 模型 的 训练 参数 , 即 每 输入 一定 数量 ( 批 : batch ) 的 训练 样例 , 就 利用 局部 的 训练 样例 更新 一 次 模型 参数 ; 其二 , 参数 dropout 可以 防止 系统 训练 时 出现 过 拟合 , 提高 系统 泛化 能力 ; 其三 , 数据 打乱 ( shuffle ) 也 对 翻译 结果 有 着 重要 影响 。	目前 , 影响 NMT 模型 效果 的 因素 有 很多 , 其一 , 当 训练 语料 规模 较大 时 , 梯度 下降 更新 方法 会 对 机器 的 内存 要求 很高 , 因 此 大多 研究 工作 中 采用 随机 梯度 下降 ( SGD ) 的 方法 来 更新 模型 的 训练 参数 , 即 每 输入 一定 数量 ( 批 : batch ) 的 训练 样例 , 就 利用 局部 的 训练 样例 更新 一 次 模型 参数 ; 其二 , 参数 dropout 可以 防止 系统 训练 时 出现 过 拟合 , 提高 系统 泛化 能力 ; 其三 , 数据 打乱 ( shuffle ) 也 对 翻译 结果 有 着 重要 影响 。	1<2	elab-addition	elab-addition
nlpabs48_Chi	40-60	109-121	其一 , 当 训练 语料 规模 较大 时 , 梯度 下降 更新 方法 会 对 机器 的 内存 要求 很高 ,	其二 , 参数 dropout 可以 防止 系统 训练 时 出现 过 拟合 ,	29-142	29-142	目前 , 影响 NMT 模型 效果 的 因素 有 很多 , 其一 , 当 训练 语料 规模 较大 时 , 梯度 下降 更新 方法 会 对 机器 的 内存 要求 很高 , 因 此 大多 研究 工作 中 采用 随机 梯度 下降 ( SGD ) 的 方法 来 更新 模型 的 训练 参数 , 即 每 输入 一定 数量 ( 批 : batch ) 的 训练 样例 , 就 利用 局部 的 训练 样例 更新 一 次 模型 参数 ; 其二 , 参数 dropout 可以 防止 系统 训练 时 出现 过 拟合 , 提高 系统 泛化 能力 ; 其三 , 数据 打乱 ( shuffle ) 也 对 翻译 结果 有 着 重要 影响 。	目前 , 影响 NMT 模型 效果 的 因素 有 很多 , 其一 , 当 训练 语料 规模 较大 时 , 梯度 下降 更新 方法 会 对 机器 的 内存 要求 很高 , 因 此 大多 研究 工作 中 采用 随机 梯度 下降 ( SGD ) 的 方法 来 更新 模型 的 训练 参数 , 即 每 输入 一定 数量 ( 批 : batch ) 的 训练 样例 , 就 利用 局部 的 训练 样例 更新 一 次 模型 参数 ; 其二 , 参数 dropout 可以 防止 系统 训练 时 出现 过 拟合 , 提高 系统 泛化 能力 ; 其三 , 数据 打乱 ( shuffle ) 也 对 翻译 结果 有 着 重要 影响 。	1<2	joint	joint
nlpabs48_Chi	109-121	122-126	其二 , 参数 dropout 可以 防止 系统 训练 时 出现 过 拟合 ,	提高 系统 泛化 能力 ;	29-142	29-142	目前 , 影响 NMT 模型 效果 的 因素 有 很多 , 其一 , 当 训练 语料 规模 较大 时 , 梯度 下降 更新 方法 会 对 机器 的 内存 要求 很高 , 因 此 大多 研究 工作 中 采用 随机 梯度 下降 ( SGD ) 的 方法 来 更新 模型 的 训练 参数 , 即 每 输入 一定 数量 ( 批 : batch ) 的 训练 样例 , 就 利用 局部 的 训练 样例 更新 一 次 模型 参数 ; 其二 , 参数 dropout 可以 防止 系统 训练 时 出现 过 拟合 , 提高 系统 泛化 能力 ; 其三 , 数据 打乱 ( shuffle ) 也 对 翻译 结果 有 着 重要 影响 。	目前 , 影响 NMT 模型 效果 的 因素 有 很多 , 其一 , 当 训练 语料 规模 较大 时 , 梯度 下降 更新 方法 会 对 机器 的 内存 要求 很高 , 因 此 大多 研究 工作 中 采用 随机 梯度 下降 ( SGD ) 的 方法 来 更新 模型 的 训练 参数 , 即 每 输入 一定 数量 ( 批 : batch ) 的 训练 样例 , 就 利用 局部 的 训练 样例 更新 一 次 模型 参数 ; 其二 , 参数 dropout 可以 防止 系统 训练 时 出现 过 拟合 , 提高 系统 泛化 能力 ; 其三 , 数据 打乱 ( shuffle ) 也 对 翻译 结果 有 着 重要 影响 。	1<2	elab-addition	elab-addition
nlpabs48_Chi	40-60	127-142	其一 , 当 训练 语料 规模 较大 时 , 梯度 下降 更新 方法 会 对 机器 的 内存 要求 很高 ,	其三 , 数据 打乱 ( shuffle ) 也 对 翻译 结果 有 着 重要 影响 。	29-142	29-142	目前 , 影响 NMT 模型 效果 的 因素 有 很多 , 其一 , 当 训练 语料 规模 较大 时 , 梯度 下降 更新 方法 会 对 机器 的 内存 要求 很高 , 因 此 大多 研究 工作 中 采用 随机 梯度 下降 ( SGD ) 的 方法 来 更新 模型 的 训练 参数 , 即 每 输入 一定 数量 ( 批 : batch ) 的 训练 样例 , 就 利用 局部 的 训练 样例 更新 一 次 模型 参数 ; 其二 , 参数 dropout 可以 防止 系统 训练 时 出现 过 拟合 , 提高 系统 泛化 能力 ; 其三 , 数据 打乱 ( shuffle ) 也 对 翻译 结果 有 着 重要 影响 。	目前 , 影响 NMT 模型 效果 的 因素 有 很多 , 其一 , 当 训练 语料 规模 较大 时 , 梯度 下降 更新 方法 会 对 机器 的 内存 要求 很高 , 因 此 大多 研究 工作 中 采用 随机 梯度 下降 ( SGD ) 的 方法 来 更新 模型 的 训练 参数 , 即 每 输入 一定 数量 ( 批 : batch ) 的 训练 样例 , 就 利用 局部 的 训练 样例 更新 一 次 模型 参数 ; 其二 , 参数 dropout 可以 防止 系统 训练 时 出现 过 拟合 , 提高 系统 泛化 能力 ; 其三 , 数据 打乱 ( shuffle ) 也 对 翻译 结果 有 着 重要 影响 。	1<2	joint	joint
nlpabs48_Chi	143-175	176-182	因 此 , 该文 的 研究 内容 主要 是 探索 批 、 dropout 和 打乱 这 三 个 因素 在 训练 神经 机器 翻译 模型 中 对 模型 翻译 质量 的 影响 ,	并 得出 以下 三 条 结论 :	143-233	143-233	因 此 , 该文 的 研究 内容 主要 是 探索 批 、 dropout 和 打乱 这 三 个 因素 在 训练 神经 机器 翻译 模型 中 对 模型 翻译 质量 的 影响 , 并 得出 以下 三 条 结论 : 一 是 批 的 大 小将 影响 神经 机器 翻译 ( NMT ) 模型 的 收敛 速度 , 二 是 dropout 可以 提升 神经 机器 翻译 模型 的 性能 , 三 是 数据 打乱 可以 在 一定 程度 上 提升 神经 机器 翻译 ( NMT ) 系统 的 翻译 质量 。	因 此 , 该文 的 研究 内容 主要 是 探索 批 、 dropout 和 打乱 这 三 个 因素 在 训练 神经 机器 翻译 模型 中 对 模型 翻译 质量 的 影响 , 并 得出 以下 三 条 结论 : 一 是 批 的 大 小将 影响 神经 机器 翻译 ( NMT ) 模型 的 收敛 速度 , 二 是 dropout 可以 提升 神经 机器 翻译 模型 的 性能 , 三 是 数据 打乱 可以 在 一定 程度 上 提升 神经 机器 翻译 ( NMT ) 系统 的 翻译 质量 。	1<2	elab-addition	elab-addition
nlpabs48_Chi	176-182	183-200	并 得出 以下 三 条 结论 :	一 是 批 的 大 小将 影响 神经 机器 翻译 ( NMT ) 模型 的 收敛 速度 ,	143-233	143-233	因 此 , 该文 的 研究 内容 主要 是 探索 批 、 dropout 和 打乱 这 三 个 因素 在 训练 神经 机器 翻译 模型 中 对 模型 翻译 质量 的 影响 , 并 得出 以下 三 条 结论 : 一 是 批 的 大 小将 影响 神经 机器 翻译 ( NMT ) 模型 的 收敛 速度 , 二 是 dropout 可以 提升 神经 机器 翻译 模型 的 性能 , 三 是 数据 打乱 可以 在 一定 程度 上 提升 神经 机器 翻译 ( NMT ) 系统 的 翻译 质量 。	因 此 , 该文 的 研究 内容 主要 是 探索 批 、 dropout 和 打乱 这 三 个 因素 在 训练 神经 机器 翻译 模型 中 对 模型 翻译 质量 的 影响 , 并 得出 以下 三 条 结论 : 一 是 批 的 大 小将 影响 神经 机器 翻译 ( NMT ) 模型 的 收敛 速度 , 二 是 dropout 可以 提升 神经 机器 翻译 模型 的 性能 , 三 是 数据 打乱 可以 在 一定 程度 上 提升 神经 机器 翻译 ( NMT ) 系统 的 翻译 质量 。	1<2	elab-enumember	elab-enumember
nlpabs48_Chi	183-200	201-212	一 是 批 的 大 小将 影响 神经 机器 翻译 ( NMT ) 模型 的 收敛 速度 ,	二 是 dropout 可以 提升 神经 机器 翻译 模型 的 性能 ,	143-233	143-233	因 此 , 该文 的 研究 内容 主要 是 探索 批 、 dropout 和 打乱 这 三 个 因素 在 训练 神经 机器 翻译 模型 中 对 模型 翻译 质量 的 影响 , 并 得出 以下 三 条 结论 : 一 是 批 的 大 小将 影响 神经 机器 翻译 ( NMT ) 模型 的 收敛 速度 , 二 是 dropout 可以 提升 神经 机器 翻译 模型 的 性能 , 三 是 数据 打乱 可以 在 一定 程度 上 提升 神经 机器 翻译 ( NMT ) 系统 的 翻译 质量 。	因 此 , 该文 的 研究 内容 主要 是 探索 批 、 dropout 和 打乱 这 三 个 因素 在 训练 神经 机器 翻译 模型 中 对 模型 翻译 质量 的 影响 , 并 得出 以下 三 条 结论 : 一 是 批 的 大 小将 影响 神经 机器 翻译 ( NMT ) 模型 的 收敛 速度 , 二 是 dropout 可以 提升 神经 机器 翻译 模型 的 性能 , 三 是 数据 打乱 可以 在 一定 程度 上 提升 神经 机器 翻译 ( NMT ) 系统 的 翻译 质量 。	1<2	joint	joint
nlpabs48_Chi	183-200	213-233	一 是 批 的 大 小将 影响 神经 机器 翻译 ( NMT ) 模型 的 收敛 速度 ,	三 是 数据 打乱 可以 在 一定 程度 上 提升 神经 机器 翻译 ( NMT ) 系统 的 翻译 质量 。	143-233	143-233	因 此 , 该文 的 研究 内容 主要 是 探索 批 、 dropout 和 打乱 这 三 个 因素 在 训练 神经 机器 翻译 模型 中 对 模型 翻译 质量 的 影响 , 并 得出 以下 三 条 结论 : 一 是 批 的 大 小将 影响 神经 机器 翻译 ( NMT ) 模型 的 收敛 速度 , 二 是 dropout 可以 提升 神经 机器 翻译 模型 的 性能 , 三 是 数据 打乱 可以 在 一定 程度 上 提升 神经 机器 翻译 ( NMT ) 系统 的 翻译 质量 。	因 此 , 该文 的 研究 内容 主要 是 探索 批 、 dropout 和 打乱 这 三 个 因素 在 训练 神经 机器 翻译 模型 中 对 模型 翻译 质量 的 影响 , 并 得出 以下 三 条 结论 : 一 是 批 的 大 小将 影响 神经 机器 翻译 ( NMT ) 模型 的 收敛 速度 , 二 是 dropout 可以 提升 神经 机器 翻译 模型 的 性能 , 三 是 数据 打乱 可以 在 一定 程度 上 提升 神经 机器 翻译 ( NMT ) 系统 的 翻译 质量 。	1<2	joint	joint
nlpabs49_Chi	1-15	16-37	该文 探讨 了 基 于 RNN 和 CNN 的 蒙汉 神经 机器 翻译 模型 ,	分别 采用 蒙古 语 的 词 模型 、 切分 模型 和 子 词 模型 作 为 翻译 系统 的 输入 信号 ,	1-51	1-51	该文 探讨 了 基 于 RNN 和 CNN 的 蒙汉 神经 机器 翻译 模型 , 分别 采用 蒙古 语 的 词 模型 、 切分 模型 和 子 词 模型 作 为 翻译 系统 的 输入 信号 , 并 与 传统 的 基 于 短语 的 SMT 进行 了 比较 分析 。	该文 探讨 了 基 于 RNN 和 CNN 的 蒙汉 神经 机器 翻译 模型 , 分别 采用 蒙古 语 的 词 模型 、 切分 模型 和 子 词 模型 作 为 翻译 系统 的 输入 信号 , 并 与 传统 的 基 于 短语 的 SMT 进行 了 比较 分析 。	1<2	elab-addition	elab-addition
nlpabs49_Chi	1-15	38-51	该文 探讨 了 基 于 RNN 和 CNN 的 蒙汉 神经 机器 翻译 模型 ,	并 与 传统 的 基 于 短语 的 SMT 进行 了 比较 分析 。	1-51	1-51	该文 探讨 了 基 于 RNN 和 CNN 的 蒙汉 神经 机器 翻译 模型 , 分别 采用 蒙古 语 的 词 模型 、 切分 模型 和 子 词 模型 作 为 翻译 系统 的 输入 信号 , 并 与 传统 的 基 于 短语 的 SMT 进行 了 比较 分析 。	该文 探讨 了 基 于 RNN 和 CNN 的 蒙汉 神经 机器 翻译 模型 , 分别 采用 蒙古 语 的 词 模型 、 切分 模型 和 子 词 模型 作 为 翻译 系统 的 输入 信号 , 并 与 传统 的 基 于 短语 的 SMT 进行 了 比较 分析 。	1<2	joint	joint
nlpabs49_Chi	52-55	56-70	实验 结果 表明 ,	子词 模型 可以 有效 地 提高 RNN NMT 和 CNN NMT 的 翻译 质量 。	52-70	52-70	实验 结果 表明 , 子词 模型 可以 有效 地 提高 RNN NMT 和 CNN NMT 的 翻译 质量 。	实验 结果 表明 , 子词 模型 可以 有效 地 提高 RNN NMT 和 CNN NMT 的 翻译 质量 。	1>2	attribution	attribution
nlpabs49_Chi	1-15	56-70	该文 探讨 了 基 于 RNN 和 CNN 的 蒙汉 神经 机器 翻译 模型 ,	子词 模型 可以 有效 地 提高 RNN NMT 和 CNN NMT 的 翻译 质量 。	1-51	52-70	该文 探讨 了 基 于 RNN 和 CNN 的 蒙汉 神经 机器 翻译 模型 , 分别 采用 蒙古 语 的 词 模型 、 切分 模型 和 子 词 模型 作 为 翻译 系统 的 输入 信号 , 并 与 传统 的 基 于 短语 的 SMT 进行 了 比较 分析 。	实验 结果 表明 , 子词 模型 可以 有效 地 提高 RNN NMT 和 CNN NMT 的 翻译 质量 。	1<2	evaluation	evaluation
nlpabs49_Chi	71-76	77-99	同时 实验 结果 也 表明 ,	基 于 RNN 的 蒙汉 NMT 模型 的 翻译 性 能 已经 超过 传统 的 基 于 短语 的 蒙汉 SMT 模型 。	71-99	71-99	同时 实验 结果 也 表明 , 基 于 RNN 的 蒙汉 NMT 模型 的 翻译 性 能 已经 超过 传统 的 基 于 短语 的 蒙汉 SMT 模型 。	同时 实验 结果 也 表明 , 基 于 RNN 的 蒙汉 NMT 模型 的 翻译 性 能 已经 超过 传统 的 基 于 短语 的 蒙汉 SMT 模型 。	1>2	attribution	attribution
nlpabs49_Chi	56-70	77-99	子词 模型 可以 有效 地 提高 RNN NMT 和 CNN NMT 的 翻译 质量 。	基 于 RNN 的 蒙汉 NMT 模型 的 翻译 性 能 已经 超过 传统 的 基 于 短语 的 蒙汉 SMT 模型 。	52-70	71-99	实验 结果 表明 , 子词 模型 可以 有效 地 提高 RNN NMT 和 CNN NMT 的 翻译 质量 。	同时 实验 结果 也 表明 , 基 于 RNN 的 蒙汉 NMT 模型 的 翻译 性 能 已经 超过 传统 的 基 于 短语 的 蒙汉 SMT 模型 。	1<2	joint	joint
nlpabs4_Chi	1-17	28-46	﻿自动 问答 技术 是 自然 语言 处理 领域 中 一 个 非常 热门 的 研究 方向 ,	本 文 介绍 了 自动 问答 技术 的 发展 现状 和 自动 问答 系统 中 常用 的 技术 。	1-27	28-46	﻿自动 问答 技术 是 自然 语言 处理 领域 中 一 个 非常 热门 的 研究 方向 , 它 综合 运用 了 各种 自然 语言 处理 技术 。	本 文 介绍 了 自动 问答 技术 的 发展 现状 和 自动 问答 系统 中 常用 的 技术 。	1>2	bg-general	bg-general
nlpabs4_Chi	1-17	18-27	﻿自动 问答 技术 是 自然 语言 处理 领域 中 一 个 非常 热门 的 研究 方向 ,	它 综合 运用 了 各种 自然 语言 处理 技术 。	1-27	1-27	﻿自动 问答 技术 是 自然 语言 处理 领域 中 一 个 非常 热门 的 研究 方向 , 它 综合 运用 了 各种 自然 语言 处理 技术 。	﻿自动 问答 技术 是 自然 语言 处理 领域 中 一 个 非常 热门 的 研究 方向 , 它 综合 运用 了 各种 自然 语言 处理 技术 。	1<2	elab-addition	elab-addition
nlpabs4_Chi	28-46	47-57	本 文 介绍 了 自动 问答 技术 的 发展 现状 和 自动 问答 系统 中 常用 的 技术 。	自动 问答 系统 一般 包括 三 个 主要 组成 部分 :	28-46	47-66	本 文 介绍 了 自动 问答 技术 的 发展 现状 和 自动 问答 系统 中 常用 的 技术 。	自动 问答 系统 一般 包括 三 个 主要 组成 部分 : 问题 分析 、 信息 检索 和 答案 抽取 。	1<2	elab-addition	elab-addition
nlpabs4_Chi	47-57	58-66	自动 问答 系统 一般 包括 三 个 主要 组成 部分 :	问题 分析 、 信息 检索 和 答案 抽取 。	47-66	47-66	自动 问答 系统 一般 包括 三 个 主要 组成 部分 : 问题 分析 、 信息 检索 和 答案 抽取 。	自动 问答 系统 一般 包括 三 个 主要 组成 部分 : 问题 分析 、 信息 检索 和 答案 抽取 。	1<2	elab-enumember	elab-enumember
nlpabs4_Chi	47-57	67-85	自动 问答 系统 一般 包括 三 个 主要 组成 部分 :	本 文 分别 介绍 了 这 三 个 主要 组成 部分 的 主要 功能 和 常用 的 方法 。	47-66	67-85	自动 问答 系统 一般 包括 三 个 主要 组成 部分 : 问题 分析 、 信息 检索 和 答案 抽取 。	本 文 分别 介绍 了 这 三 个 主要 组成 部分 的 主要 功能 和 常用 的 方法 。	1<2	elab-addition	elab-addition
nlpabs4_Chi	28-46	86-96	本 文 介绍 了 自动 问答 技术 的 发展 现状 和 自动 问答 系统 中 常用 的 技术 。	最后 还 介绍 了 自动 问答 系统 的 评价 问题 。	28-46	86-96	本 文 介绍 了 自动 问答 技术 的 发展 现状 和 自动 问答 系统 中 常用 的 技术 。	最后 还 介绍 了 自动 问答 系统 的 评价 问题 。	1<2	elab-aspect	elab-aspect
nlpabs50_Chi	1-12	33-43	统计 机器 翻译 可以 通过 统计 方法 预测 出 目标 词 ,	利用 一 种 基 于 门控 单元 循环 神经 网络 结构	1-28	29-96	统计 机器 翻译 可以 通过 统计 方法 预测 出 目标 词 , 但 没有 充分 理解 原 文 语义 关系 , 因而 得到 的 译文 质量 不高 。	针对 该 问题 , 利用 一 种 基 于 门控 单元 循环 神经 网络 结构 来 对 蒙汉 神经 机器 翻译 系统 进行 建模 , 引入 注意 力 机 制 来 获取 双 语 词语 的 对齐 信息 , 并 在 构建 字典 过程 中 对 双 语 词语 进行 词性 标注 来 强化 语义 , 以 此 来 缓解 因 欠 训练 导致 的 错译 问题 。	1>2	bg-goal	bg-goal
nlpabs50_Chi	1-12	13-21	统计 机器 翻译 可以 通过 统计 方法 预测 出 目标 词 ,	但 没有 充分 理解 原 文 语义 关系 ,	1-28	1-28	统计 机器 翻译 可以 通过 统计 方法 预测 出 目标 词 , 但 没有 充分 理解 原 文 语义 关系 , 因而 得到 的 译文 质量 不高 。	统计 机器 翻译 可以 通过 统计 方法 预测 出 目标 词 , 但 没有 充分 理解 原 文 语义 关系 , 因而 得到 的 译文 质量 不高 。	1<2	elab-addition	elab-addition
nlpabs50_Chi	13-21	22-28	但 没有 充分 理解 原 文 语义 关系 ,	因而 得到 的 译文 质量 不高 。	1-28	1-28	统计 机器 翻译 可以 通过 统计 方法 预测 出 目标 词 , 但 没有 充分 理解 原 文 语义 关系 , 因而 得到 的 译文 质量 不高 。	统计 机器 翻译 可以 通过 统计 方法 预测 出 目标 词 , 但 没有 充分 理解 原 文 语义 关系 , 因而 得到 的 译文 质量 不高 。	1<2	result	result
nlpabs50_Chi	29-32	33-43	针对 该 问题 ,	利用 一 种 基 于 门控 单元 循环 神经 网络 结构	29-96	29-96	针对 该 问题 , 利用 一 种 基 于 门控 单元 循环 神经 网络 结构 来 对 蒙汉 神经 机器 翻译 系统 进行 建模 , 引入 注意 力 机 制 来 获取 双 语 词语 的 对齐 信息 , 并 在 构建 字典 过程 中 对 双 语 词语 进行 词性 标注 来 强化 语义 , 以 此 来 缓解 因 欠 训练 导致 的 错译 问题 。	针对 该 问题 , 利用 一 种 基 于 门控 单元 循环 神经 网络 结构 来 对 蒙汉 神经 机器 翻译 系统 进行 建模 , 引入 注意 力 机 制 来 获取 双 语 词语 的 对齐 信息 , 并 在 构建 字典 过程 中 对 双 语 词语 进行 词性 标注 来 强化 语义 , 以 此 来 缓解 因 欠 训练 导致 的 错译 问题 。	1>2	bg-general	bg-general
nlpabs50_Chi	33-43	44-53	利用 一 种 基 于 门控 单元 循环 神经 网络 结构	来 对 蒙汉 神经 机器 翻译 系统 进行 建模 ,	29-96	29-96	针对 该 问题 , 利用 一 种 基 于 门控 单元 循环 神经 网络 结构 来 对 蒙汉 神经 机器 翻译 系统 进行 建模 , 引入 注意 力 机 制 来 获取 双 语 词语 的 对齐 信息 , 并 在 构建 字典 过程 中 对 双 语 词语 进行 词性 标注 来 强化 语义 , 以 此 来 缓解 因 欠 训练 导致 的 错译 问题 。	针对 该 问题 , 利用 一 种 基 于 门控 单元 循环 神经 网络 结构 来 对 蒙汉 神经 机器 翻译 系统 进行 建模 , 引入 注意 力 机 制 来 获取 双 语 词语 的 对齐 信息 , 并 在 构建 字典 过程 中 对 双 语 词语 进行 词性 标注 来 强化 语义 , 以 此 来 缓解 因 欠 训练 导致 的 错译 问题 。	1<2	enablement	enablement
nlpabs50_Chi	33-43	54-58	利用 一 种 基 于 门控 单元 循环 神经 网络 结构	引入 注意 力 机 制	29-96	29-96	针对 该 问题 , 利用 一 种 基 于 门控 单元 循环 神经 网络 结构 来 对 蒙汉 神经 机器 翻译 系统 进行 建模 , 引入 注意 力 机 制 来 获取 双 语 词语 的 对齐 信息 , 并 在 构建 字典 过程 中 对 双 语 词语 进行 词性 标注 来 强化 语义 , 以 此 来 缓解 因 欠 训练 导致 的 错译 问题 。	针对 该 问题 , 利用 一 种 基 于 门控 单元 循环 神经 网络 结构 来 对 蒙汉 神经 机器 翻译 系统 进行 建模 , 引入 注意 力 机 制 来 获取 双 语 词语 的 对齐 信息 , 并 在 构建 字典 过程 中 对 双 语 词语 进行 词性 标注 来 强化 语义 , 以 此 来 缓解 因 欠 训练 导致 的 错译 问题 。	1<2	joint	joint
nlpabs50_Chi	54-58	59-67	引入 注意 力 机 制	来 获取 双 语 词语 的 对齐 信息 ,	29-96	29-96	针对 该 问题 , 利用 一 种 基 于 门控 单元 循环 神经 网络 结构 来 对 蒙汉 神经 机器 翻译 系统 进行 建模 , 引入 注意 力 机 制 来 获取 双 语 词语 的 对齐 信息 , 并 在 构建 字典 过程 中 对 双 语 词语 进行 词性 标注 来 强化 语义 , 以 此 来 缓解 因 欠 训练 导致 的 错译 问题 。	针对 该 问题 , 利用 一 种 基 于 门控 单元 循环 神经 网络 结构 来 对 蒙汉 神经 机器 翻译 系统 进行 建模 , 引入 注意 力 机 制 来 获取 双 语 词语 的 对齐 信息 , 并 在 构建 字典 过程 中 对 双 语 词语 进行 词性 标注 来 强化 语义 , 以 此 来 缓解 因 欠 训练 导致 的 错译 问题 。	1<2	enablement	enablement
nlpabs50_Chi	68-73	74-80	并 在 构建 字典 过程 中	对 双 语 词语 进行 词性 标注	29-96	29-96	针对 该 问题 , 利用 一 种 基 于 门控 单元 循环 神经 网络 结构 来 对 蒙汉 神经 机器 翻译 系统 进行 建模 , 引入 注意 力 机 制 来 获取 双 语 词语 的 对齐 信息 , 并 在 构建 字典 过程 中 对 双 语 词语 进行 词性 标注 来 强化 语义 , 以 此 来 缓解 因 欠 训练 导致 的 错译 问题 。	针对 该 问题 , 利用 一 种 基 于 门控 单元 循环 神经 网络 结构 来 对 蒙汉 神经 机器 翻译 系统 进行 建模 , 引入 注意 力 机 制 来 获取 双 语 词语 的 对齐 信息 , 并 在 构建 字典 过程 中 对 双 语 词语 进行 词性 标注 来 强化 语义 , 以 此 来 缓解 因 欠 训练 导致 的 错译 问题 。	1>2	temporal	temporal
nlpabs50_Chi	54-58	74-80	引入 注意 力 机 制	对 双 语 词语 进行 词性 标注	29-96	29-96	针对 该 问题 , 利用 一 种 基 于 门控 单元 循环 神经 网络 结构 来 对 蒙汉 神经 机器 翻译 系统 进行 建模 , 引入 注意 力 机 制 来 获取 双 语 词语 的 对齐 信息 , 并 在 构建 字典 过程 中 对 双 语 词语 进行 词性 标注 来 强化 语义 , 以 此 来 缓解 因 欠 训练 导致 的 错译 问题 。	针对 该 问题 , 利用 一 种 基 于 门控 单元 循环 神经 网络 结构 来 对 蒙汉 神经 机器 翻译 系统 进行 建模 , 引入 注意 力 机 制 来 获取 双 语 词语 的 对齐 信息 , 并 在 构建 字典 过程 中 对 双 语 词语 进行 词性 标注 来 强化 语义 , 以 此 来 缓解 因 欠 训练 导致 的 错译 问题 。	1<2	joint	joint
nlpabs50_Chi	74-80	81-84	对 双 语 词语 进行 词性 标注	来 强化 语义 ,	29-96	29-96	针对 该 问题 , 利用 一 种 基 于 门控 单元 循环 神经 网络 结构 来 对 蒙汉 神经 机器 翻译 系统 进行 建模 , 引入 注意 力 机 制 来 获取 双 语 词语 的 对齐 信息 , 并 在 构建 字典 过程 中 对 双 语 词语 进行 词性 标注 来 强化 语义 , 以 此 来 缓解 因 欠 训练 导致 的 错译 问题 。	针对 该 问题 , 利用 一 种 基 于 门控 单元 循环 神经 网络 结构 来 对 蒙汉 神经 机器 翻译 系统 进行 建模 , 引入 注意 力 机 制 来 获取 双 语 词语 的 对齐 信息 , 并 在 构建 字典 过程 中 对 双 语 词语 进行 词性 标注 来 强化 语义 , 以 此 来 缓解 因 欠 训练 导致 的 错译 问题 。	1<2	enablement	enablement
nlpabs50_Chi	81-84	85-96	来 强化 语义 ,	以 此 来 缓解 因 欠 训练 导致 的 错译 问题 。	29-96	29-96	针对 该 问题 , 利用 一 种 基 于 门控 单元 循环 神经 网络 结构 来 对 蒙汉 神经 机器 翻译 系统 进行 建模 , 引入 注意 力 机 制 来 获取 双 语 词语 的 对齐 信息 , 并 在 构建 字典 过程 中 对 双 语 词语 进行 词性 标注 来 强化 语义 , 以 此 来 缓解 因 欠 训练 导致 的 错译 问题 。	针对 该 问题 , 利用 一 种 基 于 门控 单元 循环 神经 网络 结构 来 对 蒙汉 神经 机器 翻译 系统 进行 建模 , 引入 注意 力 机 制 来 获取 双 语 词语 的 对齐 信息 , 并 在 构建 字典 过程 中 对 双 语 词语 进行 词性 标注 来 强化 语义 , 以 此 来 缓解 因 欠 训练 导致 的 错译 问题 。	1<2	enablement	enablement
nlpabs50_Chi	97-100	115-123	实验 结果 表明 ,	该 方法 BLEU 值 得到 一定 的 提升 。	97-123	97-123	实验 结果 表明 , 与 RNN 的 基准 系统 和 传统 的 统计 机器 翻译 方法 相比 , 该 方法 BLEU 值 得到 一定 的 提升 。	实验 结果 表明 , 与 RNN 的 基准 系统 和 传统 的 统计 机器 翻译 方法 相比 , 该 方法 BLEU 值 得到 一定 的 提升 。	1>2	attribution	attribution
nlpabs50_Chi	101-114	115-123	与 RNN 的 基准 系统 和 传统 的 统计 机器 翻译 方法 相比 ,	该 方法 BLEU 值 得到 一定 的 提升 。	97-123	97-123	实验 结果 表明 , 与 RNN 的 基准 系统 和 传统 的 统计 机器 翻译 方法 相比 , 该 方法 BLEU 值 得到 一定 的 提升 。	实验 结果 表明 , 与 RNN 的 基准 系统 和 传统 的 统计 机器 翻译 方法 相比 , 该 方法 BLEU 值 得到 一定 的 提升 。	1>2	comparison	comparison
nlpabs50_Chi	33-43	115-123	利用 一 种 基 于 门控 单元 循环 神经 网络 结构	该 方法 BLEU 值 得到 一定 的 提升 。	29-96	97-123	针对 该 问题 , 利用 一 种 基 于 门控 单元 循环 神经 网络 结构 来 对 蒙汉 神经 机器 翻译 系统 进行 建模 , 引入 注意 力 机 制 来 获取 双 语 词语 的 对齐 信息 , 并 在 构建 字典 过程 中 对 双 语 词语 进行 词性 标注 来 强化 语义 , 以 此 来 缓解 因 欠 训练 导致 的 错译 问题 。	实验 结果 表明 , 与 RNN 的 基准 系统 和 传统 的 统计 机器 翻译 方法 相比 , 该 方法 BLEU 值 得到 一定 的 提升 。	1<2	evaluation	evaluation
nlpabs51_Chi	1-14	15-19	在 哈萨克 语 句法 分析 中 , 该 文 用 平均 感知 器 算法	训练 句法 分析 模型 ,	1-40	1-40	在 哈萨克 语 句法 分析 中 , 该 文 用 平均 感知 器 算法 训练 句法 分析 模型 , 用 柱 搜索 算法 进行 解码 , 可以 快速 准确 地 对 哈萨克 语 句子 进行 短语 结构 句法 分析 。	在 哈萨克 语 句法 分析 中 , 该 文 用 平均 感知 器 算法 训练 句法 分析 模型 , 用 柱 搜索 算法 进行 解码 , 可以 快速 准确 地 对 哈萨克 语 句子 进行 短语 结构 句法 分析 。	1<2	enablement	enablement
nlpabs51_Chi	1-14	20-26	在 哈萨克 语 句法 分析 中 , 该 文 用 平均 感知 器 算法	用 柱 搜索 算法 进行 解码 ,	1-40	1-40	在 哈萨克 语 句法 分析 中 , 该 文 用 平均 感知 器 算法 训练 句法 分析 模型 , 用 柱 搜索 算法 进行 解码 , 可以 快速 准确 地 对 哈萨克 语 句子 进行 短语 结构 句法 分析 。	在 哈萨克 语 句法 分析 中 , 该 文 用 平均 感知 器 算法 训练 句法 分析 模型 , 用 柱 搜索 算法 进行 解码 , 可以 快速 准确 地 对 哈萨克 语 句子 进行 短语 结构 句法 分析 。	1<2	joint	joint
nlpabs51_Chi	1-14	27-40	在 哈萨克 语 句法 分析 中 , 该 文 用 平均 感知 器 算法	可以 快速 准确 地 对 哈萨克 语 句子 进行 短语 结构 句法 分析 。	1-40	1-40	在 哈萨克 语 句法 分析 中 , 该 文 用 平均 感知 器 算法 训练 句法 分析 模型 , 用 柱 搜索 算法 进行 解码 , 可以 快速 准确 地 对 哈萨克 语 句子 进行 短语 结构 句法 分析 。	在 哈萨克 语 句法 分析 中 , 该 文 用 平均 感知 器 算法 训练 句法 分析 模型 , 用 柱 搜索 算法 进行 解码 , 可以 快速 准确 地 对 哈萨克 语 句子 进行 短语 结构 句法 分析 。	1<2	elab-addition	elab-addition
nlpabs51_Chi	1-14	41-55	在 哈萨克 语 句法 分析 中 , 该 文 用 平均 感知 器 算法	在 解析 句子 过程 中 , 构建 了 一 个 双 向 LSTM 模型 ,	1-40	41-96	在 哈萨克 语 句法 分析 中 , 该 文 用 平均 感知 器 算法 训练 句法 分析 模型 , 用 柱 搜索 算法 进行 解码 , 可以 快速 准确 地 对 哈萨克 语 句子 进行 短语 结构 句法 分析 。	在 解析 句子 过程 中 , 构建 了 一 个 双 向 LSTM 模型 , 利 用 它 提取 句子 中 每个 单词 之间 组成 结构 的 信息 , 以 预测 每个 单词 在 句法 树 中 的 句法 组成 部分 , 然后 将 结果 作 为 辅助 前瞻 特征 传递 给 句法 分析 过程 。	1<2	elab-addition	elab-addition
nlpabs51_Chi	41-55	56-69	在 解析 句子 过程 中 , 构建 了 一 个 双 向 LSTM 模型 ,	利 用 它 提取 句子 中 每个 单词 之间 组成 结构 的 信息 ,	41-96	41-96	在 解析 句子 过程 中 , 构建 了 一 个 双 向 LSTM 模型 , 利 用 它 提取 句子 中 每个 单词 之间 组成 结构 的 信息 , 以 预测 每个 单词 在 句法 树 中 的 句法 组成 部分 , 然后 将 结果 作 为 辅助 前瞻 特征 传递 给 句法 分析 过程 。	在 解析 句子 过程 中 , 构建 了 一 个 双 向 LSTM 模型 , 利 用 它 提取 句子 中 每个 单词 之间 组成 结构 的 信息 , 以 预测 每个 单词 在 句法 树 中 的 句法 组成 部分 , 然后 将 结果 作 为 辅助 前瞻 特征 传递 给 句法 分析 过程 。	1<2	elab-addition	elab-addition
nlpabs51_Chi	56-69	70-82	利 用 它 提取 句子 中 每个 单词 之间 组成 结构 的 信息 ,	以 预测 每个 单词 在 句法 树 中 的 句法 组成 部分 ,	41-96	41-96	在 解析 句子 过程 中 , 构建 了 一 个 双 向 LSTM 模型 , 利 用 它 提取 句子 中 每个 单词 之间 组成 结构 的 信息 , 以 预测 每个 单词 在 句法 树 中 的 句法 组成 部分 , 然后 将 结果 作 为 辅助 前瞻 特征 传递 给 句法 分析 过程 。	在 解析 句子 过程 中 , 构建 了 一 个 双 向 LSTM 模型 , 利 用 它 提取 句子 中 每个 单词 之间 组成 结构 的 信息 , 以 预测 每个 单词 在 句法 树 中 的 句法 组成 部分 , 然后 将 结果 作 为 辅助 前瞻 特征 传递 给 句法 分析 过程 。	1<2	enablement	enablement
nlpabs51_Chi	41-55	83-96	在 解析 句子 过程 中 , 构建 了 一 个 双 向 LSTM 模型 ,	然后 将 结果 作 为 辅助 前瞻 特征 传递 给 句法 分析 过程 。	41-96	41-96	在 解析 句子 过程 中 , 构建 了 一 个 双 向 LSTM 模型 , 利 用 它 提取 句子 中 每个 单词 之间 组成 结构 的 信息 , 以 预测 每个 单词 在 句法 树 中 的 句法 组成 部分 , 然后 将 结果 作 为 辅助 前瞻 特征 传递 给 句法 分析 过程 。	在 解析 句子 过程 中 , 构建 了 一 个 双 向 LSTM 模型 , 利 用 它 提取 句子 中 每个 单词 之间 组成 结构 的 信息 , 以 预测 每个 单词 在 句法 树 中 的 句法 组成 部分 , 然后 将 结果 作 为 辅助 前瞻 特征 传递 给 句法 分析 过程 。	1<2	joint	joint
nlpabs51_Chi	97-99	107-117	实验 证明 ,	在 准确 率 和 召回 率 上 均 有 提高 。	97-117	97-117	实验 证明 , 此 方法 与 基线 模型 相比 , 在 准确 率 和 召回 率 上 均 有 提高 。	实验 证明 , 此 方法 与 基线 模型 相比 , 在 准确 率 和 召回 率 上 均 有 提高 。	1>2	attribution	attribution
nlpabs51_Chi	100-106	107-117	此 方法 与 基线 模型 相比 ,	在 准确 率 和 召回 率 上 均 有 提高 。	97-117	97-117	实验 证明 , 此 方法 与 基线 模型 相比 , 在 准确 率 和 召回 率 上 均 有 提高 。	实验 证明 , 此 方法 与 基线 模型 相比 , 在 准确 率 和 召回 率 上 均 有 提高 。	1>2	comparison	comparison
nlpabs51_Chi	1-14	107-117	在 哈萨克 语 句法 分析 中 , 该 文 用 平均 感知 器 算法	在 准确 率 和 召回 率 上 均 有 提高 。	1-40	97-117	在 哈萨克 语 句法 分析 中 , 该 文 用 平均 感知 器 算法 训练 句法 分析 模型 , 用 柱 搜索 算法 进行 解码 , 可以 快速 准确 地 对 哈萨克 语 句子 进行 短语 结构 句法 分析 。	实验 证明 , 此 方法 与 基线 模型 相比 , 在 准确 率 和 召回 率 上 均 有 提高 。	1<2	evaluation	evaluation
nlpabs54_Chi	1-7	94-104	我们 周围 充满 了 各种 网络 ;	该文 将 尝试 运用 类似 于 分析 社交 网络 的 方法	1-24	94-132	我们 周围 充满 了 各种 网络 ; 按照 相似 的 内在 机理 , 可以 将 它们 分 为 物理 网络 和 信息 网络 。	该文 将 尝试 运用 类似 于 分析 社交 网络 的 方法 去 分析 电信 CSB 业务 系统 服务 器 集群 上 的 进程 网络 ; 具体 地 预测 进程 网络 中 节点 的 崩溃 ( 故障 ) 状态 。	1>2	bg-general	bg-general
nlpabs54_Chi	8-13	14-24	按照 相似 的 内在 机理 ,	可以 将 它们 分 为 物理 网络 和 信息 网络 。	1-24	1-24	我们 周围 充满 了 各种 网络 ; 按照 相似 的 内在 机理 , 可以 将 它们 分 为 物理 网络 和 信息 网络 。	我们 周围 充满 了 各种 网络 ; 按照 相似 的 内在 机理 , 可以 将 它们 分 为 物理 网络 和 信息 网络 。	1>2	bg-general	bg-general
nlpabs54_Chi	1-7	14-24	我们 周围 充满 了 各种 网络 ;	可以 将 它们 分 为 物理 网络 和 信息 网络 。	1-24	1-24	我们 周围 充满 了 各种 网络 ; 按照 相似 的 内在 机理 , 可以 将 它们 分 为 物理 网络 和 信息 网络 。	我们 周围 充满 了 各种 网络 ; 按照 相似 的 内在 机理 , 可以 将 它们 分 为 物理 网络 和 信息 网络 。	1<2	elab-addition	elab-addition
nlpabs54_Chi	1-7	25-46	我们 周围 充满 了 各种 网络 ;	对于 具有 明显 物理 特征 的 网络 , 我们 可以 运用 物理 常识 解释 其 内部 结构 或 节点 的 性质 ;	1-24	25-69	我们 周围 充满 了 各种 网络 ; 按照 相似 的 内在 机理 , 可以 将 它们 分 为 物理 网络 和 信息 网络 。	对于 具有 明显 物理 特征 的 网络 , 我们 可以 运用 物理 常识 解释 其 内部 结构 或 节点 的 性质 ; 而 对于 信息 网络 , 我们 往往 需要 结合 一些 先验 知识 去 理解 , 社交 网络 正是 这样 一 个 例子 。	1<2	elab-addition	elab-addition
nlpabs54_Chi	25-46	47-61	对于 具有 明显 物理 特征 的 网络 , 我们 可以 运用 物理 常识 解释 其 内部 结构 或 节点 的 性质 ;	而 对于 信息 网络 , 我们 往往 需要 结合 一些 先验 知识 去 理解 ,	25-69	25-69	对于 具有 明显 物理 特征 的 网络 , 我们 可以 运用 物理 常识 解释 其 内部 结构 或 节点 的 性质 ; 而 对于 信息 网络 , 我们 往往 需要 结合 一些 先验 知识 去 理解 , 社交 网络 正是 这样 一 个 例子 。	对于 具有 明显 物理 特征 的 网络 , 我们 可以 运用 物理 常识 解释 其 内部 结构 或 节点 的 性质 ; 而 对于 信息 网络 , 我们 往往 需要 结合 一些 先验 知识 去 理解 , 社交 网络 正是 这样 一 个 例子 。	1<2	joint	joint
nlpabs54_Chi	47-61	62-69	而 对于 信息 网络 , 我们 往往 需要 结合 一些 先验 知识 去 理解 ,	社交 网络 正是 这样 一 个 例子 。	25-69	25-69	对于 具有 明显 物理 特征 的 网络 , 我们 可以 运用 物理 常识 解释 其 内部 结构 或 节点 的 性质 ; 而 对于 信息 网络 , 我们 往往 需要 结合 一些 先验 知识 去 理解 , 社交 网络 正是 这样 一 个 例子 。	对于 具有 明显 物理 特征 的 网络 , 我们 可以 运用 物理 常识 解释 其 内部 结构 或 节点 的 性质 ; 而 对于 信息 网络 , 我们 往往 需要 结合 一些 先验 知识 去 理解 , 社交 网络 正是 这样 一 个 例子 。	1<2	elab-addition	elab-addition
nlpabs54_Chi	47-61	70-93	而 对于 信息 网络 , 我们 往往 需要 结合 一些 先验 知识 去 理解 ,	然而 , 对于 那些 并非 具有 显著 物理 或 社交 背景 的 网络 , 以往 并 没有 明确 的 分析 思路 和 方法 。	25-69	70-93	对于 具有 明显 物理 特征 的 网络 , 我们 可以 运用 物理 常识 解释 其 内部 结构 或 节点 的 性质 ; 而 对于 信息 网络 , 我们 往往 需要 结合 一些 先验 知识 去 理解 , 社交 网络 正是 这样 一 个 例子 。	然而 , 对于 那些 并非 具有 显著 物理 或 社交 背景 的 网络 , 以往 并 没有 明确 的 分析 思路 和 方法 。	1<2	elab-addition	elab-addition
nlpabs54_Chi	94-104	105-118	该文 将 尝试 运用 类似 于 分析 社交 网络 的 方法	去 分析 电信 CSB 业务 系统 服务 器 集群 上 的 进程 网络 ;	94-132	94-132	该文 将 尝试 运用 类似 于 分析 社交 网络 的 方法 去 分析 电信 CSB 业务 系统 服务 器 集群 上 的 进程 网络 ; 具体 地 预测 进程 网络 中 节点 的 崩溃 ( 故障 ) 状态 。	该文 将 尝试 运用 类似 于 分析 社交 网络 的 方法 去 分析 电信 CSB 业务 系统 服务 器 集群 上 的 进程 网络 ; 具体 地 预测 进程 网络 中 节点 的 崩溃 ( 故障 ) 状态 。	1<2	enablement	enablement
nlpabs54_Chi	105-118	119-132	去 分析 电信 CSB 业务 系统 服务 器 集群 上 的 进程 网络 ;	具体 地 预测 进程 网络 中 节点 的 崩溃 ( 故障 ) 状态 。	94-132	94-132	该文 将 尝试 运用 类似 于 分析 社交 网络 的 方法 去 分析 电信 CSB 业务 系统 服务 器 集群 上 的 进程 网络 ; 具体 地 预测 进程 网络 中 节点 的 崩溃 ( 故障 ) 状态 。	该文 将 尝试 运用 类似 于 分析 社交 网络 的 方法 去 分析 电信 CSB 业务 系统 服务 器 集群 上 的 进程 网络 ; 具体 地 预测 进程 网络 中 节点 的 崩溃 ( 故障 ) 状态 。	1<2	joint	joint
nlpabs54_Chi	94-104	133-154	该文 将 尝试 运用 类似 于 分析 社交 网络 的 方法	在 这 个 特定 的 进程 网络 上 , 这 种 建模 和 分析 思路 得到 了 较为 可信 的 结果 ;	94-132	133-217	该文 将 尝试 运用 类似 于 分析 社交 网络 的 方法 去 分析 电信 CSB 业务 系统 服务 器 集群 上 的 进程 网络 ; 具体 地 预测 进程 网络 中 节点 的 崩溃 ( 故障 ) 状态 。	在 这 个 特定 的 进程 网络 上 , 这 种 建模 和 分析 思路 得到 了 较为 可信 的 结果 ; 研究 表明 , 进程 节点 的 运行 信息 ( 如 CPU 和 内存 使用 率 ) 、 进程 间 的 通信 情况 以及 进程 节点 在 整个 网络 中 的 结构 特征 对于 判断 该 节点 的 状态 具有 一定 的 指导 价值 , 而 上述 特征 在 时间 维度 上 的 变化 量 同样 反映 了 进程 / 端口 的 状态 。	1<2	evaluation	evaluation
nlpabs54_Chi	155-157	158-198	研究 表明 ,	进程 节点 的 运行 信息 ( 如 CPU 和 内存 使用 率 ) 、 进程 间 的 通信 情况 以及 进程 节点 在 整个 网络 中 的 结构 特征 对于 判断 该 节点 的 状态 具有 一定 的 指导 价值 ,	133-217	133-217	在 这 个 特定 的 进程 网络 上 , 这 种 建模 和 分析 思路 得到 了 较为 可信 的 结果 ; 研究 表明 , 进程 节点 的 运行 信息 ( 如 CPU 和 内存 使用 率 ) 、 进程 间 的 通信 情况 以及 进程 节点 在 整个 网络 中 的 结构 特征 对于 判断 该 节点 的 状态 具有 一定 的 指导 价值 , 而 上述 特征 在 时间 维度 上 的 变化 量 同样 反映 了 进程 / 端口 的 状态 。	在 这 个 特定 的 进程 网络 上 , 这 种 建模 和 分析 思路 得到 了 较为 可信 的 结果 ; 研究 表明 , 进程 节点 的 运行 信息 ( 如 CPU 和 内存 使用 率 ) 、 进程 间 的 通信 情况 以及 进程 节点 在 整个 网络 中 的 结构 特征 对于 判断 该 节点 的 状态 具有 一定 的 指导 价值 , 而 上述 特征 在 时间 维度 上 的 变化 量 同样 反映 了 进程 / 端口 的 状态 。	1>2	attribution	attribution
nlpabs54_Chi	133-154	158-198	在 这 个 特定 的 进程 网络 上 , 这 种 建模 和 分析 思路 得到 了 较为 可信 的 结果 ;	进程 节点 的 运行 信息 ( 如 CPU 和 内存 使用 率 ) 、 进程 间 的 通信 情况 以及 进程 节点 在 整个 网络 中 的 结构 特征 对于 判断 该 节点 的 状态 具有 一定 的 指导 价值 ,	133-217	133-217	在 这 个 特定 的 进程 网络 上 , 这 种 建模 和 分析 思路 得到 了 较为 可信 的 结果 ; 研究 表明 , 进程 节点 的 运行 信息 ( 如 CPU 和 内存 使用 率 ) 、 进程 间 的 通信 情况 以及 进程 节点 在 整个 网络 中 的 结构 特征 对于 判断 该 节点 的 状态 具有 一定 的 指导 价值 , 而 上述 特征 在 时间 维度 上 的 变化 量 同样 反映 了 进程 / 端口 的 状态 。	在 这 个 特定 的 进程 网络 上 , 这 种 建模 和 分析 思路 得到 了 较为 可信 的 结果 ; 研究 表明 , 进程 节点 的 运行 信息 ( 如 CPU 和 内存 使用 率 ) 、 进程 间 的 通信 情况 以及 进程 节点 在 整个 网络 中 的 结构 特征 对于 判断 该 节点 的 状态 具有 一定 的 指导 价值 , 而 上述 特征 在 时间 维度 上 的 变化 量 同样 反映 了 进程 / 端口 的 状态 。	1<2	joint	joint
nlpabs54_Chi	158-198	199-217	进程 节点 的 运行 信息 ( 如 CPU 和 内存 使用 率 ) 、 进程 间 的 通信 情况 以及 进程 节点 在 整个 网络 中 的 结构 特征 对于 判断 该 节点 的 状态 具有 一定 的 指导 价值 ,	而 上述 特征 在 时间 维度 上 的 变化 量 同样 反映 了 进程 / 端口 的 状态 。	133-217	133-217	在 这 个 特定 的 进程 网络 上 , 这 种 建模 和 分析 思路 得到 了 较为 可信 的 结果 ; 研究 表明 , 进程 节点 的 运行 信息 ( 如 CPU 和 内存 使用 率 ) 、 进程 间 的 通信 情况 以及 进程 节点 在 整个 网络 中 的 结构 特征 对于 判断 该 节点 的 状态 具有 一定 的 指导 价值 , 而 上述 特征 在 时间 维度 上 的 变化 量 同样 反映 了 进程 / 端口 的 状态 。	在 这 个 特定 的 进程 网络 上 , 这 种 建模 和 分析 思路 得到 了 较为 可信 的 结果 ; 研究 表明 , 进程 节点 的 运行 信息 ( 如 CPU 和 内存 使用 率 ) 、 进程 间 的 通信 情况 以及 进程 节点 在 整个 网络 中 的 结构 特征 对于 判断 该 节点 的 状态 具有 一定 的 指导 价值 , 而 上述 特征 在 时间 维度 上 的 变化 量 同样 反映 了 进程 / 端口 的 状态 。	1<2	joint	joint
nlpabs55_Chi	1-19	74-85	复杂 网络 中 节点 之间 的 连接 强度 会 在 很大 程度 上 影响 网络 的 社区 结构 ,	提出 了 一 种 改进 的 节点 相关 度 度量 准则 。	1-43	44-85	复杂 网络 中 节点 之间 的 连接 强度 会 在 很大 程度 上 影响 网络 的 社区 结构 , 利用 权重 来 刻画 连接 强度 的 差异 性 , 并 将 其 应用 到 社区 发现 研究 中 具有 重要 的 意义 。	针 对 目前 有权 网络 的 社区 发现 方法 存在 的 不足 , 该文 结合 节点 的 直接 连边 权重 和 基 于 共同 邻居 节点 的 连边 权重 , 提出 了 一 种 改进 的 节点 相关 度 度量 准则 。	1>2	bg-general	bg-general
nlpabs55_Chi	1-19	20-43	复杂 网络 中 节点 之间 的 连接 强度 会 在 很大 程度 上 影响 网络 的 社区 结构 ,	利用 权重 来 刻画 连接 强度 的 差异 性 , 并 将 其 应用 到 社区 发现 研究 中 具有 重要 的 意义 。	1-43	1-43	复杂 网络 中 节点 之间 的 连接 强度 会 在 很大 程度 上 影响 网络 的 社区 结构 , 利用 权重 来 刻画 连接 强度 的 差异 性 , 并 将 其 应用 到 社区 发现 研究 中 具有 重要 的 意义 。	复杂 网络 中 节点 之间 的 连接 强度 会 在 很大 程度 上 影响 网络 的 社区 结构 , 利用 权重 来 刻画 连接 强度 的 差异 性 , 并 将 其 应用 到 社区 发现 研究 中 具有 重要 的 意义 。	1<2	elab-addition	elab-addition
nlpabs55_Chi	44-56	74-85	针 对 目前 有权 网络 的 社区 发现 方法 存在 的 不足 ,	提出 了 一 种 改进 的 节点 相关 度 度量 准则 。	44-85	44-85	针 对 目前 有权 网络 的 社区 发现 方法 存在 的 不足 , 该文 结合 节点 的 直接 连边 权重 和 基 于 共同 邻居 节点 的 连边 权重 , 提出 了 一 种 改进 的 节点 相关 度 度量 准则 。	针 对 目前 有权 网络 的 社区 发现 方法 存在 的 不足 , 该文 结合 节点 的 直接 连边 权重 和 基 于 共同 邻居 节点 的 连边 权重 , 提出 了 一 种 改进 的 节点 相关 度 度量 准则 。	1>2	bg-general	bg-general
nlpabs55_Chi	57-73	74-85	该文 结合 节点 的 直接 连边 权重 和 基 于 共同 邻居 节点 的 连边 权重 ,	提出 了 一 种 改进 的 节点 相关 度 度量 准则 。	44-85	44-85	针 对 目前 有权 网络 的 社区 发现 方法 存在 的 不足 , 该文 结合 节点 的 直接 连边 权重 和 基 于 共同 邻居 节点 的 连边 权重 , 提出 了 一 种 改进 的 节点 相关 度 度量 准则 。	针 对 目前 有权 网络 的 社区 发现 方法 存在 的 不足 , 该文 结合 节点 的 直接 连边 权重 和 基 于 共同 邻居 节点 的 连边 权重 , 提出 了 一 种 改进 的 节点 相关 度 度量 准则 。	1>2	manner-means	manner-means
nlpabs55_Chi	86-106	107-116	进 一 步 基 于 这 种 改进 的 节点 相关 度 度量 准则 和 团体 之间 的 聚集 方法 ,	构建 了 面向 有权 网络 的 社区 发现 模型 。	86-116	86-116	进 一 步 基 于 这 种 改进 的 节点 相关 度 度量 准则 和 团体 之间 的 聚集 方法 , 构建 了 面向 有权 网络 的 社区 发现 模型 。	进 一 步 基 于 这 种 改进 的 节点 相关 度 度量 准则 和 团体 之间 的 聚集 方法 , 构建 了 面向 有权 网络 的 社区 发现 模型 。	1>2	bg-general	bg-general
nlpabs55_Chi	74-85	107-116	提出 了 一 种 改进 的 节点 相关 度 度量 准则 。	构建 了 面向 有权 网络 的 社区 发现 模型 。	44-85	86-116	针 对 目前 有权 网络 的 社区 发现 方法 存在 的 不足 , 该文 结合 节点 的 直接 连边 权重 和 基 于 共同 邻居 节点 的 连边 权重 , 提出 了 一 种 改进 的 节点 相关 度 度量 准则 。	进 一 步 基 于 这 种 改进 的 节点 相关 度 度量 准则 和 团体 之间 的 聚集 方法 , 构建 了 面向 有权 网络 的 社区 发现 模型 。	1<2	progression	progression
nlpabs55_Chi	74-85	117-137	提出 了 一 种 改进 的 节点 相关 度 度量 准则 。	分别 在 有 权值 的 科学 家 合作 网络 和 全国 列车 网络 数据 集上 进行 了 社区 发现 实验 ,	44-85	117-145	针 对 目前 有权 网络 的 社区 发现 方法 存在 的 不足 , 该文 结合 节点 的 直接 连边 权重 和 基 于 共同 邻居 节点 的 连边 权重 , 提出 了 一 种 改进 的 节点 相关 度 度量 准则 。	分别 在 有 权值 的 科学 家 合作 网络 和 全国 列车 网络 数据 集上 进行 了 社区 发现 实验 , 结果 表明 了 方法 的 有效 性 。	1<2	evaluation	evaluation
nlpabs55_Chi	117-137	138-145	分别 在 有 权值 的 科学 家 合作 网络 和 全国 列车 网络 数据 集上 进行 了 社区 发现 实验 ,	结果 表明 了 方法 的 有效 性 。	117-145	117-145	分别 在 有 权值 的 科学 家 合作 网络 和 全国 列车 网络 数据 集上 进行 了 社区 发现 实验 , 结果 表明 了 方法 的 有效 性 。	分别 在 有 权值 的 科学 家 合作 网络 和 全国 列车 网络 数据 集上 进行 了 社区 发现 实验 , 结果 表明 了 方法 的 有效 性 。	1<2	elab-addition	elab-addition
nlpabs56_Chi	1-17	63-91	谣言 或 疾病 的 扩散 均 可 模拟 为 传播 源 在 网络 中 的 传播 ,	该文 分析 了 随机 、 度 、 聚类 系数 、 特征 向量 、 紧密 度 以及 介数 等 观察 点 部署 策略 对 传染 源 估计 的 影响 。	1-34	63-91	谣言 或 疾病 的 扩散 均 可 模拟 为 传播 源 在 网络 中 的 传播 , 如何 在 网络 中 估计 传播 源 位置 是 一 项 具有 挑战 性 的 任务 。	该文 分析 了 随机 、 度 、 聚类 系数 、 特征 向量 、 紧密 度 以及 介数 等 观察 点 部署 策略 对 传染 源 估计 的 影响 。	1>2	bg-general	bg-general
nlpabs56_Chi	1-17	18-34	谣言 或 疾病 的 扩散 均 可 模拟 为 传播 源 在 网络 中 的 传播 ,	如何 在 网络 中 估计 传播 源 位置 是 一 项 具有 挑战 性 的 任务 。	1-34	1-34	谣言 或 疾病 的 扩散 均 可 模拟 为 传播 源 在 网络 中 的 传播 , 如何 在 网络 中 估计 传播 源 位置 是 一 项 具有 挑战 性 的 任务 。	谣言 或 疾病 的 扩散 均 可 模拟 为 传播 源 在 网络 中 的 传播 , 如何 在 网络 中 估计 传播 源 位置 是 一 项 具有 挑战 性 的 任务 。	1<2	elab-addition	elab-addition
nlpabs56_Chi	18-34	35-46	如何 在 网络 中 估计 传播 源 位置 是 一 项 具有 挑战 性 的 任务 。	该任务 往往 根据 部分 观察 点 推断 传播 源 的 位置 ,	1-34	35-62	谣言 或 疾病 的 扩散 均 可 模拟 为 传播 源 在 网络 中 的 传播 , 如何 在 网络 中 估计 传播 源 位置 是 一 项 具有 挑战 性 的 任务 。	该任务 往往 根据 部分 观察 点 推断 传播 源 的 位置 , 故 如何 有效 的 选择 观察 点 对 准确 定位 传播 源 位置 至关 重要 。	1<2	elab-addition	elab-addition
nlpabs56_Chi	35-46	47-62	该任务 往往 根据 部分 观察 点 推断 传播 源 的 位置 ,	故 如何 有效 的 选择 观察 点 对 准确 定位 传播 源 位置 至关 重要 。	35-62	35-62	该任务 往往 根据 部分 观察 点 推断 传播 源 的 位置 , 故 如何 有效 的 选择 观察 点 对 准确 定位 传播 源 位置 至关 重要 。	该任务 往往 根据 部分 观察 点 推断 传播 源 的 位置 , 故 如何 有效 的 选择 观察 点 对 准确 定位 传播 源 位置 至关 重要 。	1<2	result	result
nlpabs56_Chi	63-91	92-103	该文 分析 了 随机 、 度 、 聚类 系数 、 特征 向量 、 紧密 度 以及 介数 等 观察 点 部署 策略 对 传染 源 估计 的 影响 。	在 实验 中 , 采用 SI 传播 模型 和 反向 贪心 算法	63-91	92-141	该文 分析 了 随机 、 度 、 聚类 系数 、 特征 向量 、 紧密 度 以及 介数 等 观察 点 部署 策略 对 传染 源 估计 的 影响 。	在 实验 中 , 采用 SI 传播 模型 和 反向 贪心 算法 估计 传播 源 在 三 类 合成 网络 和 四 个 真实 网络 进行 模拟 仿真 , 实验 结果 表明 采用 特征 向量 的 观察 点 部署 策略 更 有利 于 提高 传播 源 估计 的 精度 。	1<2	elab-addition	elab-addition
nlpabs56_Chi	92-103	104-120	在 实验 中 , 采用 SI 传播 模型 和 反向 贪心 算法	估计 传播 源 在 三 类 合成 网络 和 四 个 真实 网络 进行 模拟 仿真 ,	92-141	92-141	在 实验 中 , 采用 SI 传播 模型 和 反向 贪心 算法 估计 传播 源 在 三 类 合成 网络 和 四 个 真实 网络 进行 模拟 仿真 , 实验 结果 表明 采用 特征 向量 的 观察 点 部署 策略 更 有利 于 提高 传播 源 估计 的 精度 。	在 实验 中 , 采用 SI 传播 模型 和 反向 贪心 算法 估计 传播 源 在 三 类 合成 网络 和 四 个 真实 网络 进行 模拟 仿真 , 实验 结果 表明 采用 特征 向量 的 观察 点 部署 策略 更 有利 于 提高 传播 源 估计 的 精度 。	1<2	enablement	enablement
nlpabs56_Chi	121-123	124-141	实验 结果 表明	采用 特征 向量 的 观察 点 部署 策略 更 有利 于 提高 传播 源 估计 的 精度 。	92-141	92-141	在 实验 中 , 采用 SI 传播 模型 和 反向 贪心 算法 估计 传播 源 在 三 类 合成 网络 和 四 个 真实 网络 进行 模拟 仿真 , 实验 结果 表明 采用 特征 向量 的 观察 点 部署 策略 更 有利 于 提高 传播 源 估计 的 精度 。	在 实验 中 , 采用 SI 传播 模型 和 反向 贪心 算法 估计 传播 源 在 三 类 合成 网络 和 四 个 真实 网络 进行 模拟 仿真 , 实验 结果 表明 采用 特征 向量 的 观察 点 部署 策略 更 有利 于 提高 传播 源 估计 的 精度 。	1>2	attribution	attribution
nlpabs56_Chi	63-91	124-141	该文 分析 了 随机 、 度 、 聚类 系数 、 特征 向量 、 紧密 度 以及 介数 等 观察 点 部署 策略 对 传染 源 估计 的 影响 。	采用 特征 向量 的 观察 点 部署 策略 更 有利 于 提高 传播 源 估计 的 精度 。	63-91	92-141	该文 分析 了 随机 、 度 、 聚类 系数 、 特征 向量 、 紧密 度 以及 介数 等 观察 点 部署 策略 对 传染 源 估计 的 影响 。	在 实验 中 , 采用 SI 传播 模型 和 反向 贪心 算法 估计 传播 源 在 三 类 合成 网络 和 四 个 真实 网络 进行 模拟 仿真 , 实验 结果 表明 采用 特征 向量 的 观察 点 部署 策略 更 有利 于 提高 传播 源 估计 的 精度 。	1<2	evaluation	evaluation
nlpabs57_Chi	1-20	21-51	该文 主要 研究 在 评论 性 数据 中 用户 个性 及 产品 信息 对 数据 情感 类别 的 影响 。	在 影响 数据 情感 类型 的 众多 因素 中 , 该文 认为 评价 的 主体 即 用户 以及 被 评价 的 对象 等 信息 对 评论 数据 的 情感 至关重要 。	1-20	21-51	该文 主要 研究 在 评论 性 数据 中 用户 个性 及 产品 信息 对 数据 情感 类别 的 影响 。	在 影响 数据 情感 类型 的 众多 因素 中 , 该文 认为 评价 的 主体 即 用户 以及 被 评价 的 对象 等 信息 对 评论 数据 的 情感 至关重要 。	1<2	elab-addition	elab-addition
nlpabs57_Chi	1-20	52-69	该文 主要 研究 在 评论 性 数据 中 用户 个性 及 产品 信息 对 数据 情感 类别 的 影响 。	该文 提出 一 种 基 于 协同 过滤 Attention 机制 的 情感 分析 方法 ( LSTM-CFA ) ,	1-20	52-109	该文 主要 研究 在 评论 性 数据 中 用户 个性 及 产品 信息 对 数据 情感 类别 的 影响 。	该文 提出 一 种 基 于 协同 过滤 Attention 机制 的 情感 分析 方法 ( LSTM-CFA ) , 使用 协同 过滤 ( CF ) 算法 计算 出 用户 兴趣 分布 矩阵 , 再 将 矩阵 利用 SVD 分解 后 加入 层次 LSTM 模型 , 作 为 模型 注意 力 机制 提取 文档 特征 、 实现 情感 分类 。	1<2	elab-addition	elab-addition
nlpabs57_Chi	52-69	70-76	该文 提出 一 种 基 于 协同 过滤 Attention 机制 的 情感 分析 方法 ( LSTM-CFA ) ,	使用 协同 过滤 ( CF ) 算法	52-109	52-109	该文 提出 一 种 基 于 协同 过滤 Attention 机制 的 情感 分析 方法 ( LSTM-CFA ) , 使用 协同 过滤 ( CF ) 算法 计算 出 用户 兴趣 分布 矩阵 , 再 将 矩阵 利用 SVD 分解 后 加入 层次 LSTM 模型 , 作 为 模型 注意 力 机制 提取 文档 特征 、 实现 情感 分类 。	该文 提出 一 种 基 于 协同 过滤 Attention 机制 的 情感 分析 方法 ( LSTM-CFA ) , 使用 协同 过滤 ( CF ) 算法 计算 出 用户 兴趣 分布 矩阵 , 再 将 矩阵 利用 SVD 分解 后 加入 层次 LSTM 模型 , 作 为 模型 注意 力 机制 提取 文档 特征 、 实现 情感 分类 。	1<2	elab-process_step	elab-process_step
nlpabs57_Chi	70-76	77-83	使用 协同 过滤 ( CF ) 算法	计算 出 用户 兴趣 分布 矩阵 ,	52-109	52-109	该文 提出 一 种 基 于 协同 过滤 Attention 机制 的 情感 分析 方法 ( LSTM-CFA ) , 使用 协同 过滤 ( CF ) 算法 计算 出 用户 兴趣 分布 矩阵 , 再 将 矩阵 利用 SVD 分解 后 加入 层次 LSTM 模型 , 作 为 模型 注意 力 机制 提取 文档 特征 、 实现 情感 分类 。	该文 提出 一 种 基 于 协同 过滤 Attention 机制 的 情感 分析 方法 ( LSTM-CFA ) , 使用 协同 过滤 ( CF ) 算法 计算 出 用户 兴趣 分布 矩阵 , 再 将 矩阵 利用 SVD 分解 后 加入 层次 LSTM 模型 , 作 为 模型 注意 力 机制 提取 文档 特征 、 实现 情感 分类 。	1<2	enablement	enablement
nlpabs57_Chi	70-76	84-95	使用 协同 过滤 ( CF ) 算法	再 将 矩阵 利用 SVD 分解 后 加入 层次 LSTM 模型 ,	52-109	52-109	该文 提出 一 种 基 于 协同 过滤 Attention 机制 的 情感 分析 方法 ( LSTM-CFA ) , 使用 协同 过滤 ( CF ) 算法 计算 出 用户 兴趣 分布 矩阵 , 再 将 矩阵 利用 SVD 分解 后 加入 层次 LSTM 模型 , 作 为 模型 注意 力 机制 提取 文档 特征 、 实现 情感 分类 。	该文 提出 一 种 基 于 协同 过滤 Attention 机制 的 情感 分析 方法 ( LSTM-CFA ) , 使用 协同 过滤 ( CF ) 算法 计算 出 用户 兴趣 分布 矩阵 , 再 将 矩阵 利用 SVD 分解 后 加入 层次 LSTM 模型 , 作 为 模型 注意 力 机制 提取 文档 特征 、 实现 情感 分类 。	1<2	joint	joint
nlpabs57_Chi	84-95	96-109	再 将 矩阵 利用 SVD 分解 后 加入 层次 LSTM 模型 ,	作 为 模型 注意 力 机制 提取 文档 特征 、 实现 情感 分类 。	52-109	52-109	该文 提出 一 种 基 于 协同 过滤 Attention 机制 的 情感 分析 方法 ( LSTM-CFA ) , 使用 协同 过滤 ( CF ) 算法 计算 出 用户 兴趣 分布 矩阵 , 再 将 矩阵 利用 SVD 分解 后 加入 层次 LSTM 模型 , 作 为 模型 注意 力 机制 提取 文档 特征 、 实现 情感 分类 。	该文 提出 一 种 基 于 协同 过滤 Attention 机制 的 情感 分析 方法 ( LSTM-CFA ) , 使用 协同 过滤 ( CF ) 算法 计算 出 用户 兴趣 分布 矩阵 , 再 将 矩阵 利用 SVD 分解 后 加入 层次 LSTM 模型 , 作 为 模型 注意 力 机制 提取 文档 特征 、 实现 情感 分类 。	1<2	elab-addition	elab-addition
nlpabs57_Chi	110-111	112-123	实验 表明	LSTM-CFA 方法 能够 高效 提取 用户 个性 与 产品 属性 信息 ,	110-132	110-132	实验 表明 LSTM-CFA 方法 能够 高效 提取 用户 个性 与 产品 属性 信息 , 显著 提升 了 情感 分类 的 准确 率 。	实验 表明 LSTM-CFA 方法 能够 高效 提取 用户 个性 与 产品 属性 信息 , 显著 提升 了 情感 分类 的 准确 率 。	1>2	attribution	attribution
nlpabs57_Chi	1-20	112-123	该文 主要 研究 在 评论 性 数据 中 用户 个性 及 产品 信息 对 数据 情感 类别 的 影响 。	LSTM-CFA 方法 能够 高效 提取 用户 个性 与 产品 属性 信息 ,	1-20	110-132	该文 主要 研究 在 评论 性 数据 中 用户 个性 及 产品 信息 对 数据 情感 类别 的 影响 。	实验 表明 LSTM-CFA 方法 能够 高效 提取 用户 个性 与 产品 属性 信息 , 显著 提升 了 情感 分类 的 准确 率 。	1<2	evaluation	evaluation
nlpabs57_Chi	112-123	124-132	LSTM-CFA 方法 能够 高效 提取 用户 个性 与 产品 属性 信息 ,	显著 提升 了 情感 分类 的 准确 率 。	110-132	110-132	实验 表明 LSTM-CFA 方法 能够 高效 提取 用户 个性 与 产品 属性 信息 , 显著 提升 了 情感 分类 的 准确 率 。	实验 表明 LSTM-CFA 方法 能够 高效 提取 用户 个性 与 产品 属性 信息 , 显著 提升 了 情感 分类 的 准确 率 。	1<2	elab-addition	elab-addition
nlpabs58_Chi	1-15	16-44	该文 提出 了 一 种 面向 商品 评论 的 二 元 情感 认知 模型 。	该 模型 由 “ 二 元 情感 常识 库 ” 、 “ 评价 体系 知识 库 ” 和 “ 情感 分析 引擎 ” 三 个 主要 模块 组成 。	1-15	16-44	该文 提出 了 一 种 面向 商品 评论 的 二 元 情感 认知 模型 。	该 模型 由 “ 二 元 情感 常识 库 ” 、 “ 评价 体系 知识 库 ” 和 “ 情感 分析 引擎 ” 三 个 主要 模块 组成 。	1<2	elab-addition	elab-addition
nlpabs58_Chi	1-15	45-49	该文 提出 了 一 种 面向 商品 评论 的 二 元 情感 认知 模型 。	其 特点 体现 为 :	1-15	45-118	该文 提出 了 一 种 面向 商品 评论 的 二 元 情感 认知 模型 。	其 特点 体现 为 : ( 1 ) 模型 通过 大 规模 评论 文本 学习 领域 先验 知识 , 将 其 存储 在 知识 库 中 , 便 于 知识 的 修正 和 重用 , 体现 了 模型 的 认知 能力 ; ( 2 ) 模型 不仅 能够 挖掘 评论 文本 中 出现 的 显式 评价 观点 , 还 能 借助 领域 知识 进行 情感 推断 , 发现 更高 层次 的 用户 情感 。	1<2	elab-addition	elab-addition
nlpabs58_Chi	45-49	50-63	其 特点 体现 为 :	( 1 ) 模型 通过 大 规模 评论 文本 学习 领域 先验 知识 ,	45-118	45-118	其 特点 体现 为 : ( 1 ) 模型 通过 大 规模 评论 文本 学习 领域 先验 知识 , 将 其 存储 在 知识 库 中 , 便 于 知识 的 修正 和 重用 , 体现 了 模型 的 认知 能力 ; ( 2 ) 模型 不仅 能够 挖掘 评论 文本 中 出现 的 显式 评价 观点 , 还 能 借助 领域 知识 进行 情感 推断 , 发现 更高 层次 的 用户 情感 。	其 特点 体现 为 : ( 1 ) 模型 通过 大 规模 评论 文本 学习 领域 先验 知识 , 将 其 存储 在 知识 库 中 , 便 于 知识 的 修正 和 重用 , 体现 了 模型 的 认知 能力 ; ( 2 ) 模型 不仅 能够 挖掘 评论 文本 中 出现 的 显式 评价 观点 , 还 能 借助 领域 知识 进行 情感 推断 , 发现 更高 层次 的 用户 情感 。	1<2	elab-enumember	elab-enumember
nlpabs58_Chi	50-63	64-71	( 1 ) 模型 通过 大 规模 评论 文本 学习 领域 先验 知识 ,	将 其 存储 在 知识 库 中 ,	45-118	45-118	其 特点 体现 为 : ( 1 ) 模型 通过 大 规模 评论 文本 学习 领域 先验 知识 , 将 其 存储 在 知识 库 中 , 便 于 知识 的 修正 和 重用 , 体现 了 模型 的 认知 能力 ; ( 2 ) 模型 不仅 能够 挖掘 评论 文本 中 出现 的 显式 评价 观点 , 还 能 借助 领域 知识 进行 情感 推断 , 发现 更高 层次 的 用户 情感 。	其 特点 体现 为 : ( 1 ) 模型 通过 大 规模 评论 文本 学习 领域 先验 知识 , 将 其 存储 在 知识 库 中 , 便 于 知识 的 修正 和 重用 , 体现 了 模型 的 认知 能力 ; ( 2 ) 模型 不仅 能够 挖掘 评论 文本 中 出现 的 显式 评价 观点 , 还 能 借助 领域 知识 进行 情感 推断 , 发现 更高 层次 的 用户 情感 。	1<2	enablement	enablement
nlpabs58_Chi	64-71	72-79	将 其 存储 在 知识 库 中 ,	便 于 知识 的 修正 和 重用 ,	45-118	45-118	其 特点 体现 为 : ( 1 ) 模型 通过 大 规模 评论 文本 学习 领域 先验 知识 , 将 其 存储 在 知识 库 中 , 便 于 知识 的 修正 和 重用 , 体现 了 模型 的 认知 能力 ; ( 2 ) 模型 不仅 能够 挖掘 评论 文本 中 出现 的 显式 评价 观点 , 还 能 借助 领域 知识 进行 情感 推断 , 发现 更高 层次 的 用户 情感 。	其 特点 体现 为 : ( 1 ) 模型 通过 大 规模 评论 文本 学习 领域 先验 知识 , 将 其 存储 在 知识 库 中 , 便 于 知识 的 修正 和 重用 , 体现 了 模型 的 认知 能力 ; ( 2 ) 模型 不仅 能够 挖掘 评论 文本 中 出现 的 显式 评价 观点 , 还 能 借助 领域 知识 进行 情感 推断 , 发现 更高 层次 的 用户 情感 。	1<2	elab-addition	elab-addition
nlpabs58_Chi	50-63	80-86	( 1 ) 模型 通过 大 规模 评论 文本 学习 领域 先验 知识 ,	体现 了 模型 的 认知 能力 ;	45-118	45-118	其 特点 体现 为 : ( 1 ) 模型 通过 大 规模 评论 文本 学习 领域 先验 知识 , 将 其 存储 在 知识 库 中 , 便 于 知识 的 修正 和 重用 , 体现 了 模型 的 认知 能力 ; ( 2 ) 模型 不仅 能够 挖掘 评论 文本 中 出现 的 显式 评价 观点 , 还 能 借助 领域 知识 进行 情感 推断 , 发现 更高 层次 的 用户 情感 。	其 特点 体现 为 : ( 1 ) 模型 通过 大 规模 评论 文本 学习 领域 先验 知识 , 将 其 存储 在 知识 库 中 , 便 于 知识 的 修正 和 重用 , 体现 了 模型 的 认知 能力 ; ( 2 ) 模型 不仅 能够 挖掘 评论 文本 中 出现 的 显式 评价 观点 , 还 能 借助 领域 知识 进行 情感 推断 , 发现 更高 层次 的 用户 情感 。	1<2	elab-addition	elab-addition
nlpabs58_Chi	50-63	87-102	( 1 ) 模型 通过 大 规模 评论 文本 学习 领域 先验 知识 ,	( 2 ) 模型 不仅 能够 挖掘 评论 文本 中 出现 的 显式 评价 观点 ,	45-118	45-118	其 特点 体现 为 : ( 1 ) 模型 通过 大 规模 评论 文本 学习 领域 先验 知识 , 将 其 存储 在 知识 库 中 , 便 于 知识 的 修正 和 重用 , 体现 了 模型 的 认知 能力 ; ( 2 ) 模型 不仅 能够 挖掘 评论 文本 中 出现 的 显式 评价 观点 , 还 能 借助 领域 知识 进行 情感 推断 , 发现 更高 层次 的 用户 情感 。	其 特点 体现 为 : ( 1 ) 模型 通过 大 规模 评论 文本 学习 领域 先验 知识 , 将 其 存储 在 知识 库 中 , 便 于 知识 的 修正 和 重用 , 体现 了 模型 的 认知 能力 ; ( 2 ) 模型 不仅 能够 挖掘 评论 文本 中 出现 的 显式 评价 观点 , 还 能 借助 领域 知识 进行 情感 推断 , 发现 更高 层次 的 用户 情感 。	1<2	joint	joint
nlpabs58_Chi	87-102	103-107	( 2 ) 模型 不仅 能够 挖掘 评论 文本 中 出现 的 显式 评价 观点 ,	还 能 借助 领域 知识	45-118	45-118	其 特点 体现 为 : ( 1 ) 模型 通过 大 规模 评论 文本 学习 领域 先验 知识 , 将 其 存储 在 知识 库 中 , 便 于 知识 的 修正 和 重用 , 体现 了 模型 的 认知 能力 ; ( 2 ) 模型 不仅 能够 挖掘 评论 文本 中 出现 的 显式 评价 观点 , 还 能 借助 领域 知识 进行 情感 推断 , 发现 更高 层次 的 用户 情感 。	其 特点 体现 为 : ( 1 ) 模型 通过 大 规模 评论 文本 学习 领域 先验 知识 , 将 其 存储 在 知识 库 中 , 便 于 知识 的 修正 和 重用 , 体现 了 模型 的 认知 能力 ; ( 2 ) 模型 不仅 能够 挖掘 评论 文本 中 出现 的 显式 评价 观点 , 还 能 借助 领域 知识 进行 情感 推断 , 发现 更高 层次 的 用户 情感 。	1<2	joint	joint
nlpabs58_Chi	103-107	108-111	还 能 借助 领域 知识	进行 情感 推断 ,	45-118	45-118	其 特点 体现 为 : ( 1 ) 模型 通过 大 规模 评论 文本 学习 领域 先验 知识 , 将 其 存储 在 知识 库 中 , 便 于 知识 的 修正 和 重用 , 体现 了 模型 的 认知 能力 ; ( 2 ) 模型 不仅 能够 挖掘 评论 文本 中 出现 的 显式 评价 观点 , 还 能 借助 领域 知识 进行 情感 推断 , 发现 更高 层次 的 用户 情感 。	其 特点 体现 为 : ( 1 ) 模型 通过 大 规模 评论 文本 学习 领域 先验 知识 , 将 其 存储 在 知识 库 中 , 便 于 知识 的 修正 和 重用 , 体现 了 模型 的 认知 能力 ; ( 2 ) 模型 不仅 能够 挖掘 评论 文本 中 出现 的 显式 评价 观点 , 还 能 借助 领域 知识 进行 情感 推断 , 发现 更高 层次 的 用户 情感 。	1<2	enablement	enablement
nlpabs58_Chi	108-111	112-118	进行 情感 推断 ,	发现 更高 层次 的 用户 情感 。	45-118	45-118	其 特点 体现 为 : ( 1 ) 模型 通过 大 规模 评论 文本 学习 领域 先验 知识 , 将 其 存储 在 知识 库 中 , 便 于 知识 的 修正 和 重用 , 体现 了 模型 的 认知 能力 ; ( 2 ) 模型 不仅 能够 挖掘 评论 文本 中 出现 的 显式 评价 观点 , 还 能 借助 领域 知识 进行 情感 推断 , 发现 更高 层次 的 用户 情感 。	其 特点 体现 为 : ( 1 ) 模型 通过 大 规模 评论 文本 学习 领域 先验 知识 , 将 其 存储 在 知识 库 中 , 便 于 知识 的 修正 和 重用 , 体现 了 模型 的 认知 能力 ; ( 2 ) 模型 不仅 能够 挖掘 评论 文本 中 出现 的 显式 评价 观点 , 还 能 借助 领域 知识 进行 情感 推断 , 发现 更高 层次 的 用户 情感 。	1<2	joint	joint
nlpabs58_Chi	1-15	119-140	该文 提出 了 一 种 面向 商品 评论 的 二 元 情感 认知 模型 。	该文 给出 了 构建 “ 二 元 情感 常识 库 ” 和 “ 评价 体系 知识 库 ” 的 相关 算法 ,	1-15	119-158	该文 提出 了 一 种 面向 商品 评论 的 二 元 情感 认知 模型 。	该文 给出 了 构建 “ 二 元 情感 常识 库 ” 和 “ 评价 体系 知识 库 ” 的 相关 算法 , 并 介绍 了 “ 情感 分析 引擎 ” 在 观点 挖掘 和 情感 推断 中 的 应用 。	1<2	elab-addition	elab-addition
nlpabs58_Chi	119-140	141-158	该文 给出 了 构建 “ 二 元 情感 常识 库 ” 和 “ 评价 体系 知识 库 ” 的 相关 算法 ,	并 介绍 了 “ 情感 分析 引擎 ” 在 观点 挖掘 和 情感 推断 中 的 应用 。	119-158	119-158	该文 给出 了 构建 “ 二 元 情感 常识 库 ” 和 “ 评价 体系 知识 库 ” 的 相关 算法 , 并 介绍 了 “ 情感 分析 引擎 ” 在 观点 挖掘 和 情感 推断 中 的 应用 。	该文 给出 了 构建 “ 二 元 情感 常识 库 ” 和 “ 评价 体系 知识 库 ” 的 相关 算法 , 并 介绍 了 “ 情感 分析 引擎 ” 在 观点 挖掘 和 情感 推断 中 的 应用 。	1<2	joint	joint
nlpabs58_Chi	1-15	159-174	该文 提出 了 一 种 面向 商品 评论 的 二 元 情感 认知 模型 。	在 商品 评论 语料 集 上 的 实验 验证 了 该 模型 的 有效 性 。	1-15	159-174	该文 提出 了 一 种 面向 商品 评论 的 二 元 情感 认知 模型 。	在 商品 评论 语料 集 上 的 实验 验证 了 该 模型 的 有效 性 。	1<2	evaluation	evaluation
nlpabs5_Chi	1-20	21-41	﻿句子 间 相似 度 的 计算 在 自然 语言 处理 的 各个 领域 都 占有 很 重要 的 地位 ,	在 多 文档 自动 文摘 技术 中 , 句子 间 相似 度 的 计算 是 一 个 关键 的 问题 。	1-41	1-41	﻿句子 间 相似 度 的 计算 在 自然 语言 处理 的 各个 领域 都 占有 很 重要 的 地位 , 在 多 文档 自动 文摘 技术 中 , 句子 间 相似 度 的 计算 是 一 个 关键 的 问题 。	﻿句子 间 相似 度 的 计算 在 自然 语言 处理 的 各个 领域 都 占有 很 重要 的 地位 , 在 多 文档 自动 文摘 技术 中 , 句子 间 相似 度 的 计算 是 一 个 关键 的 问题 。	1<2	elab-addition	elab-addition
nlpabs5_Chi	42-52	65-69	由于 汉 语 句子 的 表达 形式 是 多种多样 的 ,	必须 深入 到 语义 一级	42-106	42-106	由于 汉 语 句子 的 表达 形式 是 多种多样 的 , 要 准确 地 刻画 一 个 句子 所 表达 的 意思 , 必须 深入 到 语义 一级 并 结合 语法 结构 信息 , 由 此 提出 了 一 种 基 于 语义 依存 的 汉 语 句子 相似 度 计算 的 方法 , 该 方法 取得 了 令 人 满意 的 实验 效果 。	由于 汉 语 句子 的 表达 形式 是 多种多样 的 , 要 准确 地 刻画 一 个 句子 所 表达 的 意思 , 必须 深入 到 语义 一级 并 结合 语法 结构 信息 , 由 此 提出 了 一 种 基 于 语义 依存 的 汉 语 句子 相似 度 计算 的 方法 , 该 方法 取得 了 令 人 满意 的 实验 效果 。	1>2	cause	cause
nlpabs5_Chi	53-64	65-69	要 准确 地 刻画 一 个 句子 所 表达 的 意思 ,	必须 深入 到 语义 一级	42-106	42-106	由于 汉 语 句子 的 表达 形式 是 多种多样 的 , 要 准确 地 刻画 一 个 句子 所 表达 的 意思 , 必须 深入 到 语义 一级 并 结合 语法 结构 信息 , 由 此 提出 了 一 种 基 于 语义 依存 的 汉 语 句子 相似 度 计算 的 方法 , 该 方法 取得 了 令 人 满意 的 实验 效果 。	由于 汉 语 句子 的 表达 形式 是 多种多样 的 , 要 准确 地 刻画 一 个 句子 所 表达 的 意思 , 必须 深入 到 语义 一级 并 结合 语法 结构 信息 , 由 此 提出 了 一 种 基 于 语义 依存 的 汉 语 句子 相似 度 计算 的 方法 , 该 方法 取得 了 令 人 满意 的 实验 效果 。	1>2	enablement	enablement
nlpabs5_Chi	21-41	65-69	在 多 文档 自动 文摘 技术 中 , 句子 间 相似 度 的 计算 是 一 个 关键 的 问题 。	必须 深入 到 语义 一级	1-41	42-106	﻿句子 间 相似 度 的 计算 在 自然 语言 处理 的 各个 领域 都 占有 很 重要 的 地位 , 在 多 文档 自动 文摘 技术 中 , 句子 间 相似 度 的 计算 是 一 个 关键 的 问题 。	由于 汉 语 句子 的 表达 形式 是 多种多样 的 , 要 准确 地 刻画 一 个 句子 所 表达 的 意思 , 必须 深入 到 语义 一级 并 结合 语法 结构 信息 , 由 此 提出 了 一 种 基 于 语义 依存 的 汉 语 句子 相似 度 计算 的 方法 , 该 方法 取得 了 令 人 满意 的 实验 效果 。	1<2	elab-addition	elab-addition
nlpabs5_Chi	65-69	70-75	必须 深入 到 语义 一级	并 结合 语法 结构 信息 ,	42-106	42-106	由于 汉 语 句子 的 表达 形式 是 多种多样 的 , 要 准确 地 刻画 一 个 句子 所 表达 的 意思 , 必须 深入 到 语义 一级 并 结合 语法 结构 信息 , 由 此 提出 了 一 种 基 于 语义 依存 的 汉 语 句子 相似 度 计算 的 方法 , 该 方法 取得 了 令 人 满意 的 实验 效果 。	由于 汉 语 句子 的 表达 形式 是 多种多样 的 , 要 准确 地 刻画 一 个 句子 所 表达 的 意思 , 必须 深入 到 语义 一级 并 结合 语法 结构 信息 , 由 此 提出 了 一 种 基 于 语义 依存 的 汉 语 句子 相似 度 计算 的 方法 , 该 方法 取得 了 令 人 满意 的 实验 效果 。	1<2	joint	joint
nlpabs5_Chi	65-69	76-95	必须 深入 到 语义 一级	由 此 提出 了 一 种 基 于 语义 依存 的 汉 语 句子 相似 度 计算 的 方法 ,	42-106	42-106	由于 汉 语 句子 的 表达 形式 是 多种多样 的 , 要 准确 地 刻画 一 个 句子 所 表达 的 意思 , 必须 深入 到 语义 一级 并 结合 语法 结构 信息 , 由 此 提出 了 一 种 基 于 语义 依存 的 汉 语 句子 相似 度 计算 的 方法 , 该 方法 取得 了 令 人 满意 的 实验 效果 。	由于 汉 语 句子 的 表达 形式 是 多种多样 的 , 要 准确 地 刻画 一 个 句子 所 表达 的 意思 , 必须 深入 到 语义 一级 并 结合 语法 结构 信息 , 由 此 提出 了 一 种 基 于 语义 依存 的 汉 语 句子 相似 度 计算 的 方法 , 该 方法 取得 了 令 人 满意 的 实验 效果 。	1<2	elab-addition	elab-addition
nlpabs5_Chi	76-95	96-106	由 此 提出 了 一 种 基 于 语义 依存 的 汉 语 句子 相似 度 计算 的 方法 ,	该 方法 取得 了 令 人 满意 的 实验 效果 。	42-106	42-106	由于 汉 语 句子 的 表达 形式 是 多种多样 的 , 要 准确 地 刻画 一 个 句子 所 表达 的 意思 , 必须 深入 到 语义 一级 并 结合 语法 结构 信息 , 由 此 提出 了 一 种 基 于 语义 依存 的 汉 语 句子 相似 度 计算 的 方法 , 该 方法 取得 了 令 人 满意 的 实验 效果 。	由于 汉 语 句子 的 表达 形式 是 多种多样 的 , 要 准确 地 刻画 一 个 句子 所 表达 的 意思 , 必须 深入 到 语义 一级 并 结合 语法 结构 信息 , 由 此 提出 了 一 种 基 于 语义 依存 的 汉 语 句子 相似 度 计算 的 方法 , 该 方法 取得 了 令 人 满意 的 实验 效果 。	1<2	evaluation	evaluation
nlpabs60_Chi	1-33	34-51	为了 避免 基 于 传统 机器 学习 的 中 文 文本 蕴含 识别 方法 需要 人工 筛选 大量 特征 以及 使用 多 种 自然 语言 处理 工具 造成 的 错误 累计 问题 ,	该文 提出 了 基 于 CNN 与 双 向 LSTM 的 中 文 文本 蕴含 识别 方法 。	1-51	1-51	为了 避免 基 于 传统 机器 学习 的 中 文 文本 蕴含 识别 方法 需要 人工 筛选 大量 特征 以及 使用 多 种 自然 语言 处理 工具 造成 的 错误 累计 问题 , 该文 提出 了 基 于 CNN 与 双 向 LSTM 的 中 文 文本 蕴含 识别 方法 。	为了 避免 基 于 传统 机器 学习 的 中 文 文本 蕴含 识别 方法 需要 人工 筛选 大量 特征 以及 使用 多 种 自然 语言 处理 工具 造成 的 错误 累计 问题 , 该文 提出 了 基 于 CNN 与 双 向 LSTM 的 中 文 文本 蕴含 识别 方法 。	1>2	bg-goal	bg-goal
nlpabs60_Chi	34-51	52-59	该文 提出 了 基 于 CNN 与 双 向 LSTM 的 中 文 文本 蕴含 识别 方法 。	该 方法 使用 CNN 与 双 向 LSTM	1-51	52-101	为了 避免 基 于 传统 机器 学习 的 中 文 文本 蕴含 识别 方法 需要 人工 筛选 大量 特征 以及 使用 多 种 自然 语言 处理 工具 造成 的 错误 累计 问题 , 该文 提出 了 基 于 CNN 与 双 向 LSTM 的 中 文 文本 蕴含 识别 方法 。	该 方法 使用 CNN 与 双 向 LSTM 分别 对 句子 进行 编码 , 自动 提取 相关 特征 , 然后 使用 全 连接 层 进行 分类 得到 初步 的 识别 结果 , 最后 使用 语义 规则 对 网络 识别 结果 进行 修正 , 得到 最终 的 蕴含 识别 结果 。	1<2	elab-process_step	elab-process_step
nlpabs60_Chi	52-59	60-65	该 方法 使用 CNN 与 双 向 LSTM	分别 对 句子 进行 编码 ,	52-101	52-101	该 方法 使用 CNN 与 双 向 LSTM 分别 对 句子 进行 编码 , 自动 提取 相关 特征 , 然后 使用 全 连接 层 进行 分类 得到 初步 的 识别 结果 , 最后 使用 语义 规则 对 网络 识别 结果 进行 修正 , 得到 最终 的 蕴含 识别 结果 。	该 方法 使用 CNN 与 双 向 LSTM 分别 对 句子 进行 编码 , 自动 提取 相关 特征 , 然后 使用 全 连接 层 进行 分类 得到 初步 的 识别 结果 , 最后 使用 语义 规则 对 网络 识别 结果 进行 修正 , 得到 最终 的 蕴含 识别 结果 。	1<2	enablement	enablement
nlpabs60_Chi	52-59	66-70	该 方法 使用 CNN 与 双 向 LSTM	自动 提取 相关 特征 ,	52-101	52-101	该 方法 使用 CNN 与 双 向 LSTM 分别 对 句子 进行 编码 , 自动 提取 相关 特征 , 然后 使用 全 连接 层 进行 分类 得到 初步 的 识别 结果 , 最后 使用 语义 规则 对 网络 识别 结果 进行 修正 , 得到 最终 的 蕴含 识别 结果 。	该 方法 使用 CNN 与 双 向 LSTM 分别 对 句子 进行 编码 , 自动 提取 相关 特征 , 然后 使用 全 连接 层 进行 分类 得到 初步 的 识别 结果 , 最后 使用 语义 规则 对 网络 识别 结果 进行 修正 , 得到 最终 的 蕴含 识别 结果 。	1<2	joint	joint
nlpabs60_Chi	66-70	71-75	自动 提取 相关 特征 ,	然后 使用 全 连接 层	52-101	52-101	该 方法 使用 CNN 与 双 向 LSTM 分别 对 句子 进行 编码 , 自动 提取 相关 特征 , 然后 使用 全 连接 层 进行 分类 得到 初步 的 识别 结果 , 最后 使用 语义 规则 对 网络 识别 结果 进行 修正 , 得到 最终 的 蕴含 识别 结果 。	该 方法 使用 CNN 与 双 向 LSTM 分别 对 句子 进行 编码 , 自动 提取 相关 特征 , 然后 使用 全 连接 层 进行 分类 得到 初步 的 识别 结果 , 最后 使用 语义 规则 对 网络 识别 结果 进行 修正 , 得到 最终 的 蕴含 识别 结果 。	1<2	joint	joint
nlpabs60_Chi	71-75	76-83	然后 使用 全 连接 层	进行 分类 得到 初步 的 识别 结果 ,	52-101	52-101	该 方法 使用 CNN 与 双 向 LSTM 分别 对 句子 进行 编码 , 自动 提取 相关 特征 , 然后 使用 全 连接 层 进行 分类 得到 初步 的 识别 结果 , 最后 使用 语义 规则 对 网络 识别 结果 进行 修正 , 得到 最终 的 蕴含 识别 结果 。	该 方法 使用 CNN 与 双 向 LSTM 分别 对 句子 进行 编码 , 自动 提取 相关 特征 , 然后 使用 全 连接 层 进行 分类 得到 初步 的 识别 结果 , 最后 使用 语义 规则 对 网络 识别 结果 进行 修正 , 得到 最终 的 蕴含 识别 结果 。	1<2	enablement	enablement
nlpabs60_Chi	71-75	84-87	然后 使用 全 连接 层	最后 使用 语义 规则	52-101	52-101	该 方法 使用 CNN 与 双 向 LSTM 分别 对 句子 进行 编码 , 自动 提取 相关 特征 , 然后 使用 全 连接 层 进行 分类 得到 初步 的 识别 结果 , 最后 使用 语义 规则 对 网络 识别 结果 进行 修正 , 得到 最终 的 蕴含 识别 结果 。	该 方法 使用 CNN 与 双 向 LSTM 分别 对 句子 进行 编码 , 自动 提取 相关 特征 , 然后 使用 全 连接 层 进行 分类 得到 初步 的 识别 结果 , 最后 使用 语义 规则 对 网络 识别 结果 进行 修正 , 得到 最终 的 蕴含 识别 结果 。	1<2	joint	joint
nlpabs60_Chi	84-87	88-94	最后 使用 语义 规则	对 网络 识别 结果 进行 修正 ,	52-101	52-101	该 方法 使用 CNN 与 双 向 LSTM 分别 对 句子 进行 编码 , 自动 提取 相关 特征 , 然后 使用 全 连接 层 进行 分类 得到 初步 的 识别 结果 , 最后 使用 语义 规则 对 网络 识别 结果 进行 修正 , 得到 最终 的 蕴含 识别 结果 。	该 方法 使用 CNN 与 双 向 LSTM 分别 对 句子 进行 编码 , 自动 提取 相关 特征 , 然后 使用 全 连接 层 进行 分类 得到 初步 的 识别 结果 , 最后 使用 语义 规则 对 网络 识别 结果 进行 修正 , 得到 最终 的 蕴含 识别 结果 。	1<2	enablement	enablement
nlpabs60_Chi	88-94	95-101	对 网络 识别 结果 进行 修正 ,	得到 最终 的 蕴含 识别 结果 。	52-101	52-101	该 方法 使用 CNN 与 双 向 LSTM 分别 对 句子 进行 编码 , 自动 提取 相关 特征 , 然后 使用 全 连接 层 进行 分类 得到 初步 的 识别 结果 , 最后 使用 语义 规则 对 网络 识别 结果 进行 修正 , 得到 最终 的 蕴含 识别 结果 。	该 方法 使用 CNN 与 双 向 LSTM 分别 对 句子 进行 编码 , 自动 提取 相关 特征 , 然后 使用 全 连接 层 进行 分类 得到 初步 的 识别 结果 , 最后 使用 语义 规则 对 网络 识别 结果 进行 修正 , 得到 最终 的 蕴含 识别 结果 。	1<2	elab-addition	elab-addition
nlpabs60_Chi	52-59	102-115	该 方法 使用 CNN 与 双 向 LSTM	在 2014 年 RITE-VAL 评测 任务 的 数据 集上 MacroF1 结果 为 61.74% ,	52-101	102-123	该 方法 使用 CNN 与 双 向 LSTM 分别 对 句子 进行 编码 , 自动 提取 相关 特征 , 然后 使用 全 连接 层 进行 分类 得到 初步 的 识别 结果 , 最后 使用 语义 规则 对 网络 识别 结果 进行 修正 , 得到 最终 的 蕴含 识别 结果 。	在 2014 年 RITE-VAL 评测 任务 的 数据 集上 MacroF1 结果 为 61.74% , 超过 评测 第一 名 的 结果 61.51% 。	1<2	evaluation	evaluation
nlpabs60_Chi	102-115	116-123	在 2014 年 RITE-VAL 评测 任务 的 数据 集上 MacroF1 结果 为 61.74% ,	超过 评测 第一 名 的 结果 61.51% 。	102-123	102-123	在 2014 年 RITE-VAL 评测 任务 的 数据 集上 MacroF1 结果 为 61.74% , 超过 评测 第一 名 的 结果 61.51% 。	在 2014 年 RITE-VAL 评测 任务 的 数据 集上 MacroF1 结果 为 61.74% , 超过 评测 第一 名 的 结果 61.51% 。	1<2	elab-addition	elab-addition
nlpabs60_Chi	124-127	128-139	实验 结果 表明 ,	该 方法 对于 中 文 文本 蕴含 识别 是 有效 的 。	124-139	124-139	实验 结果 表明 , 该 方法 对于 中 文 文本 蕴含 识别 是 有效 的 。	实验 结果 表明 , 该 方法 对于 中 文 文本 蕴含 识别 是 有效 的 。	1>2	attribution	attribution
nlpabs60_Chi	102-115	128-139	在 2014 年 RITE-VAL 评测 任务 的 数据 集上 MacroF1 结果 为 61.74% ,	该 方法 对于 中 文 文本 蕴含 识别 是 有效 的 。	102-123	124-139	在 2014 年 RITE-VAL 评测 任务 的 数据 集上 MacroF1 结果 为 61.74% , 超过 评测 第一 名 的 结果 61.51% 。	实验 结果 表明 , 该 方法 对于 中 文 文本 蕴含 识别 是 有效 的 。	1<2	elab-addition	elab-addition
nlpabs61_Chi	1-13	48-72	笑话 作 为 国家 级 非 物质 文化 遗产 , 历史 悠久 ,	该 文 构 建 的 大 规模 中 文笑话 语料 库 为 人工 智能 以及 语言 学 研究 提供 了 有利 的 资源 支撑 。	1-47	48-72	笑话 作 为 国家 级 非 物质 文化 遗产 , 历史 悠久 , 普遍 存在 于 人们 的 日常 生活 中 , 是 最 贴近 人们 生活 的 艺术 体裁 之 一 , 笑话 的 理解 也是 人工 智能 发展 需要 攻克 的 难题 之 一 。	该 文 构 建 的 大 规模 中 文笑话 语料 库 为 人工 智能 以及 语言 学 研究 提供 了 有利 的 资源 支撑 。	1>2	bg-general	bg-general
nlpabs61_Chi	1-13	14-22	笑话 作 为 国家 级 非 物质 文化 遗产 , 历史 悠久 ,	普遍 存在 于 人们 的 日常 生活 中 ,	1-47	1-47	笑话 作 为 国家 级 非 物质 文化 遗产 , 历史 悠久 , 普遍 存在 于 人们 的 日常 生活 中 , 是 最 贴近 人们 生活 的 艺术 体裁 之 一 , 笑话 的 理解 也是 人工 智能 发展 需要 攻克 的 难题 之 一 。	笑话 作 为 国家 级 非 物质 文化 遗产 , 历史 悠久 , 普遍 存在 于 人们 的 日常 生活 中 , 是 最 贴近 人们 生活 的 艺术 体裁 之 一 , 笑话 的 理解 也是 人工 智能 发展 需要 攻克 的 难题 之 一 。	1<2	elab-addition	elab-addition
nlpabs61_Chi	1-13	23-33	笑话 作 为 国家 级 非 物质 文化 遗产 , 历史 悠久 ,	是 最 贴近 人们 生活 的 艺术 体裁 之 一 ,	1-47	1-47	笑话 作 为 国家 级 非 物质 文化 遗产 , 历史 悠久 , 普遍 存在 于 人们 的 日常 生活 中 , 是 最 贴近 人们 生活 的 艺术 体裁 之 一 , 笑话 的 理解 也是 人工 智能 发展 需要 攻克 的 难题 之 一 。	笑话 作 为 国家 级 非 物质 文化 遗产 , 历史 悠久 , 普遍 存在 于 人们 的 日常 生活 中 , 是 最 贴近 人们 生活 的 艺术 体裁 之 一 , 笑话 的 理解 也是 人工 智能 发展 需要 攻克 的 难题 之 一 。	1<2	elab-addition	elab-addition
nlpabs61_Chi	1-13	34-47	笑话 作 为 国家 级 非 物质 文化 遗产 , 历史 悠久 ,	笑话 的 理解 也是 人工 智能 发展 需要 攻克 的 难题 之 一 。	1-47	1-47	笑话 作 为 国家 级 非 物质 文化 遗产 , 历史 悠久 , 普遍 存在 于 人们 的 日常 生活 中 , 是 最 贴近 人们 生活 的 艺术 体裁 之 一 , 笑话 的 理解 也是 人工 智能 发展 需要 攻克 的 难题 之 一 。	笑话 作 为 国家 级 非 物质 文化 遗产 , 历史 悠久 , 普遍 存在 于 人们 的 日常 生活 中 , 是 最 贴近 人们 生活 的 艺术 体裁 之 一 , 笑话 的 理解 也是 人工 智能 发展 需要 攻克 的 难题 之 一 。	1<2	elab-addition	elab-addition
nlpabs61_Chi	48-72	73-87	该 文 构 建 的 大 规模 中 文笑话 语料 库 为 人工 智能 以及 语言 学 研究 提供 了 有利 的 资源 支撑 。	该文 首先 归纳 总结 笑话 语料 库 所 依据 的 笑话 相关 理论 基础 ,	48-72	73-152	该 文 构 建 的 大 规模 中 文笑话 语料 库 为 人工 智能 以及 语言 学 研究 提供 了 有利 的 资源 支撑 。	该文 首先 归纳 总结 笑话 语料 库 所 依据 的 笑话 相关 理论 基础 , 然后 对 语料 库 构建 中 语料 标注 、 语料 分析 等 工作 做 了 详细 的 介绍 , 最后 在 语料 库 的 基础 上 , 分别 将 笑话 与 故事 、 微博 、 歇后 语 / 谚语 以及 新闻 四 种 体裁 分别 做 了 识别 工作 , 验证 了 笑话 简洁 、 具有 一定 的 情节 、 富含 情感 等 特征 。	1<2	elab-process_step	elab-process_step
nlpabs61_Chi	73-87	88-106	该文 首先 归纳 总结 笑话 语料 库 所 依据 的 笑话 相关 理论 基础 ,	然后 对 语料 库 构建 中 语料 标注 、 语料 分析 等 工作 做 了 详细 的 介绍 ,	73-152	73-152	该文 首先 归纳 总结 笑话 语料 库 所 依据 的 笑话 相关 理论 基础 , 然后 对 语料 库 构建 中 语料 标注 、 语料 分析 等 工作 做 了 详细 的 介绍 , 最后 在 语料 库 的 基础 上 , 分别 将 笑话 与 故事 、 微博 、 歇后 语 / 谚语 以及 新闻 四 种 体裁 分别 做 了 识别 工作 , 验证 了 笑话 简洁 、 具有 一定 的 情节 、 富含 情感 等 特征 。	该文 首先 归纳 总结 笑话 语料 库 所 依据 的 笑话 相关 理论 基础 , 然后 对 语料 库 构建 中 语料 标注 、 语料 分析 等 工作 做 了 详细 的 介绍 , 最后 在 语料 库 的 基础 上 , 分别 将 笑话 与 故事 、 微博 、 歇后 语 / 谚语 以及 新闻 四 种 体裁 分别 做 了 识别 工作 , 验证 了 笑话 简洁 、 具有 一定 的 情节 、 富含 情感 等 特征 。	1<2	joint	joint
nlpabs61_Chi	107-114	115-137	最后 在 语料 库 的 基础 上 ,	分别 将 笑话 与 故事 、 微博 、 歇后 语 / 谚语 以及 新闻 四 种 体裁 分别 做 了 识别 工作 ,	73-152	73-152	该文 首先 归纳 总结 笑话 语料 库 所 依据 的 笑话 相关 理论 基础 , 然后 对 语料 库 构建 中 语料 标注 、 语料 分析 等 工作 做 了 详细 的 介绍 , 最后 在 语料 库 的 基础 上 , 分别 将 笑话 与 故事 、 微博 、 歇后 语 / 谚语 以及 新闻 四 种 体裁 分别 做 了 识别 工作 , 验证 了 笑话 简洁 、 具有 一定 的 情节 、 富含 情感 等 特征 。	该文 首先 归纳 总结 笑话 语料 库 所 依据 的 笑话 相关 理论 基础 , 然后 对 语料 库 构建 中 语料 标注 、 语料 分析 等 工作 做 了 详细 的 介绍 , 最后 在 语料 库 的 基础 上 , 分别 将 笑话 与 故事 、 微博 、 歇后 语 / 谚语 以及 新闻 四 种 体裁 分别 做 了 识别 工作 , 验证 了 笑话 简洁 、 具有 一定 的 情节 、 富含 情感 等 特征 。	1>2	bg-general	bg-general
nlpabs61_Chi	88-106	115-137	然后 对 语料 库 构建 中 语料 标注 、 语料 分析 等 工作 做 了 详细 的 介绍 ,	分别 将 笑话 与 故事 、 微博 、 歇后 语 / 谚语 以及 新闻 四 种 体裁 分别 做 了 识别 工作 ,	73-152	73-152	该文 首先 归纳 总结 笑话 语料 库 所 依据 的 笑话 相关 理论 基础 , 然后 对 语料 库 构建 中 语料 标注 、 语料 分析 等 工作 做 了 详细 的 介绍 , 最后 在 语料 库 的 基础 上 , 分别 将 笑话 与 故事 、 微博 、 歇后 语 / 谚语 以及 新闻 四 种 体裁 分别 做 了 识别 工作 , 验证 了 笑话 简洁 、 具有 一定 的 情节 、 富含 情感 等 特征 。	该文 首先 归纳 总结 笑话 语料 库 所 依据 的 笑话 相关 理论 基础 , 然后 对 语料 库 构建 中 语料 标注 、 语料 分析 等 工作 做 了 详细 的 介绍 , 最后 在 语料 库 的 基础 上 , 分别 将 笑话 与 故事 、 微博 、 歇后 语 / 谚语 以及 新闻 四 种 体裁 分别 做 了 识别 工作 , 验证 了 笑话 简洁 、 具有 一定 的 情节 、 富含 情感 等 特征 。	1<2	joint	joint
nlpabs61_Chi	115-137	138-152	分别 将 笑话 与 故事 、 微博 、 歇后 语 / 谚语 以及 新闻 四 种 体裁 分别 做 了 识别 工作 ,	验证 了 笑话 简洁 、 具有 一定 的 情节 、 富含 情感 等 特征 。	73-152	73-152	该文 首先 归纳 总结 笑话 语料 库 所 依据 的 笑话 相关 理论 基础 , 然后 对 语料 库 构建 中 语料 标注 、 语料 分析 等 工作 做 了 详细 的 介绍 , 最后 在 语料 库 的 基础 上 , 分别 将 笑话 与 故事 、 微博 、 歇后 语 / 谚语 以及 新闻 四 种 体裁 分别 做 了 识别 工作 , 验证 了 笑话 简洁 、 具有 一定 的 情节 、 富含 情感 等 特征 。	该文 首先 归纳 总结 笑话 语料 库 所 依据 的 笑话 相关 理论 基础 , 然后 对 语料 库 构建 中 语料 标注 、 语料 分析 等 工作 做 了 详细 的 介绍 , 最后 在 语料 库 的 基础 上 , 分别 将 笑话 与 故事 、 微博 、 歇后 语 / 谚语 以及 新闻 四 种 体裁 分别 做 了 识别 工作 , 验证 了 笑话 简洁 、 具有 一定 的 情节 、 富含 情感 等 特征 。	1<2	elab-addition	elab-addition
nlpabs61_Chi	115-137	153-166	分别 将 笑话 与 故事 、 微博 、 歇后 语 / 谚语 以及 新闻 四 种 体裁 分别 做 了 识别 工作 ,	同时 通过 与 等长 的 负例 构成 的 数据 集 进行 笑话 识别 ,	73-152	153-175	该文 首先 归纳 总结 笑话 语料 库 所 依据 的 笑话 相关 理论 基础 , 然后 对 语料 库 构建 中 语料 标注 、 语料 分析 等 工作 做 了 详细 的 介绍 , 最后 在 语料 库 的 基础 上 , 分别 将 笑话 与 故事 、 微博 、 歇后 语 / 谚语 以及 新闻 四 种 体裁 分别 做 了 识别 工作 , 验证 了 笑话 简洁 、 具有 一定 的 情节 、 富含 情感 等 特征 。	同时 通过 与 等长 的 负例 构成 的 数据 集 进行 笑话 识别 , 验证 了 所 提出 特征 的 有效 性 。	1<2	joint	joint
nlpabs61_Chi	153-166	167-175	同时 通过 与 等长 的 负例 构成 的 数据 集 进行 笑话 识别 ,	验证 了 所 提出 特征 的 有效 性 。	153-175	153-175	同时 通过 与 等长 的 负例 构成 的 数据 集 进行 笑话 识别 , 验证 了 所 提出 特征 的 有效 性 。	同时 通过 与 等长 的 负例 构成 的 数据 集 进行 笑话 识别 , 验证 了 所 提出 特征 的 有效 性 。	1<2	elab-addition	elab-addition
nlpabs62_Chi	1-13	47-52	神经 机器 翻译 是 目前 机器 翻译 领域 最热门 的 研究 方法 。	该 文 利用 数据 增强 技术	1-13	47-72	神经 机器 翻译 是 目前 机器 翻译 领域 最热门 的 研究 方法 。	该 文 利用 数据 增强 技术 对 资源 贫乏 语种 的 训练 数据 进行 扩充 , 以 此 增强 神经 机器 翻译 的 泛化 能力 。	1>2	bg-goal	bg-goal
nlpabs62_Chi	14-19	20-35	和 统计 机器 翻译 相比 ,	神经 机器 翻译 在 语料 丰富 的 语种 上 可以 取得 非 常好 的 结果 ,	14-46	14-46	和 统计 机器 翻译 相比 , 神经 机器 翻译 在 语料 丰富 的 语种 上 可以 取得 非 常好 的 结果 , 但是 在 资源 比较 稀缺 的 语种 上 表现 一般 。	和 统计 机器 翻译 相比 , 神经 机器 翻译 在 语料 丰富 的 语种 上 可以 取得 非 常好 的 结果 , 但是 在 资源 比较 稀缺 的 语种 上 表现 一般 。	1>2	comparison	comparison
nlpabs62_Chi	1-13	20-35	神经 机器 翻译 是 目前 机器 翻译 领域 最热门 的 研究 方法 。	神经 机器 翻译 在 语料 丰富 的 语种 上 可以 取得 非 常好 的 结果 ,	1-13	14-46	神经 机器 翻译 是 目前 机器 翻译 领域 最热门 的 研究 方法 。	和 统计 机器 翻译 相比 , 神经 机器 翻译 在 语料 丰富 的 语种 上 可以 取得 非 常好 的 结果 , 但是 在 资源 比较 稀缺 的 语种 上 表现 一般 。	1<2	elab-addition	elab-addition
nlpabs62_Chi	20-35	36-46	神经 机器 翻译 在 语料 丰富 的 语种 上 可以 取得 非 常好 的 结果 ,	但是 在 资源 比较 稀缺 的 语种 上 表现 一般 。	14-46	14-46	和 统计 机器 翻译 相比 , 神经 机器 翻译 在 语料 丰富 的 语种 上 可以 取得 非 常好 的 结果 , 但是 在 资源 比较 稀缺 的 语种 上 表现 一般 。	和 统计 机器 翻译 相比 , 神经 机器 翻译 在 语料 丰富 的 语种 上 可以 取得 非 常好 的 结果 , 但是 在 资源 比较 稀缺 的 语种 上 表现 一般 。	1<2	contrast	contrast
nlpabs62_Chi	47-52	53-62	该 文 利用 数据 增强 技术	对 资源 贫乏 语种 的 训练 数据 进行 扩充 ,	47-72	47-72	该 文 利用 数据 增强 技术 对 资源 贫乏 语种 的 训练 数据 进行 扩充 , 以 此 增强 神经 机器 翻译 的 泛化 能力 。	该 文 利用 数据 增强 技术 对 资源 贫乏 语种 的 训练 数据 进行 扩充 , 以 此 增强 神经 机器 翻译 的 泛化 能力 。	1<2	enablement	enablement
nlpabs62_Chi	53-62	63-72	对 资源 贫乏 语种 的 训练 数据 进行 扩充 ,	以 此 增强 神经 机器 翻译 的 泛化 能力 。	47-72	47-72	该 文 利用 数据 增强 技术 对 资源 贫乏 语种 的 训练 数据 进行 扩充 , 以 此 增强 神经 机器 翻译 的 泛化 能力 。	该 文 利用 数据 增强 技术 对 资源 贫乏 语种 的 训练 数据 进行 扩充 , 以 此 增强 神经 机器 翻译 的 泛化 能力 。	1<2	enablement	enablement
nlpabs62_Chi	47-52	73-87	该 文 利用 数据 增强 技术	该文 在 藏 汉 、 汉 英 两 种 语言 对上 进行 了 实验 ,	47-72	73-117	该 文 利用 数据 增强 技术 对 资源 贫乏 语种 的 训练 数据 进行 扩充 , 以 此 增强 神经 机器 翻译 的 泛化 能力 。	该文 在 藏 汉 、 汉 英 两 种 语言 对上 进行 了 实验 , 当 训练 数据 规模 只有 10万 平行 句 对时 , 相较 于 基准 系统 , 在 两 种 语言 对上 均 获得 了 4 个 BLEU 值 的 提高 。	1<2	elab-addition	elab-addition
nlpabs62_Chi	88-97	103-117	当 训练 数据 规模 只有 10万 平行 句 对时 ,	在 两 种 语言 对上 均 获得 了 4 个 BLEU 值 的 提高 。	73-117	73-117	该文 在 藏 汉 、 汉 英 两 种 语言 对上 进行 了 实验 , 当 训练 数据 规模 只有 10万 平行 句 对时 , 相较 于 基准 系统 , 在 两 种 语言 对上 均 获得 了 4 个 BLEU 值 的 提高 。	该文 在 藏 汉 、 汉 英 两 种 语言 对上 进行 了 实验 , 当 训练 数据 规模 只有 10万 平行 句 对时 , 相较 于 基准 系统 , 在 两 种 语言 对上 均 获得 了 4 个 BLEU 值 的 提高 。	1>2	temporal	temporal
nlpabs62_Chi	98-102	103-117	相较 于 基准 系统 ,	在 两 种 语言 对上 均 获得 了 4 个 BLEU 值 的 提高 。	73-117	73-117	该文 在 藏 汉 、 汉 英 两 种 语言 对上 进行 了 实验 , 当 训练 数据 规模 只有 10万 平行 句 对时 , 相较 于 基准 系统 , 在 两 种 语言 对上 均 获得 了 4 个 BLEU 值 的 提高 。	该文 在 藏 汉 、 汉 英 两 种 语言 对上 进行 了 实验 , 当 训练 数据 规模 只有 10万 平行 句 对时 , 相较 于 基准 系统 , 在 两 种 语言 对上 均 获得 了 4 个 BLEU 值 的 提高 。	1>2	comparison	comparison
nlpabs62_Chi	73-87	103-117	该文 在 藏 汉 、 汉 英 两 种 语言 对上 进行 了 实验 ,	在 两 种 语言 对上 均 获得 了 4 个 BLEU 值 的 提高 。	73-117	73-117	该文 在 藏 汉 、 汉 英 两 种 语言 对上 进行 了 实验 , 当 训练 数据 规模 只有 10万 平行 句 对时 , 相较 于 基准 系统 , 在 两 种 语言 对上 均 获得 了 4 个 BLEU 值 的 提高 。	该文 在 藏 汉 、 汉 英 两 种 语言 对上 进行 了 实验 , 当 训练 数据 规模 只有 10万 平行 句 对时 , 相较 于 基准 系统 , 在 两 种 语言 对上 均 获得 了 4 个 BLEU 值 的 提高 。	1<2	elab-addition	elab-addition
nlpabs62_Chi	118-120	121-142	实验 表明 ,	数据 增强 技术 可以 有效 地 解决 神经 机器 翻译 因为 训练 数据 太少 而 导致 的 泛化 能力 不足 问题 。	118-142	118-142	实验 表明 , 数据 增强 技术 可以 有效 地 解决 神经 机器 翻译 因为 训练 数据 太少 而 导致 的 泛化 能力 不足 问题 。	实验 表明 , 数据 增强 技术 可以 有效 地 解决 神经 机器 翻译 因为 训练 数据 太少 而 导致 的 泛化 能力 不足 问题 。	1>2	attribution	attribution
nlpabs62_Chi	47-52	121-142	该 文 利用 数据 增强 技术	数据 增强 技术 可以 有效 地 解决 神经 机器 翻译 因为 训练 数据 太少 而 导致 的 泛化 能力 不足 问题 。	47-72	118-142	该 文 利用 数据 增强 技术 对 资源 贫乏 语种 的 训练 数据 进行 扩充 , 以 此 增强 神经 机器 翻译 的 泛化 能力 。	实验 表明 , 数据 增强 技术 可以 有效 地 解决 神经 机器 翻译 因为 训练 数据 太少 而 导致 的 泛化 能力 不足 问题 。	1<2	evaluation	evaluation
nlpabs63_Chi	1-7	45-66	数据 并行 训练 神经 语言 模型 ,	该文 通过 实验 对比 All-Reduce 算法 和 基 于 采样 的 梯度 更新 策略 在 数据 传输 上 的 加速 效果 ,	1-26	45-102	数据 并行 训练 神经 语言 模型 , 旨 在 不 改变 网络 结构 的 同时 , 大 幅度 降低 训练 所 带来 的 时间 消耗 。	该文 通过 实验 对比 All-Reduce 算法 和 基 于 采样 的 梯度 更新 策略 在 数据 传输 上 的 加速 效果 , 使用 了 四 块 NVIDIA TIT AN X ( Pascal ) GPU 设备 在 循环 神经 语言 模型 上 进行 训练 , 两 种 方法 分别 可 获得 约 25% 和 41% 的 速度 提升 。	1>2	bg-general	bg-general
nlpabs63_Chi	1-7	8-16	数据 并行 训练 神经 语言 模型 ,	旨 在 不 改变 网络 结构 的 同时 ,	1-26	1-26	数据 并行 训练 神经 语言 模型 , 旨 在 不 改变 网络 结构 的 同时 , 大 幅度 降低 训练 所 带来 的 时间 消耗 。	数据 并行 训练 神经 语言 模型 , 旨 在 不 改变 网络 结构 的 同时 , 大 幅度 降低 训练 所 带来 的 时间 消耗 。	1<2	elab-addition	elab-addition
nlpabs63_Chi	8-16	17-26	旨 在 不 改变 网络 结构 的 同时 ,	大 幅度 降低 训练 所 带来 的 时间 消耗 。	1-26	1-26	数据 并行 训练 神经 语言 模型 , 旨 在 不 改变 网络 结构 的 同时 , 大 幅度 降低 训练 所 带来 的 时间 消耗 。	数据 并行 训练 神经 语言 模型 , 旨 在 不 改变 网络 结构 的 同时 , 大 幅度 降低 训练 所 带来 的 时间 消耗 。	1<2	joint	joint
nlpabs63_Chi	8-16	27-44	旨 在 不 改变 网络 结构 的 同时 ,	但 由于 多 设备 之间 频繁 的 数据 传输 , 使得 整体 加速 效果 并 不 理想 。	1-26	27-44	数据 并行 训练 神经 语言 模型 , 旨 在 不 改变 网络 结构 的 同时 , 大 幅度 降低 训练 所 带来 的 时间 消耗 。	但 由于 多 设备 之间 频繁 的 数据 传输 , 使得 整体 加速 效果 并 不 理想 。	1<2	contrast	contrast
nlpabs63_Chi	45-66	67-79	该文 通过 实验 对比 All-Reduce 算法 和 基 于 采样 的 梯度 更新 策略 在 数据 传输 上 的 加速 效果 ,	使用 了 四 块 NVIDIA TIT AN X ( Pascal ) GPU 设备	45-102	45-102	该文 通过 实验 对比 All-Reduce 算法 和 基 于 采样 的 梯度 更新 策略 在 数据 传输 上 的 加速 效果 , 使用 了 四 块 NVIDIA TIT AN X ( Pascal ) GPU 设备 在 循环 神经 语言 模型 上 进行 训练 , 两 种 方法 分别 可 获得 约 25% 和 41% 的 速度 提升 。	该文 通过 实验 对比 All-Reduce 算法 和 基 于 采样 的 梯度 更新 策略 在 数据 传输 上 的 加速 效果 , 使用 了 四 块 NVIDIA TIT AN X ( Pascal ) GPU 设备 在 循环 神经 语言 模型 上 进行 训练 , 两 种 方法 分别 可 获得 约 25% 和 41% 的 速度 提升 。	1<2	elab-addition	elab-addition
nlpabs63_Chi	67-79	80-88	使用 了 四 块 NVIDIA TIT AN X ( Pascal ) GPU 设备	在 循环 神经 语言 模型 上 进行 训练 ,	45-102	45-102	该文 通过 实验 对比 All-Reduce 算法 和 基 于 采样 的 梯度 更新 策略 在 数据 传输 上 的 加速 效果 , 使用 了 四 块 NVIDIA TIT AN X ( Pascal ) GPU 设备 在 循环 神经 语言 模型 上 进行 训练 , 两 种 方法 分别 可 获得 约 25% 和 41% 的 速度 提升 。	该文 通过 实验 对比 All-Reduce 算法 和 基 于 采样 的 梯度 更新 策略 在 数据 传输 上 的 加速 效果 , 使用 了 四 块 NVIDIA TIT AN X ( Pascal ) GPU 设备 在 循环 神经 语言 模型 上 进行 训练 , 两 种 方法 分别 可 获得 约 25% 和 41% 的 速度 提升 。	1<2	enablement	enablement
nlpabs63_Chi	45-66	89-102	该文 通过 实验 对比 All-Reduce 算法 和 基 于 采样 的 梯度 更新 策略 在 数据 传输 上 的 加速 效果 ,	两 种 方法 分别 可 获得 约 25% 和 41% 的 速度 提升 。	45-102	45-102	该文 通过 实验 对比 All-Reduce 算法 和 基 于 采样 的 梯度 更新 策略 在 数据 传输 上 的 加速 效果 , 使用 了 四 块 NVIDIA TIT AN X ( Pascal ) GPU 设备 在 循环 神经 语言 模型 上 进行 训练 , 两 种 方法 分别 可 获得 约 25% 和 41% 的 速度 提升 。	该文 通过 实验 对比 All-Reduce 算法 和 基 于 采样 的 梯度 更新 策略 在 数据 传输 上 的 加速 效果 , 使用 了 四 块 NVIDIA TIT AN X ( Pascal ) GPU 设备 在 循环 神经 语言 模型 上 进行 训练 , 两 种 方法 分别 可 获得 约 25% 和 41% 的 速度 提升 。	1<2	evaluation	evaluation
nlpabs63_Chi	45-66	103-129	该文 通过 实验 对比 All-Reduce 算法 和 基 于 采样 的 梯度 更新 策略 在 数据 传输 上 的 加速 效果 ,	同时 , 该文 还 针对 数据 并行 方法 的 适用 性 以及 不同 的 硬件 设备 连接 方式 对 传输 速度 的 影响 进行 了 讨论 。	45-102	103-129	该文 通过 实验 对比 All-Reduce 算法 和 基 于 采样 的 梯度 更新 策略 在 数据 传输 上 的 加速 效果 , 使用 了 四 块 NVIDIA TIT AN X ( Pascal ) GPU 设备 在 循环 神经 语言 模型 上 进行 训练 , 两 种 方法 分别 可 获得 约 25% 和 41% 的 速度 提升 。	同时 , 该文 还 针对 数据 并行 方法 的 适用 性 以及 不同 的 硬件 设备 连接 方式 对 传输 速度 的 影响 进行 了 讨论 。	1<2	elab-addition	elab-addition
nlpabs64_Chi	1-21	22-35	该 文针 对 传统 蒙古 文 与 西里尔蒙古 文 设计 开发 了 一 个 功能 完备 的 信息 检索 系统 。	在 网页 抓取 方面 , 采用 MD5 算法 对 爬虫 进行 了 改进 ,	1-21	22-41	该 文针 对 传统 蒙古 文 与 西里尔蒙古 文 设计 开发 了 一 个 功能 完备 的 信息 检索 系统 。	在 网页 抓取 方面 , 采用 MD5 算法 对 爬虫 进行 了 改进 , 提升 了 爬虫 的 速度 。	1<2	elab-aspect	elab-aspect
nlpabs64_Chi	22-35	36-41	在 网页 抓取 方面 , 采用 MD5 算法 对 爬虫 进行 了 改进 ,	提升 了 爬虫 的 速度 。	22-41	22-41	在 网页 抓取 方面 , 采用 MD5 算法 对 爬虫 进行 了 改进 , 提升 了 爬虫 的 速度 。	在 网页 抓取 方面 , 采用 MD5 算法 对 爬虫 进行 了 改进 , 提升 了 爬虫 的 速度 。	1<2	elab-addition	elab-addition
nlpabs64_Chi	22-35	42-61	在 网页 抓取 方面 , 采用 MD5 算法 对 爬虫 进行 了 改进 ,	在 预 处理 阶段 , 对 蒙古 文 文档 进行 了 编码 转换 、 词缀 切分 转换 等 操作 。	22-41	42-61	在 网页 抓取 方面 , 采用 MD5 算法 对 爬虫 进行 了 改进 , 提升 了 爬虫 的 速度 。	在 预 处理 阶段 , 对 蒙古 文 文档 进行 了 编码 转换 、 词缀 切分 转换 等 操作 。	1<2	joint	joint
nlpabs64_Chi	22-35	62-78	在 网页 抓取 方面 , 采用 MD5 算法 对 爬虫 进行 了 改进 ,	在 检索 方面 , 使用 向量 空间 模型 实现 了 对 蒙古 文 文档 的 检索 。	22-41	62-78	在 网页 抓取 方面 , 采用 MD5 算法 对 爬虫 进行 了 改进 , 提升 了 爬虫 的 速度 。	在 检索 方面 , 使用 向量 空间 模型 实现 了 对 蒙古 文 文档 的 检索 。	1<2	joint	joint
nlpabs64_Chi	1-21	79-98	该 文针 对 传统 蒙古 文 与 西里尔蒙古 文 设计 开发 了 一 个 功能 完备 的 信息 检索 系统 。	在 该 文 系统 中 加入 了 西里尔蒙古 文 到 传统 蒙古 文 转换 和 更新 统计 等 模块 ,	1-21	79-114	该 文针 对 传统 蒙古 文 与 西里尔蒙古 文 设计 开发 了 一 个 功能 完备 的 信息 检索 系统 。	在 该 文 系统 中 加入 了 西里尔蒙古 文 到 传统 蒙古 文 转换 和 更新 统计 等 模块 , 最终 搭建 了 一 个 可以 达到 应用 要求 的 蒙古 文 信息 检索 系统 。	1<2	elab-addition	elab-addition
nlpabs64_Chi	79-98	99-114	在 该 文 系统 中 加入 了 西里尔蒙古 文 到 传统 蒙古 文 转换 和 更新 统计 等 模块 ,	最终 搭建 了 一 个 可以 达到 应用 要求 的 蒙古 文 信息 检索 系统 。	79-114	79-114	在 该 文 系统 中 加入 了 西里尔蒙古 文 到 传统 蒙古 文 转换 和 更新 统计 等 模块 , 最终 搭建 了 一 个 可以 达到 应用 要求 的 蒙古 文 信息 检索 系统 。	在 该 文 系统 中 加入 了 西里尔蒙古 文 到 传统 蒙古 文 转换 和 更新 统计 等 模块 , 最终 搭建 了 一 个 可以 达到 应用 要求 的 蒙古 文 信息 检索 系统 。	1<2	elab-addition	elab-addition
nlpabs65_Chi	1-7	23-34	由于 哈萨克 语构 词法 的 特点 ,	该 文 采用 实验 语音 学 的 基本 理论 和 方法 ,	1-22	23-48	由于 哈萨克 语构 词法 的 特点 , 九 个 元音 的 声频 特性 在 语音 识别 中 具有 重要 的 作用 。	该 文 采用 实验 语音 学 的 基本 理论 和 方法 , 研究 了 哈萨克 语 多 音 节 词 中 的 元 音 格局 。	1>2	bg-general	bg-general
nlpabs65_Chi	1-7	8-22	由于 哈萨克 语构 词法 的 特点 ,	九 个 元音 的 声频 特性 在 语音 识别 中 具有 重要 的 作用 。	1-22	1-22	由于 哈萨克 语构 词法 的 特点 , 九 个 元音 的 声频 特性 在 语音 识别 中 具有 重要 的 作用 。	由于 哈萨克 语构 词法 的 特点 , 九 个 元音 的 声频 特性 在 语音 识别 中 具有 重要 的 作用 。	1<2	result	result
nlpabs65_Chi	23-34	35-48	该 文 采用 实验 语音 学 的 基本 理论 和 方法 ,	研究 了 哈萨克 语 多 音 节 词 中 的 元 音 格局 。	23-48	23-48	该 文 采用 实验 语音 学 的 基本 理论 和 方法 , 研究 了 哈萨克 语 多 音 节 词 中 的 元 音 格局 。	该 文 采用 实验 语音 学 的 基本 理论 和 方法 , 研究 了 哈萨克 语 多 音 节 词 中 的 元 音 格局 。	1<2	enablement	enablement
nlpabs65_Chi	49-64	65-83	针 对 从 语音 库 中 挑选 的 1 062 个 多 音 节 词 ,	分别 对 其 词首 、 词腹 和 词尾 音节 中 的 元音 共振 峰频 率 值 进行 统计 ,	49-123	49-123	针 对 从 语音 库 中 挑选 的 1 062 个 多 音 节 词 , 分别 对 其 词首 、 词腹 和 词尾 音节 中 的 元音 共振 峰频 率 值 进行 统计 , 并 采用 Joos 方法 详细 地 归纳 和 分析 了 哈萨克 语 词首 、 词腹 和 词尾 音节 元 音格 局 以及 存在 的 差异 , 绘制 出 了 哈萨克 语 多 音节 词 元音 的 共 振峰 模式 。	针 对 从 语音 库 中 挑选 的 1 062 个 多 音 节 词 , 分别 对 其 词首 、 词腹 和 词尾 音节 中 的 元音 共振 峰频 率 值 进行 统计 , 并 采用 Joos 方法 详细 地 归纳 和 分析 了 哈萨克 语 词首 、 词腹 和 词尾 音节 元 音格 局 以及 存在 的 差异 , 绘制 出 了 哈萨克 语 多 音节 词 元音 的 共 振峰 模式 。	1>2	bg-general	bg-general
nlpabs65_Chi	35-48	65-83	研究 了 哈萨克 语 多 音 节 词 中 的 元 音 格局 。	分别 对 其 词首 、 词腹 和 词尾 音节 中 的 元音 共振 峰频 率 值 进行 统计 ,	23-48	49-123	该 文 采用 实验 语音 学 的 基本 理论 和 方法 , 研究 了 哈萨克 语 多 音 节 词 中 的 元 音 格局 。	针 对 从 语音 库 中 挑选 的 1 062 个 多 音 节 词 , 分别 对 其 词首 、 词腹 和 词尾 音节 中 的 元音 共振 峰频 率 值 进行 统计 , 并 采用 Joos 方法 详细 地 归纳 和 分析 了 哈萨克 语 词首 、 词腹 和 词尾 音节 元 音格 局 以及 存在 的 差异 , 绘制 出 了 哈萨克 语 多 音节 词 元音 的 共 振峰 模式 。	1<2	elab-addition	elab-addition
nlpabs65_Chi	65-83	84-109	分别 对 其 词首 、 词腹 和 词尾 音节 中 的 元音 共振 峰频 率 值 进行 统计 ,	并 采用 Joos 方法 详细 地 归纳 和 分析 了 哈萨克 语 词首 、 词腹 和 词尾 音节 元 音格 局 以及 存在 的 差异 ,	49-123	49-123	针 对 从 语音 库 中 挑选 的 1 062 个 多 音 节 词 , 分别 对 其 词首 、 词腹 和 词尾 音节 中 的 元音 共振 峰频 率 值 进行 统计 , 并 采用 Joos 方法 详细 地 归纳 和 分析 了 哈萨克 语 词首 、 词腹 和 词尾 音节 元 音格 局 以及 存在 的 差异 , 绘制 出 了 哈萨克 语 多 音节 词 元音 的 共 振峰 模式 。	针 对 从 语音 库 中 挑选 的 1 062 个 多 音 节 词 , 分别 对 其 词首 、 词腹 和 词尾 音节 中 的 元音 共振 峰频 率 值 进行 统计 , 并 采用 Joos 方法 详细 地 归纳 和 分析 了 哈萨克 语 词首 、 词腹 和 词尾 音节 元 音格 局 以及 存在 的 差异 , 绘制 出 了 哈萨克 语 多 音节 词 元音 的 共 振峰 模式 。	1<2	joint	joint
nlpabs65_Chi	84-109	110-123	并 采用 Joos 方法 详细 地 归纳 和 分析 了 哈萨克 语 词首 、 词腹 和 词尾 音节 元 音格 局 以及 存在 的 差异 ,	绘制 出 了 哈萨克 语 多 音节 词 元音 的 共 振峰 模式 。	49-123	49-123	针 对 从 语音 库 中 挑选 的 1 062 个 多 音 节 词 , 分别 对 其 词首 、 词腹 和 词尾 音节 中 的 元音 共振 峰频 率 值 进行 统计 , 并 采用 Joos 方法 详细 地 归纳 和 分析 了 哈萨克 语 词首 、 词腹 和 词尾 音节 元 音格 局 以及 存在 的 差异 , 绘制 出 了 哈萨克 语 多 音节 词 元音 的 共 振峰 模式 。	针 对 从 语音 库 中 挑选 的 1 062 个 多 音 节 词 , 分别 对 其 词首 、 词腹 和 词尾 音节 中 的 元音 共振 峰频 率 值 进行 统计 , 并 采用 Joos 方法 详细 地 归纳 和 分析 了 哈萨克 语 词首 、 词腹 和 词尾 音节 元 音格 局 以及 存在 的 差异 , 绘制 出 了 哈萨克 语 多 音节 词 元音 的 共 振峰 模式 。	1<2	enablement	enablement
nlpabs65_Chi	23-34	124-140	该 文 采用 实验 语音 学 的 基本 理论 和 方法 ,	该项 研究 结果 对 哈萨克 语 的 语音 研究 及 应用 具有 较高 的 参考 价值 。	23-48	124-140	该 文 采用 实验 语音 学 的 基本 理论 和 方法 , 研究 了 哈萨克 语 多 音 节 词 中 的 元 音 格局 。	该项 研究 结果 对 哈萨克 语 的 语音 研究 及 应用 具有 较高 的 参考 价值 。	1<2	elab-addition	elab-addition
nlpabs66_Chi	1-10	11-32	随 着 藏 语 语音 合成 研究 的 深入 ,	藏 语 同形 异音 词 的 读音 问题 成 为 影响 合成 系统 自然 度 和 可懂 度 的 主要 障碍 。	1-32	1-32	随 着 藏 语 语音 合成 研究 的 深入 , 藏 语 同形 异音 词 的 读音 问题 成 为 影响 合成 系统 自然 度 和 可懂 度 的 主要 障碍 。	随 着 藏 语 语音 合成 研究 的 深入 , 藏 语 同形 异音 词 的 读音 问题 成 为 影响 合成 系统 自然 度 和 可懂 度 的 主要 障碍 。	1>2	bg-general	bg-general
nlpabs66_Chi	11-32	96-105	藏 语 同形 异音 词 的 读音 问题 成 为 影响 合成 系统 自然 度 和 可懂 度 的 主要 障碍 。	共 收集 整理 了 465 个 同形 异 音词 ,	1-32	59-182	随 着 藏 语 语音 合成 研究 的 深入 , 藏 语 同形 异音 词 的 读音 问题 成 为 影响 合成 系统 自然 度 和 可懂 度 的 主要 障碍 。	该文 从 藏 语 本身 独有 的 语言 规则 和 语音 特点 出发 , 依据 《 藏 汉 大 词典 》 , 在 其 所 列出 的 常用 藏 语 同形 异音 词 的 基础 上 , 共 收集 整理 了 465 个 同形 异 音词 , 然后 从 372320 个 句子 文本 中 统计 出 了 同 形异 音词 在 藏 语 文本 中 的 出现 频率 及 不同 读音 的 使用 频率 , 并 深度 辨析 了 藏 语 同形异 音词 的 构词 形式 、 分类 以及 在 具体 文本 中 出现 的 形式 , 最后 结合 实例 提出 了 具体 的 消歧 方法 及 实验 结果 , 为 语音 合成 系统 的 前端 文本 分析 模块 提供 了 有力 依据 。	1>2	bg-general	bg-general
nlpabs66_Chi	11-32	33-49	藏 语 同形 异音 词 的 读音 问题 成 为 影响 合成 系统 自然 度 和 可懂 度 的 主要 障碍 。	藏 语 同形 异 音词 与 汉 语 中 多 音词 的 性质 有 所 不同 ,	1-32	33-58	随 着 藏 语 语音 合成 研究 的 深入 , 藏 语 同形 异音 词 的 读音 问题 成 为 影响 合成 系统 自然 度 和 可懂 度 的 主要 障碍 。	藏 语 同形 异 音词 与 汉 语 中 多 音词 的 性质 有 所 不同 , 仅仅 依靠 词典 不 一定 能 解决 问题 。	1<2	elab-addition	elab-addition
nlpabs66_Chi	33-49	50-58	藏 语 同形 异 音词 与 汉 语 中 多 音词 的 性质 有 所 不同 ,	仅仅 依靠 词典 不 一定 能 解决 问题 。	33-58	33-58	藏 语 同形 异 音词 与 汉 语 中 多 音词 的 性质 有 所 不同 , 仅仅 依靠 词典 不 一定 能 解决 问题 。	藏 语 同形 异 音词 与 汉 语 中 多 音词 的 性质 有 所 不同 , 仅仅 依靠 词典 不 一定 能 解决 问题 。	1<2	elab-addition	elab-addition
nlpabs66_Chi	59-72	96-105	该文 从 藏 语 本身 独有 的 语言 规则 和 语音 特点 出发 ,	共 收集 整理 了 465 个 同形 异 音词 ,	59-182	59-182	该文 从 藏 语 本身 独有 的 语言 规则 和 语音 特点 出发 , 依据 《 藏 汉 大 词典 》 , 在 其 所 列出 的 常用 藏 语 同形 异音 词 的 基础 上 , 共 收集 整理 了 465 个 同形 异 音词 , 然后 从 372320 个 句子 文本 中 统计 出 了 同 形异 音词 在 藏 语 文本 中 的 出现 频率 及 不同 读音 的 使用 频率 , 并 深度 辨析 了 藏 语 同形异 音词 的 构词 形式 、 分类 以及 在 具体 文本 中 出现 的 形式 , 最后 结合 实例 提出 了 具体 的 消歧 方法 及 实验 结果 , 为 语音 合成 系统 的 前端 文本 分析 模块 提供 了 有力 依据 。	该文 从 藏 语 本身 独有 的 语言 规则 和 语音 特点 出发 , 依据 《 藏 汉 大 词典 》 , 在 其 所 列出 的 常用 藏 语 同形 异音 词 的 基础 上 , 共 收集 整理 了 465 个 同形 异 音词 , 然后 从 372320 个 句子 文本 中 统计 出 了 同 形异 音词 在 藏 语 文本 中 的 出现 频率 及 不同 读音 的 使用 频率 , 并 深度 辨析 了 藏 语 同形异 音词 的 构词 形式 、 分类 以及 在 具体 文本 中 出现 的 形式 , 最后 结合 实例 提出 了 具体 的 消歧 方法 及 实验 结果 , 为 语音 合成 系统 的 前端 文本 分析 模块 提供 了 有力 依据 。	1>2	manner-means	manner-means
nlpabs66_Chi	59-72	73-80	该文 从 藏 语 本身 独有 的 语言 规则 和 语音 特点 出发 ,	依据 《 藏 汉 大 词典 》 ,	59-182	59-182	该文 从 藏 语 本身 独有 的 语言 规则 和 语音 特点 出发 , 依据 《 藏 汉 大 词典 》 , 在 其 所 列出 的 常用 藏 语 同形 异音 词 的 基础 上 , 共 收集 整理 了 465 个 同形 异 音词 , 然后 从 372320 个 句子 文本 中 统计 出 了 同 形异 音词 在 藏 语 文本 中 的 出现 频率 及 不同 读音 的 使用 频率 , 并 深度 辨析 了 藏 语 同形异 音词 的 构词 形式 、 分类 以及 在 具体 文本 中 出现 的 形式 , 最后 结合 实例 提出 了 具体 的 消歧 方法 及 实验 结果 , 为 语音 合成 系统 的 前端 文本 分析 模块 提供 了 有力 依据 。	该文 从 藏 语 本身 独有 的 语言 规则 和 语音 特点 出发 , 依据 《 藏 汉 大 词典 》 , 在 其 所 列出 的 常用 藏 语 同形 异音 词 的 基础 上 , 共 收集 整理 了 465 个 同形 异 音词 , 然后 从 372320 个 句子 文本 中 统计 出 了 同 形异 音词 在 藏 语 文本 中 的 出现 频率 及 不同 读音 的 使用 频率 , 并 深度 辨析 了 藏 语 同形异 音词 的 构词 形式 、 分类 以及 在 具体 文本 中 出现 的 形式 , 最后 结合 实例 提出 了 具体 的 消歧 方法 及 实验 结果 , 为 语音 合成 系统 的 前端 文本 分析 模块 提供 了 有力 依据 。	1<2	elab-addition	elab-addition
nlpabs66_Chi	73-80	81-95	依据 《 藏 汉 大 词典 》 ,	在 其 所 列出 的 常用 藏 语 同形 异音 词 的 基础 上 ,	59-182	59-182	该文 从 藏 语 本身 独有 的 语言 规则 和 语音 特点 出发 , 依据 《 藏 汉 大 词典 》 , 在 其 所 列出 的 常用 藏 语 同形 异音 词 的 基础 上 , 共 收集 整理 了 465 个 同形 异 音词 , 然后 从 372320 个 句子 文本 中 统计 出 了 同 形异 音词 在 藏 语 文本 中 的 出现 频率 及 不同 读音 的 使用 频率 , 并 深度 辨析 了 藏 语 同形异 音词 的 构词 形式 、 分类 以及 在 具体 文本 中 出现 的 形式 , 最后 结合 实例 提出 了 具体 的 消歧 方法 及 实验 结果 , 为 语音 合成 系统 的 前端 文本 分析 模块 提供 了 有力 依据 。	该文 从 藏 语 本身 独有 的 语言 规则 和 语音 特点 出发 , 依据 《 藏 汉 大 词典 》 , 在 其 所 列出 的 常用 藏 语 同形 异音 词 的 基础 上 , 共 收集 整理 了 465 个 同形 异 音词 , 然后 从 372320 个 句子 文本 中 统计 出 了 同 形异 音词 在 藏 语 文本 中 的 出现 频率 及 不同 读音 的 使用 频率 , 并 深度 辨析 了 藏 语 同形异 音词 的 构词 形式 、 分类 以及 在 具体 文本 中 出现 的 形式 , 最后 结合 实例 提出 了 具体 的 消歧 方法 及 实验 结果 , 为 语音 合成 系统 的 前端 文本 分析 模块 提供 了 有力 依据 。	1<2	elab-addition	elab-addition
nlpabs66_Chi	96-105	106-133	共 收集 整理 了 465 个 同形 异 音词 ,	然后 从 372320 个 句子 文本 中 统计 出 了 同 形异 音词 在 藏 语 文本 中 的 出现 频率 及 不同 读音 的 使用 频率 ,	59-182	59-182	该文 从 藏 语 本身 独有 的 语言 规则 和 语音 特点 出发 , 依据 《 藏 汉 大 词典 》 , 在 其 所 列出 的 常用 藏 语 同形 异音 词 的 基础 上 , 共 收集 整理 了 465 个 同形 异 音词 , 然后 从 372320 个 句子 文本 中 统计 出 了 同 形异 音词 在 藏 语 文本 中 的 出现 频率 及 不同 读音 的 使用 频率 , 并 深度 辨析 了 藏 语 同形异 音词 的 构词 形式 、 分类 以及 在 具体 文本 中 出现 的 形式 , 最后 结合 实例 提出 了 具体 的 消歧 方法 及 实验 结果 , 为 语音 合成 系统 的 前端 文本 分析 模块 提供 了 有力 依据 。	该文 从 藏 语 本身 独有 的 语言 规则 和 语音 特点 出发 , 依据 《 藏 汉 大 词典 》 , 在 其 所 列出 的 常用 藏 语 同形 异音 词 的 基础 上 , 共 收集 整理 了 465 个 同形 异 音词 , 然后 从 372320 个 句子 文本 中 统计 出 了 同 形异 音词 在 藏 语 文本 中 的 出现 频率 及 不同 读音 的 使用 频率 , 并 深度 辨析 了 藏 语 同形异 音词 的 构词 形式 、 分类 以及 在 具体 文本 中 出现 的 形式 , 最后 结合 实例 提出 了 具体 的 消歧 方法 及 实验 结果 , 为 语音 合成 系统 的 前端 文本 分析 模块 提供 了 有力 依据 。	1<2	joint	joint
nlpabs66_Chi	106-133	134-155	然后 从 372320 个 句子 文本 中 统计 出 了 同 形异 音词 在 藏 语 文本 中 的 出现 频率 及 不同 读音 的 使用 频率 ,	并 深度 辨析 了 藏 语 同形异 音词 的 构词 形式 、 分类 以及 在 具体 文本 中 出现 的 形式 ,	59-182	59-182	该文 从 藏 语 本身 独有 的 语言 规则 和 语音 特点 出发 , 依据 《 藏 汉 大 词典 》 , 在 其 所 列出 的 常用 藏 语 同形 异音 词 的 基础 上 , 共 收集 整理 了 465 个 同形 异 音词 , 然后 从 372320 个 句子 文本 中 统计 出 了 同 形异 音词 在 藏 语 文本 中 的 出现 频率 及 不同 读音 的 使用 频率 , 并 深度 辨析 了 藏 语 同形异 音词 的 构词 形式 、 分类 以及 在 具体 文本 中 出现 的 形式 , 最后 结合 实例 提出 了 具体 的 消歧 方法 及 实验 结果 , 为 语音 合成 系统 的 前端 文本 分析 模块 提供 了 有力 依据 。	该文 从 藏 语 本身 独有 的 语言 规则 和 语音 特点 出发 , 依据 《 藏 汉 大 词典 》 , 在 其 所 列出 的 常用 藏 语 同形 异音 词 的 基础 上 , 共 收集 整理 了 465 个 同形 异 音词 , 然后 从 372320 个 句子 文本 中 统计 出 了 同 形异 音词 在 藏 语 文本 中 的 出现 频率 及 不同 读音 的 使用 频率 , 并 深度 辨析 了 藏 语 同形异 音词 的 构词 形式 、 分类 以及 在 具体 文本 中 出现 的 形式 , 最后 结合 实例 提出 了 具体 的 消歧 方法 及 实验 结果 , 为 语音 合成 系统 的 前端 文本 分析 模块 提供 了 有力 依据 。	1<2	joint	joint
nlpabs66_Chi	156-158	159-168	最后 结合 实例	提出 了 具体 的 消歧 方法 及 实验 结果 ,	59-182	59-182	该文 从 藏 语 本身 独有 的 语言 规则 和 语音 特点 出发 , 依据 《 藏 汉 大 词典 》 , 在 其 所 列出 的 常用 藏 语 同形 异音 词 的 基础 上 , 共 收集 整理 了 465 个 同形 异 音词 , 然后 从 372320 个 句子 文本 中 统计 出 了 同 形异 音词 在 藏 语 文本 中 的 出现 频率 及 不同 读音 的 使用 频率 , 并 深度 辨析 了 藏 语 同形异 音词 的 构词 形式 、 分类 以及 在 具体 文本 中 出现 的 形式 , 最后 结合 实例 提出 了 具体 的 消歧 方法 及 实验 结果 , 为 语音 合成 系统 的 前端 文本 分析 模块 提供 了 有力 依据 。	该文 从 藏 语 本身 独有 的 语言 规则 和 语音 特点 出发 , 依据 《 藏 汉 大 词典 》 , 在 其 所 列出 的 常用 藏 语 同形 异音 词 的 基础 上 , 共 收集 整理 了 465 个 同形 异 音词 , 然后 从 372320 个 句子 文本 中 统计 出 了 同 形异 音词 在 藏 语 文本 中 的 出现 频率 及 不同 读音 的 使用 频率 , 并 深度 辨析 了 藏 语 同形异 音词 的 构词 形式 、 分类 以及 在 具体 文本 中 出现 的 形式 , 最后 结合 实例 提出 了 具体 的 消歧 方法 及 实验 结果 , 为 语音 合成 系统 的 前端 文本 分析 模块 提供 了 有力 依据 。	1>2	bg-general	bg-general
nlpabs66_Chi	134-155	159-168	并 深度 辨析 了 藏 语 同形异 音词 的 构词 形式 、 分类 以及 在 具体 文本 中 出现 的 形式 ,	提出 了 具体 的 消歧 方法 及 实验 结果 ,	59-182	59-182	该文 从 藏 语 本身 独有 的 语言 规则 和 语音 特点 出发 , 依据 《 藏 汉 大 词典 》 , 在 其 所 列出 的 常用 藏 语 同形 异音 词 的 基础 上 , 共 收集 整理 了 465 个 同形 异 音词 , 然后 从 372320 个 句子 文本 中 统计 出 了 同 形异 音词 在 藏 语 文本 中 的 出现 频率 及 不同 读音 的 使用 频率 , 并 深度 辨析 了 藏 语 同形异 音词 的 构词 形式 、 分类 以及 在 具体 文本 中 出现 的 形式 , 最后 结合 实例 提出 了 具体 的 消歧 方法 及 实验 结果 , 为 语音 合成 系统 的 前端 文本 分析 模块 提供 了 有力 依据 。	该文 从 藏 语 本身 独有 的 语言 规则 和 语音 特点 出发 , 依据 《 藏 汉 大 词典 》 , 在 其 所 列出 的 常用 藏 语 同形 异音 词 的 基础 上 , 共 收集 整理 了 465 个 同形 异 音词 , 然后 从 372320 个 句子 文本 中 统计 出 了 同 形异 音词 在 藏 语 文本 中 的 出现 频率 及 不同 读音 的 使用 频率 , 并 深度 辨析 了 藏 语 同形异 音词 的 构词 形式 、 分类 以及 在 具体 文本 中 出现 的 形式 , 最后 结合 实例 提出 了 具体 的 消歧 方法 及 实验 结果 , 为 语音 合成 系统 的 前端 文本 分析 模块 提供 了 有力 依据 。	1<2	joint	joint
nlpabs66_Chi	96-105	169-182	共 收集 整理 了 465 个 同形 异 音词 ,	为 语音 合成 系统 的 前端 文本 分析 模块 提供 了 有力 依据 。	59-182	59-182	该文 从 藏 语 本身 独有 的 语言 规则 和 语音 特点 出发 , 依据 《 藏 汉 大 词典 》 , 在 其 所 列出 的 常用 藏 语 同形 异音 词 的 基础 上 , 共 收集 整理 了 465 个 同形 异 音词 , 然后 从 372320 个 句子 文本 中 统计 出 了 同 形异 音词 在 藏 语 文本 中 的 出现 频率 及 不同 读音 的 使用 频率 , 并 深度 辨析 了 藏 语 同形异 音词 的 构词 形式 、 分类 以及 在 具体 文本 中 出现 的 形式 , 最后 结合 实例 提出 了 具体 的 消歧 方法 及 实验 结果 , 为 语音 合成 系统 的 前端 文本 分析 模块 提供 了 有力 依据 。	该文 从 藏 语 本身 独有 的 语言 规则 和 语音 特点 出发 , 依据 《 藏 汉 大 词典 》 , 在 其 所 列出 的 常用 藏 语 同形 异音 词 的 基础 上 , 共 收集 整理 了 465 个 同形 异 音词 , 然后 从 372320 个 句子 文本 中 统计 出 了 同 形异 音词 在 藏 语 文本 中 的 出现 频率 及 不同 读音 的 使用 频率 , 并 深度 辨析 了 藏 语 同形异 音词 的 构词 形式 、 分类 以及 在 具体 文本 中 出现 的 形式 , 最后 结合 实例 提出 了 具体 的 消歧 方法 及 实验 结果 , 为 语音 合成 系统 的 前端 文本 分析 模块 提供 了 有力 依据 。	1<2	elab-addition	elab-addition
nlpabs67_Chi	1-18	44-65	近年 来 , 随 着 人们 对 历史 和 传统 文化 的 保护 和 传承 越来越 重视 ,	该文 提出 了 一 种 基 于 卷积 降噪 自 编码 器 的 藏 文 历史 文献 版 面 分析 方法 。	1-31	32-65	近年 来 , 随 着 人们 对 历史 和 传统 文化 的 保护 和 传承 越来越 重视 , 研究 人员 对 历史 文献 数字 化 的 兴趣 也 越来越 高涨 。	版面 分析 是 历史 文献 数字 化 的 重要 基础 步骤 , 该文 提出 了 一 种 基 于 卷积 降噪 自 编码 器 的 藏 文 历史 文献 版 面 分析 方法 。	1>2	bg-general	bg-general
nlpabs67_Chi	1-18	19-31	近年 来 , 随 着 人们 对 历史 和 传统 文化 的 保护 和 传承 越来越 重视 ,	研究 人员 对 历史 文献 数字 化 的 兴趣 也 越来越 高涨 。	1-31	1-31	近年 来 , 随 着 人们 对 历史 和 传统 文化 的 保护 和 传承 越来越 重视 , 研究 人员 对 历史 文献 数字 化 的 兴趣 也 越来越 高涨 。	近年 来 , 随 着 人们 对 历史 和 传统 文化 的 保护 和 传承 越来越 重视 , 研究 人员 对 历史 文献 数字 化 的 兴趣 也 越来越 高涨 。	1<2	elab-addition	elab-addition
nlpabs67_Chi	32-43	44-65	版面 分析 是 历史 文献 数字 化 的 重要 基础 步骤 ,	该文 提出 了 一 种 基 于 卷积 降噪 自 编码 器 的 藏 文 历史 文献 版 面 分析 方法 。	32-65	32-65	版面 分析 是 历史 文献 数字 化 的 重要 基础 步骤 , 该文 提出 了 一 种 基 于 卷积 降噪 自 编码 器 的 藏 文 历史 文献 版 面 分析 方法 。	版面 分析 是 历史 文献 数字 化 的 重要 基础 步骤 , 该文 提出 了 一 种 基 于 卷积 降噪 自 编码 器 的 藏 文 历史 文献 版 面 分析 方法 。	1>2	bg-general	bg-general
nlpabs67_Chi	44-65	66-83	该文 提出 了 一 种 基 于 卷积 降噪 自 编码 器 的 藏 文 历史 文献 版 面 分析 方法 。	首先 , 将 藏 文 历史 文 献图 像 进行 超 像素 聚类 获得 超 像素 块 ;	32-65	66-128	版面 分析 是 历史 文献 数字 化 的 重要 基础 步骤 , 该文 提出 了 一 种 基 于 卷积 降噪 自 编码 器 的 藏 文 历史 文献 版 面 分析 方法 。	首先 , 将 藏 文 历史 文 献图 像 进行 超 像素 聚类 获得 超 像素 块 ; 然后 , 利用 卷积 降噪 自编码 器 提取 超 像素 块 的 特征 ; 最后 , 使用 SVM 分类 器 对 藏 文 历史 文献 的 超 像素 块 进行 分类 预测 , 从而 提取 出 藏 文 历史 文献 版面 的 各个 部分 。	1<2	elab-process_step	elab-process_step
nlpabs67_Chi	66-83	84-90	首先 , 将 藏 文 历史 文 献图 像 进行 超 像素 聚类 获得 超 像素 块 ;	然后 , 利用 卷积 降噪 自编码 器	66-128	66-128	首先 , 将 藏 文 历史 文 献图 像 进行 超 像素 聚类 获得 超 像素 块 ; 然后 , 利用 卷积 降噪 自编码 器 提取 超 像素 块 的 特征 ; 最后 , 使用 SVM 分类 器 对 藏 文 历史 文献 的 超 像素 块 进行 分类 预测 , 从而 提取 出 藏 文 历史 文献 版面 的 各个 部分 。	首先 , 将 藏 文 历史 文 献图 像 进行 超 像素 聚类 获得 超 像素 块 ; 然后 , 利用 卷积 降噪 自编码 器 提取 超 像素 块 的 特征 ; 最后 , 使用 SVM 分类 器 对 藏 文 历史 文献 的 超 像素 块 进行 分类 预测 , 从而 提取 出 藏 文 历史 文献 版面 的 各个 部分 。	1<2	joint	joint
nlpabs67_Chi	84-90	91-97	然后 , 利用 卷积 降噪 自编码 器	提取 超 像素 块 的 特征 ;	66-128	66-128	首先 , 将 藏 文 历史 文 献图 像 进行 超 像素 聚类 获得 超 像素 块 ; 然后 , 利用 卷积 降噪 自编码 器 提取 超 像素 块 的 特征 ; 最后 , 使用 SVM 分类 器 对 藏 文 历史 文献 的 超 像素 块 进行 分类 预测 , 从而 提取 出 藏 文 历史 文献 版面 的 各个 部分 。	首先 , 将 藏 文 历史 文 献图 像 进行 超 像素 聚类 获得 超 像素 块 ; 然后 , 利用 卷积 降噪 自编码 器 提取 超 像素 块 的 特征 ; 最后 , 使用 SVM 分类 器 对 藏 文 历史 文献 的 超 像素 块 进行 分类 预测 , 从而 提取 出 藏 文 历史 文献 版面 的 各个 部分 。	1<2	enablement	enablement
nlpabs67_Chi	84-90	98-103	然后 , 利用 卷积 降噪 自编码 器	最后 , 使用 SVM 分类 器	66-128	66-128	首先 , 将 藏 文 历史 文 献图 像 进行 超 像素 聚类 获得 超 像素 块 ; 然后 , 利用 卷积 降噪 自编码 器 提取 超 像素 块 的 特征 ; 最后 , 使用 SVM 分类 器 对 藏 文 历史 文献 的 超 像素 块 进行 分类 预测 , 从而 提取 出 藏 文 历史 文献 版面 的 各个 部分 。	首先 , 将 藏 文 历史 文 献图 像 进行 超 像素 聚类 获得 超 像素 块 ; 然后 , 利用 卷积 降噪 自编码 器 提取 超 像素 块 的 特征 ; 最后 , 使用 SVM 分类 器 对 藏 文 历史 文献 的 超 像素 块 进行 分类 预测 , 从而 提取 出 藏 文 历史 文献 版面 的 各个 部分 。	1<2	joint	joint
nlpabs67_Chi	98-103	104-116	最后 , 使用 SVM 分类 器	对 藏 文 历史 文献 的 超 像素 块 进行 分类 预测 ,	66-128	66-128	首先 , 将 藏 文 历史 文 献图 像 进行 超 像素 聚类 获得 超 像素 块 ; 然后 , 利用 卷积 降噪 自编码 器 提取 超 像素 块 的 特征 ; 最后 , 使用 SVM 分类 器 对 藏 文 历史 文献 的 超 像素 块 进行 分类 预测 , 从而 提取 出 藏 文 历史 文献 版面 的 各个 部分 。	首先 , 将 藏 文 历史 文 献图 像 进行 超 像素 聚类 获得 超 像素 块 ; 然后 , 利用 卷积 降噪 自编码 器 提取 超 像素 块 的 特征 ; 最后 , 使用 SVM 分类 器 对 藏 文 历史 文献 的 超 像素 块 进行 分类 预测 , 从而 提取 出 藏 文 历史 文献 版面 的 各个 部分 。	1<2	enablement	enablement
nlpabs67_Chi	104-116	117-128	对 藏 文 历史 文献 的 超 像素 块 进行 分类 预测 ,	从而 提取 出 藏 文 历史 文献 版面 的 各个 部分 。	66-128	66-128	首先 , 将 藏 文 历史 文 献图 像 进行 超 像素 聚类 获得 超 像素 块 ; 然后 , 利用 卷积 降噪 自编码 器 提取 超 像素 块 的 特征 ; 最后 , 使用 SVM 分类 器 对 藏 文 历史 文献 的 超 像素 块 进行 分类 预测 , 从而 提取 出 藏 文 历史 文献 版面 的 各个 部分 。	首先 , 将 藏 文 历史 文 献图 像 进行 超 像素 聚类 获得 超 像素 块 ; 然后 , 利用 卷积 降噪 自编码 器 提取 超 像素 块 的 特征 ; 最后 , 使用 SVM 分类 器 对 藏 文 历史 文献 的 超 像素 块 进行 分类 预测 , 从而 提取 出 藏 文 历史 文献 版面 的 各个 部分 。	1<2	enablement	enablement
nlpabs67_Chi	129-140	141-157	在 藏 文 历史 文献 数据 集 上 的 实验 表明 ,	该 方法 能够 对 藏 文 历史 文献 的 不同 版面 元素 进行 有效 的 分离 。	129-157	129-157	在 藏 文 历史 文献 数据 集 上 的 实验 表明 , 该 方法 能够 对 藏 文 历史 文献 的 不同 版面 元素 进行 有效 的 分离 。	在 藏 文 历史 文献 数据 集 上 的 实验 表明 , 该 方法 能够 对 藏 文 历史 文献 的 不同 版面 元素 进行 有效 的 分离 。	1>2	attribution	attribution
nlpabs67_Chi	44-65	141-157	该文 提出 了 一 种 基 于 卷积 降噪 自 编码 器 的 藏 文 历史 文献 版 面 分析 方法 。	该 方法 能够 对 藏 文 历史 文献 的 不同 版面 元素 进行 有效 的 分离 。	32-65	129-157	版面 分析 是 历史 文献 数字 化 的 重要 基础 步骤 , 该文 提出 了 一 种 基 于 卷积 降噪 自 编码 器 的 藏 文 历史 文献 版 面 分析 方法 。	在 藏 文 历史 文献 数据 集 上 的 实验 表明 , 该 方法 能够 对 藏 文 历史 文献 的 不同 版面 元素 进行 有效 的 分离 。	1<2	evaluation	evaluation
nlpabs68_Chi	1-18	28-40	文本 摘要 旨 在 实现 从 海量 的 文本 数据 中 快速 准确 地 获取 关键 信息 。	该文 将 文句 中 的 关键 词 嵌入 知识 网络 进行 建模 ,	1-18	19-80	文本 摘要 旨 在 实现 从 海量 的 文本 数据 中 快速 准确 地 获取 关键 信息 。	为 探索 新颖 的 摘要 句 特征 因素 , 该文 将 文句 中 的 关键 词 嵌入 知识 网络 进行 建模 , 并 将 文句 映射 至 知识 网络 进行 表达 , 进而 提出 文句 的 关键 词 建构 渗透 度 特征 模型 , 在 摘要 句 判别 中 引入 文句 中 关键 词组 的 宽度 和 深度 的 渗透 特性 。	1>2	bg-goal	bg-goal
nlpabs68_Chi	19-27	28-40	为 探索 新颖 的 摘要 句 特征 因素 ,	该文 将 文句 中 的 关键 词 嵌入 知识 网络 进行 建模 ,	19-80	19-80	为 探索 新颖 的 摘要 句 特征 因素 , 该文 将 文句 中 的 关键 词 嵌入 知识 网络 进行 建模 , 并 将 文句 映射 至 知识 网络 进行 表达 , 进而 提出 文句 的 关键 词 建构 渗透 度 特征 模型 , 在 摘要 句 判别 中 引入 文句 中 关键 词组 的 宽度 和 深度 的 渗透 特性 。	为 探索 新颖 的 摘要 句 特征 因素 , 该文 将 文句 中 的 关键 词 嵌入 知识 网络 进行 建模 , 并 将 文句 映射 至 知识 网络 进行 表达 , 进而 提出 文句 的 关键 词 建构 渗透 度 特征 模型 , 在 摘要 句 判别 中 引入 文句 中 关键 词组 的 宽度 和 深度 的 渗透 特性 。	1>2	enablement	enablement
nlpabs68_Chi	28-40	41-50	该文 将 文句 中 的 关键 词 嵌入 知识 网络 进行 建模 ,	并 将 文句 映射 至 知识 网络 进行 表达 ,	19-80	19-80	为 探索 新颖 的 摘要 句 特征 因素 , 该文 将 文句 中 的 关键 词 嵌入 知识 网络 进行 建模 , 并 将 文句 映射 至 知识 网络 进行 表达 , 进而 提出 文句 的 关键 词 建构 渗透 度 特征 模型 , 在 摘要 句 判别 中 引入 文句 中 关键 词组 的 宽度 和 深度 的 渗透 特性 。	为 探索 新颖 的 摘要 句 特征 因素 , 该文 将 文句 中 的 关键 词 嵌入 知识 网络 进行 建模 , 并 将 文句 映射 至 知识 网络 进行 表达 , 进而 提出 文句 的 关键 词 建构 渗透 度 特征 模型 , 在 摘要 句 判别 中 引入 文句 中 关键 词组 的 宽度 和 深度 的 渗透 特性 。	1<2	joint	joint
nlpabs68_Chi	41-50	51-62	并 将 文句 映射 至 知识 网络 进行 表达 ,	进而 提出 文句 的 关键 词 建构 渗透 度 特征 模型 ,	19-80	19-80	为 探索 新颖 的 摘要 句 特征 因素 , 该文 将 文句 中 的 关键 词 嵌入 知识 网络 进行 建模 , 并 将 文句 映射 至 知识 网络 进行 表达 , 进而 提出 文句 的 关键 词 建构 渗透 度 特征 模型 , 在 摘要 句 判别 中 引入 文句 中 关键 词组 的 宽度 和 深度 的 渗透 特性 。	为 探索 新颖 的 摘要 句 特征 因素 , 该文 将 文句 中 的 关键 词 嵌入 知识 网络 进行 建模 , 并 将 文句 映射 至 知识 网络 进行 表达 , 进而 提出 文句 的 关键 词 建构 渗透 度 特征 模型 , 在 摘要 句 判别 中 引入 文句 中 关键 词组 的 宽度 和 深度 的 渗透 特性 。	1<2	progression	progression
nlpabs68_Chi	51-62	63-80	进而 提出 文句 的 关键 词 建构 渗透 度 特征 模型 ,	在 摘要 句 判别 中 引入 文句 中 关键 词组 的 宽度 和 深度 的 渗透 特性 。	19-80	19-80	为 探索 新颖 的 摘要 句 特征 因素 , 该文 将 文句 中 的 关键 词 嵌入 知识 网络 进行 建模 , 并 将 文句 映射 至 知识 网络 进行 表达 , 进而 提出 文句 的 关键 词 建构 渗透 度 特征 模型 , 在 摘要 句 判别 中 引入 文句 中 关键 词组 的 宽度 和 深度 的 渗透 特性 。	为 探索 新颖 的 摘要 句 特征 因素 , 该文 将 文句 中 的 关键 词 嵌入 知识 网络 进行 建模 , 并 将 文句 映射 至 知识 网络 进行 表达 , 进而 提出 文句 的 关键 词 建构 渗透 度 特征 模型 , 在 摘要 句 判别 中 引入 文句 中 关键 词组 的 宽度 和 深度 的 渗透 特性 。	1<2	elab-addition	elab-addition
nlpabs68_Chi	81-87	88-100	结合 最大 熵 建模 分类 方法 ,	针 对 领域 语料 库 进行 不同 特征 的 影响 系数 建模 ,	81-114	81-114	结合 最大 熵 建模 分类 方法 , 针 对 领域 语料 库 进行 不同 特征 的 影响 系数 建模 , 实现 了 监督 学习 下 摘要 句 的 有效 分类 和 自动 提取 。	结合 最大 熵 建模 分类 方法 , 针 对 领域 语料 库 进行 不同 特征 的 影响 系数 建模 , 实现 了 监督 学习 下 摘要 句 的 有效 分类 和 自动 提取 。	1>2	bg-general	bg-general
nlpabs68_Chi	28-40	88-100	该文 将 文句 中 的 关键 词 嵌入 知识 网络 进行 建模 ,	针 对 领域 语料 库 进行 不同 特征 的 影响 系数 建模 ,	19-80	81-114	为 探索 新颖 的 摘要 句 特征 因素 , 该文 将 文句 中 的 关键 词 嵌入 知识 网络 进行 建模 , 并 将 文句 映射 至 知识 网络 进行 表达 , 进而 提出 文句 的 关键 词 建构 渗透 度 特征 模型 , 在 摘要 句 判别 中 引入 文句 中 关键 词组 的 宽度 和 深度 的 渗透 特性 。	结合 最大 熵 建模 分类 方法 , 针 对 领域 语料 库 进行 不同 特征 的 影响 系数 建模 , 实现 了 监督 学习 下 摘要 句 的 有效 分类 和 自动 提取 。	1<2	elab-addition	elab-addition
nlpabs68_Chi	88-100	101-114	针 对 领域 语料 库 进行 不同 特征 的 影响 系数 建模 ,	实现 了 监督 学习 下 摘要 句 的 有效 分类 和 自动 提取 。	81-114	81-114	结合 最大 熵 建模 分类 方法 , 针 对 领域 语料 库 进行 不同 特征 的 影响 系数 建模 , 实现 了 监督 学习 下 摘要 句 的 有效 分类 和 自动 提取 。	结合 最大 熵 建模 分类 方法 , 针 对 领域 语料 库 进行 不同 特征 的 影响 系数 建模 , 实现 了 监督 学习 下 摘要 句 的 有效 分类 和 自动 提取 。	1<2	elab-addition	elab-addition
nlpabs68_Chi	28-40	115-119	该文 将 文句 中 的 关键 词 嵌入 知识 网络 进行 建模 ,	文中 实验 结果 良好 ,	19-80	115-150	为 探索 新颖 的 摘要 句 特征 因素 , 该文 将 文句 中 的 关键 词 嵌入 知识 网络 进行 建模 , 并 将 文句 映射 至 知识 网络 进行 表达 , 进而 提出 文句 的 关键 词 建构 渗透 度 特征 模型 , 在 摘要 句 判别 中 引入 文句 中 关键 词组 的 宽度 和 深度 的 渗透 特性 。	文中 实验 结果 良好 , 表明 了 新 特征 模型 的 有效 性 和 在 领域 语料 库 中 的 稳定 性 , 且 特征 计算 方法 简洁 , 具有 良好 的 综合 实用 性 。	1<2	evaluation	evaluation
nlpabs68_Chi	120-121	122-137	表明 了	新 特征 模型 的 有效 性 和 在 领域 语料 库 中 的 稳定 性 ,	115-150	115-150	文中 实验 结果 良好 , 表明 了 新 特征 模型 的 有效 性 和 在 领域 语料 库 中 的 稳定 性 , 且 特征 计算 方法 简洁 , 具有 良好 的 综合 实用 性 。	文中 实验 结果 良好 , 表明 了 新 特征 模型 的 有效 性 和 在 领域 语料 库 中 的 稳定 性 , 且 特征 计算 方法 简洁 , 具有 良好 的 综合 实用 性 。	1>2	attribution	attribution
nlpabs68_Chi	115-119	122-137	文中 实验 结果 良好 ,	新 特征 模型 的 有效 性 和 在 领域 语料 库 中 的 稳定 性 ,	115-150	115-150	文中 实验 结果 良好 , 表明 了 新 特征 模型 的 有效 性 和 在 领域 语料 库 中 的 稳定 性 , 且 特征 计算 方法 简洁 , 具有 良好 的 综合 实用 性 。	文中 实验 结果 良好 , 表明 了 新 特征 模型 的 有效 性 和 在 领域 语料 库 中 的 稳定 性 , 且 特征 计算 方法 简洁 , 具有 良好 的 综合 实用 性 。	1<2	elab-addition	elab-addition
nlpabs68_Chi	122-137	138-143	新 特征 模型 的 有效 性 和 在 领域 语料 库 中 的 稳定 性 ,	且 特征 计算 方法 简洁 ,	115-150	115-150	文中 实验 结果 良好 , 表明 了 新 特征 模型 的 有效 性 和 在 领域 语料 库 中 的 稳定 性 , 且 特征 计算 方法 简洁 , 具有 良好 的 综合 实用 性 。	文中 实验 结果 良好 , 表明 了 新 特征 模型 的 有效 性 和 在 领域 语料 库 中 的 稳定 性 , 且 特征 计算 方法 简洁 , 具有 良好 的 综合 实用 性 。	1<2	joint	joint
nlpabs68_Chi	138-143	144-150	且 特征 计算 方法 简洁 ,	具有 良好 的 综合 实用 性 。	115-150	115-150	文中 实验 结果 良好 , 表明 了 新 特征 模型 的 有效 性 和 在 领域 语料 库 中 的 稳定 性 , 且 特征 计算 方法 简洁 , 具有 良好 的 综合 实用 性 。	文中 实验 结果 良好 , 表明 了 新 特征 模型 的 有效 性 和 在 领域 语料 库 中 的 稳定 性 , 且 特征 计算 方法 简洁 , 具有 良好 的 综合 实用 性 。	1<2	elab-addition	elab-addition
nlpabs69_Chi	1-18	85-102	蛋 白质 关系 抽取 研究 对于 生命 科学 各 领域 的 研究 具有 广泛 的 应用 价值 。	该文 提出 了 一 种 混合 机器 学习 和 规则 方法 的 蛋白 质 关系 抽取 框架 。	1-18	80-102	蛋 白质 关系 抽取 研究 对于 生命 科学 各 领域 的 研究 具有 广泛 的 应用 价值 。	针对 以 上 问题 , 该文 提出 了 一 种 混合 机器 学习 和 规则 方法 的 蛋白 质 关系 抽取 框架 。	1>2	bg-general	bg-general
nlpabs69_Chi	1-18	19-37	蛋 白质 关系 抽取 研究 对于 生命 科学 各 领域 的 研究 具有 广泛 的 应用 价值 。	但是 , 基 于 机器 学习 的 蛋白质 关系 抽取 方法 普遍 停留 在 二 元 关系 抽取 ,	1-18	19-79	蛋 白质 关系 抽取 研究 对于 生命 科学 各 领域 的 研究 具有 广泛 的 应用 价值 。	但是 , 基 于 机器 学习 的 蛋白质 关系 抽取 方法 普遍 停留 在 二 元 关系 抽取 , 失去 了 丰富 的 关系 类型 信息 , 而 基 于 规则 的 开放 式 信息 抽取 方法 可以 抽取 完整 的 蛋白质 关系 ( “ 蛋白质 1 , 关系 词 , 蛋白质 2 ” ) , 但是 召回 率 较低 。	1<2	contrast	contrast
nlpabs69_Chi	19-37	38-45	但是 , 基 于 机器 学习 的 蛋白质 关系 抽取 方法 普遍 停留 在 二 元 关系 抽取 ,	失去 了 丰富 的 关系 类型 信息 ,	19-79	19-79	但是 , 基 于 机器 学习 的 蛋白质 关系 抽取 方法 普遍 停留 在 二 元 关系 抽取 , 失去 了 丰富 的 关系 类型 信息 , 而 基 于 规则 的 开放 式 信息 抽取 方法 可以 抽取 完整 的 蛋白质 关系 ( “ 蛋白质 1 , 关系 词 , 蛋白质 2 ” ) , 但是 召回 率 较低 。	但是 , 基 于 机器 学习 的 蛋白质 关系 抽取 方法 普遍 停留 在 二 元 关系 抽取 , 失去 了 丰富 的 关系 类型 信息 , 而 基 于 规则 的 开放 式 信息 抽取 方法 可以 抽取 完整 的 蛋白质 关系 ( “ 蛋白质 1 , 关系 词 , 蛋白质 2 ” ) , 但是 召回 率 较低 。	1<2	elab-addition	elab-addition
nlpabs69_Chi	19-37	46-74	但是 , 基 于 机器 学习 的 蛋白质 关系 抽取 方法 普遍 停留 在 二 元 关系 抽取 ,	而 基 于 规则 的 开放 式 信息 抽取 方法 可以 抽取 完整 的 蛋白质 关系 ( “ 蛋白质 1 , 关系 词 , 蛋白质 2 ” ) ,	19-79	19-79	但是 , 基 于 机器 学习 的 蛋白质 关系 抽取 方法 普遍 停留 在 二 元 关系 抽取 , 失去 了 丰富 的 关系 类型 信息 , 而 基 于 规则 的 开放 式 信息 抽取 方法 可以 抽取 完整 的 蛋白质 关系 ( “ 蛋白质 1 , 关系 词 , 蛋白质 2 ” ) , 但是 召回 率 较低 。	但是 , 基 于 机器 学习 的 蛋白质 关系 抽取 方法 普遍 停留 在 二 元 关系 抽取 , 失去 了 丰富 的 关系 类型 信息 , 而 基 于 规则 的 开放 式 信息 抽取 方法 可以 抽取 完整 的 蛋白质 关系 ( “ 蛋白质 1 , 关系 词 , 蛋白质 2 ” ) , 但是 召回 率 较低 。	1<2	joint	joint
nlpabs69_Chi	46-74	75-79	而 基 于 规则 的 开放 式 信息 抽取 方法 可以 抽取 完整 的 蛋白质 关系 ( “ 蛋白质 1 , 关系 词 , 蛋白质 2 ” ) ,	但是 召回 率 较低 。	19-79	19-79	但是 , 基 于 机器 学习 的 蛋白质 关系 抽取 方法 普遍 停留 在 二 元 关系 抽取 , 失去 了 丰富 的 关系 类型 信息 , 而 基 于 规则 的 开放 式 信息 抽取 方法 可以 抽取 完整 的 蛋白质 关系 ( “ 蛋白质 1 , 关系 词 , 蛋白质 2 ” ) , 但是 召回 率 较低 。	但是 , 基 于 机器 学习 的 蛋白质 关系 抽取 方法 普遍 停留 在 二 元 关系 抽取 , 失去 了 丰富 的 关系 类型 信息 , 而 基 于 规则 的 开放 式 信息 抽取 方法 可以 抽取 完整 的 蛋白质 关系 ( “ 蛋白质 1 , 关系 词 , 蛋白质 2 ” ) , 但是 召回 率 较低 。	1<2	contrast	contrast
nlpabs69_Chi	80-84	85-102	针对 以 上 问题 ,	该文 提出 了 一 种 混合 机器 学习 和 规则 方法 的 蛋白 质 关系 抽取 框架 。	80-102	80-102	针对 以 上 问题 , 该文 提出 了 一 种 混合 机器 学习 和 规则 方法 的 蛋白 质 关系 抽取 框架 。	针对 以 上 问题 , 该文 提出 了 一 种 混合 机器 学习 和 规则 方法 的 蛋白 质 关系 抽取 框架 。	1>2	bg-general	bg-general
nlpabs69_Chi	85-102	103-109	该文 提出 了 一 种 混合 机器 学习 和 规则 方法 的 蛋白 质 关系 抽取 框架 。	该 框架 先利 用 机器 学习 方法	80-102	103-144	针对 以 上 问题 , 该文 提出 了 一 种 混合 机器 学习 和 规则 方法 的 蛋白 质 关系 抽取 框架 。	该 框架 先利 用 机器 学习 方法 完 成 命 名实体 识别 和 二 元 关系 抽取 , 然后 利用 基 于 句法 模板 和 词典 匹配 的 方法 抽取 表示 当前 两 个 蛋白 质间 关系 类型 的 关系 词 。	1<2	elab-process_step	elab-process_step
nlpabs69_Chi	103-109	110-120	该 框架 先利 用 机器 学习 方法	完 成 命 名实体 识别 和 二 元 关系 抽取 ,	103-144	103-144	该 框架 先利 用 机器 学习 方法 完 成 命 名实体 识别 和 二 元 关系 抽取 , 然后 利用 基 于 句法 模板 和 词典 匹配 的 方法 抽取 表示 当前 两 个 蛋白 质间 关系 类型 的 关系 词 。	该 框架 先利 用 机器 学习 方法 完 成 命 名实体 识别 和 二 元 关系 抽取 , 然后 利用 基 于 句法 模板 和 词典 匹配 的 方法 抽取 表示 当前 两 个 蛋白 质间 关系 类型 的 关系 词 。	1<2	enablement	enablement
nlpabs69_Chi	103-109	121-131	该 框架 先利 用 机器 学习 方法	然后 利用 基 于 句法 模板 和 词典 匹配 的 方法	103-144	103-144	该 框架 先利 用 机器 学习 方法 完 成 命 名实体 识别 和 二 元 关系 抽取 , 然后 利用 基 于 句法 模板 和 词典 匹配 的 方法 抽取 表示 当前 两 个 蛋白 质间 关系 类型 的 关系 词 。	该 框架 先利 用 机器 学习 方法 完 成 命 名实体 识别 和 二 元 关系 抽取 , 然后 利用 基 于 句法 模板 和 词典 匹配 的 方法 抽取 表示 当前 两 个 蛋白 质间 关系 类型 的 关系 词 。	1<2	joint	joint
nlpabs69_Chi	121-131	132-144	然后 利用 基 于 句法 模板 和 词典 匹配 的 方法	抽取 表示 当前 两 个 蛋白 质间 关系 类型 的 关系 词 。	103-144	103-144	该 框架 先利 用 机器 学习 方法 完 成 命 名实体 识别 和 二 元 关系 抽取 , 然后 利用 基 于 句法 模板 和 词典 匹配 的 方法 抽取 表示 当前 两 个 蛋白 质间 关系 类型 的 关系 词 。	该 框架 先利 用 机器 学习 方法 完 成 命 名实体 识别 和 二 元 关系 抽取 , 然后 利用 基 于 句法 模板 和 词典 匹配 的 方法 抽取 表示 当前 两 个 蛋白 质间 关系 类型 的 关系 词 。	1<2	enablement	enablement
nlpabs69_Chi	85-102	145-157	该文 提出 了 一 种 混合 机器 学习 和 规则 方法 的 蛋白 质 关系 抽取 框架 。	该 方法 在 AImed 语料 上 取得 了 40.18% 的 F 值 ,	80-102	145-168	针对 以 上 问题 , 该文 提出 了 一 种 混合 机器 学习 和 规则 方法 的 蛋白 质 关系 抽取 框架 。	该 方法 在 AImed 语料 上 取得 了 40.18% 的 F 值 , 远高 于 基 于 规则 的 Stanford Open IE 方法 。	1<2	evaluation	evaluation
nlpabs69_Chi	145-157	158-168	该 方法 在 AImed 语料 上 取得 了 40.18% 的 F 值 ,	远高 于 基 于 规则 的 Stanford Open IE 方法 。	145-168	145-168	该 方法 在 AImed 语料 上 取得 了 40.18% 的 F 值 , 远高 于 基 于 规则 的 Stanford Open IE 方法 。	该 方法 在 AImed 语料 上 取得 了 40.18% 的 F 值 , 远高 于 基 于 规则 的 Stanford Open IE 方法 。	1<2	elab-addition	elab-addition
nlpabs6_Chi	1-18	30-43	﻿在 自然 语言 处理 中 , 嵌入 表示 是 表达 语言 知识 的 重要 途径 和 手段 ,	提出 基 于 知识 库 训练 嵌入 表示 的 伪 句式 构造 方法 ,	1-56	1-56	﻿在 自然 语言 处理 中 , 嵌入 表示 是 表达 语言 知识 的 重要 途径 和 手段 , 本 研究 以 《 同义 词 词林 》 为 例 , 提出 基 于 知识 库 训练 嵌入 表示 的 伪 句式 构造 方法 , 并 在 多 项 任务 上 测试 新 方法 的 有效 性 。	﻿在 自然 语言 处理 中 , 嵌入 表示 是 表达 语言 知识 的 重要 途径 和 手段 , 本 研究 以 《 同义 词 词林 》 为 例 , 提出 基 于 知识 库 训练 嵌入 表示 的 伪 句式 构造 方法 , 并 在 多 项 任务 上 测试 新 方法 的 有效 性 。	1>2	bg-general	bg-general
nlpabs6_Chi	19-29	30-43	本 研究 以 《 同义 词 词林 》 为 例 ,	提出 基 于 知识 库 训练 嵌入 表示 的 伪 句式 构造 方法 ,	1-56	1-56	﻿在 自然 语言 处理 中 , 嵌入 表示 是 表达 语言 知识 的 重要 途径 和 手段 , 本 研究 以 《 同义 词 词林 》 为 例 , 提出 基 于 知识 库 训练 嵌入 表示 的 伪 句式 构造 方法 , 并 在 多 项 任务 上 测试 新 方法 的 有效 性 。	﻿在 自然 语言 处理 中 , 嵌入 表示 是 表达 语言 知识 的 重要 途径 和 手段 , 本 研究 以 《 同义 词 词林 》 为 例 , 提出 基 于 知识 库 训练 嵌入 表示 的 伪 句式 构造 方法 , 并 在 多 项 任务 上 测试 新 方法 的 有效 性 。	1>2	elab-addition	elab-addition
nlpabs6_Chi	30-43	44-56	提出 基 于 知识 库 训练 嵌入 表示 的 伪 句式 构造 方法 ,	并 在 多 项 任务 上 测试 新 方法 的 有效 性 。	1-56	1-56	﻿在 自然 语言 处理 中 , 嵌入 表示 是 表达 语言 知识 的 重要 途径 和 手段 , 本 研究 以 《 同义 词 词林 》 为 例 , 提出 基 于 知识 库 训练 嵌入 表示 的 伪 句式 构造 方法 , 并 在 多 项 任务 上 测试 新 方法 的 有效 性 。	﻿在 自然 语言 处理 中 , 嵌入 表示 是 表达 语言 知识 的 重要 途径 和 手段 , 本 研究 以 《 同义 词 词林 》 为 例 , 提出 基 于 知识 库 训练 嵌入 表示 的 伪 句式 构造 方法 , 并 在 多 项 任务 上 测试 新 方法 的 有效 性 。	1<2	joint	joint
nlpabs6_Chi	57-70	71-80	根据 《 同义 词 词 林 》 词义 编码 反映 的 层级 结构 ,	将 这些 编码 扩展 为 多 种 伪 句式 ,	57-131	57-131	根据 《 同义 词 词 林 》 词义 编码 反映 的 层级 结构 , 将 这些 编码 扩展 为 多 种 伪 句式 , 并 据 此 生成 不同 的 伪 语料 库 , 采用 word 2 vec 模型 在 伪 语料 库 上 训练 义素 向量 及 词 向量 , 得到 CiLin 2 Vec 资源 , 并 应 用 于 词义 合成 、 类比 推理 和 词义 相似 度 计算 等 任务 上 。	根据 《 同义 词 词 林 》 词义 编码 反映 的 层级 结构 , 将 这些 编码 扩展 为 多 种 伪 句式 , 并 据 此 生成 不同 的 伪 语料 库 , 采用 word 2 vec 模型 在 伪 语料 库 上 训练 义素 向量 及 词 向量 , 得到 CiLin 2 Vec 资源 , 并 应 用 于 词义 合成 、 类比 推理 和 词义 相似 度 计算 等 任务 上 。	1>2	bg-general	bg-general
nlpabs6_Chi	30-43	71-80	提出 基 于 知识 库 训练 嵌入 表示 的 伪 句式 构造 方法 ,	将 这些 编码 扩展 为 多 种 伪 句式 ,	1-56	57-131	﻿在 自然 语言 处理 中 , 嵌入 表示 是 表达 语言 知识 的 重要 途径 和 手段 , 本 研究 以 《 同义 词 词林 》 为 例 , 提出 基 于 知识 库 训练 嵌入 表示 的 伪 句式 构造 方法 , 并 在 多 项 任务 上 测试 新 方法 的 有效 性 。	根据 《 同义 词 词 林 》 词义 编码 反映 的 层级 结构 , 将 这些 编码 扩展 为 多 种 伪 句式 , 并 据 此 生成 不同 的 伪 语料 库 , 采用 word 2 vec 模型 在 伪 语料 库 上 训练 义素 向量 及 词 向量 , 得到 CiLin 2 Vec 资源 , 并 应 用 于 词义 合成 、 类比 推理 和 词义 相似 度 计算 等 任务 上 。	1<2	elab-addition	elab-addition
nlpabs6_Chi	71-80	81-90	将 这些 编码 扩展 为 多 种 伪 句式 ,	并 据 此 生成 不同 的 伪 语料 库 ,	57-131	57-131	根据 《 同义 词 词 林 》 词义 编码 反映 的 层级 结构 , 将 这些 编码 扩展 为 多 种 伪 句式 , 并 据 此 生成 不同 的 伪 语料 库 , 采用 word 2 vec 模型 在 伪 语料 库 上 训练 义素 向量 及 词 向量 , 得到 CiLin 2 Vec 资源 , 并 应 用 于 词义 合成 、 类比 推理 和 词义 相似 度 计算 等 任务 上 。	根据 《 同义 词 词 林 》 词义 编码 反映 的 层级 结构 , 将 这些 编码 扩展 为 多 种 伪 句式 , 并 据 此 生成 不同 的 伪 语料 库 , 采用 word 2 vec 模型 在 伪 语料 库 上 训练 义素 向量 及 词 向量 , 得到 CiLin 2 Vec 资源 , 并 应 用 于 词义 合成 、 类比 推理 和 词义 相似 度 计算 等 任务 上 。	1<2	joint	joint
nlpabs6_Chi	71-80	91-95	将 这些 编码 扩展 为 多 种 伪 句式 ,	采用 word 2 vec 模型	57-131	57-131	根据 《 同义 词 词 林 》 词义 编码 反映 的 层级 结构 , 将 这些 编码 扩展 为 多 种 伪 句式 , 并 据 此 生成 不同 的 伪 语料 库 , 采用 word 2 vec 模型 在 伪 语料 库 上 训练 义素 向量 及 词 向量 , 得到 CiLin 2 Vec 资源 , 并 应 用 于 词义 合成 、 类比 推理 和 词义 相似 度 计算 等 任务 上 。	根据 《 同义 词 词 林 》 词义 编码 反映 的 层级 结构 , 将 这些 编码 扩展 为 多 种 伪 句式 , 并 据 此 生成 不同 的 伪 语料 库 , 采用 word 2 vec 模型 在 伪 语料 库 上 训练 义素 向量 及 词 向量 , 得到 CiLin 2 Vec 资源 , 并 应 用 于 词义 合成 、 类比 推理 和 词义 相似 度 计算 等 任务 上 。	1<2	elab-addition	elab-addition
nlpabs6_Chi	91-95	96-107	采用 word 2 vec 模型	在 伪 语料 库 上 训练 义素 向量 及 词 向量 ,	57-131	57-131	根据 《 同义 词 词 林 》 词义 编码 反映 的 层级 结构 , 将 这些 编码 扩展 为 多 种 伪 句式 , 并 据 此 生成 不同 的 伪 语料 库 , 采用 word 2 vec 模型 在 伪 语料 库 上 训练 义素 向量 及 词 向量 , 得到 CiLin 2 Vec 资源 , 并 应 用 于 词义 合成 、 类比 推理 和 词义 相似 度 计算 等 任务 上 。	根据 《 同义 词 词 林 》 词义 编码 反映 的 层级 结构 , 将 这些 编码 扩展 为 多 种 伪 句式 , 并 据 此 生成 不同 的 伪 语料 库 , 采用 word 2 vec 模型 在 伪 语料 库 上 训练 义素 向量 及 词 向量 , 得到 CiLin 2 Vec 资源 , 并 应 用 于 词义 合成 、 类比 推理 和 词义 相似 度 计算 等 任务 上 。	1<2	enablement	enablement
nlpabs6_Chi	96-107	108-113	在 伪 语料 库 上 训练 义素 向量 及 词 向量 ,	得到 CiLin 2 Vec 资源 ,	57-131	57-131	根据 《 同义 词 词 林 》 词义 编码 反映 的 层级 结构 , 将 这些 编码 扩展 为 多 种 伪 句式 , 并 据 此 生成 不同 的 伪 语料 库 , 采用 word 2 vec 模型 在 伪 语料 库 上 训练 义素 向量 及 词 向量 , 得到 CiLin 2 Vec 资源 , 并 应 用 于 词义 合成 、 类比 推理 和 词义 相似 度 计算 等 任务 上 。	根据 《 同义 词 词 林 》 词义 编码 反映 的 层级 结构 , 将 这些 编码 扩展 为 多 种 伪 句式 , 并 据 此 生成 不同 的 伪 语料 库 , 采用 word 2 vec 模型 在 伪 语料 库 上 训练 义素 向量 及 词 向量 , 得到 CiLin 2 Vec 资源 , 并 应 用 于 词义 合成 、 类比 推理 和 词义 相似 度 计算 等 任务 上 。	1<2	enablement	enablement
nlpabs6_Chi	108-113	114-131	得到 CiLin 2 Vec 资源 ,	并 应 用 于 词义 合成 、 类比 推理 和 词义 相似 度 计算 等 任务 上 。	57-131	57-131	根据 《 同义 词 词 林 》 词义 编码 反映 的 层级 结构 , 将 这些 编码 扩展 为 多 种 伪 句式 , 并 据 此 生成 不同 的 伪 语料 库 , 采用 word 2 vec 模型 在 伪 语料 库 上 训练 义素 向量 及 词 向量 , 得到 CiLin 2 Vec 资源 , 并 应 用 于 词义 合成 、 类比 推理 和 词义 相似 度 计算 等 任务 上 。	根据 《 同义 词 词 林 》 词义 编码 反映 的 层级 结构 , 将 这些 编码 扩展 为 多 种 伪 句式 , 并 据 此 生成 不同 的 伪 语料 库 , 采用 word 2 vec 模型 在 伪 语料 库 上 训练 义素 向量 及 词 向量 , 得到 CiLin 2 Vec 资源 , 并 应 用 于 词义 合成 、 类比 推理 和 词义 相似 度 计算 等 任务 上 。	1<2	joint	joint
nlpabs6_Chi	30-43	132-142	提出 基 于 知识 库 训练 嵌入 表示 的 伪 句式 构造 方法 ,	在 这些 任务 上 均 取得 了 进展 或 突破 ,	1-56	132-170	﻿在 自然 语言 处理 中 , 嵌入 表示 是 表达 语言 知识 的 重要 途径 和 手段 , 本 研究 以 《 同义 词 词林 》 为 例 , 提出 基 于 知识 库 训练 嵌入 表示 的 伪 句式 构造 方法 , 并 在 多 项 任务 上 测试 新 方法 的 有效 性 。	在 这些 任务 上 均 取得 了 进展 或 突破 , 其中 , 在 词义 合成 、 类比 推理 任务 上 的 准确 率 达到 90% 以上 , 超过 了 以往 在 语料 库 上 训得 的 结果 。	1<2	evaluation	evaluation
nlpabs6_Chi	132-142	143-159	在 这些 任务 上 均 取得 了 进展 或 突破 ,	其中 , 在 词义 合成 、 类比 推理 任务 上 的 准确 率 达到 90% 以上 ,	132-170	132-170	在 这些 任务 上 均 取得 了 进展 或 突破 , 其中 , 在 词义 合成 、 类比 推理 任务 上 的 准确 率 达到 90% 以上 , 超过 了 以往 在 语料 库 上 训得 的 结果 。	在 这些 任务 上 均 取得 了 进展 或 突破 , 其中 , 在 词义 合成 、 类比 推理 任务 上 的 准确 率 达到 90% 以上 , 超过 了 以往 在 语料 库 上 训得 的 结果 。	1<2	elab-addition	elab-addition
nlpabs6_Chi	143-159	160-170	其中 , 在 词义 合成 、 类比 推理 任务 上 的 准确 率 达到 90% 以上 ,	超过 了 以往 在 语料 库 上 训得 的 结果 。	132-170	132-170	在 这些 任务 上 均 取得 了 进展 或 突破 , 其中 , 在 词义 合成 、 类比 推理 任务 上 的 准确 率 达到 90% 以上 , 超过 了 以往 在 语料 库 上 训得 的 结果 。	在 这些 任务 上 均 取得 了 进展 或 突破 , 其中 , 在 词义 合成 、 类比 推理 任务 上 的 准确 率 达到 90% 以上 , 超过 了 以往 在 语料 库 上 训得 的 结果 。	1<2	elab-addition	elab-addition
nlpabs6_Chi	171	172-189	证明	该 方法 可以 有效 地 将 知识 库 中 的 理性 知识 注入 嵌入 表示 中 去 ,	171-204	171-204	证明 该 方法 可以 有效 地 将 知识 库 中 的 理性 知识 注入 嵌入 表示 中 去 , 也 显示 了 CiLin2 Vec 嵌入 表示 资源 在 应用 上 的 巨大 潜力 。	证明 该 方法 可以 有效 地 将 知识 库 中 的 理性 知识 注入 嵌入 表示 中 去 , 也 显示 了 CiLin2 Vec 嵌入 表示 资源 在 应用 上 的 巨大 潜力 。	1>2	attribution	attribution
nlpabs6_Chi	143-159	172-189	其中 , 在 词义 合成 、 类比 推理 任务 上 的 准确 率 达到 90% 以上 ,	该 方法 可以 有效 地 将 知识 库 中 的 理性 知识 注入 嵌入 表示 中 去 ,	132-170	171-204	在 这些 任务 上 均 取得 了 进展 或 突破 , 其中 , 在 词义 合成 、 类比 推理 任务 上 的 准确 率 达到 90% 以上 , 超过 了 以往 在 语料 库 上 训得 的 结果 。	证明 该 方法 可以 有效 地 将 知识 库 中 的 理性 知识 注入 嵌入 表示 中 去 , 也 显示 了 CiLin2 Vec 嵌入 表示 资源 在 应用 上 的 巨大 潜力 。	1<2	elab-addition	elab-addition
nlpabs6_Chi	190-192	193-204	也 显示 了	CiLin2 Vec 嵌入 表示 资源 在 应用 上 的 巨大 潜力 。	171-204	171-204	证明 该 方法 可以 有效 地 将 知识 库 中 的 理性 知识 注入 嵌入 表示 中 去 , 也 显示 了 CiLin2 Vec 嵌入 表示 资源 在 应用 上 的 巨大 潜力 。	证明 该 方法 可以 有效 地 将 知识 库 中 的 理性 知识 注入 嵌入 表示 中 去 , 也 显示 了 CiLin2 Vec 嵌入 表示 资源 在 应用 上 的 巨大 潜力 。	1>2	attribution	attribution
nlpabs6_Chi	172-189	193-204	该 方法 可以 有效 地 将 知识 库 中 的 理性 知识 注入 嵌入 表示 中 去 ,	CiLin2 Vec 嵌入 表示 资源 在 应用 上 的 巨大 潜力 。	171-204	171-204	证明 该 方法 可以 有效 地 将 知识 库 中 的 理性 知识 注入 嵌入 表示 中 去 , 也 显示 了 CiLin2 Vec 嵌入 表示 资源 在 应用 上 的 巨大 潜力 。	证明 该 方法 可以 有效 地 将 知识 库 中 的 理性 知识 注入 嵌入 表示 中 去 , 也 显示 了 CiLin2 Vec 嵌入 表示 资源 在 应用 上 的 巨大 潜力 。	1<2	joint	joint
nlpabs70_Chi	1-18	19-35	针 对 无 监督 属性 选择 算法 无 类别 信息 和 未 考虑 属性 低秩 等 问题 ,	该文 提出 了 一 种 融合 K 均值 聚类 和 低秩 约束 的 属性 选择 算法 。	1-35	1-35	针 对 无 监督 属性 选择 算法 无 类别 信息 和 未 考虑 属性 低秩 等 问题 , 该文 提出 了 一 种 融合 K 均值 聚类 和 低秩 约束 的 属性 选择 算法 。	针 对 无 监督 属性 选择 算法 无 类别 信息 和 未 考虑 属性 低秩 等 问题 , 该文 提出 了 一 种 融合 K 均值 聚类 和 低秩 约束 的 属性 选择 算法 。	1>2	bg-goal	bg-goal
nlpabs70_Chi	19-35	36-51	该文 提出 了 一 种 融合 K 均值 聚类 和 低秩 约束 的 属性 选择 算法 。	算法 在 线性 回归 的 模型 框架 中 有效 地 嵌入 自表 达 方 法 ,	1-35	36-110	针 对 无 监督 属性 选择 算法 无 类别 信息 和 未 考虑 属性 低秩 等 问题 , 该文 提出 了 一 种 融合 K 均值 聚类 和 低秩 约束 的 属性 选择 算法 。	算法 在 线性 回归 的 模型 框架 中 有效 地 嵌入 自表 达 方 法 , 同时 利用 K 均值 聚类 产生 伪类 标签 最大 化类 间距 以 更好 地 稀疏 结构 , 并 使用 l2 , p- 范数 代替 传统 的 l2 , 1 - 范数 , 通过 参数 p来 灵活 调节 结果 的 稀疏 性 , 最后 证明 了 该 文算 法 具有 执行 线性 判别 分析 的 特点 和 收敛 性 。	1<2	elab-addition	elab-addition
nlpabs70_Chi	36-51	52-56	算法 在 线性 回归 的 模型 框架 中 有效 地 嵌入 自表 达 方 法 ,	同时 利用 K 均值 聚类	36-110	36-110	算法 在 线性 回归 的 模型 框架 中 有效 地 嵌入 自表 达 方 法 , 同时 利用 K 均值 聚类 产生 伪类 标签 最大 化类 间距 以 更好 地 稀疏 结构 , 并 使用 l2 , p- 范数 代替 传统 的 l2 , 1 - 范数 , 通过 参数 p来 灵活 调节 结果 的 稀疏 性 , 最后 证明 了 该 文算 法 具有 执行 线性 判别 分析 的 特点 和 收敛 性 。	算法 在 线性 回归 的 模型 框架 中 有效 地 嵌入 自表 达 方 法 , 同时 利用 K 均值 聚类 产生 伪类 标签 最大 化类 间距 以 更好 地 稀疏 结构 , 并 使用 l2 , p- 范数 代替 传统 的 l2 , 1 - 范数 , 通过 参数 p来 灵活 调节 结果 的 稀疏 性 , 最后 证明 了 该 文算 法 具有 执行 线性 判别 分析 的 特点 和 收敛 性 。	1<2	joint	joint
nlpabs70_Chi	52-56	57-62	同时 利用 K 均值 聚类	产生 伪类 标签 最大 化类 间距	36-110	36-110	算法 在 线性 回归 的 模型 框架 中 有效 地 嵌入 自表 达 方 法 , 同时 利用 K 均值 聚类 产生 伪类 标签 最大 化类 间距 以 更好 地 稀疏 结构 , 并 使用 l2 , p- 范数 代替 传统 的 l2 , 1 - 范数 , 通过 参数 p来 灵活 调节 结果 的 稀疏 性 , 最后 证明 了 该 文算 法 具有 执行 线性 判别 分析 的 特点 和 收敛 性 。	算法 在 线性 回归 的 模型 框架 中 有效 地 嵌入 自表 达 方 法 , 同时 利用 K 均值 聚类 产生 伪类 标签 最大 化类 间距 以 更好 地 稀疏 结构 , 并 使用 l2 , p- 范数 代替 传统 的 l2 , 1 - 范数 , 通过 参数 p来 灵活 调节 结果 的 稀疏 性 , 最后 证明 了 该 文算 法 具有 执行 线性 判别 分析 的 特点 和 收敛 性 。	1<2	enablement	enablement
nlpabs70_Chi	57-62	63-68	产生 伪类 标签 最大 化类 间距	以 更好 地 稀疏 结构 ,	36-110	36-110	算法 在 线性 回归 的 模型 框架 中 有效 地 嵌入 自表 达 方 法 , 同时 利用 K 均值 聚类 产生 伪类 标签 最大 化类 间距 以 更好 地 稀疏 结构 , 并 使用 l2 , p- 范数 代替 传统 的 l2 , 1 - 范数 , 通过 参数 p来 灵活 调节 结果 的 稀疏 性 , 最后 证明 了 该 文算 法 具有 执行 线性 判别 分析 的 特点 和 收敛 性 。	算法 在 线性 回归 的 模型 框架 中 有效 地 嵌入 自表 达 方 法 , 同时 利用 K 均值 聚类 产生 伪类 标签 最大 化类 间距 以 更好 地 稀疏 结构 , 并 使用 l2 , p- 范数 代替 传统 的 l2 , 1 - 范数 , 通过 参数 p来 灵活 调节 结果 的 稀疏 性 , 最后 证明 了 该 文算 法 具有 执行 线性 判别 分析 的 特点 和 收敛 性 。	1<2	enablement	enablement
nlpabs70_Chi	36-51	69-83	算法 在 线性 回归 的 模型 框架 中 有效 地 嵌入 自表 达 方 法 ,	并 使用 l2 , p- 范数 代替 传统 的 l2 , 1 - 范数 ,	36-110	36-110	算法 在 线性 回归 的 模型 框架 中 有效 地 嵌入 自表 达 方 法 , 同时 利用 K 均值 聚类 产生 伪类 标签 最大 化类 间距 以 更好 地 稀疏 结构 , 并 使用 l2 , p- 范数 代替 传统 的 l2 , 1 - 范数 , 通过 参数 p来 灵活 调节 结果 的 稀疏 性 , 最后 证明 了 该 文算 法 具有 执行 线性 判别 分析 的 特点 和 收敛 性 。	算法 在 线性 回归 的 模型 框架 中 有效 地 嵌入 自表 达 方 法 , 同时 利用 K 均值 聚类 产生 伪类 标签 最大 化类 间距 以 更好 地 稀疏 结构 , 并 使用 l2 , p- 范数 代替 传统 的 l2 , 1 - 范数 , 通过 参数 p来 灵活 调节 结果 的 稀疏 性 , 最后 证明 了 该 文算 法 具有 执行 线性 判别 分析 的 特点 和 收敛 性 。	1<2	joint	joint
nlpabs70_Chi	69-83	84-93	并 使用 l2 , p- 范数 代替 传统 的 l2 , 1 - 范数 ,	通过 参数 p来 灵活 调节 结果 的 稀疏 性 ,	36-110	36-110	算法 在 线性 回归 的 模型 框架 中 有效 地 嵌入 自表 达 方 法 , 同时 利用 K 均值 聚类 产生 伪类 标签 最大 化类 间距 以 更好 地 稀疏 结构 , 并 使用 l2 , p- 范数 代替 传统 的 l2 , 1 - 范数 , 通过 参数 p来 灵活 调节 结果 的 稀疏 性 , 最后 证明 了 该 文算 法 具有 执行 线性 判别 分析 的 特点 和 收敛 性 。	算法 在 线性 回归 的 模型 框架 中 有效 地 嵌入 自表 达 方 法 , 同时 利用 K 均值 聚类 产生 伪类 标签 最大 化类 间距 以 更好 地 稀疏 结构 , 并 使用 l2 , p- 范数 代替 传统 的 l2 , 1 - 范数 , 通过 参数 p来 灵活 调节 结果 的 稀疏 性 , 最后 证明 了 该 文算 法 具有 执行 线性 判别 分析 的 特点 和 收敛 性 。	1<2	elab-addition	elab-addition
nlpabs70_Chi	94-96	97-110	最后 证明 了	该 文算 法 具有 执行 线性 判别 分析 的 特点 和 收敛 性 。	36-110	36-110	算法 在 线性 回归 的 模型 框架 中 有效 地 嵌入 自表 达 方 法 , 同时 利用 K 均值 聚类 产生 伪类 标签 最大 化类 间距 以 更好 地 稀疏 结构 , 并 使用 l2 , p- 范数 代替 传统 的 l2 , 1 - 范数 , 通过 参数 p来 灵活 调节 结果 的 稀疏 性 , 最后 证明 了 该 文算 法 具有 执行 线性 判别 分析 的 特点 和 收敛 性 。	算法 在 线性 回归 的 模型 框架 中 有效 地 嵌入 自表 达 方 法 , 同时 利用 K 均值 聚类 产生 伪类 标签 最大 化类 间距 以 更好 地 稀疏 结构 , 并 使用 l2 , p- 范数 代替 传统 的 l2 , 1 - 范数 , 通过 参数 p来 灵活 调节 结果 的 稀疏 性 , 最后 证明 了 该 文算 法 具有 执行 线性 判别 分析 的 特点 和 收敛 性 。	1>2	attribution	attribution
nlpabs70_Chi	19-35	97-110	该文 提出 了 一 种 融合 K 均值 聚类 和 低秩 约束 的 属性 选择 算法 。	该 文算 法 具有 执行 线性 判别 分析 的 特点 和 收敛 性 。	1-35	36-110	针 对 无 监督 属性 选择 算法 无 类别 信息 和 未 考虑 属性 低秩 等 问题 , 该文 提出 了 一 种 融合 K 均值 聚类 和 低秩 约束 的 属性 选择 算法 。	算法 在 线性 回归 的 模型 框架 中 有效 地 嵌入 自表 达 方 法 , 同时 利用 K 均值 聚类 产生 伪类 标签 最大 化类 间距 以 更好 地 稀疏 结构 , 并 使用 l2 , p- 范数 代替 传统 的 l2 , 1 - 范数 , 通过 参数 p来 灵活 调节 结果 的 稀疏 性 , 最后 证明 了 该 文算 法 具有 执行 线性 判别 分析 的 特点 和 收敛 性 。	1<2	elab-addition	elab-addition
nlpabs70_Chi	111-114	133-146	经实 验验 证 ,	分类 准确 率 平均 提高 了 17.04% 、 13.95% 、 3.6% 和 9.39% ,	111-158	111-158	经实 验验 证 , 该文 提出 的 属性 算法 与 NFS 算法 、 LDA 算法 、 RFS 算法 、 RSR 算法 相比 分类 准确 率 平均 提高 了 17.04% 、 13.95% 、 3.6% 和 9.39% , 分类 准确 率 方差 也是 最小 的 , 分类 结果 稳定 。	经实 验验 证 , 该文 提出 的 属性 算法 与 NFS 算法 、 LDA 算法 、 RFS 算法 、 RSR 算法 相比 分类 准确 率 平均 提高 了 17.04% 、 13.95% 、 3.6% 和 9.39% , 分类 准确 率 方差 也是 最小 的 , 分类 结果 稳定 。	1>2	attribution	attribution
nlpabs70_Chi	115-132	133-146	该文 提出 的 属性 算法 与 NFS 算法 、 LDA 算法 、 RFS 算法 、 RSR 算法 相比	分类 准确 率 平均 提高 了 17.04% 、 13.95% 、 3.6% 和 9.39% ,	111-158	111-158	经实 验验 证 , 该文 提出 的 属性 算法 与 NFS 算法 、 LDA 算法 、 RFS 算法 、 RSR 算法 相比 分类 准确 率 平均 提高 了 17.04% 、 13.95% 、 3.6% 和 9.39% , 分类 准确 率 方差 也是 最小 的 , 分类 结果 稳定 。	经实 验验 证 , 该文 提出 的 属性 算法 与 NFS 算法 、 LDA 算法 、 RFS 算法 、 RSR 算法 相比 分类 准确 率 平均 提高 了 17.04% 、 13.95% 、 3.6% 和 9.39% , 分类 准确 率 方差 也是 最小 的 , 分类 结果 稳定 。	1>2	comparison	comparison
nlpabs70_Chi	19-35	133-146	该文 提出 了 一 种 融合 K 均值 聚类 和 低秩 约束 的 属性 选择 算法 。	分类 准确 率 平均 提高 了 17.04% 、 13.95% 、 3.6% 和 9.39% ,	1-35	111-158	针 对 无 监督 属性 选择 算法 无 类别 信息 和 未 考虑 属性 低秩 等 问题 , 该文 提出 了 一 种 融合 K 均值 聚类 和 低秩 约束 的 属性 选择 算法 。	经实 验验 证 , 该文 提出 的 属性 算法 与 NFS 算法 、 LDA 算法 、 RFS 算法 、 RSR 算法 相比 分类 准确 率 平均 提高 了 17.04% 、 13.95% 、 3.6% 和 9.39% , 分类 准确 率 方差 也是 最小 的 , 分类 结果 稳定 。	1<2	evaluation	evaluation
nlpabs70_Chi	133-146	147-154	分类 准确 率 平均 提高 了 17.04% 、 13.95% 、 3.6% 和 9.39% ,	分类 准确 率 方差 也是 最小 的 ,	111-158	111-158	经实 验验 证 , 该文 提出 的 属性 算法 与 NFS 算法 、 LDA 算法 、 RFS 算法 、 RSR 算法 相比 分类 准确 率 平均 提高 了 17.04% 、 13.95% 、 3.6% 和 9.39% , 分类 准确 率 方差 也是 最小 的 , 分类 结果 稳定 。	经实 验验 证 , 该文 提出 的 属性 算法 与 NFS 算法 、 LDA 算法 、 RFS 算法 、 RSR 算法 相比 分类 准确 率 平均 提高 了 17.04% 、 13.95% 、 3.6% 和 9.39% , 分类 准确 率 方差 也是 最小 的 , 分类 结果 稳定 。	1<2	joint	joint
nlpabs70_Chi	147-154	155-158	分类 准确 率 方差 也是 最小 的 ,	分类 结果 稳定 。	111-158	111-158	经实 验验 证 , 该文 提出 的 属性 算法 与 NFS 算法 、 LDA 算法 、 RFS 算法 、 RSR 算法 相比 分类 准确 率 平均 提高 了 17.04% 、 13.95% 、 3.6% 和 9.39% , 分类 准确 率 方差 也是 最小 的 , 分类 结果 稳定 。	经实 验验 证 , 该文 提出 的 属性 算法 与 NFS 算法 、 LDA 算法 、 RFS 算法 、 RSR 算法 相比 分类 准确 率 平均 提高 了 17.04% 、 13.95% 、 3.6% 和 9.39% , 分类 准确 率 方差 也是 最小 的 , 分类 结果 稳定 。	1<2	elab-addition	elab-addition
nlpabs71_Chi	1-17	65-86	有效 地 进行 多 轮 对话 是 开放 域人机 对话 系统 的 主要 目标 之 一 。	借鉴 强化 学习 方法 考虑 全局 的 视角 , 该 文 利用 深度 强化 学习 算法 DQN ( deep Q-network ) ,	1-17	65-126	有效 地 进行 多 轮 对话 是 开放 域人机 对话 系统 的 主要 目标 之 一 。	借鉴 强化 学习 方法 考虑 全局 的 视角 , 该 文 利用 深度 强化 学习 算法 DQN ( deep Q-network ) , 提出 了 使用 深度 价值 网络 对 每 一 轮 的 候选 句子 进行 评估 , 并 选择 未来 收益 最大 的 而 非 生成 概率 最大 的 句子 作 为 回复 的 多 轮 对话 策略 学习 方法 。	1>2	bg-general	bg-general
nlpabs71_Chi	1-17	18-45	有效 地 进行 多 轮 对话 是 开放 域人机 对话 系统 的 主要 目标 之 一 。	目前 的 神经 网络 对话 生成 模型 在 开放 域 多轮 对话 过程 中 存在 着 容易 产生 万能 回复 、 很快 陷入 死 循环 的 问题 ;	1-17	18-64	有效 地 进行 多 轮 对话 是 开放 域人机 对话 系统 的 主要 目标 之 一 。	目前 的 神经 网络 对话 生成 模型 在 开放 域 多轮 对话 过程 中 存在 着 容易 产生 万能 回复 、 很快 陷入 死 循环 的 问题 ; 而 已 有 的 多 轮 对话 研究 工作 存在 着 没有 考虑 未来 对话 走向 的 问题 。	1<2	elab-addition	elab-addition
nlpabs71_Chi	18-45	46-64	目前 的 神经 网络 对话 生成 模型 在 开放 域 多轮 对话 过程 中 存在 着 容易 产生 万能 回复 、 很快 陷入 死 循环 的 问题 ;	而 已 有 的 多 轮 对话 研究 工作 存在 着 没有 考虑 未来 对话 走向 的 问题 。	18-64	18-64	目前 的 神经 网络 对话 生成 模型 在 开放 域 多轮 对话 过程 中 存在 着 容易 产生 万能 回复 、 很快 陷入 死 循环 的 问题 ; 而 已 有 的 多 轮 对话 研究 工作 存在 着 没有 考虑 未来 对话 走向 的 问题 。	目前 的 神经 网络 对话 生成 模型 在 开放 域 多轮 对话 过程 中 存在 着 容易 产生 万能 回复 、 很快 陷入 死 循环 的 问题 ; 而 已 有 的 多 轮 对话 研究 工作 存在 着 没有 考虑 未来 对话 走向 的 问题 。	1<2	elab-addition	elab-addition
nlpabs71_Chi	65-86	87-102	借鉴 强化 学习 方法 考虑 全局 的 视角 , 该 文 利用 深度 强化 学习 算法 DQN ( deep Q-network ) ,	提出 了 使用 深度 价值 网络 对 每 一 轮 的 候选 句子 进行 评估 ,	65-126	65-126	借鉴 强化 学习 方法 考虑 全局 的 视角 , 该 文 利用 深度 强化 学习 算法 DQN ( deep Q-network ) , 提出 了 使用 深度 价值 网络 对 每 一 轮 的 候选 句子 进行 评估 , 并 选择 未来 收益 最大 的 而 非 生成 概率 最大 的 句子 作 为 回复 的 多 轮 对话 策略 学习 方法 。	借鉴 强化 学习 方法 考虑 全局 的 视角 , 该 文 利用 深度 强化 学习 算法 DQN ( deep Q-network ) , 提出 了 使用 深度 价值 网络 对 每 一 轮 的 候选 句子 进行 评估 , 并 选择 未来 收益 最大 的 而 非 生成 概率 最大 的 句子 作 为 回复 的 多 轮 对话 策略 学习 方法 。	1<2	enablement	enablement
nlpabs71_Chi	87-102	103-126	提出 了 使用 深度 价值 网络 对 每 一 轮 的 候选 句子 进行 评估 ,	并 选择 未来 收益 最大 的 而 非 生成 概率 最大 的 句子 作 为 回复 的 多 轮 对话 策略 学习 方法 。	65-126	65-126	借鉴 强化 学习 方法 考虑 全局 的 视角 , 该 文 利用 深度 强化 学习 算法 DQN ( deep Q-network ) , 提出 了 使用 深度 价值 网络 对 每 一 轮 的 候选 句子 进行 评估 , 并 选择 未来 收益 最大 的 而 非 生成 概率 最大 的 句子 作 为 回复 的 多 轮 对话 策略 学习 方法 。	借鉴 强化 学习 方法 考虑 全局 的 视角 , 该 文 利用 深度 强化 学习 算法 DQN ( deep Q-network ) , 提出 了 使用 深度 价值 网络 对 每 一 轮 的 候选 句子 进行 评估 , 并 选择 未来 收益 最大 的 而 非 生成 概率 最大 的 句子 作 为 回复 的 多 轮 对话 策略 学习 方法 。	1<2	joint	joint
nlpabs71_Chi	127-130	131-147	实验 结果 表明 ,	该文 提出 的 方法 将 多 轮 对话 的 平均 对话 轮数 提高 了 两 轮 ,	127-160	127-160	实验 结果 表明 , 该文 提出 的 方法 将 多 轮 对话 的 平均 对话 轮数 提高 了 两 轮 , 同时 在 主观 对比 评价 指标 上 获胜 比例 高出 了 45% 。	实验 结果 表明 , 该文 提出 的 方法 将 多 轮 对话 的 平均 对话 轮数 提高 了 两 轮 , 同时 在 主观 对比 评价 指标 上 获胜 比例 高出 了 45% 。	1>2	attribution	attribution
nlpabs71_Chi	65-86	131-147	借鉴 强化 学习 方法 考虑 全局 的 视角 , 该 文 利用 深度 强化 学习 算法 DQN ( deep Q-network ) ,	该文 提出 的 方法 将 多 轮 对话 的 平均 对话 轮数 提高 了 两 轮 ,	65-126	127-160	借鉴 强化 学习 方法 考虑 全局 的 视角 , 该 文 利用 深度 强化 学习 算法 DQN ( deep Q-network ) , 提出 了 使用 深度 价值 网络 对 每 一 轮 的 候选 句子 进行 评估 , 并 选择 未来 收益 最大 的 而 非 生成 概率 最大 的 句子 作 为 回复 的 多 轮 对话 策略 学习 方法 。	实验 结果 表明 , 该文 提出 的 方法 将 多 轮 对话 的 平均 对话 轮数 提高 了 两 轮 , 同时 在 主观 对比 评价 指标 上 获胜 比例 高出 了 45% 。	1<2	evaluation	evaluation
nlpabs71_Chi	131-147	148-160	该文 提出 的 方法 将 多 轮 对话 的 平均 对话 轮数 提高 了 两 轮 ,	同时 在 主观 对比 评价 指标 上 获胜 比例 高出 了 45% 。	127-160	127-160	实验 结果 表明 , 该文 提出 的 方法 将 多 轮 对话 的 平均 对话 轮数 提高 了 两 轮 , 同时 在 主观 对比 评价 指标 上 获胜 比例 高出 了 45% 。	实验 结果 表明 , 该文 提出 的 方法 将 多 轮 对话 的 平均 对话 轮数 提高 了 两 轮 , 同时 在 主观 对比 评价 指标 上 获胜 比例 高出 了 45% 。	1<2	joint	joint
nlpabs72_Chi	1-20	21-29	在 微博 系统 中 , 寻找 高 质量 微博 用户 进行 关注 是 获取 高 质量 信息 的 前提 。	该文 研究 高质 量微 博 用户 发现 问题 ,	1-20	21-45	在 微博 系统 中 , 寻找 高 质量 微博 用户 进行 关注 是 获取 高 质量 信息 的 前提 。	该文 研究 高质 量微 博 用户 发现 问题 , 即 给定 领域 词 查询 , 系统 根据 用户 质量 返回 相关 用户 排序 列表 。	1>2	bg-general	bg-general
nlpabs72_Chi	21-29	30-45	该文 研究 高质 量微 博 用户 发现 问题 ,	即 给定 领域 词 查询 , 系统 根据 用户 质量 返回 相关 用户 排序 列表 。	21-45	21-45	该文 研究 高质 量微 博 用户 发现 问题 , 即 给定 领域 词 查询 , 系统 根据 用户 质量 返回 相关 用户 排序 列表 。	该文 研究 高质 量微 博 用户 发现 问题 , 即 给定 领域 词 查询 , 系统 根据 用户 质量 返回 相关 用户 排序 列表 。	1<2	elab-addition	elab-addition
nlpabs72_Chi	21-29	46-55	该文 研究 高质 量微 博 用户 发现 问题 ,	将 该 问题 分解 成 两 个 子 问题 :	21-45	46-71	该文 研究 高质 量微 博 用户 发现 问题 , 即 给定 领域 词 查询 , 系统 根据 用户 质量 返回 相关 用户 排序 列表 。	将 该 问题 分解 成 两 个 子 问题 : 一 是 领域 相关 用户 的 检索 问题 , 二 是 微博 用户 排序 问题 。	1<2	elab-addition	elab-addition
nlpabs72_Chi	46-55	56-64	将 该 问题 分解 成 两 个 子 问题 :	一 是 领域 相关 用户 的 检索 问题 ,	46-71	46-71	将 该 问题 分解 成 两 个 子 问题 : 一 是 领域 相关 用户 的 检索 问题 , 二 是 微博 用户 排序 问题 。	将 该 问题 分解 成 两 个 子 问题 : 一 是 领域 相关 用户 的 检索 问题 , 二 是 微博 用户 排序 问题 。	1<2	elab-enumember	elab-enumember
nlpabs72_Chi	56-64	65-71	一 是 领域 相关 用户 的 检索 问题 ,	二 是 微博 用户 排序 问题 。	46-71	46-71	将 该 问题 分解 成 两 个 子 问题 : 一 是 领域 相关 用户 的 检索 问题 , 二 是 微博 用户 排序 问题 。	将 该 问题 分解 成 两 个 子 问题 : 一 是 领域 相关 用户 的 检索 问题 , 二 是 微博 用户 排序 问题 。	1<2	joint	joint
nlpabs72_Chi	72-76	77-100	针对 用户 检索 问题 ,	提出 了 基 于 用户 标签 的 用户 表示 方法 以及 基 于 维基 百科 的 查询 — 用户 相似 度 匹配 方法 ,	72-143	72-143	针对 用户 检索 问题 , 提出 了 基 于 用户 标签 的 用户 表示 方法 以及 基 于 维基 百科 的 查询 — 用户 相似 度 匹配 方法 , 该 方法 作 为 ESA ( explicit semantic analysis ) 的 一 个 扩展 应用 , 结果 具有 良好 的 可 解释 性 , 实验 表明 基 于 维基 百科 的 效果 要 优 于 基 于 其他 资源 的 检索 效果 。	针对 用户 检索 问题 , 提出 了 基 于 用户 标签 的 用户 表示 方法 以及 基 于 维基 百科 的 查询 — 用户 相似 度 匹配 方法 , 该 方法 作 为 ESA ( explicit semantic analysis ) 的 一 个 扩展 应用 , 结果 具有 良好 的 可 解释 性 , 实验 表明 基 于 维基 百科 的 效果 要 优 于 基 于 其他 资源 的 检索 效果 。	1>2	bg-general	bg-general
nlpabs72_Chi	56-64	77-100	一 是 领域 相关 用户 的 检索 问题 ,	提出 了 基 于 用户 标签 的 用户 表示 方法 以及 基 于 维基 百科 的 查询 — 用户 相似 度 匹配 方法 ,	46-71	72-143	将 该 问题 分解 成 两 个 子 问题 : 一 是 领域 相关 用户 的 检索 问题 , 二 是 微博 用户 排序 问题 。	针对 用户 检索 问题 , 提出 了 基 于 用户 标签 的 用户 表示 方法 以及 基 于 维基 百科 的 查询 — 用户 相似 度 匹配 方法 , 该 方法 作 为 ESA ( explicit semantic analysis ) 的 一 个 扩展 应用 , 结果 具有 良好 的 可 解释 性 , 实验 表明 基 于 维基 百科 的 效果 要 优 于 基 于 其他 资源 的 检索 效果 。	1<2	elab-addition	elab-addition
nlpabs72_Chi	77-100	101-124	提出 了 基 于 用户 标签 的 用户 表示 方法 以及 基 于 维基 百科 的 查询 — 用户 相似 度 匹配 方法 ,	该 方法 作 为 ESA ( explicit semantic analysis ) 的 一 个 扩展 应用 , 结果 具有 良好 的 可 解释 性 ,	72-143	72-143	针对 用户 检索 问题 , 提出 了 基 于 用户 标签 的 用户 表示 方法 以及 基 于 维基 百科 的 查询 — 用户 相似 度 匹配 方法 , 该 方法 作 为 ESA ( explicit semantic analysis ) 的 一 个 扩展 应用 , 结果 具有 良好 的 可 解释 性 , 实验 表明 基 于 维基 百科 的 效果 要 优 于 基 于 其他 资源 的 检索 效果 。	针对 用户 检索 问题 , 提出 了 基 于 用户 标签 的 用户 表示 方法 以及 基 于 维基 百科 的 查询 — 用户 相似 度 匹配 方法 , 该 方法 作 为 ESA ( explicit semantic analysis ) 的 一 个 扩展 应用 , 结果 具有 良好 的 可 解释 性 , 实验 表明 基 于 维基 百科 的 效果 要 优 于 基 于 其他 资源 的 检索 效果 。	1<2	elab-addition	elab-addition
nlpabs72_Chi	125-126	127-143	实验 表明	基 于 维基 百科 的 效果 要 优 于 基 于 其他 资源 的 检索 效果 。	72-143	72-143	针对 用户 检索 问题 , 提出 了 基 于 用户 标签 的 用户 表示 方法 以及 基 于 维基 百科 的 查询 — 用户 相似 度 匹配 方法 , 该 方法 作 为 ESA ( explicit semantic analysis ) 的 一 个 扩展 应用 , 结果 具有 良好 的 可 解释 性 , 实验 表明 基 于 维基 百科 的 效果 要 优 于 基 于 其他 资源 的 检索 效果 。	针对 用户 检索 问题 , 提出 了 基 于 用户 标签 的 用户 表示 方法 以及 基 于 维基 百科 的 查询 — 用户 相似 度 匹配 方法 , 该 方法 作 为 ESA ( explicit semantic analysis ) 的 一 个 扩展 应用 , 结果 具有 良好 的 可 解释 性 , 实验 表明 基 于 维基 百科 的 效果 要 优 于 基 于 其他 资源 的 检索 效果 。	1>2	attribution	attribution
nlpabs72_Chi	77-100	127-143	提出 了 基 于 用户 标签 的 用户 表示 方法 以及 基 于 维基 百科 的 查询 — 用户 相似 度 匹配 方法 ,	基 于 维基 百科 的 效果 要 优 于 基 于 其他 资源 的 检索 效果 。	72-143	72-143	针对 用户 检索 问题 , 提出 了 基 于 用户 标签 的 用户 表示 方法 以及 基 于 维基 百科 的 查询 — 用户 相似 度 匹配 方法 , 该 方法 作 为 ESA ( explicit semantic analysis ) 的 一 个 扩展 应用 , 结果 具有 良好 的 可 解释 性 , 实验 表明 基 于 维基 百科 的 效果 要 优 于 基 于 其他 资源 的 检索 效果 。	针对 用户 检索 问题 , 提出 了 基 于 用户 标签 的 用户 表示 方法 以及 基 于 维基 百科 的 查询 — 用户 相似 度 匹配 方法 , 该 方法 作 为 ESA ( explicit semantic analysis ) 的 一 个 扩展 应用 , 结果 具有 良好 的 可 解释 性 , 实验 表明 基 于 维基 百科 的 效果 要 优 于 基 于 其他 资源 的 检索 效果 。	1<2	evaluation	evaluation
nlpabs72_Chi	144-148	149-159	针对 用户 排序 问题 ,	提出 了 基 于 图 的 迭代 排序 方法 UBRank ,	144-201	144-201	针对 用户 排序 问题 , 提出 了 基 于 图 的 迭代 排序 方法 UBRank , 在 计算 用户 质量 时 同时 考虑 用户 发布 消息 的 数量 和 消息 的 权威 度 , 并且 只 选择 含 URL 的 消息 来 构 建图 , 实验 验证 了 该 方法 的 高 效 性 和 优越 性 。	针对 用户 排序 问题 , 提出 了 基 于 图 的 迭代 排序 方法 UBRank , 在 计算 用户 质量 时 同时 考虑 用户 发布 消息 的 数量 和 消息 的 权威 度 , 并且 只 选择 含 URL 的 消息 来 构 建图 , 实验 验证 了 该 方法 的 高 效 性 和 优越 性 。	1>2	bg-general	bg-general
nlpabs72_Chi	65-71	149-159	二 是 微博 用户 排序 问题 。	提出 了 基 于 图 的 迭代 排序 方法 UBRank ,	46-71	144-201	将 该 问题 分解 成 两 个 子 问题 : 一 是 领域 相关 用户 的 检索 问题 , 二 是 微博 用户 排序 问题 。	针对 用户 排序 问题 , 提出 了 基 于 图 的 迭代 排序 方法 UBRank , 在 计算 用户 质量 时 同时 考虑 用户 发布 消息 的 数量 和 消息 的 权威 度 , 并且 只 选择 含 URL 的 消息 来 构 建图 , 实验 验证 了 该 方法 的 高 效 性 和 优越 性 。	1<2	elab-addition	elab-addition
nlpabs72_Chi	149-159	160-177	提出 了 基 于 图 的 迭代 排序 方法 UBRank ,	在 计算 用户 质量 时 同时 考虑 用户 发布 消息 的 数量 和 消息 的 权威 度 ,	144-201	144-201	针对 用户 排序 问题 , 提出 了 基 于 图 的 迭代 排序 方法 UBRank , 在 计算 用户 质量 时 同时 考虑 用户 发布 消息 的 数量 和 消息 的 权威 度 , 并且 只 选择 含 URL 的 消息 来 构 建图 , 实验 验证 了 该 方法 的 高 效 性 和 优越 性 。	针对 用户 排序 问题 , 提出 了 基 于 图 的 迭代 排序 方法 UBRank , 在 计算 用户 质量 时 同时 考虑 用户 发布 消息 的 数量 和 消息 的 权威 度 , 并且 只 选择 含 URL 的 消息 来 构 建图 , 实验 验证 了 该 方法 的 高 效 性 和 优越 性 。	1<2	elab-addition	elab-addition
nlpabs72_Chi	160-177	178-188	在 计算 用户 质量 时 同时 考虑 用户 发布 消息 的 数量 和 消息 的 权威 度 ,	并且 只 选择 含 URL 的 消息 来 构 建图 ,	144-201	144-201	针对 用户 排序 问题 , 提出 了 基 于 图 的 迭代 排序 方法 UBRank , 在 计算 用户 质量 时 同时 考虑 用户 发布 消息 的 数量 和 消息 的 权威 度 , 并且 只 选择 含 URL 的 消息 来 构 建图 , 实验 验证 了 该 方法 的 高 效 性 和 优越 性 。	针对 用户 排序 问题 , 提出 了 基 于 图 的 迭代 排序 方法 UBRank , 在 计算 用户 质量 时 同时 考虑 用户 发布 消息 的 数量 和 消息 的 权威 度 , 并且 只 选择 含 URL 的 消息 来 构 建图 , 实验 验证 了 该 方法 的 高 效 性 和 优越 性 。	1<2	joint	joint
nlpabs72_Chi	149-159	189-201	提出 了 基 于 图 的 迭代 排序 方法 UBRank ,	实验 验证 了 该 方法 的 高 效 性 和 优越 性 。	144-201	144-201	针对 用户 排序 问题 , 提出 了 基 于 图 的 迭代 排序 方法 UBRank , 在 计算 用户 质量 时 同时 考虑 用户 发布 消息 的 数量 和 消息 的 权威 度 , 并且 只 选择 含 URL 的 消息 来 构 建图 , 实验 验证 了 该 方法 的 高 效 性 和 优越 性 。	针对 用户 排序 问题 , 提出 了 基 于 图 的 迭代 排序 方法 UBRank , 在 计算 用户 质量 时 同时 考虑 用户 发布 消息 的 数量 和 消息 的 权威 度 , 并且 只 选择 含 URL 的 消息 来 构 建图 , 实验 验证 了 该 方法 的 高 效 性 和 优越 性 。	1<2	evaluation	evaluation
nlpabs73_Chi	1-22	100-118	在 线 技术 社区 是 技术 爱好 者 或者 从业 者 进行 技术 交流 、 咨询 和 分享 的 重要 平台 。	从而 提出 了 一 种 作者 — 读者 — 话题 ( aut hor-rea der-topic , ART ) 模型 ,	1-22	67-128	在 线 技术 社区 是 技术 爱好 者 或者 从业 者 进行 技术 交流 、 咨询 和 分享 的 重要 平台 。	考虑 到 社区 用户 既是 内容 的 生产 者 ( 作者 ) 又是 内容 的 消费 者 ( 读者 ) , 生产 者 体现 用户 技能 , 消费 者 体现 用户 兴趣 , 从而 提出 了 一 种 作者 — 读者 — 话题 ( aut hor-rea der-topic , ART ) 模型 , 同时 对 用户 的 技能 和 兴趣 进行 建模 。	1>2	bg-general	bg-general
nlpabs73_Chi	1-22	23-55	在 线 技术 社区 是 技术 爱好 者 或者 从业 者 进行 技术 交流 、 咨询 和 分享 的 重要 平台 。	社区 运营 者 如果 能够 准确 掌握 每个 用户 的 技能 和 兴趣 , 对 用户 进行 画像 , 将 有助 于 为 用户 提供 精准 的 推荐 和 个性 化 服务 ,	1-22	23-66	在 线 技术 社区 是 技术 爱好 者 或者 从业 者 进行 技术 交流 、 咨询 和 分享 的 重要 平台 。	社区 运营 者 如果 能够 准确 掌握 每个 用户 的 技能 和 兴趣 , 对 用户 进行 画像 , 将 有助 于 为 用户 提供 精准 的 推荐 和 个性 化 服务 , 从而 增加 用户 的 黏性 和 社区 的 活跃 度 。	1<2	elab-addition	elab-addition
nlpabs73_Chi	23-55	56-66	社区 运营 者 如果 能够 准确 掌握 每个 用户 的 技能 和 兴趣 , 对 用户 进行 画像 , 将 有助 于 为 用户 提供 精准 的 推荐 和 个性 化 服务 ,	从而 增加 用户 的 黏性 和 社区 的 活跃 度 。	23-66	23-66	社区 运营 者 如果 能够 准确 掌握 每个 用户 的 技能 和 兴趣 , 对 用户 进行 画像 , 将 有助 于 为 用户 提供 精准 的 推荐 和 个性 化 服务 , 从而 增加 用户 的 黏性 和 社区 的 活跃 度 。	社区 运营 者 如果 能够 准确 掌握 每个 用户 的 技能 和 兴趣 , 对 用户 进行 画像 , 将 有助 于 为 用户 提供 精准 的 推荐 和 个性 化 服务 , 从而 增加 用户 的 黏性 和 社区 的 活跃 度 。	1<2	elab-addition	elab-addition
nlpabs73_Chi	67-99	100-118	考虑 到 社区 用户 既是 内容 的 生产 者 ( 作者 ) 又是 内容 的 消费 者 ( 读者 ) , 生产 者 体现 用户 技能 , 消费 者 体现 用户 兴趣 ,	从而 提出 了 一 种 作者 — 读者 — 话题 ( aut hor-rea der-topic , ART ) 模型 ,	67-128	67-128	考虑 到 社区 用户 既是 内容 的 生产 者 ( 作者 ) 又是 内容 的 消费 者 ( 读者 ) , 生产 者 体现 用户 技能 , 消费 者 体现 用户 兴趣 , 从而 提出 了 一 种 作者 — 读者 — 话题 ( aut hor-rea der-topic , ART ) 模型 , 同时 对 用户 的 技能 和 兴趣 进行 建模 。	考虑 到 社区 用户 既是 内容 的 生产 者 ( 作者 ) 又是 内容 的 消费 者 ( 读者 ) , 生产 者 体现 用户 技能 , 消费 者 体现 用户 兴趣 , 从而 提出 了 一 种 作者 — 读者 — 话题 ( aut hor-rea der-topic , ART ) 模型 , 同时 对 用户 的 技能 和 兴趣 进行 建模 。	1>2	exp-reason	exp-reason
nlpabs73_Chi	100-118	119-128	从而 提出 了 一 种 作者 — 读者 — 话题 ( aut hor-rea der-topic , ART ) 模型 ,	同时 对 用户 的 技能 和 兴趣 进行 建模 。	67-128	67-128	考虑 到 社区 用户 既是 内容 的 生产 者 ( 作者 ) 又是 内容 的 消费 者 ( 读者 ) , 生产 者 体现 用户 技能 , 消费 者 体现 用户 兴趣 , 从而 提出 了 一 种 作者 — 读者 — 话题 ( aut hor-rea der-topic , ART ) 模型 , 同时 对 用户 的 技能 和 兴趣 进行 建模 。	考虑 到 社区 用户 既是 内容 的 生产 者 ( 作者 ) 又是 内容 的 消费 者 ( 读者 ) , 生产 者 体现 用户 技能 , 消费 者 体现 用户 兴趣 , 从而 提出 了 一 种 作者 — 读者 — 话题 ( aut hor-rea der-topic , ART ) 模型 , 同时 对 用户 的 技能 和 兴趣 进行 建模 。	1<2	joint	joint
nlpabs73_Chi	100-118	129-140	从而 提出 了 一 种 作者 — 读者 — 话题 ( aut hor-rea der-topic , ART ) 模型 ,	该 模型 可以 将 文档 的 作者 和 读者 关联 起来 ,	67-128	129-160	考虑 到 社区 用户 既是 内容 的 生产 者 ( 作者 ) 又是 内容 的 消费 者 ( 读者 ) , 生产 者 体现 用户 技能 , 消费 者 体现 用户 兴趣 , 从而 提出 了 一 种 作者 — 读者 — 话题 ( aut hor-rea der-topic , ART ) 模型 , 同时 对 用户 的 技能 和 兴趣 进行 建模 。	该 模型 可以 将 文档 的 作者 和 读者 关联 起来 , 因而 能够 提升 话题 的 聚集 效果 , 产生 更 准确 的 作者 话题 分布 和 读者 话题 分布 。	1<2	elab-addition	elab-addition
nlpabs73_Chi	129-140	141-148	该 模型 可以 将 文档 的 作者 和 读者 关联 起来 ,	因而 能够 提升 话题 的 聚集 效果 ,	129-160	129-160	该 模型 可以 将 文档 的 作者 和 读者 关联 起来 , 因而 能够 提升 话题 的 聚集 效果 , 产生 更 准确 的 作者 话题 分布 和 读者 话题 分布 。	该 模型 可以 将 文档 的 作者 和 读者 关联 起来 , 因而 能够 提升 话题 的 聚集 效果 , 产生 更 准确 的 作者 话题 分布 和 读者 话题 分布 。	1<2	result	result
nlpabs73_Chi	141-148	149-160	因而 能够 提升 话题 的 聚集 效果 ,	产生 更 准确 的 作者 话题 分布 和 读者 话题 分布 。	129-160	129-160	该 模型 可以 将 文档 的 作者 和 读者 关联 起来 , 因而 能够 提升 话题 的 聚集 效果 , 产生 更 准确 的 作者 话题 分布 和 读者 话题 分布 。	该 模型 可以 将 文档 的 作者 和 读者 关联 起来 , 因而 能够 提升 话题 的 聚集 效果 , 产生 更 准确 的 作者 话题 分布 和 读者 话题 分布 。	1<2	joint	joint
nlpabs73_Chi	100-118	161-178	从而 提出 了 一 种 作者 — 读者 — 话题 ( aut hor-rea der-topic , ART ) 模型 ,	该 文 基 于 CSDN 技术 社区 的 真实 数据 集 进行 了 实验 对比 和 分析 ,	67-128	161-205	考虑 到 社区 用户 既是 内容 的 生产 者 ( 作者 ) 又是 内容 的 消费 者 ( 读者 ) , 生产 者 体现 用户 技能 , 消费 者 体现 用户 兴趣 , 从而 提出 了 一 种 作者 — 读者 — 话题 ( aut hor-rea der-topic , ART ) 模型 , 同时 对 用户 的 技能 和 兴趣 进行 建模 。	该 文 基 于 CSDN 技术 社区 的 真实 数据 集 进行 了 实验 对比 和 分析 , 实验 结果 表明 , 该文 提出 的 ART 模型 能够 有效 地 发现 用户 的 技能 和 兴趣 , 明显 优 于 现有 的 各种 话题 模型	1<2	evaluation	evaluation
nlpabs73_Chi	179-182	183-197	实验 结果 表明 ,	该文 提出 的 ART 模型 能够 有效 地 发现 用户 的 技能 和 兴趣 ,	161-205	161-205	该 文 基 于 CSDN 技术 社区 的 真实 数据 集 进行 了 实验 对比 和 分析 , 实验 结果 表明 , 该文 提出 的 ART 模型 能够 有效 地 发现 用户 的 技能 和 兴趣 , 明显 优 于 现有 的 各种 话题 模型	该 文 基 于 CSDN 技术 社区 的 真实 数据 集 进行 了 实验 对比 和 分析 , 实验 结果 表明 , 该文 提出 的 ART 模型 能够 有效 地 发现 用户 的 技能 和 兴趣 , 明显 优 于 现有 的 各种 话题 模型	1>2	attribution	attribution
nlpabs73_Chi	161-178	183-197	该 文 基 于 CSDN 技术 社区 的 真实 数据 集 进行 了 实验 对比 和 分析 ,	该文 提出 的 ART 模型 能够 有效 地 发现 用户 的 技能 和 兴趣 ,	161-205	161-205	该 文 基 于 CSDN 技术 社区 的 真实 数据 集 进行 了 实验 对比 和 分析 , 实验 结果 表明 , 该文 提出 的 ART 模型 能够 有效 地 发现 用户 的 技能 和 兴趣 , 明显 优 于 现有 的 各种 话题 模型	该 文 基 于 CSDN 技术 社区 的 真实 数据 集 进行 了 实验 对比 和 分析 , 实验 结果 表明 , 该文 提出 的 ART 模型 能够 有效 地 发现 用户 的 技能 和 兴趣 , 明显 优 于 现有 的 各种 话题 模型	1<2	elab-addition	elab-addition
nlpabs73_Chi	183-197	198-205	该文 提出 的 ART 模型 能够 有效 地 发现 用户 的 技能 和 兴趣 ,	明显 优 于 现有 的 各种 话题 模型	161-205	161-205	该 文 基 于 CSDN 技术 社区 的 真实 数据 集 进行 了 实验 对比 和 分析 , 实验 结果 表明 , 该文 提出 的 ART 模型 能够 有效 地 发现 用户 的 技能 和 兴趣 , 明显 优 于 现有 的 各种 话题 模型	该 文 基 于 CSDN 技术 社区 的 真实 数据 集 进行 了 实验 对比 和 分析 , 实验 结果 表明 , 该文 提出 的 ART 模型 能够 有效 地 发现 用户 的 技能 和 兴趣 , 明显 优 于 现有 的 各种 话题 模型	1<2	elab-addition	elab-addition
nlpabs74_Chi	1-14	49-60	以往 小说 人物 心理 分析 主要 是 对 人物 性格 的 定性 分析 ,	该文 采用 基 于 数据 挖掘 的 文学 智能 分析 方法 ,	1-48	49-110	以往 小说 人物 心理 分析 主要 是 对 人物 性格 的 定性 分析 , 易 受 研究 者 个人 主观 经验 影响 ; 而 相比 于 描述 繁杂 的 性格 而 言 , 更加 稳定 系统 的 人格 能够 更好 地 描述 并 传达 小说 人物 心理 。	该文 采用 基 于 数据 挖掘 的 文学 智能 分析 方法 , 通过 中 文 心理 分析 系统 对 《 平凡 的 世界 》 人物 对话 进行 处理 , 得到 人物 的 大五 人格 预测 分数 ; 进而 , 考察 文艺 学 文献 、 小说 剧情 对 预测 分数 的 验证 情况 , 以 确定 这 种 方法 的 有效 性 。	1>2	bg-compare	bg-compare
nlpabs74_Chi	1-14	15-23	以往 小说 人物 心理 分析 主要 是 对 人物 性格 的 定性 分析 ,	易 受 研究 者 个人 主观 经验 影响 ;	1-48	1-48	以往 小说 人物 心理 分析 主要 是 对 人物 性格 的 定性 分析 , 易 受 研究 者 个人 主观 经验 影响 ; 而 相比 于 描述 繁杂 的 性格 而 言 , 更加 稳定 系统 的 人格 能够 更好 地 描述 并 传达 小说 人物 心理 。	以往 小说 人物 心理 分析 主要 是 对 人物 性格 的 定性 分析 , 易 受 研究 者 个人 主观 经验 影响 ; 而 相比 于 描述 繁杂 的 性格 而 言 , 更加 稳定 系统 的 人格 能够 更好 地 描述 并 传达 小说 人物 心理 。	1<2	elab-addition	elab-addition
nlpabs74_Chi	24-33	34-48	而 相比 于 描述 繁杂 的 性格 而 言 ,	更加 稳定 系统 的 人格 能够 更好 地 描述 并 传达 小说 人物 心理 。	1-48	1-48	以往 小说 人物 心理 分析 主要 是 对 人物 性格 的 定性 分析 , 易 受 研究 者 个人 主观 经验 影响 ; 而 相比 于 描述 繁杂 的 性格 而 言 , 更加 稳定 系统 的 人格 能够 更好 地 描述 并 传达 小说 人物 心理 。	以往 小说 人物 心理 分析 主要 是 对 人物 性格 的 定性 分析 , 易 受 研究 者 个人 主观 经验 影响 ; 而 相比 于 描述 繁杂 的 性格 而 言 , 更加 稳定 系统 的 人格 能够 更好 地 描述 并 传达 小说 人物 心理 。	1>2	comparison	comparison
nlpabs74_Chi	1-14	34-48	以往 小说 人物 心理 分析 主要 是 对 人物 性格 的 定性 分析 ,	更加 稳定 系统 的 人格 能够 更好 地 描述 并 传达 小说 人物 心理 。	1-48	1-48	以往 小说 人物 心理 分析 主要 是 对 人物 性格 的 定性 分析 , 易 受 研究 者 个人 主观 经验 影响 ; 而 相比 于 描述 繁杂 的 性格 而 言 , 更加 稳定 系统 的 人格 能够 更好 地 描述 并 传达 小说 人物 心理 。	以往 小说 人物 心理 分析 主要 是 对 人物 性格 的 定性 分析 , 易 受 研究 者 个人 主观 经验 影响 ; 而 相比 于 描述 繁杂 的 性格 而 言 , 更加 稳定 系统 的 人格 能够 更好 地 描述 并 传达 小说 人物 心理 。	1<2	joint	joint
nlpabs74_Chi	49-60	61-77	该文 采用 基 于 数据 挖掘 的 文学 智能 分析 方法 ,	通过 中 文 心理 分析 系统 对 《 平凡 的 世界 》 人物 对话 进行 处理 ,	49-110	49-110	该文 采用 基 于 数据 挖掘 的 文学 智能 分析 方法 , 通过 中 文 心理 分析 系统 对 《 平凡 的 世界 》 人物 对话 进行 处理 , 得到 人物 的 大五 人格 预测 分数 ; 进而 , 考察 文艺 学 文献 、 小说 剧情 对 预测 分数 的 验证 情况 , 以 确定 这 种 方法 的 有效 性 。	该文 采用 基 于 数据 挖掘 的 文学 智能 分析 方法 , 通过 中 文 心理 分析 系统 对 《 平凡 的 世界 》 人物 对话 进行 处理 , 得到 人物 的 大五 人格 预测 分数 ; 进而 , 考察 文艺 学 文献 、 小说 剧情 对 预测 分数 的 验证 情况 , 以 确定 这 种 方法 的 有效 性 。	1<2	elab-addition	elab-addition
nlpabs74_Chi	49-60	78-85	该文 采用 基 于 数据 挖掘 的 文学 智能 分析 方法 ,	得到 人物 的 大五 人格 预测 分数 ;	49-110	49-110	该文 采用 基 于 数据 挖掘 的 文学 智能 分析 方法 , 通过 中 文 心理 分析 系统 对 《 平凡 的 世界 》 人物 对话 进行 处理 , 得到 人物 的 大五 人格 预测 分数 ; 进而 , 考察 文艺 学 文献 、 小说 剧情 对 预测 分数 的 验证 情况 , 以 确定 这 种 方法 的 有效 性 。	该文 采用 基 于 数据 挖掘 的 文学 智能 分析 方法 , 通过 中 文 心理 分析 系统 对 《 平凡 的 世界 》 人物 对话 进行 处理 , 得到 人物 的 大五 人格 预测 分数 ; 进而 , 考察 文艺 学 文献 、 小说 剧情 对 预测 分数 的 验证 情况 , 以 确定 这 种 方法 的 有效 性 。	1<2	enablement	enablement
nlpabs74_Chi	49-60	86-101	该文 采用 基 于 数据 挖掘 的 文学 智能 分析 方法 ,	进而 , 考察 文艺 学 文献 、 小说 剧情 对 预测 分数 的 验证 情况 ,	49-110	49-110	该文 采用 基 于 数据 挖掘 的 文学 智能 分析 方法 , 通过 中 文 心理 分析 系统 对 《 平凡 的 世界 》 人物 对话 进行 处理 , 得到 人物 的 大五 人格 预测 分数 ; 进而 , 考察 文艺 学 文献 、 小说 剧情 对 预测 分数 的 验证 情况 , 以 确定 这 种 方法 的 有效 性 。	该文 采用 基 于 数据 挖掘 的 文学 智能 分析 方法 , 通过 中 文 心理 分析 系统 对 《 平凡 的 世界 》 人物 对话 进行 处理 , 得到 人物 的 大五 人格 预测 分数 ; 进而 , 考察 文艺 学 文献 、 小说 剧情 对 预测 分数 的 验证 情况 , 以 确定 这 种 方法 的 有效 性 。	1<2	progression	progression
nlpabs74_Chi	86-101	102-110	进而 , 考察 文艺 学 文献 、 小说 剧情 对 预测 分数 的 验证 情况 ,	以 确定 这 种 方法 的 有效 性 。	49-110	49-110	该文 采用 基 于 数据 挖掘 的 文学 智能 分析 方法 , 通过 中 文 心理 分析 系统 对 《 平凡 的 世界 》 人物 对话 进行 处理 , 得到 人物 的 大五 人格 预测 分数 ; 进而 , 考察 文艺 学 文献 、 小说 剧情 对 预测 分数 的 验证 情况 , 以 确定 这 种 方法 的 有效 性 。	该文 采用 基 于 数据 挖掘 的 文学 智能 分析 方法 , 通过 中 文 心理 分析 系统 对 《 平凡 的 世界 》 人物 对话 进行 处理 , 得到 人物 的 大五 人格 预测 分数 ; 进而 , 考察 文艺 学 文献 、 小说 剧情 对 预测 分数 的 验证 情况 , 以 确定 这 种 方法 的 有效 性 。	1<2	enablement	enablement
nlpabs74_Chi	111-113	114-125	结果 表明 :	年轻 的 孙 少平 和 田 晓霞 开放 性 相对 较强 ,	111-165	111-165	结果 表明 : 年轻 的 孙 少平 和 田 晓霞 开放 性 相对 较强 , 而 年长 的 孙 少安 和 田 润叶 外向 性 较强 ; 此外 , 孙 少平 和 田 润叶 尽责 性 较强 , 孙 少安 和 田 晓霞 宜人性 较好 , 孙 少安 和 孙 少平 情绪 性 较高 。	结果 表明 : 年轻 的 孙 少平 和 田 晓霞 开放 性 相对 较强 , 而 年长 的 孙 少安 和 田 润叶 外向 性 较强 ; 此外 , 孙 少平 和 田 润叶 尽责 性 较强 , 孙 少安 和 田 晓霞 宜人性 较好 , 孙 少安 和 孙 少平 情绪 性 较高 。	1>2	attribution	attribution
nlpabs74_Chi	49-60	114-125	该文 采用 基 于 数据 挖掘 的 文学 智能 分析 方法 ,	年轻 的 孙 少平 和 田 晓霞 开放 性 相对 较强 ,	49-110	111-165	该文 采用 基 于 数据 挖掘 的 文学 智能 分析 方法 , 通过 中 文 心理 分析 系统 对 《 平凡 的 世界 》 人物 对话 进行 处理 , 得到 人物 的 大五 人格 预测 分数 ; 进而 , 考察 文艺 学 文献 、 小说 剧情 对 预测 分数 的 验证 情况 , 以 确定 这 种 方法 的 有效 性 。	结果 表明 : 年轻 的 孙 少平 和 田 晓霞 开放 性 相对 较强 , 而 年长 的 孙 少安 和 田 润叶 外向 性 较强 ; 此外 , 孙 少平 和 田 润叶 尽责 性 较强 , 孙 少安 和 田 晓霞 宜人性 较好 , 孙 少安 和 孙 少平 情绪 性 较高 。	1<2	elab-addition	elab-addition
nlpabs74_Chi	114-125	126-137	年轻 的 孙 少平 和 田 晓霞 开放 性 相对 较强 ,	而 年长 的 孙 少安 和 田 润叶 外向 性 较强 ;	111-165	111-165	结果 表明 : 年轻 的 孙 少平 和 田 晓霞 开放 性 相对 较强 , 而 年长 的 孙 少安 和 田 润叶 外向 性 较强 ; 此外 , 孙 少平 和 田 润叶 尽责 性 较强 , 孙 少安 和 田 晓霞 宜人性 较好 , 孙 少安 和 孙 少平 情绪 性 较高 。	结果 表明 : 年轻 的 孙 少平 和 田 晓霞 开放 性 相对 较强 , 而 年长 的 孙 少安 和 田 润叶 外向 性 较强 ; 此外 , 孙 少平 和 田 润叶 尽责 性 较强 , 孙 少安 和 田 晓霞 宜人性 较好 , 孙 少安 和 孙 少平 情绪 性 较高 。	1<2	joint	joint
nlpabs74_Chi	114-125	138-148	年轻 的 孙 少平 和 田 晓霞 开放 性 相对 较强 ,	此外 , 孙 少平 和 田 润叶 尽责 性 较强 ,	111-165	111-165	结果 表明 : 年轻 的 孙 少平 和 田 晓霞 开放 性 相对 较强 , 而 年长 的 孙 少安 和 田 润叶 外向 性 较强 ; 此外 , 孙 少平 和 田 润叶 尽责 性 较强 , 孙 少安 和 田 晓霞 宜人性 较好 , 孙 少安 和 孙 少平 情绪 性 较高 。	结果 表明 : 年轻 的 孙 少平 和 田 晓霞 开放 性 相对 较强 , 而 年长 的 孙 少安 和 田 润叶 外向 性 较强 ; 此外 , 孙 少平 和 田 润叶 尽责 性 较强 , 孙 少安 和 田 晓霞 宜人性 较好 , 孙 少安 和 孙 少平 情绪 性 较高 。	1<2	joint	joint
nlpabs74_Chi	138-148	149-156	此外 , 孙 少平 和 田 润叶 尽责 性 较强 ,	孙 少安 和 田 晓霞 宜人性 较好 ,	111-165	111-165	结果 表明 : 年轻 的 孙 少平 和 田 晓霞 开放 性 相对 较强 , 而 年长 的 孙 少安 和 田 润叶 外向 性 较强 ; 此外 , 孙 少平 和 田 润叶 尽责 性 较强 , 孙 少安 和 田 晓霞 宜人性 较好 , 孙 少安 和 孙 少平 情绪 性 较高 。	结果 表明 : 年轻 的 孙 少平 和 田 晓霞 开放 性 相对 较强 , 而 年长 的 孙 少安 和 田 润叶 外向 性 较强 ; 此外 , 孙 少平 和 田 润叶 尽责 性 较强 , 孙 少安 和 田 晓霞 宜人性 较好 , 孙 少安 和 孙 少平 情绪 性 较高 。	1<2	joint	joint
nlpabs74_Chi	138-148	157-165	此外 , 孙 少平 和 田 润叶 尽责 性 较强 ,	孙 少安 和 孙 少平 情绪 性 较高 。	111-165	111-165	结果 表明 : 年轻 的 孙 少平 和 田 晓霞 开放 性 相对 较强 , 而 年长 的 孙 少安 和 田 润叶 外向 性 较强 ; 此外 , 孙 少平 和 田 润叶 尽责 性 较强 , 孙 少安 和 田 晓霞 宜人性 较好 , 孙 少安 和 孙 少平 情绪 性 较高 。	结果 表明 : 年轻 的 孙 少平 和 田 晓霞 开放 性 相对 较强 , 而 年长 的 孙 少安 和 田 润叶 外向 性 较强 ; 此外 , 孙 少平 和 田 润叶 尽责 性 较强 , 孙 少安 和 田 晓霞 宜人性 较好 , 孙 少安 和 孙 少平 情绪 性 较高 。	1<2	joint	joint
nlpabs74_Chi	114-125	166-175	年轻 的 孙 少平 和 田 晓霞 开放 性 相对 较强 ,	上述 预测 结果 得到 文献 、 剧情 的 支持 ,	111-165	166-207	结果 表明 : 年轻 的 孙 少平 和 田 晓霞 开放 性 相对 较强 , 而 年长 的 孙 少安 和 田 润叶 外向 性 较强 ; 此外 , 孙 少平 和 田 润叶 尽责 性 较强 , 孙 少安 和 田 晓霞 宜人性 较好 , 孙 少安 和 孙 少平 情绪 性 较高 。	上述 预测 结果 得到 文献 、 剧情 的 支持 , 这 说明 文学 智能 分析 小说 人物 人格 是 有效 的 , 它 为 小说 人物 心理 分析 开辟 出 一 条 客观 、 体系 化 且 智能 化 的 道路 。	1<2	evaluation	evaluation
nlpabs74_Chi	166-175	176-187	上述 预测 结果 得到 文献 、 剧情 的 支持 ,	这 说明 文学 智能 分析 小说 人物 人格 是 有效 的 ,	166-207	166-207	上述 预测 结果 得到 文献 、 剧情 的 支持 , 这 说明 文学 智能 分析 小说 人物 人格 是 有效 的 , 它 为 小说 人物 心理 分析 开辟 出 一 条 客观 、 体系 化 且 智能 化 的 道路 。	上述 预测 结果 得到 文献 、 剧情 的 支持 , 这 说明 文学 智能 分析 小说 人物 人格 是 有效 的 , 它 为 小说 人物 心理 分析 开辟 出 一 条 客观 、 体系 化 且 智能 化 的 道路 。	1<2	elab-addition	elab-addition
nlpabs74_Chi	166-175	188-207	上述 预测 结果 得到 文献 、 剧情 的 支持 ,	它 为 小说 人物 心理 分析 开辟 出 一 条 客观 、 体系 化 且 智能 化 的 道路 。	166-207	166-207	上述 预测 结果 得到 文献 、 剧情 的 支持 , 这 说明 文学 智能 分析 小说 人物 人格 是 有效 的 , 它 为 小说 人物 心理 分析 开辟 出 一 条 客观 、 体系 化 且 智能 化 的 道路 。	上述 预测 结果 得到 文献 、 剧情 的 支持 , 这 说明 文学 智能 分析 小说 人物 人格 是 有效 的 , 它 为 小说 人物 心理 分析 开辟 出 一 条 客观 、 体系 化 且 智能 化 的 道路 。	1<2	elab-addition	elab-addition
nlpabs75_Chi	1-14	56-63	未识 甲骨 字 的 考释 是 甲骨 文 研究 最 重要 的 内容 ,	通过 建模 定义 甲骨字 之间 的 距离 ,	1-29	44-68	未识 甲骨 字 的 考释 是 甲骨 文 研究 最 重要 的 内容 , 也是 历史 学 家 和 计算 机学 家 研究 甲骨文 遇到 的 最大 瓶颈 。	因 此 , 该文 以 甲骨 文 拓片 为 基础 数据 , 通过 建模 定义 甲骨字 之间 的 距离 , 进而 构建 甲骨字 网络 。	1>2	bg-general	bg-general
nlpabs75_Chi	1-14	15-29	未识 甲骨 字 的 考释 是 甲骨 文 研究 最 重要 的 内容 ,	也是 历史 学 家 和 计算 机学 家 研究 甲骨文 遇到 的 最大 瓶颈 。	1-29	1-29	未识 甲骨 字 的 考释 是 甲骨 文 研究 最 重要 的 内容 , 也是 历史 学 家 和 计算 机学 家 研究 甲骨文 遇到 的 最大 瓶颈 。	未识 甲骨 字 的 考释 是 甲骨 文 研究 最 重要 的 内容 , 也是 历史 学 家 和 计算 机学 家 研究 甲骨文 遇到 的 最大 瓶颈 。	1<2	elab-addition	elab-addition
nlpabs75_Chi	1-14	30-43	未识 甲骨 字 的 考释 是 甲骨 文 研究 最 重要 的 内容 ,	甲骨文 研究 积累 的 数据 已 体现 出 海量 化 和 系统 化 。	1-29	30-43	未识 甲骨 字 的 考释 是 甲骨 文 研究 最 重要 的 内容 , 也是 历史 学 家 和 计算 机学 家 研究 甲骨文 遇到 的 最大 瓶颈 。	甲骨文 研究 积累 的 数据 已 体现 出 海量 化 和 系统 化 。	1<2	elab-addition	elab-addition
nlpabs75_Chi	44-55	56-63	因 此 , 该文 以 甲骨 文 拓片 为 基础 数据 ,	通过 建模 定义 甲骨字 之间 的 距离 ,	44-68	44-68	因 此 , 该文 以 甲骨 文 拓片 为 基础 数据 , 通过 建模 定义 甲骨字 之间 的 距离 , 进而 构建 甲骨字 网络 。	因 此 , 该文 以 甲骨 文 拓片 为 基础 数据 , 通过 建模 定义 甲骨字 之间 的 距离 , 进而 构建 甲骨字 网络 。	1>2	bg-general	bg-general
nlpabs75_Chi	56-63	64-68	通过 建模 定义 甲骨字 之间 的 距离 ,	进而 构建 甲骨字 网络 。	44-68	44-68	因 此 , 该文 以 甲骨 文 拓片 为 基础 数据 , 通过 建模 定义 甲骨字 之间 的 距离 , 进而 构建 甲骨字 网络 。	因 此 , 该文 以 甲骨 文 拓片 为 基础 数据 , 通过 建模 定义 甲骨字 之间 的 距离 , 进而 构建 甲骨字 网络 。	1<2	enablement	enablement
nlpabs75_Chi	56-63	69-92	通过 建模 定义 甲骨字 之间 的 距离 ,	在 此 网络 之上 , 分析 网络 的 度 分布 、 局部 连接 比率 、 聚类 系数 、 模块 度 等 相关 特性 。	44-68	69-92	因 此 , 该文 以 甲骨 文 拓片 为 基础 数据 , 通过 建模 定义 甲骨字 之间 的 距离 , 进而 构建 甲骨字 网络 。	在 此 网络 之上 , 分析 网络 的 度 分布 、 局部 连接 比率 、 聚类 系数 、 模块 度 等 相关 特性 。	1<2	elab-addition	elab-addition
nlpabs75_Chi	93-95	96-121	结果 表明 :	构建 的 甲骨 字 网络 不仅 能 充分 反映 甲骨 文 系统 的 单 音节 词 多 和 复音节 词 少 的 古 文字 特征 ,	93-137	93-137	结果 表明 : 构建 的 甲骨 字 网络 不仅 能 充分 反映 甲骨 文 系统 的 单 音节 词 多 和 复音节 词 少 的 古 文字 特征 , 而且 能 捕捉 甲骨文 拓片 的 语义 单元 , 并 具有 很强 的 模块 特性 。	结果 表明 : 构建 的 甲骨 字 网络 不仅 能 充分 反映 甲骨 文 系统 的 单 音节 词 多 和 复音节 词 少 的 古 文字 特征 , 而且 能 捕捉 甲骨文 拓片 的 语义 单元 , 并 具有 很强 的 模块 特性 。	1>2	attribution	attribution
nlpabs75_Chi	56-63	96-121	通过 建模 定义 甲骨字 之间 的 距离 ,	构建 的 甲骨 字 网络 不仅 能 充分 反映 甲骨 文 系统 的 单 音节 词 多 和 复音节 词 少 的 古 文字 特征 ,	44-68	93-137	因 此 , 该文 以 甲骨 文 拓片 为 基础 数据 , 通过 建模 定义 甲骨字 之间 的 距离 , 进而 构建 甲骨字 网络 。	结果 表明 : 构建 的 甲骨 字 网络 不仅 能 充分 反映 甲骨 文 系统 的 单 音节 词 多 和 复音节 词 少 的 古 文字 特征 , 而且 能 捕捉 甲骨文 拓片 的 语义 单元 , 并 具有 很强 的 模块 特性 。	1<2	evaluation	evaluation
nlpabs75_Chi	96-121	122-137	构建 的 甲骨 字 网络 不仅 能 充分 反映 甲骨 文 系统 的 单 音节 词 多 和 复音节 词 少 的 古 文字 特征 ,	而且 能 捕捉 甲骨文 拓片 的 语义 单元 , 并 具有 很强 的 模块 特性 。	93-137	93-137	结果 表明 : 构建 的 甲骨 字 网络 不仅 能 充分 反映 甲骨 文 系统 的 单 音节 词 多 和 复音节 词 少 的 古 文字 特征 , 而且 能 捕捉 甲骨文 拓片 的 语义 单元 , 并 具有 很强 的 模块 特性 。	结果 表明 : 构建 的 甲骨 字 网络 不仅 能 充分 反映 甲骨 文 系统 的 单 音节 词 多 和 复音节 词 少 的 古 文字 特征 , 而且 能 捕捉 甲骨文 拓片 的 语义 单元 , 并 具有 很强 的 模块 特性 。	1<2	joint	joint
nlpabs75_Chi	56-63	138-170	通过 建模 定义 甲骨字 之间 的 距离 ,	该 文 构 建 的 网络 及 其 特性 可 为 历史 学 家 和 网络 甲骨 学 家 揭示 未 知 甲骨 字 的 语义 提供 新 的 数据 和 理论 基础	44-68	138-170	因 此 , 该文 以 甲骨 文 拓片 为 基础 数据 , 通过 建模 定义 甲骨字 之间 的 距离 , 进而 构建 甲骨字 网络 。	该 文 构 建 的 网络 及 其 特性 可 为 历史 学 家 和 网络 甲骨 学 家 揭示 未 知 甲骨 字 的 语义 提供 新 的 数据 和 理论 基础	1<2	elab-addition	elab-addition
nlpabs76_Chi	1-14	15-27	该文 提出 一 种 结合 短语 结构 句法 的 语义 角色 标注 方法 。	结合 短语 结构 句法 对 句子 进行 剪枝 、 子句 抽取 处理 ,	1-14	15-41	该文 提出 一 种 结合 短语 结构 句法 的 语义 角色 标注 方法 。	结合 短语 结构 句法 对 句子 进行 剪枝 、 子句 抽取 处理 , 然后 , 对 处理 过 的 句子 进行 语义 角色 分析 并 还原 。	1<2	elab-process_step	elab-process_step
nlpabs76_Chi	15-27	28-41	结合 短语 结构 句法 对 句子 进行 剪枝 、 子句 抽取 处理 ,	然后 , 对 处理 过 的 句子 进行 语义 角色 分析 并 还原 。	15-41	15-41	结合 短语 结构 句法 对 句子 进行 剪枝 、 子句 抽取 处理 , 然后 , 对 处理 过 的 句子 进行 语义 角色 分析 并 还原 。	结合 短语 结构 句法 对 句子 进行 剪枝 、 子句 抽取 处理 , 然后 , 对 处理 过 的 句子 进行 语义 角色 分析 并 还原 。	1<2	joint	joint
nlpabs76_Chi	28-41	42-55	然后 , 对 处理 过 的 句子 进行 语义 角色 分析 并 还原 。	最后 , 结合 短语 树 对 还原 后 的 论元 边界 进行 修正 。	15-41	42-55	结合 短语 结构 句法 对 句子 进行 剪枝 、 子句 抽取 处理 , 然后 , 对 处理 过 的 句子 进行 语义 角色 分析 并 还原 。	最后 , 结合 短语 树 对 还原 后 的 论元 边界 进行 修正 。	1<2	joint	joint
nlpabs76_Chi	15-27	56-67	结合 短语 结构 句法 对 句子 进行 剪枝 、 子句 抽取 处理 ,	其中 , 剪枝 包括 并列 结构 、 插入 语 的 剪枝 ,	15-41	56-80	结合 短语 结构 句法 对 句子 进行 剪枝 、 子句 抽取 处理 , 然后 , 对 处理 过 的 句子 进行 语义 角色 分析 并 还原 。	其中 , 剪枝 包括 并列 结构 、 插入 语 的 剪枝 , 子句 抽取 针对 不同 形式 的 子句 有 不同 的 处理 方式 。	1<2	elab-addition	elab-addition
nlpabs76_Chi	56-67	68-80	其中 , 剪枝 包括 并列 结构 、 插入 语 的 剪枝 ,	子句 抽取 针对 不同 形式 的 子句 有 不同 的 处理 方式 。	56-80	56-80	其中 , 剪枝 包括 并列 结构 、 插入 语 的 剪枝 , 子句 抽取 针对 不同 形式 的 子句 有 不同 的 处理 方式 。	其中 , 剪枝 包括 并列 结构 、 插入 语 的 剪枝 , 子句 抽取 针对 不同 形式 的 子句 有 不同 的 处理 方式 。	1<2	joint	joint
nlpabs76_Chi	42-55	81-91	最后 , 结合 短语 树 对 还原 后 的 论元 边界 进行 修正 。	边界 修正 主要 是 针对 某些 类型 论元 进行 修正 。	42-55	81-91	最后 , 结合 短语 树 对 还原 后 的 论元 边界 进行 修正 。	边界 修正 主要 是 针对 某些 类型 论元 进行 修正 。	1<2	elab-addition	elab-addition
nlpabs76_Chi	1-14	92-104	该文 提出 一 种 结合 短语 结构 句法 的 语义 角色 标注 方法 。	该文 分别 在 CoNLL2004 与 CoNLL2005 评测 语料 中 做 了 实验 ,	1-14	92-130	该文 提出 一 种 结合 短语 结构 句法 的 语义 角色 标注 方法 。	该文 分别 在 CoNLL2004 与 CoNLL2005 评测 语料 中 做 了 实验 , 在 CoNLL2005 Shared Task 的 test _ wsj 数据 集上 F值 为 88.25% , 在 CoNLL2004 Shared Task 的 test 数据 集上 F值 为 85.66% 。	1<2	evaluation	evaluation
nlpabs76_Chi	92-104	105-130	该文 分别 在 CoNLL2004 与 CoNLL2005 评测 语料 中 做 了 实验 ,	在 CoNLL2005 Shared Task 的 test _ wsj 数据 集上 F值 为 88.25% , 在 CoNLL2004 Shared Task 的 test 数据 集上 F值 为 85.66% 。	92-130	92-130	该文 分别 在 CoNLL2004 与 CoNLL2005 评测 语料 中 做 了 实验 , 在 CoNLL2005 Shared Task 的 test _ wsj 数据 集上 F值 为 88.25% , 在 CoNLL2004 Shared Task 的 test 数据 集上 F值 为 85.66% 。	该文 分别 在 CoNLL2004 与 CoNLL2005 评测 语料 中 做 了 实验 , 在 CoNLL2005 Shared Task 的 test _ wsj 数据 集上 F值 为 88.25% , 在 CoNLL2004 Shared Task 的 test 数据 集上 F值 为 85.66% 。	1<2	elab-addition	elab-addition
nlpabs76_Chi	131-134	135-148	实验 结果 表明 ,	引入 短语 结构 句法 能 有效 地 提升 语义 角色 的 识别 效果 。	131-148	131-148	实验 结果 表明 , 引入 短语 结构 句法 能 有效 地 提升 语义 角色 的 识别 效果 。	实验 结果 表明 , 引入 短语 结构 句法 能 有效 地 提升 语义 角色 的 识别 效果 。	1>2	attribution	attribution
nlpabs76_Chi	92-104	135-148	该文 分别 在 CoNLL2004 与 CoNLL2005 评测 语料 中 做 了 实验 ,	引入 短语 结构 句法 能 有效 地 提升 语义 角色 的 识别 效果 。	92-130	131-148	该文 分别 在 CoNLL2004 与 CoNLL2005 评测 语料 中 做 了 实验 , 在 CoNLL2005 Shared Task 的 test _ wsj 数据 集上 F值 为 88.25% , 在 CoNLL2004 Shared Task 的 test 数据 集上 F值 为 85.66% 。	实验 结果 表明 , 引入 短语 结构 句法 能 有效 地 提升 语义 角色 的 识别 效果 。	1<2	elab-addition	elab-addition
nlpabs77_Chi	1-12	104-121	国际 汉 语 教学 领域 中 存在 大量 的 动态 词 。	该文 首先 介绍 三 音节 名词 型 动态 词 结构 模式 的 一 种 知识 表示 方法 ;	1-12	104-193	国际 汉 语 教学 领域 中 存在 大量 的 动态 词 。	该文 首先 介绍 三 音节 名词 型 动态 词 结构 模式 的 一 种 知识 表示 方法 ; 然后 通过 标注 一定 规模 的 国际 汉 语 教材 语料 , 获取 三 音节 名 词 型 动态 词 的 所有 结构 模式 类型 以及 对应 的 动态 词 及 词频 信息 , 构建 基 于 国际 汉 语 教学 的 三 音节 名词 型 动态 词 结构 模式 知识 库 ; 最后 在 结构 模式 知识 库 的 基础 上 对 三 音节 名词 型 动态 词 进行 分析 。	1>2	bg-general	bg-general
nlpabs77_Chi	1-12	13-29	国际 汉 语 教学 领域 中 存在 大量 的 动态 词 。	深入 细致 地 研究 分析 国际 汉 语 教材 语料 中 真实 出现 的 动态 词 ,	1-12	13-64	国际 汉 语 教学 领域 中 存在 大量 的 动态 词 。	深入 细致 地 研究 分析 国际 汉 语 教材 语料 中 真实 出现 的 动态 词 , 一 方面 有助 于 国际 汉 语 教学 的 词汇 研究 与 词汇 教学 ; 另 一 方面 , 对面 向 国际 汉 语 教学 的 信息 处理 工作 具有 重要 的 促进 作用 。	1<2	elab-addition	elab-addition
nlpabs77_Chi	13-29	30-44	深入 细致 地 研究 分析 国际 汉 语 教材 语料 中 真实 出现 的 动态 词 ,	一 方面 有助 于 国际 汉 语 教学 的 词汇 研究 与 词汇 教学 ;	13-64	13-64	深入 细致 地 研究 分析 国际 汉 语 教材 语料 中 真实 出现 的 动态 词 , 一 方面 有助 于 国际 汉 语 教学 的 词汇 研究 与 词汇 教学 ; 另 一 方面 , 对面 向 国际 汉 语 教学 的 信息 处理 工作 具有 重要 的 促进 作用 。	深入 细致 地 研究 分析 国际 汉 语 教材 语料 中 真实 出现 的 动态 词 , 一 方面 有助 于 国际 汉 语 教学 的 词汇 研究 与 词汇 教学 ; 另 一 方面 , 对面 向 国际 汉 语 教学 的 信息 处理 工作 具有 重要 的 促进 作用 。	1<2	elab-addition	elab-addition
nlpabs77_Chi	30-44	45-64	一 方面 有助 于 国际 汉 语 教学 的 词汇 研究 与 词汇 教学 ;	另 一 方面 , 对面 向 国际 汉 语 教学 的 信息 处理 工作 具有 重要 的 促进 作用 。	13-64	13-64	深入 细致 地 研究 分析 国际 汉 语 教材 语料 中 真实 出现 的 动态 词 , 一 方面 有助 于 国际 汉 语 教学 的 词汇 研究 与 词汇 教学 ; 另 一 方面 , 对面 向 国际 汉 语 教学 的 信息 处理 工作 具有 重要 的 促进 作用 。	深入 细致 地 研究 分析 国际 汉 语 教材 语料 中 真实 出现 的 动态 词 , 一 方面 有助 于 国际 汉 语 教学 的 词汇 研究 与 词汇 教学 ; 另 一 方面 , 对面 向 国际 汉 语 教学 的 信息 处理 工作 具有 重要 的 促进 作用 。	1<2	joint	joint
nlpabs77_Chi	1-12	65-80	国际 汉 语 教学 领域 中 存在 大量 的 动态 词 。	三 音节 名词 是 国际 汉 语 教学 中 一 种 常见 的 词汇 类型 ,	1-12	65-103	国际 汉 语 教学 领域 中 存在 大量 的 动态 词 。	三 音节 名词 是 国际 汉 语 教学 中 一 种 常见 的 词汇 类型 , 在 词汇 教学 中 占有 重要 的 位置 , 而 其中 三 音节 名词 型 动态 词 又 占有 较高 的 比重 。	1<2	joint	joint
nlpabs77_Chi	65-80	81-89	三 音节 名词 是 国际 汉 语 教学 中 一 种 常见 的 词汇 类型 ,	在 词汇 教学 中 占有 重要 的 位置 ,	65-103	65-103	三 音节 名词 是 国际 汉 语 教学 中 一 种 常见 的 词汇 类型 , 在 词汇 教学 中 占有 重要 的 位置 , 而 其中 三 音节 名词 型 动态 词 又 占有 较高 的 比重 。	三 音节 名词 是 国际 汉 语 教学 中 一 种 常见 的 词汇 类型 , 在 词汇 教学 中 占有 重要 的 位置 , 而 其中 三 音节 名词 型 动态 词 又 占有 较高 的 比重 。	1<2	elab-addition	elab-addition
nlpabs77_Chi	65-80	90-103	三 音节 名词 是 国际 汉 语 教学 中 一 种 常见 的 词汇 类型 ,	而 其中 三 音节 名词 型 动态 词 又 占有 较高 的 比重 。	65-103	65-103	三 音节 名词 是 国际 汉 语 教学 中 一 种 常见 的 词汇 类型 , 在 词汇 教学 中 占有 重要 的 位置 , 而 其中 三 音节 名词 型 动态 词 又 占有 较高 的 比重 。	三 音节 名词 是 国际 汉 语 教学 中 一 种 常见 的 词汇 类型 , 在 词汇 教学 中 占有 重要 的 位置 , 而 其中 三 音节 名词 型 动态 词 又 占有 较高 的 比重 。	1<2	elab-addition	elab-addition
nlpabs77_Chi	104-121	122-133	该文 首先 介绍 三 音节 名词 型 动态 词 结构 模式 的 一 种 知识 表示 方法 ;	然后 通过 标注 一定 规模 的 国际 汉 语 教材 语料 ,	104-193	104-193	该文 首先 介绍 三 音节 名词 型 动态 词 结构 模式 的 一 种 知识 表示 方法 ; 然后 通过 标注 一定 规模 的 国际 汉 语 教材 语料 , 获取 三 音节 名 词 型 动态 词 的 所有 结构 模式 类型 以及 对应 的 动态 词 及 词频 信息 , 构建 基 于 国际 汉 语 教学 的 三 音节 名词 型 动态 词 结构 模式 知识 库 ; 最后 在 结构 模式 知识 库 的 基础 上 对 三 音节 名词 型 动态 词 进行 分析 。	该文 首先 介绍 三 音节 名词 型 动态 词 结构 模式 的 一 种 知识 表示 方法 ; 然后 通过 标注 一定 规模 的 国际 汉 语 教材 语料 , 获取 三 音节 名 词 型 动态 词 的 所有 结构 模式 类型 以及 对应 的 动态 词 及 词频 信息 , 构建 基 于 国际 汉 语 教学 的 三 音节 名词 型 动态 词 结构 模式 知识 库 ; 最后 在 结构 模式 知识 库 的 基础 上 对 三 音节 名词 型 动态 词 进行 分析 。	1<2	joint	joint
nlpabs77_Chi	122-133	134-155	然后 通过 标注 一定 规模 的 国际 汉 语 教材 语料 ,	获取 三 音节 名 词 型 动态 词 的 所有 结构 模式 类型 以及 对应 的 动态 词 及 词频 信息 ,	104-193	104-193	该文 首先 介绍 三 音节 名词 型 动态 词 结构 模式 的 一 种 知识 表示 方法 ; 然后 通过 标注 一定 规模 的 国际 汉 语 教材 语料 , 获取 三 音节 名 词 型 动态 词 的 所有 结构 模式 类型 以及 对应 的 动态 词 及 词频 信息 , 构建 基 于 国际 汉 语 教学 的 三 音节 名词 型 动态 词 结构 模式 知识 库 ; 最后 在 结构 模式 知识 库 的 基础 上 对 三 音节 名词 型 动态 词 进行 分析 。	该文 首先 介绍 三 音节 名词 型 动态 词 结构 模式 的 一 种 知识 表示 方法 ; 然后 通过 标注 一定 规模 的 国际 汉 语 教材 语料 , 获取 三 音节 名 词 型 动态 词 的 所有 结构 模式 类型 以及 对应 的 动态 词 及 词频 信息 , 构建 基 于 国际 汉 语 教学 的 三 音节 名词 型 动态 词 结构 模式 知识 库 ; 最后 在 结构 模式 知识 库 的 基础 上 对 三 音节 名词 型 动态 词 进行 分析 。	1<2	enablement	enablement
nlpabs77_Chi	134-155	156-174	获取 三 音节 名 词 型 动态 词 的 所有 结构 模式 类型 以及 对应 的 动态 词 及 词频 信息 ,	构建 基 于 国际 汉 语 教学 的 三 音节 名词 型 动态 词 结构 模式 知识 库 ;	104-193	104-193	该文 首先 介绍 三 音节 名词 型 动态 词 结构 模式 的 一 种 知识 表示 方法 ; 然后 通过 标注 一定 规模 的 国际 汉 语 教材 语料 , 获取 三 音节 名 词 型 动态 词 的 所有 结构 模式 类型 以及 对应 的 动态 词 及 词频 信息 , 构建 基 于 国际 汉 语 教学 的 三 音节 名词 型 动态 词 结构 模式 知识 库 ; 最后 在 结构 模式 知识 库 的 基础 上 对 三 音节 名词 型 动态 词 进行 分析 。	该文 首先 介绍 三 音节 名词 型 动态 词 结构 模式 的 一 种 知识 表示 方法 ; 然后 通过 标注 一定 规模 的 国际 汉 语 教材 语料 , 获取 三 音节 名 词 型 动态 词 的 所有 结构 模式 类型 以及 对应 的 动态 词 及 词频 信息 , 构建 基 于 国际 汉 语 教学 的 三 音节 名词 型 动态 词 结构 模式 知识 库 ; 最后 在 结构 模式 知识 库 的 基础 上 对 三 音节 名词 型 动态 词 进行 分析 。	1<2	enablement	enablement
nlpabs77_Chi	104-121	175-193	该文 首先 介绍 三 音节 名词 型 动态 词 结构 模式 的 一 种 知识 表示 方法 ;	最后 在 结构 模式 知识 库 的 基础 上 对 三 音节 名词 型 动态 词 进行 分析 。	104-193	104-193	该文 首先 介绍 三 音节 名词 型 动态 词 结构 模式 的 一 种 知识 表示 方法 ; 然后 通过 标注 一定 规模 的 国际 汉 语 教材 语料 , 获取 三 音节 名 词 型 动态 词 的 所有 结构 模式 类型 以及 对应 的 动态 词 及 词频 信息 , 构建 基 于 国际 汉 语 教学 的 三 音节 名词 型 动态 词 结构 模式 知识 库 ; 最后 在 结构 模式 知识 库 的 基础 上 对 三 音节 名词 型 动态 词 进行 分析 。	该文 首先 介绍 三 音节 名词 型 动态 词 结构 模式 的 一 种 知识 表示 方法 ; 然后 通过 标注 一定 规模 的 国际 汉 语 教材 语料 , 获取 三 音节 名 词 型 动态 词 的 所有 结构 模式 类型 以及 对应 的 动态 词 及 词频 信息 , 构建 基 于 国际 汉 语 教学 的 三 音节 名词 型 动态 词 结构 模式 知识 库 ; 最后 在 结构 模式 知识 库 的 基础 上 对 三 音节 名词 型 动态 词 进行 分析 。	1<2	joint	joint
nlpabs78_Chi	1-24	25-48	针 对 英 语 文章 语法 错误 自动 纠正 ( Grammatical Error Correction , GEC ) 问题 中 的 冠词 和 介词 错误 ,	该文 提出 一 种 基 于 LSTM ( Long Short - Term Memory , 长短 时 记忆 ) 的 序列 标注 GEC 方法 ;	1-96	1-96	针 对 英 语 文章 语法 错误 自动 纠正 ( Grammatical Error Correction , GEC ) 问题 中 的 冠词 和 介词 错误 , 该文 提出 一 种 基 于 LSTM ( Long Short - Term Memory , 长短 时 记忆 ) 的 序列 标注 GEC 方法 ; 针对 名词 单 复 数 错误 、 动词 形式 错误 和 主谓 不 一致 错误 , 因 其 混淆 集 为 开放 集合 , 该文 提出 一 种 基 于 ESL ( English as Second Lauguage ) 和 新闻 语料 的 N-gram 投票 策略 的 GEC 方法 。	针 对 英 语 文章 语法 错误 自动 纠正 ( Grammatical Error Correction , GEC ) 问题 中 的 冠词 和 介词 错误 , 该文 提出 一 种 基 于 LSTM ( Long Short - Term Memory , 长短 时 记忆 ) 的 序列 标注 GEC 方法 ; 针对 名词 单 复 数 错误 、 动词 形式 错误 和 主谓 不 一致 错误 , 因 其 混淆 集 为 开放 集合 , 该文 提出 一 种 基 于 ESL ( English as Second Lauguage ) 和 新闻 语料 的 N-gram 投票 策略 的 GEC 方法 。	1>2	bg-goal	bg-goal
nlpabs78_Chi	49-64	73-96	针对 名词 单 复 数 错误 、 动词 形式 错误 和 主谓 不 一致 错误 ,	该文 提出 一 种 基 于 ESL ( English as Second Lauguage ) 和 新闻 语料 的 N-gram 投票 策略 的 GEC 方法 。	1-96	1-96	针 对 英 语 文章 语法 错误 自动 纠正 ( Grammatical Error Correction , GEC ) 问题 中 的 冠词 和 介词 错误 , 该文 提出 一 种 基 于 LSTM ( Long Short - Term Memory , 长短 时 记忆 ) 的 序列 标注 GEC 方法 ; 针对 名词 单 复 数 错误 、 动词 形式 错误 和 主谓 不 一致 错误 , 因 其 混淆 集 为 开放 集合 , 该文 提出 一 种 基 于 ESL ( English as Second Lauguage ) 和 新闻 语料 的 N-gram 投票 策略 的 GEC 方法 。	针 对 英 语 文章 语法 错误 自动 纠正 ( Grammatical Error Correction , GEC ) 问题 中 的 冠词 和 介词 错误 , 该文 提出 一 种 基 于 LSTM ( Long Short - Term Memory , 长短 时 记忆 ) 的 序列 标注 GEC 方法 ; 针对 名词 单 复 数 错误 、 动词 形式 错误 和 主谓 不 一致 错误 , 因 其 混淆 集 为 开放 集合 , 该文 提出 一 种 基 于 ESL ( English as Second Lauguage ) 和 新闻 语料 的 N-gram 投票 策略 的 GEC 方法 。	1>2	bg-goal	bg-goal
nlpabs78_Chi	65-72	73-96	因 其 混淆 集 为 开放 集合 ,	该文 提出 一 种 基 于 ESL ( English as Second Lauguage ) 和 新闻 语料 的 N-gram 投票 策略 的 GEC 方法 。	1-96	1-96	针 对 英 语 文章 语法 错误 自动 纠正 ( Grammatical Error Correction , GEC ) 问题 中 的 冠词 和 介词 错误 , 该文 提出 一 种 基 于 LSTM ( Long Short - Term Memory , 长短 时 记忆 ) 的 序列 标注 GEC 方法 ; 针对 名词 单 复 数 错误 、 动词 形式 错误 和 主谓 不 一致 错误 , 因 其 混淆 集 为 开放 集合 , 该文 提出 一 种 基 于 ESL ( English as Second Lauguage ) 和 新闻 语料 的 N-gram 投票 策略 的 GEC 方法 。	针 对 英 语 文章 语法 错误 自动 纠正 ( Grammatical Error Correction , GEC ) 问题 中 的 冠词 和 介词 错误 , 该文 提出 一 种 基 于 LSTM ( Long Short - Term Memory , 长短 时 记忆 ) 的 序列 标注 GEC 方法 ; 针对 名词 单 复 数 错误 、 动词 形式 错误 和 主谓 不 一致 错误 , 因 其 混淆 集 为 开放 集合 , 该文 提出 一 种 基 于 ESL ( English as Second Lauguage ) 和 新闻 语料 的 N-gram 投票 策略 的 GEC 方法 。	1>2	exp-reason	exp-reason
nlpabs78_Chi	25-48	73-96	该文 提出 一 种 基 于 LSTM ( Long Short - Term Memory , 长短 时 记忆 ) 的 序列 标注 GEC 方法 ;	该文 提出 一 种 基 于 ESL ( English as Second Lauguage ) 和 新闻 语料 的 N-gram 投票 策略 的 GEC 方法 。	1-96	1-96	针 对 英 语 文章 语法 错误 自动 纠正 ( Grammatical Error Correction , GEC ) 问题 中 的 冠词 和 介词 错误 , 该文 提出 一 种 基 于 LSTM ( Long Short - Term Memory , 长短 时 记忆 ) 的 序列 标注 GEC 方法 ; 针对 名词 单 复 数 错误 、 动词 形式 错误 和 主谓 不 一致 错误 , 因 其 混淆 集 为 开放 集合 , 该文 提出 一 种 基 于 ESL ( English as Second Lauguage ) 和 新闻 语料 的 N-gram 投票 策略 的 GEC 方法 。	针 对 英 语 文章 语法 错误 自动 纠正 ( Grammatical Error Correction , GEC ) 问题 中 的 冠词 和 介词 错误 , 该文 提出 一 种 基 于 LSTM ( Long Short - Term Memory , 长短 时 记忆 ) 的 序列 标注 GEC 方法 ; 针对 名词 单 复 数 错误 、 动词 形式 错误 和 主谓 不 一致 错误 , 因 其 混淆 集 为 开放 集合 , 该文 提出 一 种 基 于 ESL ( English as Second Lauguage ) 和 新闻 语料 的 N-gram 投票 策略 的 GEC 方法 。	1<2	joint	joint
nlpabs78_Chi	25-48	97-116	该文 提出 一 种 基 于 LSTM ( Long Short - Term Memory , 长短 时 记忆 ) 的 序列 标注 GEC 方法 ;	该 文 方 法 在 2013 年 CoNLL 的 GEC 数据 上 实验 的 整体 F1 值 为 33.87% ,	1-96	97-125	针 对 英 语 文章 语法 错误 自动 纠正 ( Grammatical Error Correction , GEC ) 问题 中 的 冠词 和 介词 错误 , 该文 提出 一 种 基 于 LSTM ( Long Short - Term Memory , 长短 时 记忆 ) 的 序列 标注 GEC 方法 ; 针对 名词 单 复 数 错误 、 动词 形式 错误 和 主谓 不 一致 错误 , 因 其 混淆 集 为 开放 集合 , 该文 提出 一 种 基 于 ESL ( English as Second Lauguage ) 和 新闻 语料 的 N-gram 投票 策略 的 GEC 方法 。	该 文 方 法 在 2013 年 CoNLL 的 GEC 数据 上 实验 的 整体 F1 值 为 33.87% , 超过 第一 名 UIUC 的 F1 值 31.20% 。	1<2	evaluation	evaluation
nlpabs78_Chi	97-116	117-125	该 文 方 法 在 2013 年 CoNLL 的 GEC 数据 上 实验 的 整体 F1 值 为 33.87% ,	超过 第一 名 UIUC 的 F1 值 31.20% 。	97-125	97-125	该 文 方 法 在 2013 年 CoNLL 的 GEC 数据 上 实验 的 整体 F1 值 为 33.87% , 超过 第一 名 UIUC 的 F1 值 31.20% 。	该 文 方 法 在 2013 年 CoNLL 的 GEC 数据 上 实验 的 整体 F1 值 为 33.87% , 超过 第一 名 UIUC 的 F1 值 31.20% 。	1<2	elab-addition	elab-addition
nlpabs78_Chi	97-116	126-136	该 文 方 法 在 2013 年 CoNLL 的 GEC 数据 上 实验 的 整体 F1 值 为 33.87% ,	其中 , 冠词 错误 纠正 的 F1 值 为 38.05% ,	97-125	126-164	该 文 方 法 在 2013 年 CoNLL 的 GEC 数据 上 实验 的 整体 F1 值 为 33.87% , 超过 第一 名 UIUC 的 F1 值 31.20% 。	其中 , 冠词 错误 纠正 的 F1 值 为 38.05% , 超过 UIUC 冠词 错误 纠正 的 F1 值 33.40% , 介词 错误 的 纠正 F1 为 28.89% , 超过 UIUC 的 介词 错误 纠正 F1 值 7.22% 。	1<2	elab-addition	elab-addition
nlpabs78_Chi	126-136	137-146	其中 , 冠词 错误 纠正 的 F1 值 为 38.05% ,	超过 UIUC 冠词 错误 纠正 的 F1 值 33.40% ,	126-164	126-164	其中 , 冠词 错误 纠正 的 F1 值 为 38.05% , 超过 UIUC 冠词 错误 纠正 的 F1 值 33.40% , 介词 错误 的 纠正 F1 为 28.89% , 超过 UIUC 的 介词 错误 纠正 F1 值 7.22% 。	其中 , 冠词 错误 纠正 的 F1 值 为 38.05% , 超过 UIUC 冠词 错误 纠正 的 F1 值 33.40% , 介词 错误 的 纠正 F1 为 28.89% , 超过 UIUC 的 介词 错误 纠正 F1 值 7.22% 。	1<2	elab-addition	elab-addition
nlpabs78_Chi	126-136	147-154	其中 , 冠词 错误 纠正 的 F1 值 为 38.05% ,	介词 错误 的 纠正 F1 为 28.89% ,	126-164	126-164	其中 , 冠词 错误 纠正 的 F1 值 为 38.05% , 超过 UIUC 冠词 错误 纠正 的 F1 值 33.40% , 介词 错误 的 纠正 F1 为 28.89% , 超过 UIUC 的 介词 错误 纠正 F1 值 7.22% 。	其中 , 冠词 错误 纠正 的 F1 值 为 38.05% , 超过 UIUC 冠词 错误 纠正 的 F1 值 33.40% , 介词 错误 的 纠正 F1 为 28.89% , 超过 UIUC 的 介词 错误 纠正 F1 值 7.22% 。	1<2	joint	joint
nlpabs78_Chi	147-154	155-164	介词 错误 的 纠正 F1 为 28.89% ,	超过 UIUC 的 介词 错误 纠正 F1 值 7.22% 。	126-164	126-164	其中 , 冠词 错误 纠正 的 F1 值 为 38.05% , 超过 UIUC 冠词 错误 纠正 的 F1 值 33.40% , 介词 错误 的 纠正 F1 为 28.89% , 超过 UIUC 的 介词 错误 纠正 F1 值 7.22% 。	其中 , 冠词 错误 纠正 的 F1 值 为 38.05% , 超过 UIUC 冠词 错误 纠正 的 F1 值 33.40% , 介词 错误 的 纠正 F1 为 28.89% , 超过 UIUC 的 介词 错误 纠正 F1 值 7.22% 。	1<2	elab-addition	elab-addition
nlpabs79_Chi	1-17	83-93	高考 语文 阅读 理解 篇章 标题 选择 题 要求 机器 根据 对 篇章 内容 的 理解 ,	提出 了 标题 与 篇章 要点 相关 性 分析 模型 。	1-35	79-93	高考 语文 阅读 理解 篇章 标题 选择 题 要求 机器 根据 对 篇章 内容 的 理解 , 从 多 个 候选 项 中 选取 能够 准确 恰当 的 概括 表达 篇章 内容 的 选项 。	针对 该 问题 , 提出 了 标题 与 篇章 要点 相关 性 分析 模型 。	1>2	bg-general	bg-general
nlpabs79_Chi	1-17	18-35	高考 语文 阅读 理解 篇章 标题 选择 题 要求 机器 根据 对 篇章 内容 的 理解 ,	从 多 个 候选 项 中 选取 能够 准确 恰当 的 概括 表达 篇章 内容 的 选项 。	1-35	1-35	高考 语文 阅读 理解 篇章 标题 选择 题 要求 机器 根据 对 篇章 内容 的 理解 , 从 多 个 候选 项 中 选取 能够 准确 恰当 的 概括 表达 篇章 内容 的 选项 。	高考 语文 阅读 理解 篇章 标题 选择 题 要求 机器 根据 对 篇章 内容 的 理解 , 从 多 个 候选 项 中 选取 能够 准确 恰当 的 概括 表达 篇章 内容 的 选项 。	1<2	elab-addition	elab-addition
nlpabs79_Chi	36-51	52-78	标题 往往 是 高度 凝练 且 能 准确 表达 文意 、 结构 鲜明 的 词串 。	因 此 , 如何 对 篇章 内容 进行 归纳 概括 、 对 标题 结构 进行 梳理 和 分析 是 解答 篇章 标题 选择 题 的 关键 。	36-51	52-78	标题 往往 是 高度 凝练 且 能 准确 表达 文意 、 结构 鲜明 的 词串 。	因 此 , 如何 对 篇章 内容 进行 归纳 概括 、 对 标题 结构 进行 梳理 和 分析 是 解答 篇章 标题 选择 题 的 关键 。	1>2	exp-reason	exp-reason
nlpabs79_Chi	1-17	52-78	高考 语文 阅读 理解 篇章 标题 选择 题 要求 机器 根据 对 篇章 内容 的 理解 ,	因 此 , 如何 对 篇章 内容 进行 归纳 概括 、 对 标题 结构 进行 梳理 和 分析 是 解答 篇章 标题 选择 题 的 关键 。	1-35	52-78	高考 语文 阅读 理解 篇章 标题 选择 题 要求 机器 根据 对 篇章 内容 的 理解 , 从 多 个 候选 项 中 选取 能够 准确 恰当 的 概括 表达 篇章 内容 的 选项 。	因 此 , 如何 对 篇章 内容 进行 归纳 概括 、 对 标题 结构 进行 梳理 和 分析 是 解答 篇章 标题 选择 题 的 关键 。	1<2	elab-addition	elab-addition
nlpabs79_Chi	79-82	83-93	针对 该 问题 ,	提出 了 标题 与 篇章 要点 相关 性 分析 模型 。	79-93	79-93	针对 该 问题 , 提出 了 标题 与 篇章 要点 相关 性 分析 模型 。	针对 该 问题 , 提出 了 标题 与 篇章 要点 相关 性 分析 模型 。	1>2	bg-general	bg-general
nlpabs79_Chi	94-105	106-118	该 模型 通过 分析 标题 与 篇章 要点 的 相关 性 ,	构建 了 基 于 标题 和 篇章 要点 的 相关 度 矩阵 。	94-118	94-118	该 模型 通过 分析 标题 与 篇章 要点 的 相关 性 , 构建 了 基 于 标题 和 篇章 要点 的 相关 度 矩阵 。	该 模型 通过 分析 标题 与 篇章 要点 的 相关 性 , 构建 了 基 于 标题 和 篇章 要点 的 相关 度 矩阵 。	1>2	manner-means	manner-means
nlpabs79_Chi	83-93	106-118	提出 了 标题 与 篇章 要点 相关 性 分析 模型 。	构建 了 基 于 标题 和 篇章 要点 的 相关 度 矩阵 。	79-93	94-118	针对 该 问题 , 提出 了 标题 与 篇章 要点 相关 性 分析 模型 。	该 模型 通过 分析 标题 与 篇章 要点 的 相关 性 , 构建 了 基 于 标题 和 篇章 要点 的 相关 度 矩阵 。	1<2	elab-addition	elab-addition
nlpabs79_Chi	106-118	119-127	构建 了 基 于 标题 和 篇章 要点 的 相关 度 矩阵 。	在 此 基础 上 融入 标题 结构 特征 ,	94-118	119-135	该 模型 通过 分析 标题 与 篇章 要点 的 相关 性 , 构建 了 基 于 标题 和 篇章 要点 的 相关 度 矩阵 。	在 此 基础 上 融入 标题 结构 特征 , 选取 与 篇章 最 相关 的 标题 。	1<2	elab-addition	elab-addition
nlpabs79_Chi	119-127	128-135	在 此 基础 上 融入 标题 结构 特征 ,	选取 与 篇章 最 相关 的 标题 。	119-135	119-135	在 此 基础 上 融入 标题 结构 特征 , 选取 与 篇章 最 相关 的 标题 。	在 此 基础 上 融入 标题 结构 特征 , 选取 与 篇章 最 相关 的 标题 。	1<2	enablement	enablement
nlpabs79_Chi	83-93	136-149	提出 了 标题 与 篇章 要点 相关 性 分析 模型 。	在 全国 近 10 年 高考 真题 和 测试 题 上 进行 实验 ,	79-93	136-157	针对 该 问题 , 提出 了 标题 与 篇章 要点 相关 性 分析 模型 。	在 全国 近 10 年 高考 真题 和 测试 题 上 进行 实验 , 验证 了 该 方法 的 有效 性 。	1<2	evaluation	evaluation
nlpabs79_Chi	136-149	150-157	在 全国 近 10 年 高考 真题 和 测试 题 上 进行 实验 ,	验证 了 该 方法 的 有效 性 。	136-157	136-157	在 全国 近 10 年 高考 真题 和 测试 题 上 进行 实验 , 验证 了 该 方法 的 有效 性 。	在 全国 近 10 年 高考 真题 和 测试 题 上 进行 实验 , 验证 了 该 方法 的 有效 性 。	1<2	elab-addition	elab-addition
nlpabs7_Chi	1-15	55-68	﻿形容 词 与 名词 、 动词 构成 汉 语 实词 的 主体 组成 部分 ,	该文 主要 叙述 汉 语 形容 词 知识 库 构建 的 相关 工作 。	1-54	55-68	﻿形容 词 与 名词 、 动词 构成 汉 语 实词 的 主体 组成 部分 , 在 句法 上 表现 出 对 " 名词 " 的 极度 依赖 , 其 核心 功能 是 在 概念 层面 上 , 在 认知 注意 机制 的 调适 作用 下 对 名词 的 特征 进行 " 评价 " 。	该文 主要 叙述 汉 语 形容 词 知识 库 构建 的 相关 工作 。	1>2	bg-general	bg-general
nlpabs7_Chi	1-15	16-28	﻿形容 词 与 名词 、 动词 构成 汉 语 实词 的 主体 组成 部分 ,	在 句法 上 表现 出 对 " 名词 " 的 极度 依赖 ,	1-54	1-54	﻿形容 词 与 名词 、 动词 构成 汉 语 实词 的 主体 组成 部分 , 在 句法 上 表现 出 对 " 名词 " 的 极度 依赖 , 其 核心 功能 是 在 概念 层面 上 , 在 认知 注意 机制 的 调适 作用 下 对 名词 的 特征 进行 " 评价 " 。	﻿形容 词 与 名词 、 动词 构成 汉 语 实词 的 主体 组成 部分 , 在 句法 上 表现 出 对 " 名词 " 的 极度 依赖 , 其 核心 功能 是 在 概念 层面 上 , 在 认知 注意 机制 的 调适 作用 下 对 名词 的 特征 进行 " 评价 " 。	1<2	elab-addition	elab-addition
nlpabs7_Chi	1-15	29-54	﻿形容 词 与 名词 、 动词 构成 汉 语 实词 的 主体 组成 部分 ,	其 核心 功能 是 在 概念 层面 上 , 在 认知 注意 机制 的 调适 作用 下 对 名词 的 特征 进行 " 评价 " 。	1-54	1-54	﻿形容 词 与 名词 、 动词 构成 汉 语 实词 的 主体 组成 部分 , 在 句法 上 表现 出 对 " 名词 " 的 极度 依赖 , 其 核心 功能 是 在 概念 层面 上 , 在 认知 注意 机制 的 调适 作用 下 对 名词 的 特征 进行 " 评价 " 。	﻿形容 词 与 名词 、 动词 构成 汉 语 实词 的 主体 组成 部分 , 在 句法 上 表现 出 对 " 名词 " 的 极度 依赖 , 其 核心 功能 是 在 概念 层面 上 , 在 认知 注意 机制 的 调适 作用 下 对 名词 的 特征 进行 " 评价 " 。	1<2	elab-addition	elab-addition
nlpabs7_Chi	55-68	69-79	该文 主要 叙述 汉 语 形容 词 知识 库 构建 的 相关 工作 。	首先 是 考察 已有 的 形容 词 的 收词 情况 ,	55-68	69-134	该文 主要 叙述 汉 语 形容 词 知识 库 构建 的 相关 工作 。	首先 是 考察 已有 的 形容 词 的 收词 情况 , 并 结合 语言 演变 中 新 产生 的 形容 词 , 构建 了 一 个 较为 全面 的 形容 词 词集 ; 其次 是 详细 阐述 知识 库 的 构建 理念 ; 再次 是 具体 阐述 知识 库 的 特征 描述 体系 ; 最后 是 对 该 知识 库 的 应用 场景 进行 展望 。	1<2	elab-addition	elab-addition
nlpabs7_Chi	69-79	80-101	首先 是 考察 已有 的 形容 词 的 收词 情况 ,	并 结合 语言 演变 中 新 产生 的 形容 词 , 构建 了 一 个 较为 全面 的 形容 词 词集 ;	69-134	69-134	首先 是 考察 已有 的 形容 词 的 收词 情况 , 并 结合 语言 演变 中 新 产生 的 形容 词 , 构建 了 一 个 较为 全面 的 形容 词 词集 ; 其次 是 详细 阐述 知识 库 的 构建 理念 ; 再次 是 具体 阐述 知识 库 的 特征 描述 体系 ; 最后 是 对 该 知识 库 的 应用 场景 进行 展望 。	首先 是 考察 已有 的 形容 词 的 收词 情况 , 并 结合 语言 演变 中 新 产生 的 形容 词 , 构建 了 一 个 较为 全面 的 形容 词 词集 ; 其次 是 详细 阐述 知识 库 的 构建 理念 ; 再次 是 具体 阐述 知识 库 的 特征 描述 体系 ; 最后 是 对 该 知识 库 的 应用 场景 进行 展望 。	1<2	joint	joint
nlpabs7_Chi	80-101	102-111	并 结合 语言 演变 中 新 产生 的 形容 词 , 构建 了 一 个 较为 全面 的 形容 词 词集 ;	其次 是 详细 阐述 知识 库 的 构建 理念 ;	69-134	69-134	首先 是 考察 已有 的 形容 词 的 收词 情况 , 并 结合 语言 演变 中 新 产生 的 形容 词 , 构建 了 一 个 较为 全面 的 形容 词 词集 ; 其次 是 详细 阐述 知识 库 的 构建 理念 ; 再次 是 具体 阐述 知识 库 的 特征 描述 体系 ; 最后 是 对 该 知识 库 的 应用 场景 进行 展望 。	首先 是 考察 已有 的 形容 词 的 收词 情况 , 并 结合 语言 演变 中 新 产生 的 形容 词 , 构建 了 一 个 较为 全面 的 形容 词 词集 ; 其次 是 详细 阐述 知识 库 的 构建 理念 ; 再次 是 具体 阐述 知识 库 的 特征 描述 体系 ; 最后 是 对 该 知识 库 的 应用 场景 进行 展望 。	1<2	joint	joint
nlpabs7_Chi	102-111	112-122	其次 是 详细 阐述 知识 库 的 构建 理念 ;	再次 是 具体 阐述 知识 库 的 特征 描述 体系 ;	69-134	69-134	首先 是 考察 已有 的 形容 词 的 收词 情况 , 并 结合 语言 演变 中 新 产生 的 形容 词 , 构建 了 一 个 较为 全面 的 形容 词 词集 ; 其次 是 详细 阐述 知识 库 的 构建 理念 ; 再次 是 具体 阐述 知识 库 的 特征 描述 体系 ; 最后 是 对 该 知识 库 的 应用 场景 进行 展望 。	首先 是 考察 已有 的 形容 词 的 收词 情况 , 并 结合 语言 演变 中 新 产生 的 形容 词 , 构建 了 一 个 较为 全面 的 形容 词 词集 ; 其次 是 详细 阐述 知识 库 的 构建 理念 ; 再次 是 具体 阐述 知识 库 的 特征 描述 体系 ; 最后 是 对 该 知识 库 的 应用 场景 进行 展望 。	1<2	joint	joint
nlpabs7_Chi	112-122	123-134	再次 是 具体 阐述 知识 库 的 特征 描述 体系 ;	最后 是 对 该 知识 库 的 应用 场景 进行 展望 。	69-134	69-134	首先 是 考察 已有 的 形容 词 的 收词 情况 , 并 结合 语言 演变 中 新 产生 的 形容 词 , 构建 了 一 个 较为 全面 的 形容 词 词集 ; 其次 是 详细 阐述 知识 库 的 构建 理念 ; 再次 是 具体 阐述 知识 库 的 特征 描述 体系 ; 最后 是 对 该 知识 库 的 应用 场景 进行 展望 。	首先 是 考察 已有 的 形容 词 的 收词 情况 , 并 结合 语言 演变 中 新 产生 的 形容 词 , 构建 了 一 个 较为 全面 的 形容 词 词集 ; 其次 是 详细 阐述 知识 库 的 构建 理念 ; 再次 是 具体 阐述 知识 库 的 特征 描述 体系 ; 最后 是 对 该 知识 库 的 应用 场景 进行 展望 。	1<2	joint	joint
nlpabs80_Chi	1-21	51-62	神经 网络 机器 翻译 模型 在 蒙古 文 到 汉 文 的 翻译 任务 上 取得 了 很好 的 效果 。	该文 将 先验 信息 融合 到 神经 网络 机器 翻译 中 ,	1-21	51-101	神经 网络 机器 翻译 模型 在 蒙古 文 到 汉 文 的 翻译 任务 上 取得 了 很好 的 效果 。	该文 将 先验 信息 融合 到 神经 网络 机器 翻译 中 , 首先 将 大 规模 单 语 语料 训练 得到 的 词 向量 作 为 翻译 模型 的 初始 词 向量 , 同时 在 词 向量 中 加入 词性 特征 , 从而 缓解 单 词 的 语法 歧义 问题 。	1>2	bg-general	bg-general
nlpabs80_Chi	1-21	22-35	神经 网络 机器 翻译 模型 在 蒙古 文 到 汉 文 的 翻译 任务 上 取得 了 很好 的 效果 。	神经 网络 翻译 模型 仅 利 用 双 语 语料 获得 词 向量 ,	1-21	22-50	神经 网络 机器 翻译 模型 在 蒙古 文 到 汉 文 的 翻译 任务 上 取得 了 很好 的 效果 。	神经 网络 翻译 模型 仅 利 用 双 语 语料 获得 词 向量 , 而 有限 的 双 语 语料 规模 却 限制 了 词 向量 的 表示 。	1<2	elab-addition	elab-addition
nlpabs80_Chi	22-35	36-50	神经 网络 翻译 模型 仅 利 用 双 语 语料 获得 词 向量 ,	而 有限 的 双 语 语料 规模 却 限制 了 词 向量 的 表示 。	22-50	22-50	神经 网络 翻译 模型 仅 利 用 双 语 语料 获得 词 向量 , 而 有限 的 双 语 语料 规模 却 限制 了 词 向量 的 表示 。	神经 网络 翻译 模型 仅 利 用 双 语 语料 获得 词 向量 , 而 有限 的 双 语 语料 规模 却 限制 了 词 向量 的 表示 。	1<2	contrast	contrast
nlpabs80_Chi	51-62	63-83	该文 将 先验 信息 融合 到 神经 网络 机器 翻译 中 ,	首先 将 大 规模 单 语 语料 训练 得到 的 词 向量 作 为 翻译 模型 的 初始 词 向量 ,	51-101	51-101	该文 将 先验 信息 融合 到 神经 网络 机器 翻译 中 , 首先 将 大 规模 单 语 语料 训练 得到 的 词 向量 作 为 翻译 模型 的 初始 词 向量 , 同时 在 词 向量 中 加入 词性 特征 , 从而 缓解 单 词 的 语法 歧义 问题 。	该文 将 先验 信息 融合 到 神经 网络 机器 翻译 中 , 首先 将 大 规模 单 语 语料 训练 得到 的 词 向量 作 为 翻译 模型 的 初始 词 向量 , 同时 在 词 向量 中 加入 词性 特征 , 从而 缓解 单 词 的 语法 歧义 问题 。	1<2	elab-aspect	elab-aspect
nlpabs80_Chi	63-83	84-92	首先 将 大 规模 单 语 语料 训练 得到 的 词 向量 作 为 翻译 模型 的 初始 词 向量 ,	同时 在 词 向量 中 加入 词性 特征 ,	51-101	51-101	该文 将 先验 信息 融合 到 神经 网络 机器 翻译 中 , 首先 将 大 规模 单 语 语料 训练 得到 的 词 向量 作 为 翻译 模型 的 初始 词 向量 , 同时 在 词 向量 中 加入 词性 特征 , 从而 缓解 单 词 的 语法 歧义 问题 。	该文 将 先验 信息 融合 到 神经 网络 机器 翻译 中 , 首先 将 大 规模 单 语 语料 训练 得到 的 词 向量 作 为 翻译 模型 的 初始 词 向量 , 同时 在 词 向量 中 加入 词性 特征 , 从而 缓解 单 词 的 语法 歧义 问题 。	1<2	joint	joint
nlpabs80_Chi	84-92	93-101	同时 在 词 向量 中 加入 词性 特征 ,	从而 缓解 单 词 的 语法 歧义 问题 。	51-101	51-101	该文 将 先验 信息 融合 到 神经 网络 机器 翻译 中 , 首先 将 大 规模 单 语 语料 训练 得到 的 词 向量 作 为 翻译 模型 的 初始 词 向量 , 同时 在 词 向量 中 加入 词性 特征 , 从而 缓解 单 词 的 语法 歧义 问题 。	该文 将 先验 信息 融合 到 神经 网络 机器 翻译 中 , 首先 将 大 规模 单 语 语料 训练 得到 的 词 向量 作 为 翻译 模型 的 初始 词 向量 , 同时 在 词 向量 中 加入 词性 特征 , 从而 缓解 单 词 的 语法 歧义 问题 。	1<2	enablement	enablement
nlpabs80_Chi	102-119	120-126	其次 , 为了 降低 翻译 模型 解码 器 的 计算 复杂 度 以及 模型 的 训练 时间 ,	通常 会 限制 目标 词典 大小 ,	102-135	102-135	其次 , 为了 降低 翻译 模型 解码 器 的 计算 复杂 度 以及 模型 的 训练 时间 , 通常 会 限制 目标 词典 大小 , 这 导致 大量 未 登录 词 的 出现 。	其次 , 为了 降低 翻译 模型 解码 器 的 计算 复杂 度 以及 模型 的 训练 时间 , 通常 会 限制 目标 词典 大小 , 这 导致 大量 未 登录 词 的 出现 。	1>2	enablement	enablement
nlpabs80_Chi	51-62	120-126	该文 将 先验 信息 融合 到 神经 网络 机器 翻译 中 ,	通常 会 限制 目标 词典 大小 ,	51-101	102-135	该文 将 先验 信息 融合 到 神经 网络 机器 翻译 中 , 首先 将 大 规模 单 语 语料 训练 得到 的 词 向量 作 为 翻译 模型 的 初始 词 向量 , 同时 在 词 向量 中 加入 词性 特征 , 从而 缓解 单 词 的 语法 歧义 问题 。	其次 , 为了 降低 翻译 模型 解码 器 的 计算 复杂 度 以及 模型 的 训练 时间 , 通常 会 限制 目标 词典 大小 , 这 导致 大量 未 登录 词 的 出现 。	1<2	elab-aspect	elab-aspect
nlpabs80_Chi	120-126	127-135	通常 会 限制 目标 词典 大小 ,	这 导致 大量 未 登录 词 的 出现 。	102-135	102-135	其次 , 为了 降低 翻译 模型 解码 器 的 计算 复杂 度 以及 模型 的 训练 时间 , 通常 会 限制 目标 词典 大小 , 这 导致 大量 未 登录 词 的 出现 。	其次 , 为了 降低 翻译 模型 解码 器 的 计算 复杂 度 以及 模型 的 训练 时间 , 通常 会 限制 目标 词典 大小 , 这 导致 大量 未 登录 词 的 出现 。	1<2	result	result
nlpabs80_Chi	51-62	136-145	该文 将 先验 信息 融合 到 神经 网络 机器 翻译 中 ,	该 文 利 用 加入 词性 特征 的 词 向量	51-101	136-176	该文 将 先验 信息 融合 到 神经 网络 机器 翻译 中 , 首先 将 大 规模 单 语 语料 训练 得到 的 词 向量 作 为 翻译 模型 的 初始 词 向量 , 同时 在 词 向量 中 加入 词性 特征 , 从而 缓解 单 词 的 语法 歧义 问题 。	该 文 利 用 加入 词性 特征 的 词 向量 计算 单 词 之间 的 相似 度 , 将 未 登录 词用 目标 词典 中 与 之 最 相近 的 单 词 替换 , 以 缓解 未 登录 词 问题 。	1<2	elab-aspect	elab-aspect
nlpabs80_Chi	136-145	146-153	该 文 利 用 加入 词性 特征 的 词 向量	计算 单 词 之间 的 相似 度 ,	136-176	136-176	该 文 利 用 加入 词性 特征 的 词 向量 计算 单 词 之间 的 相似 度 , 将 未 登录 词用 目标 词典 中 与 之 最 相近 的 单 词 替换 , 以 缓解 未 登录 词 问题 。	该 文 利 用 加入 词性 特征 的 词 向量 计算 单 词 之间 的 相似 度 , 将 未 登录 词用 目标 词典 中 与 之 最 相近 的 单 词 替换 , 以 缓解 未 登录 词 问题 。	1<2	elab-addition	elab-addition
nlpabs80_Chi	136-145	154-169	该 文 利 用 加入 词性 特征 的 词 向量	将 未 登录 词用 目标 词典 中 与 之 最 相近 的 单 词 替换 ,	136-176	136-176	该 文 利 用 加入 词性 特征 的 词 向量 计算 单 词 之间 的 相似 度 , 将 未 登录 词用 目标 词典 中 与 之 最 相近 的 单 词 替换 , 以 缓解 未 登录 词 问题 。	该 文 利 用 加入 词性 特征 的 词 向量 计算 单 词 之间 的 相似 度 , 将 未 登录 词用 目标 词典 中 与 之 最 相近 的 单 词 替换 , 以 缓解 未 登录 词 问题 。	1<2	joint	joint
nlpabs80_Chi	154-169	170-176	将 未 登录 词用 目标 词典 中 与 之 最 相近 的 单 词 替换 ,	以 缓解 未 登录 词 问题 。	136-176	136-176	该 文 利 用 加入 词性 特征 的 词 向量 计算 单 词 之间 的 相似 度 , 将 未 登录 词用 目标 词典 中 与 之 最 相近 的 单 词 替换 , 以 缓解 未 登录 词 问题 。	该 文 利 用 加入 词性 特征 的 词 向量 计算 单 词 之间 的 相似 度 , 将 未 登录 词用 目标 词典 中 与 之 最 相近 的 单 词 替换 , 以 缓解 未 登录 词 问题 。	1<2	enablement	enablement
nlpabs80_Chi	177-179	180-201	最终 实验 显示	在 蒙古 文 到 汉 文 的 翻译 任务 上 将 译文 的 BLEU 值 提高 了 2.68 个 BLEU 点 。	177-201	177-201	最终 实验 显示 在 蒙古 文 到 汉 文 的 翻译 任务 上 将 译文 的 BLEU 值 提高 了 2.68 个 BLEU 点 。	最终 实验 显示 在 蒙古 文 到 汉 文 的 翻译 任务 上 将 译文 的 BLEU 值 提高 了 2.68 个 BLEU 点 。	1>2	attribution	attribution
nlpabs80_Chi	51-62	180-201	该文 将 先验 信息 融合 到 神经 网络 机器 翻译 中 ,	在 蒙古 文 到 汉 文 的 翻译 任务 上 将 译文 的 BLEU 值 提高 了 2.68 个 BLEU 点 。	51-101	177-201	该文 将 先验 信息 融合 到 神经 网络 机器 翻译 中 , 首先 将 大 规模 单 语 语料 训练 得到 的 词 向量 作 为 翻译 模型 的 初始 词 向量 , 同时 在 词 向量 中 加入 词性 特征 , 从而 缓解 单 词 的 语法 歧义 问题 。	最终 实验 显示 在 蒙古 文 到 汉 文 的 翻译 任务 上 将 译文 的 BLEU 值 提高 了 2.68 个 BLEU 点 。	1<2	evaluation	evaluation
nlpabs81_Chi	1-7	8-19	蒙古 语 属 于 小 语种 ,	蒙古 语 到 汉 语 机器 翻译 相关 研究 进展 缓慢 。	1-19	1-19	蒙古 语 属 于 小 语种 , 蒙古 语 到 汉 语 机器 翻译 相关 研究 进展 缓慢 。	蒙古 语 属 于 小 语种 , 蒙古 语 到 汉 语 机器 翻译 相关 研究 进展 缓慢 。	1>2	exp-reason	exp-reason
nlpabs81_Chi	8-19	20-41	蒙古 语 到 汉 语 机器 翻译 相关 研究 进展 缓慢 。	所以 , 实现 高 质量 的 蒙汉 机器 翻译 对 我国 少数 民族 地区 信息 化 发展 有 着重 要 意义 。	1-19	20-41	蒙古 语 属 于 小 语种 , 蒙古 语 到 汉 语 机器 翻译 相关 研究 进展 缓慢 。	所以 , 实现 高 质量 的 蒙汉 机器 翻译 对 我国 少数 民族 地区 信息 化 发展 有 着重 要 意义 。	1>2	exp-reason	exp-reason
nlpabs81_Chi	20-41	56-79	所以 , 实现 高 质量 的 蒙汉 机器 翻译 对 我国 少数 民族 地区 信息 化 发展 有 着重 要 意义 。	该文 提出 了 一 种 基 于 蒙古 语 切分 的 词干 词缀 为 基本 单位 的 蒙汉 机器 翻译 词对 齐 方法 。	20-41	56-79	所以 , 实现 高 质量 的 蒙汉 机器 翻译 对 我国 少数 民族 地区 信息 化 发展 有 着重 要 意义 。	该文 提出 了 一 种 基 于 蒙古 语 切分 的 词干 词缀 为 基本 单位 的 蒙汉 机器 翻译 词对 齐 方法 。	1>2	bg-general	bg-general
nlpabs81_Chi	20-41	42-55	所以 , 实现 高 质量 的 蒙汉 机器 翻译 对 我国 少数 民族 地区 信息 化 发展 有 着重 要 意义 。	其中 , 词语 对齐 对 机器 翻译 质量 起 着 至关重要 的 作用 。	20-41	42-55	所以 , 实现 高 质量 的 蒙汉 机器 翻译 对 我国 少数 民族 地区 信息 化 发展 有 着重 要 意义 。	其中 , 词语 对齐 对 机器 翻译 质量 起 着 至关重要 的 作用 。	1<2	elab-addition	elab-addition
nlpabs81_Chi	56-79	80-90	该文 提出 了 一 种 基 于 蒙古 语 切分 的 词干 词缀 为 基本 单位 的 蒙汉 机器 翻译 词对 齐 方法 。	该 方法 利用 词干 词缀 表 和 逆向 最大匹 配算 法	56-79	80-99	该文 提出 了 一 种 基 于 蒙古 语 切分 的 词干 词缀 为 基本 单位 的 蒙汉 机器 翻译 词对 齐 方法 。	该 方法 利用 词干 词缀 表 和 逆向 最大匹 配算 法 来 实现 蒙古 语句子 词干 词缀 的 切分 。	1<2	elab-addition	elab-addition
nlpabs81_Chi	80-90	91-99	该 方法 利用 词干 词缀 表 和 逆向 最大匹 配算 法	来 实现 蒙古 语句子 词干 词缀 的 切分 。	80-99	80-99	该 方法 利用 词干 词缀 表 和 逆向 最大匹 配算 法 来 实现 蒙古 语句子 词干 词缀 的 切分 。	该 方法 利用 词干 词缀 表 和 逆向 最大匹 配算 法 来 实现 蒙古 语句子 词干 词缀 的 切分 。	1<2	enablement	enablement
nlpabs81_Chi	100-102	103-122	实验 结果 表明	对 蒙古 语 进行 词干 词缀 的 切分 能够 显著 提高 对数 线性 词对 齐 模型 的 对齐 质量 。	100-122	100-122	实验 结果 表明 对 蒙古 语 进行 词干 词缀 的 切分 能够 显著 提高 对数 线性 词对 齐 模型 的 对齐 质量 。	实验 结果 表明 对 蒙古 语 进行 词干 词缀 的 切分 能够 显著 提高 对数 线性 词对 齐 模型 的 对齐 质量 。	1>2	attribution	attribution
nlpabs81_Chi	56-79	103-122	该文 提出 了 一 种 基 于 蒙古 语 切分 的 词干 词缀 为 基本 单位 的 蒙汉 机器 翻译 词对 齐 方法 。	对 蒙古 语 进行 词干 词缀 的 切分 能够 显著 提高 对数 线性 词对 齐 模型 的 对齐 质量 。	56-79	100-122	该文 提出 了 一 种 基 于 蒙古 语 切分 的 词干 词缀 为 基本 单位 的 蒙汉 机器 翻译 词对 齐 方法 。	实验 结果 表明 对 蒙古 语 进行 词干 词缀 的 切分 能够 显著 提高 对数 线性 词对 齐 模型 的 对齐 质量 。	1<2	evaluation	evaluation
nlpabs82_Chi	1-9	10-48	结合 对 维吾尔 语 语言 的 特点 分析 ,	该文 提出 一 种 基 于 深度 卷积 神经 网络 ( deep convolutional neural networks , DCNNs ) 联合 长短期 记忆 网络 ( long-short term memory , LSTM ) 实现 的 维吾尔 语文 本 突发 事件 识别 方法 。	1-48	1-48	结合 对 维吾尔 语 语言 的 特点 分析 , 该文 提出 一 种 基 于 深度 卷积 神经 网络 ( deep convolutional neural networks , DCNNs ) 联合 长短期 记忆 网络 ( long-short term memory , LSTM ) 实现 的 维吾尔 语文 本 突发 事件 识别 方法 。	结合 对 维吾尔 语 语言 的 特点 分析 , 该文 提出 一 种 基 于 深度 卷积 神经 网络 ( deep convolutional neural networks , DCNNs ) 联合 长短期 记忆 网络 ( long-short term memory , LSTM ) 实现 的 维吾尔 语文 本 突发 事件 识别 方法 。	1>2	bg-general	bg-general
nlpabs82_Chi	10-48	49-59	该文 提出 一 种 基 于 深度 卷积 神经 网络 ( deep convolutional neural networks , DCNNs ) 联合 长短期 记忆 网络 ( long-short term memory , LSTM ) 实现 的 维吾尔 语文 本 突发 事件 识别 方法 。	该 方法 提取 突发 事件 包含 六 大 特征 块 ,	1-48	49-138	结合 对 维吾尔 语 语言 的 特点 分析 , 该文 提出 一 种 基 于 深度 卷积 神经 网络 ( deep convolutional neural networks , DCNNs ) 联合 长短期 记忆 网络 ( long-short term memory , LSTM ) 实现 的 维吾尔 语文 本 突发 事件 识别 方法 。	该 方法 提取 突发 事件 包含 六 大 特征 块 , 并 在 特征 集 中 引入 富含 词汇 语义 及 上下 文位 置 关系 的 Word Embedding , 利用 DCNNs 对 黏着 性 语言 特征 抽象 化 的 学习 能力 抽取 事件 句 中 的 高阶 局部 特征 , 以 此 作 为 LSTM 网络 的 输入 , 利用 其 对于 事件 句 中 抽象 含义 序列 关系 的 捕获 特性 获取 全局 特征 , 训练 Softma x 分 类器 完成 维吾尔 语 突发 事件 的 识别 任务 。	1<2	elab-addition	elab-addition
nlpabs82_Chi	49-59	60-77	该 方法 提取 突发 事件 包含 六 大 特征 块 ,	并 在 特征 集 中 引入 富含 词汇 语义 及 上下 文位 置 关系 的 Word Embedding ,	49-138	49-138	该 方法 提取 突发 事件 包含 六 大 特征 块 , 并 在 特征 集 中 引入 富含 词汇 语义 及 上下 文位 置 关系 的 Word Embedding , 利用 DCNNs 对 黏着 性 语言 特征 抽象 化 的 学习 能力 抽取 事件 句 中 的 高阶 局部 特征 , 以 此 作 为 LSTM 网络 的 输入 , 利用 其 对于 事件 句 中 抽象 含义 序列 关系 的 捕获 特性 获取 全局 特征 , 训练 Softma x 分 类器 完成 维吾尔 语 突发 事件 的 识别 任务 。	该 方法 提取 突发 事件 包含 六 大 特征 块 , 并 在 特征 集 中 引入 富含 词汇 语义 及 上下 文位 置 关系 的 Word Embedding , 利用 DCNNs 对 黏着 性 语言 特征 抽象 化 的 学习 能力 抽取 事件 句 中 的 高阶 局部 特征 , 以 此 作 为 LSTM 网络 的 输入 , 利用 其 对于 事件 句 中 抽象 含义 序列 关系 的 捕获 特性 获取 全局 特征 , 训练 Softma x 分 类器 完成 维吾尔 语 突发 事件 的 识别 任务 。	1<2	joint	joint
nlpabs82_Chi	49-59	78-79	该 方法 提取 突发 事件 包含 六 大 特征 块 ,	利用 DCNNs	49-138	49-138	该 方法 提取 突发 事件 包含 六 大 特征 块 , 并 在 特征 集 中 引入 富含 词汇 语义 及 上下 文位 置 关系 的 Word Embedding , 利用 DCNNs 对 黏着 性 语言 特征 抽象 化 的 学习 能力 抽取 事件 句 中 的 高阶 局部 特征 , 以 此 作 为 LSTM 网络 的 输入 , 利用 其 对于 事件 句 中 抽象 含义 序列 关系 的 捕获 特性 获取 全局 特征 , 训练 Softma x 分 类器 完成 维吾尔 语 突发 事件 的 识别 任务 。	该 方法 提取 突发 事件 包含 六 大 特征 块 , 并 在 特征 集 中 引入 富含 词汇 语义 及 上下 文位 置 关系 的 Word Embedding , 利用 DCNNs 对 黏着 性 语言 特征 抽象 化 的 学习 能力 抽取 事件 句 中 的 高阶 局部 特征 , 以 此 作 为 LSTM 网络 的 输入 , 利用 其 对于 事件 句 中 抽象 含义 序列 关系 的 捕获 特性 获取 全局 特征 , 训练 Softma x 分 类器 完成 维吾尔 语 突发 事件 的 识别 任务 。	1<2	joint	joint
nlpabs82_Chi	78-79	80-98	利用 DCNNs	对 黏着 性 语言 特征 抽象 化 的 学习 能力 抽取 事件 句 中 的 高阶 局部 特征 ,	49-138	49-138	该 方法 提取 突发 事件 包含 六 大 特征 块 , 并 在 特征 集 中 引入 富含 词汇 语义 及 上下 文位 置 关系 的 Word Embedding , 利用 DCNNs 对 黏着 性 语言 特征 抽象 化 的 学习 能力 抽取 事件 句 中 的 高阶 局部 特征 , 以 此 作 为 LSTM 网络 的 输入 , 利用 其 对于 事件 句 中 抽象 含义 序列 关系 的 捕获 特性 获取 全局 特征 , 训练 Softma x 分 类器 完成 维吾尔 语 突发 事件 的 识别 任务 。	该 方法 提取 突发 事件 包含 六 大 特征 块 , 并 在 特征 集 中 引入 富含 词汇 语义 及 上下 文位 置 关系 的 Word Embedding , 利用 DCNNs 对 黏着 性 语言 特征 抽象 化 的 学习 能力 抽取 事件 句 中 的 高阶 局部 特征 , 以 此 作 为 LSTM 网络 的 输入 , 利用 其 对于 事件 句 中 抽象 含义 序列 关系 的 捕获 特性 获取 全局 特征 , 训练 Softma x 分 类器 完成 维吾尔 语 突发 事件 的 识别 任务 。	1<2	enablement	enablement
nlpabs82_Chi	80-98	99-107	对 黏着 性 语言 特征 抽象 化 的 学习 能力 抽取 事件 句 中 的 高阶 局部 特征 ,	以 此 作 为 LSTM 网络 的 输入 ,	49-138	49-138	该 方法 提取 突发 事件 包含 六 大 特征 块 , 并 在 特征 集 中 引入 富含 词汇 语义 及 上下 文位 置 关系 的 Word Embedding , 利用 DCNNs 对 黏着 性 语言 特征 抽象 化 的 学习 能力 抽取 事件 句 中 的 高阶 局部 特征 , 以 此 作 为 LSTM 网络 的 输入 , 利用 其 对于 事件 句 中 抽象 含义 序列 关系 的 捕获 特性 获取 全局 特征 , 训练 Softma x 分 类器 完成 维吾尔 语 突发 事件 的 识别 任务 。	该 方法 提取 突发 事件 包含 六 大 特征 块 , 并 在 特征 集 中 引入 富含 词汇 语义 及 上下 文位 置 关系 的 Word Embedding , 利用 DCNNs 对 黏着 性 语言 特征 抽象 化 的 学习 能力 抽取 事件 句 中 的 高阶 局部 特征 , 以 此 作 为 LSTM 网络 的 输入 , 利用 其 对于 事件 句 中 抽象 含义 序列 关系 的 捕获 特性 获取 全局 特征 , 训练 Softma x 分 类器 完成 维吾尔 语 突发 事件 的 识别 任务 。	1<2	elab-addition	elab-addition
nlpabs82_Chi	49-59	108-124	该 方法 提取 突发 事件 包含 六 大 特征 块 ,	利用 其 对于 事件 句 中 抽象 含义 序列 关系 的 捕获 特性 获取 全局 特征 ,	49-138	49-138	该 方法 提取 突发 事件 包含 六 大 特征 块 , 并 在 特征 集 中 引入 富含 词汇 语义 及 上下 文位 置 关系 的 Word Embedding , 利用 DCNNs 对 黏着 性 语言 特征 抽象 化 的 学习 能力 抽取 事件 句 中 的 高阶 局部 特征 , 以 此 作 为 LSTM 网络 的 输入 , 利用 其 对于 事件 句 中 抽象 含义 序列 关系 的 捕获 特性 获取 全局 特征 , 训练 Softma x 分 类器 完成 维吾尔 语 突发 事件 的 识别 任务 。	该 方法 提取 突发 事件 包含 六 大 特征 块 , 并 在 特征 集 中 引入 富含 词汇 语义 及 上下 文位 置 关系 的 Word Embedding , 利用 DCNNs 对 黏着 性 语言 特征 抽象 化 的 学习 能力 抽取 事件 句 中 的 高阶 局部 特征 , 以 此 作 为 LSTM 网络 的 输入 , 利用 其 对于 事件 句 中 抽象 含义 序列 关系 的 捕获 特性 获取 全局 特征 , 训练 Softma x 分 类器 完成 维吾尔 语 突发 事件 的 识别 任务 。	1<2	joint	joint
nlpabs82_Chi	108-124	125-138	利用 其 对于 事件 句 中 抽象 含义 序列 关系 的 捕获 特性 获取 全局 特征 ,	训练 Softma x 分 类器 完成 维吾尔 语 突发 事件 的 识别 任务 。	49-138	49-138	该 方法 提取 突发 事件 包含 六 大 特征 块 , 并 在 特征 集 中 引入 富含 词汇 语义 及 上下 文位 置 关系 的 Word Embedding , 利用 DCNNs 对 黏着 性 语言 特征 抽象 化 的 学习 能力 抽取 事件 句 中 的 高阶 局部 特征 , 以 此 作 为 LSTM 网络 的 输入 , 利用 其 对于 事件 句 中 抽象 含义 序列 关系 的 捕获 特性 获取 全局 特征 , 训练 Softma x 分 类器 完成 维吾尔 语 突发 事件 的 识别 任务 。	该 方法 提取 突发 事件 包含 六 大 特征 块 , 并 在 特征 集 中 引入 富含 词汇 语义 及 上下 文位 置 关系 的 Word Embedding , 利用 DCNNs 对 黏着 性 语言 特征 抽象 化 的 学习 能力 抽取 事件 句 中 的 高阶 局部 特征 , 以 此 作 为 LSTM 网络 的 输入 , 利用 其 对于 事件 句 中 抽象 含义 序列 关系 的 捕获 特性 获取 全局 特征 , 训练 Softma x 分 类器 完成 维吾尔 语 突发 事件 的 识别 任务 。	1<2	enablement	enablement
nlpabs82_Chi	10-48	139-160	该文 提出 一 种 基 于 深度 卷积 神经 网络 ( deep convolutional neural networks , DCNNs ) 联合 长短期 记忆 网络 ( long-short term memory , LSTM ) 实现 的 维吾尔 语文 本 突发 事件 识别 方法 。	该 方法 在 维吾尔 语 突发 事件 识别 中 的 准确 率 达到 80.60% , 召回 率 81.39% , F值 80.99% 。	1-48	139-160	结合 对 维吾尔 语 语言 的 特点 分析 , 该文 提出 一 种 基 于 深度 卷积 神经 网络 ( deep convolutional neural networks , DCNNs ) 联合 长短期 记忆 网络 ( long-short term memory , LSTM ) 实现 的 维吾尔 语文 本 突发 事件 识别 方法 。	该 方法 在 维吾尔 语 突发 事件 识别 中 的 准确 率 达到 80.60% , 召回 率 81.39% , F值 80.99% 。	1<2	evaluation	evaluation
nlpabs82_Chi	161-164	177-189	实验 结果 表明 ,	DCNNs-LSTM 模型 更 具备 挖掘 隐含 上下文 深层 语义 信息 的 能力 ,	161-204	161-204	实验 结果 表明 , 与 不同 层数 的 DCNNs 和 独立 的 LSTM 网络 相比 , DCNNs-LSTM 模型 更 具备 挖掘 隐含 上下文 深层 语义 信息 的 能力 , 对 Word Embedding 特征 项 的 引入 有效 地 提高 了 模型 识别 性能 。	实验 结果 表明 , 与 不同 层数 的 DCNNs 和 独立 的 LSTM 网络 相比 , DCNNs-LSTM 模型 更 具备 挖掘 隐含 上下文 深层 语义 信息 的 能力 , 对 Word Embedding 特征 项 的 引入 有效 地 提高 了 模型 识别 性能 。	1>2	attribution	attribution
nlpabs82_Chi	165-176	177-189	与 不同 层数 的 DCNNs 和 独立 的 LSTM 网络 相比 ,	DCNNs-LSTM 模型 更 具备 挖掘 隐含 上下文 深层 语义 信息 的 能力 ,	161-204	161-204	实验 结果 表明 , 与 不同 层数 的 DCNNs 和 独立 的 LSTM 网络 相比 , DCNNs-LSTM 模型 更 具备 挖掘 隐含 上下文 深层 语义 信息 的 能力 , 对 Word Embedding 特征 项 的 引入 有效 地 提高 了 模型 识别 性能 。	实验 结果 表明 , 与 不同 层数 的 DCNNs 和 独立 的 LSTM 网络 相比 , DCNNs-LSTM 模型 更 具备 挖掘 隐含 上下文 深层 语义 信息 的 能力 , 对 Word Embedding 特征 项 的 引入 有效 地 提高 了 模型 识别 性能 。	1>2	comparison	comparison
nlpabs82_Chi	10-48	177-189	该文 提出 一 种 基 于 深度 卷积 神经 网络 ( deep convolutional neural networks , DCNNs ) 联合 长短期 记忆 网络 ( long-short term memory , LSTM ) 实现 的 维吾尔 语文 本 突发 事件 识别 方法 。	DCNNs-LSTM 模型 更 具备 挖掘 隐含 上下文 深层 语义 信息 的 能力 ,	1-48	161-204	结合 对 维吾尔 语 语言 的 特点 分析 , 该文 提出 一 种 基 于 深度 卷积 神经 网络 ( deep convolutional neural networks , DCNNs ) 联合 长短期 记忆 网络 ( long-short term memory , LSTM ) 实现 的 维吾尔 语文 本 突发 事件 识别 方法 。	实验 结果 表明 , 与 不同 层数 的 DCNNs 和 独立 的 LSTM 网络 相比 , DCNNs-LSTM 模型 更 具备 挖掘 隐含 上下文 深层 语义 信息 的 能力 , 对 Word Embedding 特征 项 的 引入 有效 地 提高 了 模型 识别 性能 。	1<2	evaluation	evaluation
nlpabs82_Chi	177-189	190-204	DCNNs-LSTM 模型 更 具备 挖掘 隐含 上下文 深层 语义 信息 的 能力 ,	对 Word Embedding 特征 项 的 引入 有效 地 提高 了 模型 识别 性能 。	161-204	161-204	实验 结果 表明 , 与 不同 层数 的 DCNNs 和 独立 的 LSTM 网络 相比 , DCNNs-LSTM 模型 更 具备 挖掘 隐含 上下文 深层 语义 信息 的 能力 , 对 Word Embedding 特征 项 的 引入 有效 地 提高 了 模型 识别 性能 。	实验 结果 表明 , 与 不同 层数 的 DCNNs 和 独立 的 LSTM 网络 相比 , DCNNs-LSTM 模型 更 具备 挖掘 隐含 上下文 深层 语义 信息 的 能力 , 对 Word Embedding 特征 项 的 引入 有效 地 提高 了 模型 识别 性能 。	1<2	elab-addition	elab-addition
nlpabs83_Chi	1-9	59-73	音节 是 缅甸 语 的 最小 构词 单位 。	该文 提出 一 种 基 于 卷积 神经 网络 的 缅甸 语 分词 方法 ,	1-9	59-153	音节 是 缅甸 语 的 最小 构词 单位 。	该文 提出 一 种 基 于 卷积 神经 网络 的 缅甸 语 分词 方法 , 首先 将 缅甸 语 音节 结构 特征 应用 于 缅甸 语 音节 词 向量 特征 分布 式 表示 , 然后 基 于 卷积 神经 网络 将 音节 及 其 上 下文 的 特征 进行 融合 , 得到 有效 的 特征 表示 , 并 通过 深层 网络 的 逐层 特征 优化 自 动 学习 到 缅甸 语 分词 的 有效 特征 向量 , 最后 利用 softmax 分类 器 来 对 构成 缅甸 语 词汇 的 音节 序列 标记 进行 预测 。	1>2	bg-general	bg-general
nlpabs83_Chi	1-9	10-37	音节 是 缅甸 语 的 最小 构词 单位 。	当前 主流 的 基 于 统计 的 分词 方法 效果 严重 依赖 于 预先 标注 的 训练 样本 集 规模 及 人工 方式 选取 特征 的 质量 ,	1-9	10-58	音节 是 缅甸 语 的 最小 构词 单位 。	当前 主流 的 基 于 统计 的 分词 方法 效果 严重 依赖 于 预先 标注 的 训练 样本 集 规模 及 人工 方式 选取 特征 的 质量 , 然而 , 缅甸 语 属 于 稀缺 资源 语言 , 分词 语料 标注 及 特征 选取 面临 较 大 困难 。	1<2	elab-addition	elab-addition
nlpabs83_Chi	10-37	38-47	当前 主流 的 基 于 统计 的 分词 方法 效果 严重 依赖 于 预先 标注 的 训练 样本 集 规模 及 人工 方式 选取 特征 的 质量 ,	然而 , 缅甸 语 属 于 稀缺 资源 语言 ,	10-58	10-58	当前 主流 的 基 于 统计 的 分词 方法 效果 严重 依赖 于 预先 标注 的 训练 样本 集 规模 及 人工 方式 选取 特征 的 质量 , 然而 , 缅甸 语 属 于 稀缺 资源 语言 , 分词 语料 标注 及 特征 选取 面临 较 大 困难 。	当前 主流 的 基 于 统计 的 分词 方法 效果 严重 依赖 于 预先 标注 的 训练 样本 集 规模 及 人工 方式 选取 特征 的 质量 , 然而 , 缅甸 语 属 于 稀缺 资源 语言 , 分词 语料 标注 及 特征 选取 面临 较 大 困难 。	1<2	contrast	contrast
nlpabs83_Chi	38-47	48-58	然而 , 缅甸 语 属 于 稀缺 资源 语言 ,	分词 语料 标注 及 特征 选取 面临 较 大 困难 。	10-58	10-58	当前 主流 的 基 于 统计 的 分词 方法 效果 严重 依赖 于 预先 标注 的 训练 样本 集 规模 及 人工 方式 选取 特征 的 质量 , 然而 , 缅甸 语 属 于 稀缺 资源 语言 , 分词 语料 标注 及 特征 选取 面临 较 大 困难 。	当前 主流 的 基 于 统计 的 分词 方法 效果 严重 依赖 于 预先 标注 的 训练 样本 集 规模 及 人工 方式 选取 特征 的 质量 , 然而 , 缅甸 语 属 于 稀缺 资源 语言 , 分词 语料 标注 及 特征 选取 面临 较 大 困难 。	1<2	result	result
nlpabs83_Chi	59-73	74-92	该文 提出 一 种 基 于 卷积 神经 网络 的 缅甸 语 分词 方法 ,	首先 将 缅甸 语 音节 结构 特征 应用 于 缅甸 语 音节 词 向量 特征 分布 式 表示 ,	59-153	59-153	该文 提出 一 种 基 于 卷积 神经 网络 的 缅甸 语 分词 方法 , 首先 将 缅甸 语 音节 结构 特征 应用 于 缅甸 语 音节 词 向量 特征 分布 式 表示 , 然后 基 于 卷积 神经 网络 将 音节 及 其 上 下文 的 特征 进行 融合 , 得到 有效 的 特征 表示 , 并 通过 深层 网络 的 逐层 特征 优化 自 动 学习 到 缅甸 语 分词 的 有效 特征 向量 , 最后 利用 softmax 分类 器 来 对 构成 缅甸 语 词汇 的 音节 序列 标记 进行 预测 。	该文 提出 一 种 基 于 卷积 神经 网络 的 缅甸 语 分词 方法 , 首先 将 缅甸 语 音节 结构 特征 应用 于 缅甸 语 音节 词 向量 特征 分布 式 表示 , 然后 基 于 卷积 神经 网络 将 音节 及 其 上 下文 的 特征 进行 融合 , 得到 有效 的 特征 表示 , 并 通过 深层 网络 的 逐层 特征 优化 自 动 学习 到 缅甸 语 分词 的 有效 特征 向量 , 最后 利用 softmax 分类 器 来 对 构成 缅甸 语 词汇 的 音节 序列 标记 进行 预测 。	1<2	elab-process_step	elab-process_step
nlpabs83_Chi	74-92	93-109	首先 将 缅甸 语 音节 结构 特征 应用 于 缅甸 语 音节 词 向量 特征 分布 式 表示 ,	然后 基 于 卷积 神经 网络 将 音节 及 其 上 下文 的 特征 进行 融合 ,	59-153	59-153	该文 提出 一 种 基 于 卷积 神经 网络 的 缅甸 语 分词 方法 , 首先 将 缅甸 语 音节 结构 特征 应用 于 缅甸 语 音节 词 向量 特征 分布 式 表示 , 然后 基 于 卷积 神经 网络 将 音节 及 其 上 下文 的 特征 进行 融合 , 得到 有效 的 特征 表示 , 并 通过 深层 网络 的 逐层 特征 优化 自 动 学习 到 缅甸 语 分词 的 有效 特征 向量 , 最后 利用 softmax 分类 器 来 对 构成 缅甸 语 词汇 的 音节 序列 标记 进行 预测 。	该文 提出 一 种 基 于 卷积 神经 网络 的 缅甸 语 分词 方法 , 首先 将 缅甸 语 音节 结构 特征 应用 于 缅甸 语 音节 词 向量 特征 分布 式 表示 , 然后 基 于 卷积 神经 网络 将 音节 及 其 上 下文 的 特征 进行 融合 , 得到 有效 的 特征 表示 , 并 通过 深层 网络 的 逐层 特征 优化 自 动 学习 到 缅甸 语 分词 的 有效 特征 向量 , 最后 利用 softmax 分类 器 来 对 构成 缅甸 语 词汇 的 音节 序列 标记 进行 预测 。	1<2	joint	joint
nlpabs83_Chi	93-109	110-115	然后 基 于 卷积 神经 网络 将 音节 及 其 上 下文 的 特征 进行 融合 ,	得到 有效 的 特征 表示 ,	59-153	59-153	该文 提出 一 种 基 于 卷积 神经 网络 的 缅甸 语 分词 方法 , 首先 将 缅甸 语 音节 结构 特征 应用 于 缅甸 语 音节 词 向量 特征 分布 式 表示 , 然后 基 于 卷积 神经 网络 将 音节 及 其 上 下文 的 特征 进行 融合 , 得到 有效 的 特征 表示 , 并 通过 深层 网络 的 逐层 特征 优化 自 动 学习 到 缅甸 语 分词 的 有效 特征 向量 , 最后 利用 softmax 分类 器 来 对 构成 缅甸 语 词汇 的 音节 序列 标记 进行 预测 。	该文 提出 一 种 基 于 卷积 神经 网络 的 缅甸 语 分词 方法 , 首先 将 缅甸 语 音节 结构 特征 应用 于 缅甸 语 音节 词 向量 特征 分布 式 表示 , 然后 基 于 卷积 神经 网络 将 音节 及 其 上 下文 的 特征 进行 融合 , 得到 有效 的 特征 表示 , 并 通过 深层 网络 的 逐层 特征 优化 自 动 学习 到 缅甸 语 分词 的 有效 特征 向量 , 最后 利用 softmax 分类 器 来 对 构成 缅甸 语 词汇 的 音节 序列 标记 进行 预测 。	1<2	enablement	enablement
nlpabs83_Chi	93-109	116-135	然后 基 于 卷积 神经 网络 将 音节 及 其 上 下文 的 特征 进行 融合 ,	并 通过 深层 网络 的 逐层 特征 优化 自 动 学习 到 缅甸 语 分词 的 有效 特征 向量 ,	59-153	59-153	该文 提出 一 种 基 于 卷积 神经 网络 的 缅甸 语 分词 方法 , 首先 将 缅甸 语 音节 结构 特征 应用 于 缅甸 语 音节 词 向量 特征 分布 式 表示 , 然后 基 于 卷积 神经 网络 将 音节 及 其 上 下文 的 特征 进行 融合 , 得到 有效 的 特征 表示 , 并 通过 深层 网络 的 逐层 特征 优化 自 动 学习 到 缅甸 语 分词 的 有效 特征 向量 , 最后 利用 softmax 分类 器 来 对 构成 缅甸 语 词汇 的 音节 序列 标记 进行 预测 。	该文 提出 一 种 基 于 卷积 神经 网络 的 缅甸 语 分词 方法 , 首先 将 缅甸 语 音节 结构 特征 应用 于 缅甸 语 音节 词 向量 特征 分布 式 表示 , 然后 基 于 卷积 神经 网络 将 音节 及 其 上 下文 的 特征 进行 融合 , 得到 有效 的 特征 表示 , 并 通过 深层 网络 的 逐层 特征 优化 自 动 学习 到 缅甸 语 分词 的 有效 特征 向量 , 最后 利用 softmax 分类 器 来 对 构成 缅甸 语 词汇 的 音节 序列 标记 进行 预测 。	1<2	joint	joint
nlpabs83_Chi	93-109	136-140	然后 基 于 卷积 神经 网络 将 音节 及 其 上 下文 的 特征 进行 融合 ,	最后 利用 softmax 分类 器	59-153	59-153	该文 提出 一 种 基 于 卷积 神经 网络 的 缅甸 语 分词 方法 , 首先 将 缅甸 语 音节 结构 特征 应用 于 缅甸 语 音节 词 向量 特征 分布 式 表示 , 然后 基 于 卷积 神经 网络 将 音节 及 其 上 下文 的 特征 进行 融合 , 得到 有效 的 特征 表示 , 并 通过 深层 网络 的 逐层 特征 优化 自 动 学习 到 缅甸 语 分词 的 有效 特征 向量 , 最后 利用 softmax 分类 器 来 对 构成 缅甸 语 词汇 的 音节 序列 标记 进行 预测 。	该文 提出 一 种 基 于 卷积 神经 网络 的 缅甸 语 分词 方法 , 首先 将 缅甸 语 音节 结构 特征 应用 于 缅甸 语 音节 词 向量 特征 分布 式 表示 , 然后 基 于 卷积 神经 网络 将 音节 及 其 上 下文 的 特征 进行 融合 , 得到 有效 的 特征 表示 , 并 通过 深层 网络 的 逐层 特征 优化 自 动 学习 到 缅甸 语 分词 的 有效 特征 向量 , 最后 利用 softmax 分类 器 来 对 构成 缅甸 语 词汇 的 音节 序列 标记 进行 预测 。	1<2	joint	joint
nlpabs83_Chi	136-140	141-153	最后 利用 softmax 分类 器	来 对 构成 缅甸 语 词汇 的 音节 序列 标记 进行 预测 。	59-153	59-153	该文 提出 一 种 基 于 卷积 神经 网络 的 缅甸 语 分词 方法 , 首先 将 缅甸 语 音节 结构 特征 应用 于 缅甸 语 音节 词 向量 特征 分布 式 表示 , 然后 基 于 卷积 神经 网络 将 音节 及 其 上 下文 的 特征 进行 融合 , 得到 有效 的 特征 表示 , 并 通过 深层 网络 的 逐层 特征 优化 自 动 学习 到 缅甸 语 分词 的 有效 特征 向量 , 最后 利用 softmax 分类 器 来 对 构成 缅甸 语 词汇 的 音节 序列 标记 进行 预测 。	该文 提出 一 种 基 于 卷积 神经 网络 的 缅甸 语 分词 方法 , 首先 将 缅甸 语 音节 结构 特征 应用 于 缅甸 语 音节 词 向量 特征 分布 式 表示 , 然后 基 于 卷积 神经 网络 将 音节 及 其 上 下文 的 特征 进行 融合 , 得到 有效 的 特征 表示 , 并 通过 深层 网络 的 逐层 特征 优化 自 动 学习 到 缅甸 语 分词 的 有效 特征 向量 , 最后 利用 softmax 分类 器 来 对 构成 缅甸 语 词汇 的 音节 序列 标记 进行 预测 。	1<2	enablement	enablement
nlpabs83_Chi	154-157	158-165	实验 结果 表明 ,	该 方法 取得 了 较好 的 效果 。	154-165	154-165	实验 结果 表明 , 该 方法 取得 了 较好 的 效果 。	实验 结果 表明 , 该 方法 取得 了 较好 的 效果 。	1>2	attribution	attribution
nlpabs83_Chi	59-73	158-165	该文 提出 一 种 基 于 卷积 神经 网络 的 缅甸 语 分词 方法 ,	该 方法 取得 了 较好 的 效果 。	59-153	154-165	该文 提出 一 种 基 于 卷积 神经 网络 的 缅甸 语 分词 方法 , 首先 将 缅甸 语 音节 结构 特征 应用 于 缅甸 语 音节 词 向量 特征 分布 式 表示 , 然后 基 于 卷积 神经 网络 将 音节 及 其 上 下文 的 特征 进行 融合 , 得到 有效 的 特征 表示 , 并 通过 深层 网络 的 逐层 特征 优化 自 动 学习 到 缅甸 语 分词 的 有效 特征 向量 , 最后 利用 softmax 分类 器 来 对 构成 缅甸 语 词汇 的 音节 序列 标记 进行 预测 。	实验 结果 表明 , 该 方法 取得 了 较好 的 效果 。	1<2	evaluation	evaluation
nlpabs84_Chi	1-10	11-21	随 着 互联 网上 信息 的 爆炸 式 增长 ,	如何 有效 提高 知识 获取 效率 变 得 尤为 重要 。	1-21	1-21	随 着 互联 网上 信息 的 爆炸 式 增长 , 如何 有效 提高 知识 获取 效率 变 得 尤为 重要 。	随 着 互联 网上 信息 的 爆炸 式 增长 , 如何 有效 提高 知识 获取 效率 变 得 尤为 重要 。	1>2	bg-general	bg-general
nlpabs84_Chi	11-21	78-94	如何 有效 提高 知识 获取 效率 变 得 尤为 重要 。	该文 提出 一 种 新 的 两 阶段 的 长文 本 自动 摘要 方法 TP -AS ,	1-21	75-137	随 着 互联 网上 信息 的 爆炸 式 增长 , 如何 有效 提高 知识 获取 效率 变 得 尤为 重要 。	为 此 , 该文 提出 一 种 新 的 两 阶段 的 长文 本 自动 摘要 方法 TP -AS , 首先 利用 基 于 图模型 的 混合 文本 相似 度 计算 方法 进行 关键句 抽取 , 然后 结合 指针 机制 和 注意 力 机制 构建 一 种 基 于 循环 神经 网络 的 编码 器 — 解码 器 模型 进行 摘要 生成 。	1>2	bg-general	bg-general
nlpabs84_Chi	11-21	22-33	如何 有效 提高 知识 获取 效率 变 得 尤为 重要 。	文本 自动 摘要 技术 通过 对 信息 的 压缩 和 精炼 ,	1-21	22-45	随 着 互联 网上 信息 的 爆炸 式 增长 , 如何 有效 提高 知识 获取 效率 变 得 尤为 重要 。	文本 自动 摘要 技术 通过 对 信息 的 压缩 和 精炼 , 为 知识 的 快速 获取 提供 了 很好 的 辅助 手段 。	1<2	elab-addition	elab-addition
nlpabs84_Chi	22-33	34-45	文本 自动 摘要 技术 通过 对 信息 的 压缩 和 精炼 ,	为 知识 的 快速 获取 提供 了 很好 的 辅助 手段 。	22-45	22-45	文本 自动 摘要 技术 通过 对 信息 的 压缩 和 精炼 , 为 知识 的 快速 获取 提供 了 很好 的 辅助 手段 。	文本 自动 摘要 技术 通过 对 信息 的 压缩 和 精炼 , 为 知识 的 快速 获取 提供 了 很好 的 辅助 手段 。	1<2	enablement	enablement
nlpabs84_Chi	22-33	46-65	文本 自动 摘要 技术 通过 对 信息 的 压缩 和 精炼 ,	现有 的 文本 自动 摘要 方法 在 处理 长 文本 的 过程 中 , 存在 准确 率低 的 问题 ,	22-45	46-74	文本 自动 摘要 技术 通过 对 信息 的 压缩 和 精炼 , 为 知识 的 快速 获取 提供 了 很好 的 辅助 手段 。	现有 的 文本 自动 摘要 方法 在 处理 长 文本 的 过程 中 , 存在 准确 率低 的 问题 , 无法 达到 令 用户 满意 的 性能 效果 。	1<2	elab-addition	elab-addition
nlpabs84_Chi	46-65	66-74	现有 的 文本 自动 摘要 方法 在 处理 长 文本 的 过程 中 , 存在 准确 率低 的 问题 ,	无法 达到 令 用户 满意 的 性能 效果 。	46-74	46-74	现有 的 文本 自动 摘要 方法 在 处理 长 文本 的 过程 中 , 存在 准确 率低 的 问题 , 无法 达到 令 用户 满意 的 性能 效果 。	现有 的 文本 自动 摘要 方法 在 处理 长 文本 的 过程 中 , 存在 准确 率低 的 问题 , 无法 达到 令 用户 满意 的 性能 效果 。	1<2	elab-addition	elab-addition
nlpabs84_Chi	75-77	78-94	为 此 ,	该文 提出 一 种 新 的 两 阶段 的 长文 本 自动 摘要 方法 TP -AS ,	75-137	75-137	为 此 , 该文 提出 一 种 新 的 两 阶段 的 长文 本 自动 摘要 方法 TP -AS , 首先 利用 基 于 图模型 的 混合 文本 相似 度 计算 方法 进行 关键句 抽取 , 然后 结合 指针 机制 和 注意 力 机制 构建 一 种 基 于 循环 神经 网络 的 编码 器 — 解码 器 模型 进行 摘要 生成 。	为 此 , 该文 提出 一 种 新 的 两 阶段 的 长文 本 自动 摘要 方法 TP -AS , 首先 利用 基 于 图模型 的 混合 文本 相似 度 计算 方法 进行 关键句 抽取 , 然后 结合 指针 机制 和 注意 力 机制 构建 一 种 基 于 循环 神经 网络 的 编码 器 — 解码 器 模型 进行 摘要 生成 。	1>2	enablement	enablement
nlpabs84_Chi	78-94	95-106	该文 提出 一 种 新 的 两 阶段 的 长文 本 自动 摘要 方法 TP -AS ,	首先 利用 基 于 图模型 的 混合 文本 相似 度 计算 方法	75-137	75-137	为 此 , 该文 提出 一 种 新 的 两 阶段 的 长文 本 自动 摘要 方法 TP -AS , 首先 利用 基 于 图模型 的 混合 文本 相似 度 计算 方法 进行 关键句 抽取 , 然后 结合 指针 机制 和 注意 力 机制 构建 一 种 基 于 循环 神经 网络 的 编码 器 — 解码 器 模型 进行 摘要 生成 。	为 此 , 该文 提出 一 种 新 的 两 阶段 的 长文 本 自动 摘要 方法 TP -AS , 首先 利用 基 于 图模型 的 混合 文本 相似 度 计算 方法 进行 关键句 抽取 , 然后 结合 指针 机制 和 注意 力 机制 构建 一 种 基 于 循环 神经 网络 的 编码 器 — 解码 器 模型 进行 摘要 生成 。	1<2	elab-process_step	elab-process_step
nlpabs84_Chi	95-106	107-110	首先 利用 基 于 图模型 的 混合 文本 相似 度 计算 方法	进行 关键句 抽取 ,	75-137	75-137	为 此 , 该文 提出 一 种 新 的 两 阶段 的 长文 本 自动 摘要 方法 TP -AS , 首先 利用 基 于 图模型 的 混合 文本 相似 度 计算 方法 进行 关键句 抽取 , 然后 结合 指针 机制 和 注意 力 机制 构建 一 种 基 于 循环 神经 网络 的 编码 器 — 解码 器 模型 进行 摘要 生成 。	为 此 , 该文 提出 一 种 新 的 两 阶段 的 长文 本 自动 摘要 方法 TP -AS , 首先 利用 基 于 图模型 的 混合 文本 相似 度 计算 方法 进行 关键句 抽取 , 然后 结合 指针 机制 和 注意 力 机制 构建 一 种 基 于 循环 神经 网络 的 编码 器 — 解码 器 模型 进行 摘要 生成 。	1<2	enablement	enablement
nlpabs84_Chi	95-106	111-118	首先 利用 基 于 图模型 的 混合 文本 相似 度 计算 方法	然后 结合 指针 机制 和 注意 力 机制	75-137	75-137	为 此 , 该文 提出 一 种 新 的 两 阶段 的 长文 本 自动 摘要 方法 TP -AS , 首先 利用 基 于 图模型 的 混合 文本 相似 度 计算 方法 进行 关键句 抽取 , 然后 结合 指针 机制 和 注意 力 机制 构建 一 种 基 于 循环 神经 网络 的 编码 器 — 解码 器 模型 进行 摘要 生成 。	为 此 , 该文 提出 一 种 新 的 两 阶段 的 长文 本 自动 摘要 方法 TP -AS , 首先 利用 基 于 图模型 的 混合 文本 相似 度 计算 方法 进行 关键句 抽取 , 然后 结合 指针 机制 和 注意 力 机制 构建 一 种 基 于 循环 神经 网络 的 编码 器 — 解码 器 模型 进行 摘要 生成 。	1<2	joint	joint
nlpabs84_Chi	111-118	119-133	然后 结合 指针 机制 和 注意 力 机制	构建 一 种 基 于 循环 神经 网络 的 编码 器 — 解码 器 模型	75-137	75-137	为 此 , 该文 提出 一 种 新 的 两 阶段 的 长文 本 自动 摘要 方法 TP -AS , 首先 利用 基 于 图模型 的 混合 文本 相似 度 计算 方法 进行 关键句 抽取 , 然后 结合 指针 机制 和 注意 力 机制 构建 一 种 基 于 循环 神经 网络 的 编码 器 — 解码 器 模型 进行 摘要 生成 。	为 此 , 该文 提出 一 种 新 的 两 阶段 的 长文 本 自动 摘要 方法 TP -AS , 首先 利用 基 于 图模型 的 混合 文本 相似 度 计算 方法 进行 关键句 抽取 , 然后 结合 指针 机制 和 注意 力 机制 构建 一 种 基 于 循环 神经 网络 的 编码 器 — 解码 器 模型 进行 摘要 生成 。	1<2	enablement	enablement
nlpabs84_Chi	119-133	134-137	构建 一 种 基 于 循环 神经 网络 的 编码 器 — 解码 器 模型	进行 摘要 生成 。	75-137	75-137	为 此 , 该文 提出 一 种 新 的 两 阶段 的 长文 本 自动 摘要 方法 TP -AS , 首先 利用 基 于 图模型 的 混合 文本 相似 度 计算 方法 进行 关键句 抽取 , 然后 结合 指针 机制 和 注意 力 机制 构建 一 种 基 于 循环 神经 网络 的 编码 器 — 解码 器 模型 进行 摘要 生成 。	为 此 , 该文 提出 一 种 新 的 两 阶段 的 长文 本 自动 摘要 方法 TP -AS , 首先 利用 基 于 图模型 的 混合 文本 相似 度 计算 方法 进行 关键句 抽取 , 然后 结合 指针 机制 和 注意 力 机制 构建 一 种 基 于 循环 神经 网络 的 编码 器 — 解码 器 模型 进行 摘要 生成 。	1<2	enablement	enablement
nlpabs84_Chi	138-152	153-161	通过 基 于 真实 大 规模 金融 领域 长文 本 数据 上 的 实验 ,	验证 了 TP -AS 方法 的 有效 性 ,	138-192	138-192	通过 基 于 真实 大 规模 金融 领域 长文 本 数据 上 的 实验 , 验证 了 TP -AS 方法 的 有效 性 , 其 自动 摘要 的 准确 性 在 ROUGE-1 的 指标 下 分别 达到 了 36.6% ( 词 ) 和 33.9% ( 字符 ) , 明显 优 于 现有 其他 方法 。	通过 基 于 真实 大 规模 金融 领域 长文 本 数据 上 的 实验 , 验证 了 TP -AS 方法 的 有效 性 , 其 自动 摘要 的 准确 性 在 ROUGE-1 的 指标 下 分别 达到 了 36.6% ( 词 ) 和 33.9% ( 字符 ) , 明显 优 于 现有 其他 方法 。	1>2	manner-means	manner-means
nlpabs84_Chi	78-94	153-161	该文 提出 一 种 新 的 两 阶段 的 长文 本 自动 摘要 方法 TP -AS ,	验证 了 TP -AS 方法 的 有效 性 ,	75-137	138-192	为 此 , 该文 提出 一 种 新 的 两 阶段 的 长文 本 自动 摘要 方法 TP -AS , 首先 利用 基 于 图模型 的 混合 文本 相似 度 计算 方法 进行 关键句 抽取 , 然后 结合 指针 机制 和 注意 力 机制 构建 一 种 基 于 循环 神经 网络 的 编码 器 — 解码 器 模型 进行 摘要 生成 。	通过 基 于 真实 大 规模 金融 领域 长文 本 数据 上 的 实验 , 验证 了 TP -AS 方法 的 有效 性 , 其 自动 摘要 的 准确 性 在 ROUGE-1 的 指标 下 分别 达到 了 36.6% ( 词 ) 和 33.9% ( 字符 ) , 明显 优 于 现有 其他 方法 。	1<2	evaluation	evaluation
nlpabs84_Chi	153-161	162-185	验证 了 TP -AS 方法 的 有效 性 ,	其 自动 摘要 的 准确 性 在 ROUGE-1 的 指标 下 分别 达到 了 36.6% ( 词 ) 和 33.9% ( 字符 ) ,	138-192	138-192	通过 基 于 真实 大 规模 金融 领域 长文 本 数据 上 的 实验 , 验证 了 TP -AS 方法 的 有效 性 , 其 自动 摘要 的 准确 性 在 ROUGE-1 的 指标 下 分别 达到 了 36.6% ( 词 ) 和 33.9% ( 字符 ) , 明显 优 于 现有 其他 方法 。	通过 基 于 真实 大 规模 金融 领域 长文 本 数据 上 的 实验 , 验证 了 TP -AS 方法 的 有效 性 , 其 自动 摘要 的 准确 性 在 ROUGE-1 的 指标 下 分别 达到 了 36.6% ( 词 ) 和 33.9% ( 字符 ) , 明显 优 于 现有 其他 方法 。	1<2	elab-addition	elab-addition
nlpabs84_Chi	162-185	186-192	其 自动 摘要 的 准确 性 在 ROUGE-1 的 指标 下 分别 达到 了 36.6% ( 词 ) 和 33.9% ( 字符 ) ,	明显 优 于 现有 其他 方法 。	138-192	138-192	通过 基 于 真实 大 规模 金融 领域 长文 本 数据 上 的 实验 , 验证 了 TP -AS 方法 的 有效 性 , 其 自动 摘要 的 准确 性 在 ROUGE-1 的 指标 下 分别 达到 了 36.6% ( 词 ) 和 33.9% ( 字符 ) , 明显 优 于 现有 其他 方法 。	通过 基 于 真实 大 规模 金融 领域 长文 本 数据 上 的 实验 , 验证 了 TP -AS 方法 的 有效 性 , 其 自动 摘要 的 准确 性 在 ROUGE-1 的 指标 下 分别 达到 了 36.6% ( 词 ) 和 33.9% ( 字符 ) , 明显 优 于 现有 其他 方法 。	1<2	elab-addition	elab-addition
nlpabs85_Chi	1-11	35-51	评论 对象 抽取 是 情感 分析 的 重要 研究 内容 。	该 文 提 出 用 于 评价 对象 抽取 的 七 种 新 的 语义 特征 。	1-11	12-51	评论 对象 抽取 是 情感 分析 的 重要 研究 内容 。	基 于 语义 词典 , 从 评论 对象 的 类别 视角 出发 , 运用 语义 相似 度 和 相关 度 计算 方法 , 该 文 提 出 用 于 评价 对象 抽取 的 七 种 新 的 语义 特征 。	1>2	bg-general	bg-general
nlpabs85_Chi	12-24	35-51	基 于 语义 词典 , 从 评论 对象 的 类别 视角 出发 ,	该 文 提 出 用 于 评价 对象 抽取 的 七 种 新 的 语义 特征 。	12-51	12-51	基 于 语义 词典 , 从 评论 对象 的 类别 视角 出发 , 运用 语义 相似 度 和 相关 度 计算 方法 , 该 文 提 出 用 于 评价 对象 抽取 的 七 种 新 的 语义 特征 。	基 于 语义 词典 , 从 评论 对象 的 类别 视角 出发 , 运用 语义 相似 度 和 相关 度 计算 方法 , 该 文 提 出 用 于 评价 对象 抽取 的 七 种 新 的 语义 特征 。	1>2	bg-general	bg-general
nlpabs85_Chi	25-34	35-51	运用 语义 相似 度 和 相关 度 计算 方法 ,	该 文 提 出 用 于 评价 对象 抽取 的 七 种 新 的 语义 特征 。	12-51	12-51	基 于 语义 词典 , 从 评论 对象 的 类别 视角 出发 , 运用 语义 相似 度 和 相关 度 计算 方法 , 该 文 提 出 用 于 评价 对象 抽取 的 七 种 新 的 语义 特征 。	基 于 语义 词典 , 从 评论 对象 的 类别 视角 出发 , 运用 语义 相似 度 和 相关 度 计算 方法 , 该 文 提 出 用 于 评价 对象 抽取 的 七 种 新 的 语义 特征 。	1>2	manner-means	manner-means
nlpabs85_Chi	52-63	82-89	评价 对象 和 评价 词 之间 通常 存在 句法 依存 关系 ,	提出 句法 情感 依存 特征 抽取 方法 ,	52-110	52-110	评价 对象 和 评价 词 之间 通常 存在 句法 依存 关系 , 并且 评价 词 往往 带有 情感 倾向 , 将 句法 依存 分析 和 评价 词 识别 结合 , 提出 句法 情感 依存 特征 抽取 方法 , 忽略 无情 感 词 和 微情 感 词 的 句法 依存 关系 , 提高 评价 对象 抽取 的 准确 率 。	评价 对象 和 评价 词 之间 通常 存在 句法 依存 关系 , 并且 评价 词 往往 带有 情感 倾向 , 将 句法 依存 分析 和 评价 词 识别 结合 , 提出 句法 情感 依存 特征 抽取 方法 , 忽略 无情 感 词 和 微情 感 词 的 句法 依存 关系 , 提高 评价 对象 抽取 的 准确 率 。	1>2	bg-general	bg-general
nlpabs85_Chi	52-63	64-71	评价 对象 和 评价 词 之间 通常 存在 句法 依存 关系 ,	并且 评价 词 往往 带有 情感 倾向 ,	52-110	52-110	评价 对象 和 评价 词 之间 通常 存在 句法 依存 关系 , 并且 评价 词 往往 带有 情感 倾向 , 将 句法 依存 分析 和 评价 词 识别 结合 , 提出 句法 情感 依存 特征 抽取 方法 , 忽略 无情 感 词 和 微情 感 词 的 句法 依存 关系 , 提高 评价 对象 抽取 的 准确 率 。	评价 对象 和 评价 词 之间 通常 存在 句法 依存 关系 , 并且 评价 词 往往 带有 情感 倾向 , 将 句法 依存 分析 和 评价 词 识别 结合 , 提出 句法 情感 依存 特征 抽取 方法 , 忽略 无情 感 词 和 微情 感 词 的 句法 依存 关系 , 提高 评价 对象 抽取 的 准确 率 。	1<2	joint	joint
nlpabs85_Chi	72-81	82-89	将 句法 依存 分析 和 评价 词 识别 结合 ,	提出 句法 情感 依存 特征 抽取 方法 ,	52-110	52-110	评价 对象 和 评价 词 之间 通常 存在 句法 依存 关系 , 并且 评价 词 往往 带有 情感 倾向 , 将 句法 依存 分析 和 评价 词 识别 结合 , 提出 句法 情感 依存 特征 抽取 方法 , 忽略 无情 感 词 和 微情 感 词 的 句法 依存 关系 , 提高 评价 对象 抽取 的 准确 率 。	评价 对象 和 评价 词 之间 通常 存在 句法 依存 关系 , 并且 评价 词 往往 带有 情感 倾向 , 将 句法 依存 分析 和 评价 词 识别 结合 , 提出 句法 情感 依存 特征 抽取 方法 , 忽略 无情 感 词 和 微情 感 词 的 句法 依存 关系 , 提高 评价 对象 抽取 的 准确 率 。	1>2	manner-means	manner-means
nlpabs85_Chi	35-51	82-89	该 文 提 出 用 于 评价 对象 抽取 的 七 种 新 的 语义 特征 。	提出 句法 情感 依存 特征 抽取 方法 ,	12-51	52-110	基 于 语义 词典 , 从 评论 对象 的 类别 视角 出发 , 运用 语义 相似 度 和 相关 度 计算 方法 , 该 文 提 出 用 于 评价 对象 抽取 的 七 种 新 的 语义 特征 。	评价 对象 和 评价 词 之间 通常 存在 句法 依存 关系 , 并且 评价 词 往往 带有 情感 倾向 , 将 句法 依存 分析 和 评价 词 识别 结合 , 提出 句法 情感 依存 特征 抽取 方法 , 忽略 无情 感 词 和 微情 感 词 的 句法 依存 关系 , 提高 评价 对象 抽取 的 准确 率 。	1<2	elab-addition	elab-addition
nlpabs85_Chi	82-89	90-102	提出 句法 情感 依存 特征 抽取 方法 ,	忽略 无情 感 词 和 微情 感 词 的 句法 依存 关系 ,	52-110	52-110	评价 对象 和 评价 词 之间 通常 存在 句法 依存 关系 , 并且 评价 词 往往 带有 情感 倾向 , 将 句法 依存 分析 和 评价 词 识别 结合 , 提出 句法 情感 依存 特征 抽取 方法 , 忽略 无情 感 词 和 微情 感 词 的 句法 依存 关系 , 提高 评价 对象 抽取 的 准确 率 。	评价 对象 和 评价 词 之间 通常 存在 句法 依存 关系 , 并且 评价 词 往往 带有 情感 倾向 , 将 句法 依存 分析 和 评价 词 识别 结合 , 提出 句法 情感 依存 特征 抽取 方法 , 忽略 无情 感 词 和 微情 感 词 的 句法 依存 关系 , 提高 评价 对象 抽取 的 准确 率 。	1<2	elab-addition	elab-addition
nlpabs85_Chi	90-102	103-110	忽略 无情 感 词 和 微情 感 词 的 句法 依存 关系 ,	提高 评价 对象 抽取 的 准确 率 。	52-110	52-110	评价 对象 和 评价 词 之间 通常 存在 句法 依存 关系 , 并且 评价 词 往往 带有 情感 倾向 , 将 句法 依存 分析 和 评价 词 识别 结合 , 提出 句法 情感 依存 特征 抽取 方法 , 忽略 无情 感 词 和 微情 感 词 的 句法 依存 关系 , 提高 评价 对象 抽取 的 准确 率 。	评价 对象 和 评价 词 之间 通常 存在 句法 依存 关系 , 并且 评价 词 往往 带有 情感 倾向 , 将 句法 依存 分析 和 评价 词 识别 结合 , 提出 句法 情感 依存 特征 抽取 方法 , 忽略 无情 感 词 和 微情 感 词 的 句法 依存 关系 , 提高 评价 对象 抽取 的 准确 率 。	1<2	enablement	enablement
nlpabs85_Chi	111-116	117-128	使用 条件 随 机场 模型 ,	在 SEMEVAL 比赛 的 三 个 领域 数据 集上 进行 实验 ,	111-171	111-171	使用 条件 随 机场 模型 , 在 SEMEVAL 比赛 的 三 个 领域 数据 集上 进行 实验 , 新 的 语义 特征 和 句法 情感 依存 特征 组合 的 F1 分数 比 SEMEVAL 比赛 限制 性 系统 最好 成绩 平均 高 3.78％ , 比非 限制 性 系统 最好 成绩 平均 高 2％ , 证明 了 所提 特征 的 有效 性 。	使用 条件 随 机场 模型 , 在 SEMEVAL 比赛 的 三 个 领域 数据 集上 进行 实验 , 新 的 语义 特征 和 句法 情感 依存 特征 组合 的 F1 分数 比 SEMEVAL 比赛 限制 性 系统 最好 成绩 平均 高 3.78％ , 比非 限制 性 系统 最好 成绩 平均 高 2％ , 证明 了 所提 特征 的 有效 性 。	1>2	manner-means	manner-means
nlpabs85_Chi	35-51	117-128	该 文 提 出 用 于 评价 对象 抽取 的 七 种 新 的 语义 特征 。	在 SEMEVAL 比赛 的 三 个 领域 数据 集上 进行 实验 ,	12-51	111-171	基 于 语义 词典 , 从 评论 对象 的 类别 视角 出发 , 运用 语义 相似 度 和 相关 度 计算 方法 , 该 文 提 出 用 于 评价 对象 抽取 的 七 种 新 的 语义 特征 。	使用 条件 随 机场 模型 , 在 SEMEVAL 比赛 的 三 个 领域 数据 集上 进行 实验 , 新 的 语义 特征 和 句法 情感 依存 特征 组合 的 F1 分数 比 SEMEVAL 比赛 限制 性 系统 最好 成绩 平均 高 3.78％ , 比非 限制 性 系统 最好 成绩 平均 高 2％ , 证明 了 所提 特征 的 有效 性 。	1<2	evaluation	evaluation
nlpabs85_Chi	117-128	129-153	在 SEMEVAL 比赛 的 三 个 领域 数据 集上 进行 实验 ,	新 的 语义 特征 和 句法 情感 依存 特征 组合 的 F1 分数 比 SEMEVAL 比赛 限制 性 系统 最好 成绩 平均 高 3.78％ ,	111-171	111-171	使用 条件 随 机场 模型 , 在 SEMEVAL 比赛 的 三 个 领域 数据 集上 进行 实验 , 新 的 语义 特征 和 句法 情感 依存 特征 组合 的 F1 分数 比 SEMEVAL 比赛 限制 性 系统 最好 成绩 平均 高 3.78％ , 比非 限制 性 系统 最好 成绩 平均 高 2％ , 证明 了 所提 特征 的 有效 性 。	使用 条件 随 机场 模型 , 在 SEMEVAL 比赛 的 三 个 领域 数据 集上 进行 实验 , 新 的 语义 特征 和 句法 情感 依存 特征 组合 的 F1 分数 比 SEMEVAL 比赛 限制 性 系统 最好 成绩 平均 高 3.78％ , 比非 限制 性 系统 最好 成绩 平均 高 2％ , 证明 了 所提 特征 的 有效 性 。	1<2	elab-addition	elab-addition
nlpabs85_Chi	129-153	154-163	新 的 语义 特征 和 句法 情感 依存 特征 组合 的 F1 分数 比 SEMEVAL 比赛 限制 性 系统 最好 成绩 平均 高 3.78％ ,	比非 限制 性 系统 最好 成绩 平均 高 2％ ,	111-171	111-171	使用 条件 随 机场 模型 , 在 SEMEVAL 比赛 的 三 个 领域 数据 集上 进行 实验 , 新 的 语义 特征 和 句法 情感 依存 特征 组合 的 F1 分数 比 SEMEVAL 比赛 限制 性 系统 最好 成绩 平均 高 3.78％ , 比非 限制 性 系统 最好 成绩 平均 高 2％ , 证明 了 所提 特征 的 有效 性 。	使用 条件 随 机场 模型 , 在 SEMEVAL 比赛 的 三 个 领域 数据 集上 进行 实验 , 新 的 语义 特征 和 句法 情感 依存 特征 组合 的 F1 分数 比 SEMEVAL 比赛 限制 性 系统 最好 成绩 平均 高 3.78％ , 比非 限制 性 系统 最好 成绩 平均 高 2％ , 证明 了 所提 特征 的 有效 性 。	1<2	joint	joint
nlpabs85_Chi	129-153	164-171	新 的 语义 特征 和 句法 情感 依存 特征 组合 的 F1 分数 比 SEMEVAL 比赛 限制 性 系统 最好 成绩 平均 高 3.78％ ,	证明 了 所提 特征 的 有效 性 。	111-171	111-171	使用 条件 随 机场 模型 , 在 SEMEVAL 比赛 的 三 个 领域 数据 集上 进行 实验 , 新 的 语义 特征 和 句法 情感 依存 特征 组合 的 F1 分数 比 SEMEVAL 比赛 限制 性 系统 最好 成绩 平均 高 3.78％ , 比非 限制 性 系统 最好 成绩 平均 高 2％ , 证明 了 所提 特征 的 有效 性 。	使用 条件 随 机场 模型 , 在 SEMEVAL 比赛 的 三 个 领域 数据 集上 进行 实验 , 新 的 语义 特征 和 句法 情感 依存 特征 组合 的 F1 分数 比 SEMEVAL 比赛 限制 性 系统 最好 成绩 平均 高 3.78％ , 比非 限制 性 系统 最好 成绩 平均 高 2％ , 证明 了 所提 特征 的 有效 性 。	1<2	elab-addition	elab-addition
nlpabs86_Chi	1-12	13-27	语言 优美 是 学生 写作 能力 中 重要 的 一 部分 。	该文 提出 一 个 面向 作文 自动 评分 的 作文 优美 句 识别 任务 ,	1-12	13-40	语言 优美 是 学生 写作 能力 中 重要 的 一 部分 。	该文 提出 一 个 面向 作文 自动 评分 的 作文 优美 句 识别 任务 , 主要 识别 中 学 生 中 文 作 文中 的 优美 句 。	1>2	bg-general	bg-general
nlpabs86_Chi	13-27	28-40	该文 提出 一 个 面向 作文 自动 评分 的 作文 优美 句 识别 任务 ,	主要 识别 中 学 生 中 文 作 文中 的 优美 句 。	13-40	13-40	该文 提出 一 个 面向 作文 自动 评分 的 作文 优美 句 识别 任务 , 主要 识别 中 学 生 中 文 作 文中 的 优美 句 。	该文 提出 一 个 面向 作文 自动 评分 的 作文 优美 句 识别 任务 , 主要 识别 中 学 生 中 文 作 文中 的 优美 句 。	1<2	elab-addition	elab-addition
nlpabs86_Chi	41-47	48-60	相比 传统 文 本 分类 任务 ,	优美 句 识别 更 加难 以 用 特征 工程 的 方式 解决 。	41-60	41-60	相比 传统 文 本 分类 任务 , 优美 句 识别 更 加难 以 用 特征 工程 的 方式 解决 。	相比 传统 文 本 分类 任务 , 优美 句 识别 更 加难 以 用 特征 工程 的 方式 解决 。	1>2	comparison	comparison
nlpabs86_Chi	48-60	61-90	优美 句 识别 更 加难 以 用 特征 工程 的 方式 解决 。	因 此 , 该文 提出 一 种 基 于 卷积 神经 网络 ( CNN ) 和 双 向 长短 时 记忆 ( BiLSTM ) 网络 的 混合 神经 网络 结构	41-60	61-104	相比 传统 文 本 分类 任务 , 优美 句 识别 更 加难 以 用 特征 工程 的 方式 解决 。	因 此 , 该文 提出 一 种 基 于 卷积 神经 网络 ( CNN ) 和 双 向 长短 时 记忆 ( BiLSTM ) 网络 的 混合 神经 网络 结构 进行 优美句 识别 , 并 和 CNN 、 BiLSTM 网络 进行 了 对比 。	1>2	exp-reason	exp-reason
nlpabs86_Chi	28-40	61-90	主要 识别 中 学 生 中 文 作 文中 的 优美 句 。	因 此 , 该文 提出 一 种 基 于 卷积 神经 网络 ( CNN ) 和 双 向 长短 时 记忆 ( BiLSTM ) 网络 的 混合 神经 网络 结构	13-40	61-104	该文 提出 一 个 面向 作文 自动 评分 的 作文 优美 句 识别 任务 , 主要 识别 中 学 生 中 文 作 文中 的 优美 句 。	因 此 , 该文 提出 一 种 基 于 卷积 神经 网络 ( CNN ) 和 双 向 长短 时 记忆 ( BiLSTM ) 网络 的 混合 神经 网络 结构 进行 优美句 识别 , 并 和 CNN 、 BiLSTM 网络 进行 了 对比 。	1<2	elab-addition	elab-addition
nlpabs86_Chi	61-90	91-94	因 此 , 该文 提出 一 种 基 于 卷积 神经 网络 ( CNN ) 和 双 向 长短 时 记忆 ( BiLSTM ) 网络 的 混合 神经 网络 结构	进行 优美句 识别 ,	61-104	61-104	因 此 , 该文 提出 一 种 基 于 卷积 神经 网络 ( CNN ) 和 双 向 长短 时 记忆 ( BiLSTM ) 网络 的 混合 神经 网络 结构 进行 优美句 识别 , 并 和 CNN 、 BiLSTM 网络 进行 了 对比 。	因 此 , 该文 提出 一 种 基 于 卷积 神经 网络 ( CNN ) 和 双 向 长短 时 记忆 ( BiLSTM ) 网络 的 混合 神经 网络 结构 进行 优美句 识别 , 并 和 CNN 、 BiLSTM 网络 进行 了 对比 。	1<2	enablement	enablement
nlpabs86_Chi	61-90	95-104	因 此 , 该文 提出 一 种 基 于 卷积 神经 网络 ( CNN ) 和 双 向 长短 时 记忆 ( BiLSTM ) 网络 的 混合 神经 网络 结构	并 和 CNN 、 BiLSTM 网络 进行 了 对比 。	61-104	61-104	因 此 , 该文 提出 一 种 基 于 卷积 神经 网络 ( CNN ) 和 双 向 长短 时 记忆 ( BiLSTM ) 网络 的 混合 神经 网络 结构 进行 优美句 识别 , 并 和 CNN 、 BiLSTM 网络 进行 了 对比 。	因 此 , 该文 提出 一 种 基 于 卷积 神经 网络 ( CNN ) 和 双 向 长短 时 记忆 ( BiLSTM ) 网络 的 混合 神经 网络 结构 进行 优美句 识别 , 并 和 CNN 、 BiLSTM 网络 进行 了 对比 。	1<2	joint	joint
nlpabs86_Chi	105-107	108-115	实验 证明 ,	混合 神经 网络 的 准确 率 最高 ,	105-128	105-128	实验 证明 , 混合 神经 网络 的 准确 率 最高 , 达到 89.23% , F1 值 与 BiL STM 相当 , 达到 75.39% 。	实验 证明 , 混合 神经 网络 的 准确 率 最高 , 达到 89.23% , F1 值 与 BiL STM 相当 , 达到 75.39% 。	1>2	attribution	attribution
nlpabs86_Chi	61-90	108-115	因 此 , 该文 提出 一 种 基 于 卷积 神经 网络 ( CNN ) 和 双 向 长短 时 记忆 ( BiLSTM ) 网络 的 混合 神经 网络 结构	混合 神经 网络 的 准确 率 最高 ,	61-104	105-128	因 此 , 该文 提出 一 种 基 于 卷积 神经 网络 ( CNN ) 和 双 向 长短 时 记忆 ( BiLSTM ) 网络 的 混合 神经 网络 结构 进行 优美句 识别 , 并 和 CNN 、 BiLSTM 网络 进行 了 对比 。	实验 证明 , 混合 神经 网络 的 准确 率 最高 , 达到 89.23% , F1 值 与 BiL STM 相当 , 达到 75.39% 。	1<2	evaluation	evaluation
nlpabs86_Chi	108-115	116-118	混合 神经 网络 的 准确 率 最高 ,	达到 89.23% ,	105-128	105-128	实验 证明 , 混合 神经 网络 的 准确 率 最高 , 达到 89.23% , F1 值 与 BiL STM 相当 , 达到 75.39% 。	实验 证明 , 混合 神经 网络 的 准确 率 最高 , 达到 89.23% , F1 值 与 BiL STM 相当 , 达到 75.39% 。	1<2	elab-addition	elab-addition
nlpabs86_Chi	108-115	119-125	混合 神经 网络 的 准确 率 最高 ,	F1 值 与 BiL STM 相当 ,	105-128	105-128	实验 证明 , 混合 神经 网络 的 准确 率 最高 , 达到 89.23% , F1 值 与 BiL STM 相当 , 达到 75.39% 。	实验 证明 , 混合 神经 网络 的 准确 率 最高 , 达到 89.23% , F1 值 与 BiL STM 相当 , 达到 75.39% 。	1<2	joint	joint
nlpabs86_Chi	119-125	126-128	F1 值 与 BiL STM 相当 ,	达到 75.39% 。	105-128	105-128	实验 证明 , 混合 神经 网络 的 准确 率 最高 , 达到 89.23% , F1 值 与 BiL STM 相当 , 达到 75.39% 。	实验 证明 , 混合 神经 网络 的 准确 率 最高 , 达到 89.23% , F1 值 与 BiL STM 相当 , 达到 75.39% 。	1<2	elab-addition	elab-addition
nlpabs86_Chi	13-27	129-142	该文 提出 一 个 面向 作文 自动 评分 的 作文 优美 句 识别 任务 ,	此外 , 该文 将 优美 句子 特征 用 于 作文 自动 评分 任务 ,	13-40	129-158	该文 提出 一 个 面向 作文 自动 评分 的 作文 优美 句 识别 任务 , 主要 识别 中 学 生 中 文 作 文中 的 优美 句 。	此外 , 该文 将 优美 句子 特征 用 于 作文 自动 评分 任务 , 可 使 计算 机 评分 和 人工 评分 的 大 分差 比例 下 降 21.41% 。	1<2	elab-addition	elab-addition
nlpabs86_Chi	129-142	143-158	此外 , 该文 将 优美 句子 特征 用 于 作文 自动 评分 任务 ,	可 使 计算 机 评分 和 人工 评分 的 大 分差 比例 下 降 21.41% 。	129-158	129-158	此外 , 该文 将 优美 句子 特征 用 于 作文 自动 评分 任务 , 可 使 计算 机 评分 和 人工 评分 的 大 分差 比例 下 降 21.41% 。	此外 , 该文 将 优美 句子 特征 用 于 作文 自动 评分 任务 , 可 使 计算 机 评分 和 人工 评分 的 大 分差 比例 下 降 21.41% 。	1<2	elab-addition	elab-addition
nlpabs87_Chi	1-17	81-99	事件 抽取 旨 在 从 非 结构 化 的 文本 中 抽取 出 事件 的 信息 ,	为 此 , 该文 提出 了 一 种 联合 深度 学习 和 主动 学习 的 事件 抽取 方法 。	1-27	81-99	事件 抽取 旨 在 从 非 结构 化 的 文本 中 抽取 出 事件 的 信息 , 并 以 结构 化 的 形式 予 以 呈现 。	为 此 , 该文 提出 了 一 种 联合 深度 学习 和 主动 学习 的 事件 抽取 方法 。	1>2	bg-general	bg-general
nlpabs87_Chi	1-17	18-27	事件 抽取 旨 在 从 非 结构 化 的 文本 中 抽取 出 事件 的 信息 ,	并 以 结构 化 的 形式 予 以 呈现 。	1-27	1-27	事件 抽取 旨 在 从 非 结构 化 的 文本 中 抽取 出 事件 的 信息 , 并 以 结构 化 的 形式 予 以 呈现 。	事件 抽取 旨 在 从 非 结构 化 的 文本 中 抽取 出 事件 的 信息 , 并 以 结构 化 的 形式 予 以 呈现 。	1<2	joint	joint
nlpabs87_Chi	1-17	28-55	事件 抽取 旨 在 从 非 结构 化 的 文本 中 抽取 出 事件 的 信息 ,	监督 学 习 作 为 基础 的 事件 抽取 方法 往往 受制 于 训练 语料 规模 小 、 类别 分布 不 平衡 和 质量 参差不齐 的 问题 。	1-27	28-55	事件 抽取 旨 在 从 非 结构 化 的 文本 中 抽取 出 事件 的 信息 , 并 以 结构 化 的 形式 予 以 呈现 。	监督 学 习 作 为 基础 的 事件 抽取 方法 往往 受制 于 训练 语料 规模 小 、 类别 分布 不 平衡 和 质量 参差不齐 的 问题 。	1<2	elab-addition	elab-addition
nlpabs87_Chi	28-55	56-74	监督 学 习 作 为 基础 的 事件 抽取 方法 往往 受制 于 训练 语料 规模 小 、 类别 分布 不 平衡 和 质量 参差不齐 的 问题 。	同时 , 传统 基 于 特征 工程 的 事件 抽取 方法 往往 会 产生 错误 传递 的 问题 ,	28-55	56-80	监督 学 习 作 为 基础 的 事件 抽取 方法 往往 受制 于 训练 语料 规模 小 、 类别 分布 不 平衡 和 质量 参差不齐 的 问题 。	同时 , 传统 基 于 特征 工程 的 事件 抽取 方法 往往 会 产生 错误 传递 的 问题 , 且 特征 工程 较为 复杂 。	1<2	joint	joint
nlpabs87_Chi	56-74	75-80	同时 , 传统 基 于 特征 工程 的 事件 抽取 方法 往往 会 产生 错误 传递 的 问题 ,	且 特征 工程 较为 复杂 。	56-80	56-80	同时 , 传统 基 于 特征 工程 的 事件 抽取 方法 往往 会 产生 错误 传递 的 问题 , 且 特征 工程 较为 复杂 。	同时 , 传统 基 于 特征 工程 的 事件 抽取 方法 往往 会 产生 错误 传递 的 问题 , 且 特征 工程 较为 复杂 。	1<2	joint	joint
nlpabs87_Chi	81-99	100-120	为 此 , 该文 提出 了 一 种 联合 深度 学习 和 主动 学习 的 事件 抽取 方法 。	该 方法 将 RNN 模型 对 触发 词 分类 的 置信 度 融入 在 主动 学习 的 查询 函数 中 ,	81-99	100-139	为 此 , 该文 提出 了 一 种 联合 深度 学习 和 主动 学习 的 事件 抽取 方法 。	该 方法 将 RNN 模型 对 触发 词 分类 的 置信 度 融入 在 主动 学习 的 查询 函数 中 , 以 此 在 主动 学习 过程 中 提高 语料 标注 效率 , 进而 提高 实验 的 最终 性能 。	1<2	elab-addition	elab-addition
nlpabs87_Chi	100-120	121-132	该 方法 将 RNN 模型 对 触发 词 分类 的 置信 度 融入 在 主动 学习 的 查询 函数 中 ,	以 此 在 主动 学习 过程 中 提高 语料 标注 效率 ,	100-139	100-139	该 方法 将 RNN 模型 对 触发 词 分类 的 置信 度 融入 在 主动 学习 的 查询 函数 中 , 以 此 在 主动 学习 过程 中 提高 语料 标注 效率 , 进而 提高 实验 的 最终 性能 。	该 方法 将 RNN 模型 对 触发 词 分类 的 置信 度 融入 在 主动 学习 的 查询 函数 中 , 以 此 在 主动 学习 过程 中 提高 语料 标注 效率 , 进而 提高 实验 的 最终 性能 。	1<2	elab-addition	elab-addition
nlpabs87_Chi	121-132	133-139	以 此 在 主动 学习 过程 中 提高 语料 标注 效率 ,	进而 提高 实验 的 最终 性能 。	100-139	100-139	该 方法 将 RNN 模型 对 触发 词 分类 的 置信 度 融入 在 主动 学习 的 查询 函数 中 , 以 此 在 主动 学习 过程 中 提高 语料 标注 效率 , 进而 提高 实验 的 最终 性能 。	该 方法 将 RNN 模型 对 触发 词 分类 的 置信 度 融入 在 主动 学习 的 查询 函数 中 , 以 此 在 主动 学习 过程 中 提高 语料 标注 效率 , 进而 提高 实验 的 最终 性能 。	1<2	enablement	enablement
nlpabs87_Chi	140-143	144-156	实验 结果 显示 ,	这 一 联合 学习 方法 能够 辅助 事件 抽取 性能 的 提升 ,	140-177	140-177	实验 结果 显示 , 这 一 联合 学习 方法 能够 辅助 事件 抽取 性能 的 提升 , 但 也 显示 , 联合 模式 仍 有 较高 的 提升 空间 , 有待 进 一 步 思考 和 探索 。	实验 结果 显示 , 这 一 联合 学习 方法 能够 辅助 事件 抽取 性能 的 提升 , 但 也 显示 , 联合 模式 仍 有 较高 的 提升 空间 , 有待 进 一 步 思考 和 探索 。	1>2	enablement	enablement
nlpabs87_Chi	81-99	144-156	为 此 , 该文 提出 了 一 种 联合 深度 学习 和 主动 学习 的 事件 抽取 方法 。	这 一 联合 学习 方法 能够 辅助 事件 抽取 性能 的 提升 ,	81-99	140-177	为 此 , 该文 提出 了 一 种 联合 深度 学习 和 主动 学习 的 事件 抽取 方法 。	实验 结果 显示 , 这 一 联合 学习 方法 能够 辅助 事件 抽取 性能 的 提升 , 但 也 显示 , 联合 模式 仍 有 较高 的 提升 空间 , 有待 进 一 步 思考 和 探索 。	1<2	evaluation	evaluation
nlpabs87_Chi	157-160	161-169	但 也 显示 ,	联合 模式 仍 有 较高 的 提升 空间 ,	140-177	140-177	实验 结果 显示 , 这 一 联合 学习 方法 能够 辅助 事件 抽取 性能 的 提升 , 但 也 显示 , 联合 模式 仍 有 较高 的 提升 空间 , 有待 进 一 步 思考 和 探索 。	实验 结果 显示 , 这 一 联合 学习 方法 能够 辅助 事件 抽取 性能 的 提升 , 但 也 显示 , 联合 模式 仍 有 较高 的 提升 空间 , 有待 进 一 步 思考 和 探索 。	1>2	attribution	attribution
nlpabs87_Chi	144-156	161-169	这 一 联合 学习 方法 能够 辅助 事件 抽取 性能 的 提升 ,	联合 模式 仍 有 较高 的 提升 空间 ,	140-177	140-177	实验 结果 显示 , 这 一 联合 学习 方法 能够 辅助 事件 抽取 性能 的 提升 , 但 也 显示 , 联合 模式 仍 有 较高 的 提升 空间 , 有待 进 一 步 思考 和 探索 。	实验 结果 显示 , 这 一 联合 学习 方法 能够 辅助 事件 抽取 性能 的 提升 , 但 也 显示 , 联合 模式 仍 有 较高 的 提升 空间 , 有待 进 一 步 思考 和 探索 。	1<2	contrast	contrast
nlpabs87_Chi	161-169	170-177	联合 模式 仍 有 较高 的 提升 空间 ,	有待 进 一 步 思考 和 探索 。	140-177	140-177	实验 结果 显示 , 这 一 联合 学习 方法 能够 辅助 事件 抽取 性能 的 提升 , 但 也 显示 , 联合 模式 仍 有 较高 的 提升 空间 , 有待 进 一 步 思考 和 探索 。	实验 结果 显示 , 这 一 联合 学习 方法 能够 辅助 事件 抽取 性能 的 提升 , 但 也 显示 , 联合 模式 仍 有 较高 的 提升 空间 , 有待 进 一 步 思考 和 探索 。	1<2	elab-addition	elab-addition
nlpabs88_Chi	1-17	45-74	微博 用户 转发 行 为 预测 是 微博 社交 网络 消息 扩散 模型 构建 的 基础 ,	该文 在 马尔科夫 随机 场框 架 下 综合 分析 了 用户 属性 与 微博 内容 特征 、 用户 转发 行为 约束 等 因素 对 用户 转发 行为 的 影响 ,	1-35	36-99	微博 用户 转发 行 为 预测 是 微博 社交 网络 消息 扩散 模型 构建 的 基础 , 在 图书 阅读 推广 、 舆情 监控 与 市场 营销 等 领域 有 着 广泛 的 应用 。	为了 提高 用户 转发 行为 预测 的 精度 , 该文 在 马尔科夫 随机 场框 架 下 综合 分析 了 用户 属性 与 微博 内容 特征 、 用户 转发 行为 约束 等 因素 对 用户 转发 行为 的 影响 , 并 在 逻辑 回归 模型 的 基础 上 构造 了 相应 的 能量 函数 对 用户 转发 行为 进行 了 全局 性 的 预测 。	1>2	bg-general	bg-general
nlpabs88_Chi	1-17	18-35	微博 用户 转发 行 为 预测 是 微博 社交 网络 消息 扩散 模型 构建 的 基础 ,	在 图书 阅读 推广 、 舆情 监控 与 市场 营销 等 领域 有 着 广泛 的 应用 。	1-35	1-35	微博 用户 转发 行 为 预测 是 微博 社交 网络 消息 扩散 模型 构建 的 基础 , 在 图书 阅读 推广 、 舆情 监控 与 市场 营销 等 领域 有 着 广泛 的 应用 。	微博 用户 转发 行 为 预测 是 微博 社交 网络 消息 扩散 模型 构建 的 基础 , 在 图书 阅读 推广 、 舆情 监控 与 市场 营销 等 领域 有 着 广泛 的 应用 。	1<2	elab-addition	elab-addition
nlpabs88_Chi	36-44	45-74	为了 提高 用户 转发 行为 预测 的 精度 ,	该文 在 马尔科夫 随机 场框 架 下 综合 分析 了 用户 属性 与 微博 内容 特征 、 用户 转发 行为 约束 等 因素 对 用户 转发 行为 的 影响 ,	36-99	36-99	为了 提高 用户 转发 行为 预测 的 精度 , 该文 在 马尔科夫 随机 场框 架 下 综合 分析 了 用户 属性 与 微博 内容 特征 、 用户 转发 行为 约束 等 因素 对 用户 转发 行为 的 影响 , 并 在 逻辑 回归 模型 的 基础 上 构造 了 相应 的 能量 函数 对 用户 转发 行为 进行 了 全局 性 的 预测 。	为了 提高 用户 转发 行为 预测 的 精度 , 该文 在 马尔科夫 随机 场框 架 下 综合 分析 了 用户 属性 与 微博 内容 特征 、 用户 转发 行为 约束 等 因素 对 用户 转发 行为 的 影响 , 并 在 逻辑 回归 模型 的 基础 上 构造 了 相应 的 能量 函数 对 用户 转发 行为 进行 了 全局 性 的 预测 。	1>2	enablement	enablement
nlpabs88_Chi	75-82	83-88	并 在 逻辑 回归 模型 的 基础 上	构造 了 相应 的 能量 函数	36-99	36-99	为了 提高 用户 转发 行为 预测 的 精度 , 该文 在 马尔科夫 随机 场框 架 下 综合 分析 了 用户 属性 与 微博 内容 特征 、 用户 转发 行为 约束 等 因素 对 用户 转发 行为 的 影响 , 并 在 逻辑 回归 模型 的 基础 上 构造 了 相应 的 能量 函数 对 用户 转发 行为 进行 了 全局 性 的 预测 。	为了 提高 用户 转发 行为 预测 的 精度 , 该文 在 马尔科夫 随机 场框 架 下 综合 分析 了 用户 属性 与 微博 内容 特征 、 用户 转发 行为 约束 等 因素 对 用户 转发 行为 的 影响 , 并 在 逻辑 回归 模型 的 基础 上 构造 了 相应 的 能量 函数 对 用户 转发 行为 进行 了 全局 性 的 预测 。	1>2	bg-general	bg-general
nlpabs88_Chi	45-74	83-88	该文 在 马尔科夫 随机 场框 架 下 综合 分析 了 用户 属性 与 微博 内容 特征 、 用户 转发 行为 约束 等 因素 对 用户 转发 行为 的 影响 ,	构造 了 相应 的 能量 函数	36-99	36-99	为了 提高 用户 转发 行为 预测 的 精度 , 该文 在 马尔科夫 随机 场框 架 下 综合 分析 了 用户 属性 与 微博 内容 特征 、 用户 转发 行为 约束 等 因素 对 用户 转发 行为 的 影响 , 并 在 逻辑 回归 模型 的 基础 上 构造 了 相应 的 能量 函数 对 用户 转发 行为 进行 了 全局 性 的 预测 。	为了 提高 用户 转发 行为 预测 的 精度 , 该文 在 马尔科夫 随机 场框 架 下 综合 分析 了 用户 属性 与 微博 内容 特征 、 用户 转发 行为 约束 等 因素 对 用户 转发 行为 的 影响 , 并 在 逻辑 回归 模型 的 基础 上 构造 了 相应 的 能量 函数 对 用户 转发 行为 进行 了 全局 性 的 预测 。	1<2	joint	joint
nlpabs88_Chi	83-88	89-99	构造 了 相应 的 能量 函数	对 用户 转发 行为 进行 了 全局 性 的 预测 。	36-99	36-99	为了 提高 用户 转发 行为 预测 的 精度 , 该文 在 马尔科夫 随机 场框 架 下 综合 分析 了 用户 属性 与 微博 内容 特征 、 用户 转发 行为 约束 等 因素 对 用户 转发 行为 的 影响 , 并 在 逻辑 回归 模型 的 基础 上 构造 了 相应 的 能量 函数 对 用户 转发 行为 进行 了 全局 性 的 预测 。	为了 提高 用户 转发 行为 预测 的 精度 , 该文 在 马尔科夫 随机 场框 架 下 综合 分析 了 用户 属性 与 微博 内容 特征 、 用户 转发 行为 约束 等 因素 对 用户 转发 行为 的 影响 , 并 在 逻辑 回归 模型 的 基础 上 构造 了 相应 的 能量 函数 对 用户 转发 行为 进行 了 全局 性 的 预测 。	1<2	enablement	enablement
nlpabs88_Chi	100-103	104-118	实验 结果 表明 ,	微博 用户 转发 行为 不仅 取决 于 用户 属性 、 微博 内容 等 特征 ,	100-130	100-130	实验 结果 表明 , 微博 用户 转发 行为 不仅 取决 于 用户 属性 、 微博 内容 等 特征 , 而且 也 受到 与 其 相邻 用户 转发 行为 的 约束 。	实验 结果 表明 , 微博 用户 转发 行为 不仅 取决 于 用户 属性 、 微博 内容 等 特征 , 而且 也 受到 与 其 相邻 用户 转发 行为 的 约束 。	1>2	attribution	attribution
nlpabs88_Chi	45-74	104-118	该文 在 马尔科夫 随机 场框 架 下 综合 分析 了 用户 属性 与 微博 内容 特征 、 用户 转发 行为 约束 等 因素 对 用户 转发 行为 的 影响 ,	微博 用户 转发 行为 不仅 取决 于 用户 属性 、 微博 内容 等 特征 ,	36-99	100-130	为了 提高 用户 转发 行为 预测 的 精度 , 该文 在 马尔科夫 随机 场框 架 下 综合 分析 了 用户 属性 与 微博 内容 特征 、 用户 转发 行为 约束 等 因素 对 用户 转发 行为 的 影响 , 并 在 逻辑 回归 模型 的 基础 上 构造 了 相应 的 能量 函数 对 用户 转发 行为 进行 了 全局 性 的 预测 。	实验 结果 表明 , 微博 用户 转发 行为 不仅 取决 于 用户 属性 、 微博 内容 等 特征 , 而且 也 受到 与 其 相邻 用户 转发 行为 的 约束 。	1<2	elab-addition	elab-addition
nlpabs88_Chi	104-118	119-130	微博 用户 转发 行为 不仅 取决 于 用户 属性 、 微博 内容 等 特征 ,	而且 也 受到 与 其 相邻 用户 转发 行为 的 约束 。	100-130	100-130	实验 结果 表明 , 微博 用户 转发 行为 不仅 取决 于 用户 属性 、 微博 内容 等 特征 , 而且 也 受到 与 其 相邻 用户 转发 行为 的 约束 。	实验 结果 表明 , 微博 用户 转发 行为 不仅 取决 于 用户 属性 、 微博 内容 等 特征 , 而且 也 受到 与 其 相邻 用户 转发 行为 的 约束 。	1<2	joint	joint
nlpabs88_Chi	131-134	135-149	相对 于 传统 算法	该 文算 法 可以 更 准确 地 对 用户 转发 行 为 进行 建模 ,	131-157	131-157	相对 于 传统 算法 该 文算 法 可以 更 准确 地 对 用户 转发 行 为 进行 建模 , 因而 可 获得 更好 的 预测 结果 。	相对 于 传统 算法 该 文算 法 可以 更 准确 地 对 用户 转发 行 为 进行 建模 , 因而 可 获得 更好 的 预测 结果 。	1>2	comparison	comparison
nlpabs88_Chi	45-74	135-149	该文 在 马尔科夫 随机 场框 架 下 综合 分析 了 用户 属性 与 微博 内容 特征 、 用户 转发 行为 约束 等 因素 对 用户 转发 行为 的 影响 ,	该 文算 法 可以 更 准确 地 对 用户 转发 行 为 进行 建模 ,	36-99	131-157	为了 提高 用户 转发 行为 预测 的 精度 , 该文 在 马尔科夫 随机 场框 架 下 综合 分析 了 用户 属性 与 微博 内容 特征 、 用户 转发 行为 约束 等 因素 对 用户 转发 行为 的 影响 , 并 在 逻辑 回归 模型 的 基础 上 构造 了 相应 的 能量 函数 对 用户 转发 行为 进行 了 全局 性 的 预测 。	相对 于 传统 算法 该 文算 法 可以 更 准确 地 对 用户 转发 行 为 进行 建模 , 因而 可 获得 更好 的 预测 结果 。	1<2	evaluation	evaluation
nlpabs88_Chi	135-149	150-157	该 文算 法 可以 更 准确 地 对 用户 转发 行 为 进行 建模 ,	因而 可 获得 更好 的 预测 结果 。	131-157	131-157	相对 于 传统 算法 该 文算 法 可以 更 准确 地 对 用户 转发 行 为 进行 建模 , 因而 可 获得 更好 的 预测 结果 。	相对 于 传统 算法 该 文算 法 可以 更 准确 地 对 用户 转发 行 为 进行 建模 , 因而 可 获得 更好 的 预测 结果 。	1<2	result	result
nlpabs89_Chi	1-15	16-34	社交 网络 特征 和 用户 关系 是 社交 网络 分析 研究 的 重要 内容 。	该文 对 移动 社交 网络 中 存在 的 幂律 分布 及 用户 亲属 关系 判别 问题 进行 研究 。	1-15	16-34	社交 网络 特征 和 用户 关系 是 社交 网络 分析 研究 的 重要 内容 。	该文 对 移动 社交 网络 中 存在 的 幂律 分布 及 用户 亲属 关系 判别 问题 进行 研究 。	1>2	bg-general	bg-general
nlpabs89_Chi	16-34	35-64	该文 对 移动 社交 网络 中 存在 的 幂律 分布 及 用户 亲属 关系 判别 问题 进行 研究 。	在 幂律 分布 的 研究 中 , 该文 在 度 、 连通 子图 规模 及 用户 联系 人 数量 的 分布 中 找出 存在 的 三 个 幂律 分布 ,	16-34	35-79	该文 对 移动 社交 网络 中 存在 的 幂律 分布 及 用户 亲属 关系 判别 问题 进行 研究 。	在 幂律 分布 的 研究 中 , 该文 在 度 、 连通 子图 规模 及 用户 联系 人 数量 的 分布 中 找出 存在 的 三 个 幂律 分布 , 同时 分析 其中 规律 和 结论 , 并 与 其他 社交 网络 进行 对比 。	1<2	elab-aspect	elab-aspect
nlpabs89_Chi	35-64	65-71	在 幂律 分布 的 研究 中 , 该文 在 度 、 连通 子图 规模 及 用户 联系 人 数量 的 分布 中 找出 存在 的 三 个 幂律 分布 ,	同时 分析 其中 规律 和 结论 ,	35-79	35-79	在 幂律 分布 的 研究 中 , 该文 在 度 、 连通 子图 规模 及 用户 联系 人 数量 的 分布 中 找出 存在 的 三 个 幂律 分布 , 同时 分析 其中 规律 和 结论 , 并 与 其他 社交 网络 进行 对比 。	在 幂律 分布 的 研究 中 , 该文 在 度 、 连通 子图 规模 及 用户 联系 人 数量 的 分布 中 找出 存在 的 三 个 幂律 分布 , 同时 分析 其中 规律 和 结论 , 并 与 其他 社交 网络 进行 对比 。	1<2	elab-addition	elab-addition
nlpabs89_Chi	65-71	72-79	同时 分析 其中 规律 和 结论 ,	并 与 其他 社交 网络 进行 对比 。	35-79	35-79	在 幂律 分布 的 研究 中 , 该文 在 度 、 连通 子图 规模 及 用户 联系 人 数量 的 分布 中 找出 存在 的 三 个 幂律 分布 , 同时 分析 其中 规律 和 结论 , 并 与 其他 社交 网络 进行 对比 。	在 幂律 分布 的 研究 中 , 该文 在 度 、 连通 子图 规模 及 用户 联系 人 数量 的 分布 中 找出 存在 的 三 个 幂律 分布 , 同时 分析 其中 规律 和 结论 , 并 与 其他 社交 网络 进行 对比 。	1<2	joint	joint
nlpabs89_Chi	16-34	80-99	该文 对 移动 社交 网络 中 存在 的 幂律 分布 及 用户 亲属 关系 判别 问题 进行 研究 。	在 该 文亲 属 关系 判别 研究 中 , 通过 提取 用户 通话 行为 的 多 种 显著 特征 ,	16-34	80-149	该文 对 移动 社交 网络 中 存在 的 幂律 分布 及 用户 亲属 关系 判别 问题 进行 研究 。	在 该 文亲 属 关系 判别 研究 中 , 通过 提取 用户 通话 行为 的 多 种 显著 特征 , 采用 GBD T ( gradient boost decision tree ) 与 LR ( logistic regression ) 融合 方法 , 提出 一 种 用户 亲 属 关系 判别 模型 , 并 通过 实验 验证 该 模型 能 有效 判别 出用 户间 是否 存在 亲属 关系 , 判别 精确 率 达到 81.01% 。	1<2	elab-aspect	elab-aspect
nlpabs89_Chi	80-99	100-117	在 该 文亲 属 关系 判别 研究 中 , 通过 提取 用户 通话 行为 的 多 种 显著 特征 ,	采用 GBD T ( gradient boost decision tree ) 与 LR ( logistic regression ) 融合 方法 ,	80-149	80-149	在 该 文亲 属 关系 判别 研究 中 , 通过 提取 用户 通话 行为 的 多 种 显著 特征 , 采用 GBD T ( gradient boost decision tree ) 与 LR ( logistic regression ) 融合 方法 , 提出 一 种 用户 亲 属 关系 判别 模型 , 并 通过 实验 验证 该 模型 能 有效 判别 出用 户间 是否 存在 亲属 关系 , 判别 精确 率 达到 81.01% 。	在 该 文亲 属 关系 判别 研究 中 , 通过 提取 用户 通话 行为 的 多 种 显著 特征 , 采用 GBD T ( gradient boost decision tree ) 与 LR ( logistic regression ) 融合 方法 , 提出 一 种 用户 亲 属 关系 判别 模型 , 并 通过 实验 验证 该 模型 能 有效 判别 出用 户间 是否 存在 亲属 关系 , 判别 精确 率 达到 81.01% 。	1<2	joint	joint
nlpabs89_Chi	80-99	118-127	在 该 文亲 属 关系 判别 研究 中 , 通过 提取 用户 通话 行为 的 多 种 显著 特征 ,	提出 一 种 用户 亲 属 关系 判别 模型 ,	80-149	80-149	在 该 文亲 属 关系 判别 研究 中 , 通过 提取 用户 通话 行为 的 多 种 显著 特征 , 采用 GBD T ( gradient boost decision tree ) 与 LR ( logistic regression ) 融合 方法 , 提出 一 种 用户 亲 属 关系 判别 模型 , 并 通过 实验 验证 该 模型 能 有效 判别 出用 户间 是否 存在 亲属 关系 , 判别 精确 率 达到 81.01% 。	在 该 文亲 属 关系 判别 研究 中 , 通过 提取 用户 通话 行为 的 多 种 显著 特征 , 采用 GBD T ( gradient boost decision tree ) 与 LR ( logistic regression ) 融合 方法 , 提出 一 种 用户 亲 属 关系 判别 模型 , 并 通过 实验 验证 该 模型 能 有效 判别 出用 户间 是否 存在 亲属 关系 , 判别 精确 率 达到 81.01% 。	1<2	enablement	enablement
nlpabs89_Chi	118-127	128-143	提出 一 种 用户 亲 属 关系 判别 模型 ,	并 通过 实验 验证 该 模型 能 有效 判别 出用 户间 是否 存在 亲属 关系 ,	80-149	80-149	在 该 文亲 属 关系 判别 研究 中 , 通过 提取 用户 通话 行为 的 多 种 显著 特征 , 采用 GBD T ( gradient boost decision tree ) 与 LR ( logistic regression ) 融合 方法 , 提出 一 种 用户 亲 属 关系 判别 模型 , 并 通过 实验 验证 该 模型 能 有效 判别 出用 户间 是否 存在 亲属 关系 , 判别 精确 率 达到 81.01% 。	在 该 文亲 属 关系 判别 研究 中 , 通过 提取 用户 通话 行为 的 多 种 显著 特征 , 采用 GBD T ( gradient boost decision tree ) 与 LR ( logistic regression ) 融合 方法 , 提出 一 种 用户 亲 属 关系 判别 模型 , 并 通过 实验 验证 该 模型 能 有效 判别 出用 户间 是否 存在 亲属 关系 , 判别 精确 率 达到 81.01% 。	1<2	joint	joint
nlpabs89_Chi	128-143	144-149	并 通过 实验 验证 该 模型 能 有效 判别 出用 户间 是否 存在 亲属 关系 ,	判别 精确 率 达到 81.01% 。	80-149	80-149	在 该 文亲 属 关系 判别 研究 中 , 通过 提取 用户 通话 行为 的 多 种 显著 特征 , 采用 GBD T ( gradient boost decision tree ) 与 LR ( logistic regression ) 融合 方法 , 提出 一 种 用户 亲 属 关系 判别 模型 , 并 通过 实验 验证 该 模型 能 有效 判别 出用 户间 是否 存在 亲属 关系 , 判别 精确 率 达到 81.01% 。	在 该 文亲 属 关系 判别 研究 中 , 通过 提取 用户 通话 行为 的 多 种 显著 特征 , 采用 GBD T ( gradient boost decision tree ) 与 LR ( logistic regression ) 融合 方法 , 提出 一 种 用户 亲 属 关系 判别 模型 , 并 通过 实验 验证 该 模型 能 有效 判别 出用 户间 是否 存在 亲属 关系 , 判别 精确 率 达到 81.01% 。	1<2	elab-addition	elab-addition
nlpabs8_Chi	1-16	35-47	﻿聚类 作 为 一 种 自动 化 程度 较高 的 无 监督 机器 学习 方法 ,	本文 首先 讨论 了 文档 聚类 的 应用 背景 和 体系 结构 ,	1-34	35-71	﻿聚类 作 为 一 种 自动 化 程度 较高 的 无 监督 机器 学习 方法 , 近年 来 在 信息 检索 、 多 文档 自动 文摘 等 领域 获得 了 广泛 的 应用 。	本文 首先 讨论 了 文档 聚类 的 应用 背景 和 体系 结构 , 然后 对 文档 聚类 算法 、 聚类 空间 的 构造 和 降维 方法 、 文档 聚类 中 的 语义 问题 进行 了 综述 。	1>2	bg-general	bg-general
nlpabs8_Chi	1-16	17-34	﻿聚类 作 为 一 种 自动 化 程度 较高 的 无 监督 机器 学习 方法 ,	近年 来 在 信息 检索 、 多 文档 自动 文摘 等 领域 获得 了 广泛 的 应用 。	1-34	1-34	﻿聚类 作 为 一 种 自动 化 程度 较高 的 无 监督 机器 学习 方法 , 近年 来 在 信息 检索 、 多 文档 自动 文摘 等 领域 获得 了 广泛 的 应用 。	﻿聚类 作 为 一 种 自动 化 程度 较高 的 无 监督 机器 学习 方法 , 近年 来 在 信息 检索 、 多 文档 自动 文摘 等 领域 获得 了 广泛 的 应用 。	1<2	elab-addition	elab-addition
nlpabs8_Chi	35-47	48-71	本文 首先 讨论 了 文档 聚类 的 应用 背景 和 体系 结构 ,	然后 对 文档 聚类 算法 、 聚类 空间 的 构造 和 降维 方法 、 文档 聚类 中 的 语义 问题 进行 了 综述 。	35-71	35-71	本文 首先 讨论 了 文档 聚类 的 应用 背景 和 体系 结构 , 然后 对 文档 聚类 算法 、 聚类 空间 的 构造 和 降维 方法 、 文档 聚类 中 的 语义 问题 进行 了 综述 。	本文 首先 讨论 了 文档 聚类 的 应用 背景 和 体系 结构 , 然后 对 文档 聚类 算法 、 聚类 空间 的 构造 和 降维 方法 、 文档 聚类 中 的 语义 问题 进行 了 综述 。	1<2	joint	joint
nlpabs8_Chi	48-71	72-80	然后 对 文档 聚类 算法 、 聚类 空间 的 构造 和 降维 方法 、 文档 聚类 中 的 语义 问题 进行 了 综述 。	最后 还 介绍 了 聚类 质量 评测 问题 。	35-71	72-80	本文 首先 讨论 了 文档 聚类 的 应用 背景 和 体系 结构 , 然后 对 文档 聚类 算法 、 聚类 空间 的 构造 和 降维 方法 、 文档 聚类 中 的 语义 问题 进行 了 综述 。	最后 还 介绍 了 聚类 质量 评测 问题 。	1<2	joint	joint
nlpabs90_Chi	1-13	46-54	文本 情感 分析 是 自然 语言 处理 的 热点 问题 之 一 ,	构建 了 一 个 情感 词汇 分类 模型 。	1-21	22-54	文本 情感 分析 是 自然 语言 处理 的 热点 问题 之 一 , 而 词汇 是 情感 分析 的 基础 。	汉 字 通过 声音 和 形状 表达 意义 , 该 文 综合 考虑 词汇 中 每个 字 的 部首 和 音位 等 信息 , 构建 了 一 个 情感 词汇 分类 模型 。	1>2	bg-general	bg-general
nlpabs90_Chi	1-13	14-21	文本 情感 分析 是 自然 语言 处理 的 热点 问题 之 一 ,	而 词汇 是 情感 分析 的 基础 。	1-21	1-21	文本 情感 分析 是 自然 语言 处理 的 热点 问题 之 一 , 而 词汇 是 情感 分析 的 基础 。	文本 情感 分析 是 自然 语言 处理 的 热点 问题 之 一 , 而 词汇 是 情感 分析 的 基础 。	1<2	elab-addition	elab-addition
nlpabs90_Chi	22-30	31-45	汉 字 通过 声音 和 形状 表达 意义 ,	该 文 综合 考虑 词汇 中 每个 字 的 部首 和 音位 等 信息 ,	22-54	22-54	汉 字 通过 声音 和 形状 表达 意义 , 该 文 综合 考虑 词汇 中 每个 字 的 部首 和 音位 等 信息 , 构建 了 一 个 情感 词汇 分类 模型 。	汉 字 通过 声音 和 形状 表达 意义 , 该 文 综合 考虑 词汇 中 每个 字 的 部首 和 音位 等 信息 , 构建 了 一 个 情感 词汇 分类 模型 。	1>2	bg-general	bg-general
nlpabs90_Chi	31-45	46-54	该 文 综合 考虑 词汇 中 每个 字 的 部首 和 音位 等 信息 ,	构建 了 一 个 情感 词汇 分类 模型 。	22-54	22-54	汉 字 通过 声音 和 形状 表达 意义 , 该 文 综合 考虑 词汇 中 每个 字 的 部首 和 音位 等 信息 , 构建 了 一 个 情感 词汇 分类 模型 。	汉 字 通过 声音 和 形状 表达 意义 , 该 文 综合 考虑 词汇 中 每个 字 的 部首 和 音位 等 信息 , 构建 了 一 个 情感 词汇 分类 模型 。	1>2	manner-means	manner-means
nlpabs90_Chi	46-54	55-72	构建 了 一 个 情感 词汇 分类 模型 。	在 模型 中 , 将 词汇 的 字 、 部首 和 音位 三 种 信息 向量 化 ,	22-54	55-102	汉 字 通过 声音 和 形状 表达 意义 , 该 文 综合 考虑 词汇 中 每个 字 的 部首 和 音位 等 信息 , 构建 了 一 个 情感 词汇 分类 模型 。	在 模型 中 , 将 词汇 的 字 、 部首 和 音位 三 种 信息 向量 化 , 与 原始 词汇 向量 融合 , 生成 新 的 情感 词汇 表示 , 最后 采用 前馈 神经 网络 和 卷积 神经 网络 对 情感 词汇 的 极性 进行 分类 。	1<2	elab-process_step	elab-process_step
nlpabs90_Chi	55-72	73-78	在 模型 中 , 将 词汇 的 字 、 部首 和 音位 三 种 信息 向量 化 ,	与 原始 词汇 向量 融合 ,	55-102	55-102	在 模型 中 , 将 词汇 的 字 、 部首 和 音位 三 种 信息 向量 化 , 与 原始 词汇 向量 融合 , 生成 新 的 情感 词汇 表示 , 最后 采用 前馈 神经 网络 和 卷积 神经 网络 对 情感 词汇 的 极性 进行 分类 。	在 模型 中 , 将 词汇 的 字 、 部首 和 音位 三 种 信息 向量 化 , 与 原始 词汇 向量 融合 , 生成 新 的 情感 词汇 表示 , 最后 采用 前馈 神经 网络 和 卷积 神经 网络 对 情感 词汇 的 极性 进行 分类 。	1<2	joint	joint
nlpabs90_Chi	73-78	79-85	与 原始 词汇 向量 融合 ,	生成 新 的 情感 词汇 表示 ,	55-102	55-102	在 模型 中 , 将 词汇 的 字 、 部首 和 音位 三 种 信息 向量 化 , 与 原始 词汇 向量 融合 , 生成 新 的 情感 词汇 表示 , 最后 采用 前馈 神经 网络 和 卷积 神经 网络 对 情感 词汇 的 极性 进行 分类 。	在 模型 中 , 将 词汇 的 字 、 部首 和 音位 三 种 信息 向量 化 , 与 原始 词汇 向量 融合 , 生成 新 的 情感 词汇 表示 , 最后 采用 前馈 神经 网络 和 卷积 神经 网络 对 情感 词汇 的 极性 进行 分类 。	1<2	joint	joint
nlpabs90_Chi	79-85	86-94	生成 新 的 情感 词汇 表示 ,	最后 采用 前馈 神经 网络 和 卷积 神经 网络	55-102	55-102	在 模型 中 , 将 词汇 的 字 、 部首 和 音位 三 种 信息 向量 化 , 与 原始 词汇 向量 融合 , 生成 新 的 情感 词汇 表示 , 最后 采用 前馈 神经 网络 和 卷积 神经 网络 对 情感 词汇 的 极性 进行 分类 。	在 模型 中 , 将 词汇 的 字 、 部首 和 音位 三 种 信息 向量 化 , 与 原始 词汇 向量 融合 , 生成 新 的 情感 词汇 表示 , 最后 采用 前馈 神经 网络 和 卷积 神经 网络 对 情感 词汇 的 极性 进行 分类 。	1<2	joint	joint
nlpabs90_Chi	86-94	95-102	最后 采用 前馈 神经 网络 和 卷积 神经 网络	对 情感 词汇 的 极性 进行 分类 。	55-102	55-102	在 模型 中 , 将 词汇 的 字 、 部首 和 音位 三 种 信息 向量 化 , 与 原始 词汇 向量 融合 , 生成 新 的 情感 词汇 表示 , 最后 采用 前馈 神经 网络 和 卷积 神经 网络 对 情感 词汇 的 极性 进行 分类 。	在 模型 中 , 将 词汇 的 字 、 部首 和 音位 三 种 信息 向量 化 , 与 原始 词汇 向量 融合 , 生成 新 的 情感 词汇 表示 , 最后 采用 前馈 神经 网络 和 卷积 神经 网络 对 情感 词汇 的 极性 进行 分类 。	1<2	enablement	enablement
nlpabs90_Chi	103-106	107-122	实验 结果 表明 ,	三 种 细粒 度 特征 都 能 有效 地 提高 情感 词汇 的 分类 效果 ,	103-137	103-137	实验 结果 表明 , 三 种 细粒 度 特征 都 能 有效 地 提高 情感 词汇 的 分类 效果 , 并且 该文 在 COAE 评测 的 语料 上 验证 了 模型 的 有效 性 。	实验 结果 表明 , 三 种 细粒 度 特征 都 能 有效 地 提高 情感 词汇 的 分类 效果 , 并且 该文 在 COAE 评测 的 语料 上 验证 了 模型 的 有效 性 。	1>2	attribution	attribution
nlpabs90_Chi	46-54	107-122	构建 了 一 个 情感 词汇 分类 模型 。	三 种 细粒 度 特征 都 能 有效 地 提高 情感 词汇 的 分类 效果 ,	22-54	103-137	汉 字 通过 声音 和 形状 表达 意义 , 该 文 综合 考虑 词汇 中 每个 字 的 部首 和 音位 等 信息 , 构建 了 一 个 情感 词汇 分类 模型 。	实验 结果 表明 , 三 种 细粒 度 特征 都 能 有效 地 提高 情感 词汇 的 分类 效果 , 并且 该文 在 COAE 评测 的 语料 上 验证 了 模型 的 有效 性 。	1<2	evaluation	evaluation
nlpabs90_Chi	107-122	123-137	三 种 细粒 度 特征 都 能 有效 地 提高 情感 词汇 的 分类 效果 ,	并且 该文 在 COAE 评测 的 语料 上 验证 了 模型 的 有效 性 。	103-137	103-137	实验 结果 表明 , 三 种 细粒 度 特征 都 能 有效 地 提高 情感 词汇 的 分类 效果 , 并且 该文 在 COAE 评测 的 语料 上 验证 了 模型 的 有效 性 。	实验 结果 表明 , 三 种 细粒 度 特征 都 能 有效 地 提高 情感 词汇 的 分类 效果 , 并且 该文 在 COAE 评测 的 语料 上 验证 了 模型 的 有效 性 。	1<2	joint	joint
nlpabs92_Chi	1-29	30-60	该文 对 中 亚 地区 属 于 同 一 个 语族 的 土耳其 语 、 哈萨克 语 等 诸 语言 的 自然 语言 处理 现状 进行 了 综述 。	首先 分别 回顾 土耳其 语 、 哈萨克 语 和 其他 中 亚 语言 在 词法 分析 、 句法 分析 、 命名 实体 识别 、 机器 翻译 方面 的 研究 进展 ,	1-29	30-105	该文 对 中 亚 地区 属 于 同 一 个 语族 的 土耳其 语 、 哈萨克 语 等 诸 语言 的 自然 语言 处理 现状 进行 了 综述 。	首先 分别 回顾 土耳其 语 、 哈萨克 语 和 其他 中 亚 语言 在 词法 分析 、 句法 分析 、 命名 实体 识别 、 机器 翻译 方面 的 研究 进展 , 随后 讨论 了 与 具体 语言 无关 的 黏着 语 词法 分析 方面 的 研究 情况 , 最后 指出 国 内外 中 亚 诸 语言 处理 自然 语言 领域 中 所 面临 的 问题 和 挑战 , 并 对 未来 的 研究 提出 了 建议	1<2	elab-process_step	elab-process_step
nlpabs92_Chi	30-60	61-77	首先 分别 回顾 土耳其 语 、 哈萨克 语 和 其他 中 亚 语言 在 词法 分析 、 句法 分析 、 命名 实体 识别 、 机器 翻译 方面 的 研究 进展 ,	随后 讨论 了 与 具体 语言 无关 的 黏着 语 词法 分析 方面 的 研究 情况 ,	30-105	30-105	首先 分别 回顾 土耳其 语 、 哈萨克 语 和 其他 中 亚 语言 在 词法 分析 、 句法 分析 、 命名 实体 识别 、 机器 翻译 方面 的 研究 进展 , 随后 讨论 了 与 具体 语言 无关 的 黏着 语 词法 分析 方面 的 研究 情况 , 最后 指出 国 内外 中 亚 诸 语言 处理 自然 语言 领域 中 所 面临 的 问题 和 挑战 , 并 对 未来 的 研究 提出 了 建议	首先 分别 回顾 土耳其 语 、 哈萨克 语 和 其他 中 亚 语言 在 词法 分析 、 句法 分析 、 命名 实体 识别 、 机器 翻译 方面 的 研究 进展 , 随后 讨论 了 与 具体 语言 无关 的 黏着 语 词法 分析 方面 的 研究 情况 , 最后 指出 国 内外 中 亚 诸 语言 处理 自然 语言 领域 中 所 面临 的 问题 和 挑战 , 并 对 未来 的 研究 提出 了 建议	1<2	joint	joint
nlpabs92_Chi	61-77	78-97	随后 讨论 了 与 具体 语言 无关 的 黏着 语 词法 分析 方面 的 研究 情况 ,	最后 指出 国 内外 中 亚 诸 语言 处理 自然 语言 领域 中 所 面临 的 问题 和 挑战 ,	30-105	30-105	首先 分别 回顾 土耳其 语 、 哈萨克 语 和 其他 中 亚 语言 在 词法 分析 、 句法 分析 、 命名 实体 识别 、 机器 翻译 方面 的 研究 进展 , 随后 讨论 了 与 具体 语言 无关 的 黏着 语 词法 分析 方面 的 研究 情况 , 最后 指出 国 内外 中 亚 诸 语言 处理 自然 语言 领域 中 所 面临 的 问题 和 挑战 , 并 对 未来 的 研究 提出 了 建议	首先 分别 回顾 土耳其 语 、 哈萨克 语 和 其他 中 亚 语言 在 词法 分析 、 句法 分析 、 命名 实体 识别 、 机器 翻译 方面 的 研究 进展 , 随后 讨论 了 与 具体 语言 无关 的 黏着 语 词法 分析 方面 的 研究 情况 , 最后 指出 国 内外 中 亚 诸 语言 处理 自然 语言 领域 中 所 面临 的 问题 和 挑战 , 并 对 未来 的 研究 提出 了 建议	1<2	joint	joint
nlpabs92_Chi	78-97	98-105	最后 指出 国 内外 中 亚 诸 语言 处理 自然 语言 领域 中 所 面临 的 问题 和 挑战 ,	并 对 未来 的 研究 提出 了 建议	30-105	30-105	首先 分别 回顾 土耳其 语 、 哈萨克 语 和 其他 中 亚 语言 在 词法 分析 、 句法 分析 、 命名 实体 识别 、 机器 翻译 方面 的 研究 进展 , 随后 讨论 了 与 具体 语言 无关 的 黏着 语 词法 分析 方面 的 研究 情况 , 最后 指出 国 内外 中 亚 诸 语言 处理 自然 语言 领域 中 所 面临 的 问题 和 挑战 , 并 对 未来 的 研究 提出 了 建议	首先 分别 回顾 土耳其 语 、 哈萨克 语 和 其他 中 亚 语言 在 词法 分析 、 句法 分析 、 命名 实体 识别 、 机器 翻译 方面 的 研究 进展 , 随后 讨论 了 与 具体 语言 无关 的 黏着 语 词法 分析 方面 的 研究 情况 , 最后 指出 国 内外 中 亚 诸 语言 处理 自然 语言 领域 中 所 面临 的 问题 和 挑战 , 并 对 未来 的 研究 提出 了 建议	1<2	joint	joint
nlpabs93_Chi	1-9	10-22	标注 《 文心 雕龙 》 的 篇章 结构 ,	据 此 研究 其 连接 词 的 显隐 、 语义 及 用法 。	1-22	1-22	标注 《 文心 雕龙 》 的 篇章 结构 , 据 此 研究 其 连接 词 的 显隐 、 语义 及 用法 。	标注 《 文心 雕龙 》 的 篇章 结构 , 据 此 研究 其 连接 词 的 显隐 、 语义 及 用法 。	1<2	joint	joint
nlpabs93_Chi	1-9	23-25	标注 《 文心 雕龙 》 的 篇章 结构 ,	研究 发现 :	1-22	23-122	标注 《 文心 雕龙 》 的 篇章 结构 , 据 此 研究 其 连接 词 的 显隐 、 语义 及 用法 。	研究 发现 : ( 1 ) 隐式 关系 ( 78.1%) 多 于 显式 关系 ( 21.9% ) , 17 类 关系 仅 有 四 类 ( 因果 、 转折 、 假设 、 目 的 ) 显多隐少 ; ( 2 ) 各类 关系 的 同义 连接 词 种数 与 使用 有 差异 , 其中 种数 最多 17 ( 顺承 ) , 最少 则无 ( 总分 、 背景 ) ; ( 3 ) 连接 词 ( 56 种 ) 单义 为 多 ( 44 ) , 多义 为 少 ( 12 ) , 义项 最多 为 5 , 分布 有 差异 。	1<2	elab-addition	elab-addition
nlpabs93_Chi	23-25	26-40	研究 发现 :	( 1 ) 隐式 关系 ( 78.1%) 多 于 显式 关系 ( 21.9% ) ,	23-122	23-122	研究 发现 : ( 1 ) 隐式 关系 ( 78.1%) 多 于 显式 关系 ( 21.9% ) , 17 类 关系 仅 有 四 类 ( 因果 、 转折 、 假设 、 目 的 ) 显多隐少 ; ( 2 ) 各类 关系 的 同义 连接 词 种数 与 使用 有 差异 , 其中 种数 最多 17 ( 顺承 ) , 最少 则无 ( 总分 、 背景 ) ; ( 3 ) 连接 词 ( 56 种 ) 单义 为 多 ( 44 ) , 多义 为 少 ( 12 ) , 义项 最多 为 5 , 分布 有 差异 。	研究 发现 : ( 1 ) 隐式 关系 ( 78.1%) 多 于 显式 关系 ( 21.9% ) , 17 类 关系 仅 有 四 类 ( 因果 、 转折 、 假设 、 目 的 ) 显多隐少 ; ( 2 ) 各类 关系 的 同义 连接 词 种数 与 使用 有 差异 , 其中 种数 最多 17 ( 顺承 ) , 最少 则无 ( 总分 、 背景 ) ; ( 3 ) 连接 词 ( 56 种 ) 单义 为 多 ( 44 ) , 多义 为 少 ( 12 ) , 义项 最多 为 5 , 分布 有 差异 。	1<2	elab-enumember	elab-enumember
nlpabs93_Chi	26-40	41-59	( 1 ) 隐式 关系 ( 78.1%) 多 于 显式 关系 ( 21.9% ) ,	17 类 关系 仅 有 四 类 ( 因果 、 转折 、 假设 、 目 的 ) 显多隐少 ;	23-122	23-122	研究 发现 : ( 1 ) 隐式 关系 ( 78.1%) 多 于 显式 关系 ( 21.9% ) , 17 类 关系 仅 有 四 类 ( 因果 、 转折 、 假设 、 目 的 ) 显多隐少 ; ( 2 ) 各类 关系 的 同义 连接 词 种数 与 使用 有 差异 , 其中 种数 最多 17 ( 顺承 ) , 最少 则无 ( 总分 、 背景 ) ; ( 3 ) 连接 词 ( 56 种 ) 单义 为 多 ( 44 ) , 多义 为 少 ( 12 ) , 义项 最多 为 5 , 分布 有 差异 。	研究 发现 : ( 1 ) 隐式 关系 ( 78.1%) 多 于 显式 关系 ( 21.9% ) , 17 类 关系 仅 有 四 类 ( 因果 、 转折 、 假设 、 目 的 ) 显多隐少 ; ( 2 ) 各类 关系 的 同义 连接 词 种数 与 使用 有 差异 , 其中 种数 最多 17 ( 顺承 ) , 最少 则无 ( 总分 、 背景 ) ; ( 3 ) 连接 词 ( 56 种 ) 单义 为 多 ( 44 ) , 多义 为 少 ( 12 ) , 义项 最多 为 5 , 分布 有 差异 。	1<2	joint	joint
nlpabs93_Chi	26-40	60-74	( 1 ) 隐式 关系 ( 78.1%) 多 于 显式 关系 ( 21.9% ) ,	( 2 ) 各类 关系 的 同义 连接 词 种数 与 使用 有 差异 ,	23-122	23-122	研究 发现 : ( 1 ) 隐式 关系 ( 78.1%) 多 于 显式 关系 ( 21.9% ) , 17 类 关系 仅 有 四 类 ( 因果 、 转折 、 假设 、 目 的 ) 显多隐少 ; ( 2 ) 各类 关系 的 同义 连接 词 种数 与 使用 有 差异 , 其中 种数 最多 17 ( 顺承 ) , 最少 则无 ( 总分 、 背景 ) ; ( 3 ) 连接 词 ( 56 种 ) 单义 为 多 ( 44 ) , 多义 为 少 ( 12 ) , 义项 最多 为 5 , 分布 有 差异 。	研究 发现 : ( 1 ) 隐式 关系 ( 78.1%) 多 于 显式 关系 ( 21.9% ) , 17 类 关系 仅 有 四 类 ( 因果 、 转折 、 假设 、 目 的 ) 显多隐少 ; ( 2 ) 各类 关系 的 同义 连接 词 种数 与 使用 有 差异 , 其中 种数 最多 17 ( 顺承 ) , 最少 则无 ( 总分 、 背景 ) ; ( 3 ) 连接 词 ( 56 种 ) 单义 为 多 ( 44 ) , 多义 为 少 ( 12 ) , 义项 最多 为 5 , 分布 有 差异 。	1<2	joint	joint
nlpabs93_Chi	60-74	75-82	( 2 ) 各类 关系 的 同义 连接 词 种数 与 使用 有 差异 ,	其中 种数 最多 17 ( 顺承 ) ,	23-122	23-122	研究 发现 : ( 1 ) 隐式 关系 ( 78.1%) 多 于 显式 关系 ( 21.9% ) , 17 类 关系 仅 有 四 类 ( 因果 、 转折 、 假设 、 目 的 ) 显多隐少 ; ( 2 ) 各类 关系 的 同义 连接 词 种数 与 使用 有 差异 , 其中 种数 最多 17 ( 顺承 ) , 最少 则无 ( 总分 、 背景 ) ; ( 3 ) 连接 词 ( 56 种 ) 单义 为 多 ( 44 ) , 多义 为 少 ( 12 ) , 义项 最多 为 5 , 分布 有 差异 。	研究 发现 : ( 1 ) 隐式 关系 ( 78.1%) 多 于 显式 关系 ( 21.9% ) , 17 类 关系 仅 有 四 类 ( 因果 、 转折 、 假设 、 目 的 ) 显多隐少 ; ( 2 ) 各类 关系 的 同义 连接 词 种数 与 使用 有 差异 , 其中 种数 最多 17 ( 顺承 ) , 最少 则无 ( 总分 、 背景 ) ; ( 3 ) 连接 词 ( 56 种 ) 单义 为 多 ( 44 ) , 多义 为 少 ( 12 ) , 义项 最多 为 5 , 分布 有 差异 。	1<2	elab-addition	elab-addition
nlpabs93_Chi	75-82	83-90	其中 种数 最多 17 ( 顺承 ) ,	最少 则无 ( 总分 、 背景 ) ;	23-122	23-122	研究 发现 : ( 1 ) 隐式 关系 ( 78.1%) 多 于 显式 关系 ( 21.9% ) , 17 类 关系 仅 有 四 类 ( 因果 、 转折 、 假设 、 目 的 ) 显多隐少 ; ( 2 ) 各类 关系 的 同义 连接 词 种数 与 使用 有 差异 , 其中 种数 最多 17 ( 顺承 ) , 最少 则无 ( 总分 、 背景 ) ; ( 3 ) 连接 词 ( 56 种 ) 单义 为 多 ( 44 ) , 多义 为 少 ( 12 ) , 义项 最多 为 5 , 分布 有 差异 。	研究 发现 : ( 1 ) 隐式 关系 ( 78.1%) 多 于 显式 关系 ( 21.9% ) , 17 类 关系 仅 有 四 类 ( 因果 、 转折 、 假设 、 目 的 ) 显多隐少 ; ( 2 ) 各类 关系 的 同义 连接 词 种数 与 使用 有 差异 , 其中 种数 最多 17 ( 顺承 ) , 最少 则无 ( 总分 、 背景 ) ; ( 3 ) 连接 词 ( 56 种 ) 单义 为 多 ( 44 ) , 多义 为 少 ( 12 ) , 义项 最多 为 5 , 分布 有 差异 。	1<2	joint	joint
nlpabs93_Chi	26-40	91-106	( 1 ) 隐式 关系 ( 78.1%) 多 于 显式 关系 ( 21.9% ) ,	( 3 ) 连接 词 ( 56 种 ) 单义 为 多 ( 44 ) ,	23-122	23-122	研究 发现 : ( 1 ) 隐式 关系 ( 78.1%) 多 于 显式 关系 ( 21.9% ) , 17 类 关系 仅 有 四 类 ( 因果 、 转折 、 假设 、 目 的 ) 显多隐少 ; ( 2 ) 各类 关系 的 同义 连接 词 种数 与 使用 有 差异 , 其中 种数 最多 17 ( 顺承 ) , 最少 则无 ( 总分 、 背景 ) ; ( 3 ) 连接 词 ( 56 种 ) 单义 为 多 ( 44 ) , 多义 为 少 ( 12 ) , 义项 最多 为 5 , 分布 有 差异 。	研究 发现 : ( 1 ) 隐式 关系 ( 78.1%) 多 于 显式 关系 ( 21.9% ) , 17 类 关系 仅 有 四 类 ( 因果 、 转折 、 假设 、 目 的 ) 显多隐少 ; ( 2 ) 各类 关系 的 同义 连接 词 种数 与 使用 有 差异 , 其中 种数 最多 17 ( 顺承 ) , 最少 则无 ( 总分 、 背景 ) ; ( 3 ) 连接 词 ( 56 种 ) 单义 为 多 ( 44 ) , 多义 为 少 ( 12 ) , 义项 最多 为 5 , 分布 有 差异 。	1<2	joint	joint
nlpabs93_Chi	91-106	107-113	( 3 ) 连接 词 ( 56 种 ) 单义 为 多 ( 44 ) ,	多义 为 少 ( 12 ) ,	23-122	23-122	研究 发现 : ( 1 ) 隐式 关系 ( 78.1%) 多 于 显式 关系 ( 21.9% ) , 17 类 关系 仅 有 四 类 ( 因果 、 转折 、 假设 、 目 的 ) 显多隐少 ; ( 2 ) 各类 关系 的 同义 连接 词 种数 与 使用 有 差异 , 其中 种数 最多 17 ( 顺承 ) , 最少 则无 ( 总分 、 背景 ) ; ( 3 ) 连接 词 ( 56 种 ) 单义 为 多 ( 44 ) , 多义 为 少 ( 12 ) , 义项 最多 为 5 , 分布 有 差异 。	研究 发现 : ( 1 ) 隐式 关系 ( 78.1%) 多 于 显式 关系 ( 21.9% ) , 17 类 关系 仅 有 四 类 ( 因果 、 转折 、 假设 、 目 的 ) 显多隐少 ; ( 2 ) 各类 关系 的 同义 连接 词 种数 与 使用 有 差异 , 其中 种数 最多 17 ( 顺承 ) , 最少 则无 ( 总分 、 背景 ) ; ( 3 ) 连接 词 ( 56 种 ) 单义 为 多 ( 44 ) , 多义 为 少 ( 12 ) , 义项 最多 为 5 , 分布 有 差异 。	1<2	joint	joint
nlpabs93_Chi	91-106	114-118	( 3 ) 连接 词 ( 56 种 ) 单义 为 多 ( 44 ) ,	义项 最多 为 5 ,	23-122	23-122	研究 发现 : ( 1 ) 隐式 关系 ( 78.1%) 多 于 显式 关系 ( 21.9% ) , 17 类 关系 仅 有 四 类 ( 因果 、 转折 、 假设 、 目 的 ) 显多隐少 ; ( 2 ) 各类 关系 的 同义 连接 词 种数 与 使用 有 差异 , 其中 种数 最多 17 ( 顺承 ) , 最少 则无 ( 总分 、 背景 ) ; ( 3 ) 连接 词 ( 56 种 ) 单义 为 多 ( 44 ) , 多义 为 少 ( 12 ) , 义项 最多 为 5 , 分布 有 差异 。	研究 发现 : ( 1 ) 隐式 关系 ( 78.1%) 多 于 显式 关系 ( 21.9% ) , 17 类 关系 仅 有 四 类 ( 因果 、 转折 、 假设 、 目 的 ) 显多隐少 ; ( 2 ) 各类 关系 的 同义 连接 词 种数 与 使用 有 差异 , 其中 种数 最多 17 ( 顺承 ) , 最少 则无 ( 总分 、 背景 ) ; ( 3 ) 连接 词 ( 56 种 ) 单义 为 多 ( 44 ) , 多义 为 少 ( 12 ) , 义项 最多 为 5 , 分布 有 差异 。	1<2	joint	joint
nlpabs93_Chi	91-106	119-122	( 3 ) 连接 词 ( 56 种 ) 单义 为 多 ( 44 ) ,	分布 有 差异 。	23-122	23-122	研究 发现 : ( 1 ) 隐式 关系 ( 78.1%) 多 于 显式 关系 ( 21.9% ) , 17 类 关系 仅 有 四 类 ( 因果 、 转折 、 假设 、 目 的 ) 显多隐少 ; ( 2 ) 各类 关系 的 同义 连接 词 种数 与 使用 有 差异 , 其中 种数 最多 17 ( 顺承 ) , 最少 则无 ( 总分 、 背景 ) ; ( 3 ) 连接 词 ( 56 种 ) 单义 为 多 ( 44 ) , 多义 为 少 ( 12 ) , 义项 最多 为 5 , 分布 有 差异 。	研究 发现 : ( 1 ) 隐式 关系 ( 78.1%) 多 于 显式 关系 ( 21.9% ) , 17 类 关系 仅 有 四 类 ( 因果 、 转折 、 假设 、 目 的 ) 显多隐少 ; ( 2 ) 各类 关系 的 同义 连接 词 种数 与 使用 有 差异 , 其中 种数 最多 17 ( 顺承 ) , 最少 则无 ( 总分 、 背景 ) ; ( 3 ) 连接 词 ( 56 种 ) 单义 为 多 ( 44 ) , 多义 为 少 ( 12 ) , 义项 最多 为 5 , 分布 有 差异 。	1<2	joint	joint
nlpabs93_Chi	1-9	123-137	标注 《 文心 雕龙 》 的 篇章 结构 ,	最后 , 个案 分析 同义 连接 词 与 多 义 连接 词 的 用法 ,	1-22	123-149	标注 《 文心 雕龙 》 的 篇章 结构 , 据 此 研究 其 连接 词 的 显隐 、 语义 及 用法 。	最后 , 个案 分析 同义 连接 词 与 多 义 连接 词 的 用法 , 并 与 同 时期 著作 连接 词 的 使用 进行 了 对比	1<2	elab-addition	elab-addition
nlpabs93_Chi	123-137	138-149	最后 , 个案 分析 同义 连接 词 与 多 义 连接 词 的 用法 ,	并 与 同 时期 著作 连接 词 的 使用 进行 了 对比	123-149	123-149	最后 , 个案 分析 同义 连接 词 与 多 义 连接 词 的 用法 , 并 与 同 时期 著作 连接 词 的 使用 进行 了 对比	最后 , 个案 分析 同义 连接 词 与 多 义 连接 词 的 用法 , 并 与 同 时期 著作 连接 词 的 使用 进行 了 对比	1<2	joint	joint
nlpabs94_Chi	1-11	22-38	该文 以 126 名 中国 大学 生 为 测试 样本 ,	讨论 英 语 花园 幽径 句 解码 效果 与 解码 反应 时 之间 的 关联 性 。	1-38	1-38	该文 以 126 名 中国 大学 生 为 测试 样本 , 并 采用 非 独立 t 检验 为 计算 方法 , 讨论 英 语 花园 幽径 句 解码 效果 与 解码 反应 时 之间 的 关联 性 。	该文 以 126 名 中国 大学 生 为 测试 样本 , 并 采用 非 独立 t 检验 为 计算 方法 , 讨论 英 语 花园 幽径 句 解码 效果 与 解码 反应 时 之间 的 关联 性 。	1>2	bg-general	bg-general
nlpabs94_Chi	12-21	22-38	并 采用 非 独立 t 检验 为 计算 方法 ,	讨论 英 语 花园 幽径 句 解码 效果 与 解码 反应 时 之间 的 关联 性 。	1-38	1-38	该文 以 126 名 中国 大学 生 为 测试 样本 , 并 采用 非 独立 t 检验 为 计算 方法 , 讨论 英 语 花园 幽径 句 解码 效果 与 解码 反应 时 之间 的 关联 性 。	该文 以 126 名 中国 大学 生 为 测试 样本 , 并 采用 非 独立 t 检验 为 计算 方法 , 讨论 英 语 花园 幽径 句 解码 效果 与 解码 反应 时 之间 的 关联 性 。	1>2	manner-means	manner-means
nlpabs94_Chi	22-38	39-51	讨论 英 语 花园 幽径 句 解码 效果 与 解码 反应 时 之间 的 关联 性 。	花园 幽径 句 是 能 引发 行进 错位 的 局部 歧义 句 ,	1-38	39-63	该文 以 126 名 中国 大学 生 为 测试 样本 , 并 采用 非 独立 t 检验 为 计算 方法 , 讨论 英 语 花园 幽径 句 解码 效果 与 解码 反应 时 之间 的 关联 性 。	花园 幽径 句 是 能 引发 行进 错位 的 局部 歧义 句 , 大学 生 在 歧义 消解 过程 中 易 产生 认知 困惑 。	1<2	elab-addition	elab-addition
nlpabs94_Chi	39-51	52-63	花园 幽径 句 是 能 引发 行进 错位 的 局部 歧义 句 ,	大学 生 在 歧义 消解 过程 中 易 产生 认知 困惑 。	39-63	39-63	花园 幽径 句 是 能 引发 行进 错位 的 局部 歧义 句 , 大学 生 在 歧义 消解 过程 中 易 产生 认知 困惑 。	花园 幽径 句 是 能 引发 行进 错位 的 局部 歧义 句 , 大学 生 在 歧义 消解 过程 中 易 产生 认知 困惑 。	1<2	elab-addition	elab-addition
nlpabs94_Chi	64-71	72-93	在 其他 条件 不变 的 情况 下 ,	先后 两 次 的 语言 实验 将 单样 本 花园 幽径 句 的 反应 时 从 5s 延长 至 10 s ,	64-101	64-101	在 其他 条件 不变 的 情况 下 , 先后 两 次 的 语言 实验 将 单样 本 花园 幽径 句 的 反应 时 从 5s 延长 至 10 s , 并 进行 了 相应 的 t值 计算 。	在 其他 条件 不变 的 情况 下 , 先后 两 次 的 语言 实验 将 单样 本 花园 幽径 句 的 反应 时 从 5s 延长 至 10 s , 并 进行 了 相应 的 t值 计算 。	1>2	bg-general	bg-general
nlpabs94_Chi	22-38	72-93	讨论 英 语 花园 幽径 句 解码 效果 与 解码 反应 时 之间 的 关联 性 。	先后 两 次 的 语言 实验 将 单样 本 花园 幽径 句 的 反应 时 从 5s 延长 至 10 s ,	1-38	64-101	该文 以 126 名 中国 大学 生 为 测试 样本 , 并 采用 非 独立 t 检验 为 计算 方法 , 讨论 英 语 花园 幽径 句 解码 效果 与 解码 反应 时 之间 的 关联 性 。	在 其他 条件 不变 的 情况 下 , 先后 两 次 的 语言 实验 将 单样 本 花园 幽径 句 的 反应 时 从 5s 延长 至 10 s , 并 进行 了 相应 的 t值 计算 。	1<2	elab-addition	elab-addition
nlpabs94_Chi	72-93	94-101	先后 两 次 的 语言 实验 将 单样 本 花园 幽径 句 的 反应 时 从 5s 延长 至 10 s ,	并 进行 了 相应 的 t值 计算 。	64-101	64-101	在 其他 条件 不变 的 情况 下 , 先后 两 次 的 语言 实验 将 单样 本 花园 幽径 句 的 反应 时 从 5s 延长 至 10 s , 并 进行 了 相应 的 t值 计算 。	在 其他 条件 不变 的 情况 下 , 先后 两 次 的 语言 实验 将 单样 本 花园 幽径 句 的 反应 时 从 5s 延长 至 10 s , 并 进行 了 相应 的 t值 计算 。	1<2	joint	joint
nlpabs94_Chi	94-101	102-122	并 进行 了 相应 的 t值 计算 。	S1 实验 中 , 测定 5s 反应 时 和 10s 反应 时 的 非 独立 t 检验 值 为 3.71 ,	64-101	102-133	在 其他 条件 不变 的 情况 下 , 先后 两 次 的 语言 实验 将 单样 本 花园 幽径 句 的 反应 时 从 5s 延长 至 10 s , 并 进行 了 相应 的 t值 计算 。	S1 实验 中 , 测定 5s 反应 时 和 10s 反应 时 的 非 独立 t 检验 值 为 3.71 , 大 于 理论 临界 值 并 具有 显著 性 差异 。	1<2	elab-addition	elab-addition
nlpabs94_Chi	102-122	123-133	S1 实验 中 , 测定 5s 反应 时 和 10s 反应 时 的 非 独立 t 检验 值 为 3.71 ,	大 于 理论 临界 值 并 具有 显著 性 差异 。	102-133	102-133	S1 实验 中 , 测定 5s 反应 时 和 10s 反应 时 的 非 独立 t 检验 值 为 3.71 , 大 于 理论 临界 值 并 具有 显著 性 差异 。	S1 实验 中 , 测定 5s 反应 时 和 10s 反应 时 的 非 独立 t 检验 值 为 3.71 , 大 于 理论 临界 值 并 具有 显著 性 差异 。	1<2	elab-addition	elab-addition
nlpabs94_Chi	102-122	134-152	S1 实验 中 , 测定 5s 反应 时 和 10s 反应 时 的 非 独立 t 检验 值 为 3.71 ,	在 S2 - S100 的 实验 中 , 分析 发现 材料 的 选择 对 实验 结果 有 影响 。	102-133	134-152	S1 实验 中 , 测定 5s 反应 时 和 10s 反应 时 的 非 独立 t 检验 值 为 3.71 , 大 于 理论 临界 值 并 具有 显著 性 差异 。	在 S2 - S100 的 实验 中 , 分析 发现 材料 的 选择 对 实验 结果 有 影响 。	1<2	joint	joint
nlpabs94_Chi	22-38	153-173	讨论 英 语 花园 幽径 句 解码 效果 与 解码 反应 时 之间 的 关联 性 。	总体 而 言 , 英 语 花园 幽径 句 解码 效果 与 解码 反应 时 之间 具有 一定 关联 性 ,	1-38	153-189	该文 以 126 名 中国 大学 生 为 测试 样本 , 并 采用 非 独立 t 检验 为 计算 方法 , 讨论 英 语 花园 幽径 句 解码 效果 与 解码 反应 时 之间 的 关联 性 。	总体 而 言 , 英 语 花园 幽径 句 解码 效果 与 解码 反应 时 之间 具有 一定 关联 性 , 阅读 时间 的 延长 可以 在 一定 程度 上 帮助 学生 更好 地 消解 局部 歧义	1<2	summary	summary
nlpabs94_Chi	153-173	174-189	总体 而 言 , 英 语 花园 幽径 句 解码 效果 与 解码 反应 时 之间 具有 一定 关联 性 ,	阅读 时间 的 延长 可以 在 一定 程度 上 帮助 学生 更好 地 消解 局部 歧义	153-189	153-189	总体 而 言 , 英 语 花园 幽径 句 解码 效果 与 解码 反应 时 之间 具有 一定 关联 性 , 阅读 时间 的 延长 可以 在 一定 程度 上 帮助 学生 更好 地 消解 局部 歧义	总体 而 言 , 英 语 花园 幽径 句 解码 效果 与 解码 反应 时 之间 具有 一定 关联 性 , 阅读 时间 的 延长 可以 在 一定 程度 上 帮助 学生 更好 地 消解 局部 歧义	1<2	elab-addition	elab-addition
nlpabs95_Chi	1-21	102-116	随 着 深度 学习 技术 的 兴起 , 自然 语言 处理 与 计算 机 视觉 领域 呈现相 结合 的 趋势 。	该文 详细 介绍 了 这 三 类 方法 各自 具有 代表 性 的 工作 ,	1-21	102-165	随 着 深度 学习 技术 的 兴起 , 自然 语言 处理 与 计算 机 视觉 领域 呈现相 结合 的 趋势 。	该文 详细 介绍 了 这 三 类 方法 各自 具有 代表 性 的 工作 , 并 进 一 步 分析 了 各 方法 的 优劣 ; 然后 对 图像 文本 描述 方法 的 相关 数据 集 、 评测 标准 和 主要 开源 工具 包 进行 了 阐述 ; 最后 , 分析 了 图像 的 文本 描述 中 需要 解决 的 关键 技术 问题 。	1>2	bg-general	bg-general
nlpabs95_Chi	1-21	22-57	随 着 深度 学习 技术 的 兴起 , 自然 语言 处理 与 计算 机 视觉 领域 呈现相 结合 的 趋势 。	作 为 融合 视觉 和 语言 的 多 模态 研究 任务 , 图像 的 文本 描述 可 应 用 于 基 于 文本 内容 的 图像 检索 、 网络 图像 分析 等 众多 场景 中 ,	1-21	22-69	随 着 深度 学习 技术 的 兴起 , 自然 语言 处理 与 计算 机 视觉 领域 呈现相 结合 的 趋势 。	作 为 融合 视觉 和 语言 的 多 模态 研究 任务 , 图像 的 文本 描述 可 应 用 于 基 于 文本 内容 的 图像 检索 、 网络 图像 分析 等 众多 场景 中 , 从而 受到 了 研究 界 和 企业 界 的 广泛 关注 。	1<2	elab-addition	elab-addition
nlpabs95_Chi	22-57	58-69	作 为 融合 视觉 和 语言 的 多 模态 研究 任务 , 图像 的 文本 描述 可 应 用 于 基 于 文本 内容 的 图像 检索 、 网络 图像 分析 等 众多 场景 中 ,	从而 受到 了 研究 界 和 企业 界 的 广泛 关注 。	22-69	22-69	作 为 融合 视觉 和 语言 的 多 模态 研究 任务 , 图像 的 文本 描述 可 应 用 于 基 于 文本 内容 的 图像 检索 、 网络 图像 分析 等 众多 场景 中 , 从而 受到 了 研究 界 和 企业 界 的 广泛 关注 。	作 为 融合 视觉 和 语言 的 多 模态 研究 任务 , 图像 的 文本 描述 可 应 用 于 基 于 文本 内容 的 图像 检索 、 网络 图像 分析 等 众多 场景 中 , 从而 受到 了 研究 界 和 企业 界 的 广泛 关注 。	1<2	elab-addition	elab-addition
nlpabs95_Chi	22-57	70-81	作 为 融合 视觉 和 语言 的 多 模态 研究 任务 , 图像 的 文本 描述 可 应 用 于 基 于 文本 内容 的 图像 检索 、 网络 图像 分析 等 众多 场景 中 ,	图像 的 文本 描述 方法 可 归纳 为 三 大 类 :	22-69	70-101	作 为 融合 视觉 和 语言 的 多 模态 研究 任务 , 图像 的 文本 描述 可 应 用 于 基 于 文本 内容 的 图像 检索 、 网络 图像 分析 等 众多 场景 中 , 从而 受到 了 研究 界 和 企业 界 的 广泛 关注 。	图像 的 文本 描述 方法 可 归纳 为 三 大 类 : 基 于 生成 的 方法 、 基 于 检索 的 方法 和 基 于 编码 — 解码 的 方法 。	1<2	elab-addition	elab-addition
nlpabs95_Chi	70-81	82-101	图像 的 文本 描述 方法 可 归纳 为 三 大 类 :	基 于 生成 的 方法 、 基 于 检索 的 方法 和 基 于 编码 — 解码 的 方法 。	70-101	70-101	图像 的 文本 描述 方法 可 归纳 为 三 大 类 : 基 于 生成 的 方法 、 基 于 检索 的 方法 和 基 于 编码 — 解码 的 方法 。	图像 的 文本 描述 方法 可 归纳 为 三 大 类 : 基 于 生成 的 方法 、 基 于 检索 的 方法 和 基 于 编码 — 解码 的 方法 。	1<2	elab-enumember	elab-enumember
nlpabs95_Chi	102-116	117-127	该文 详细 介绍 了 这 三 类 方法 各自 具有 代表 性 的 工作 ,	并 进 一 步 分析 了 各 方法 的 优劣 ;	102-165	102-165	该文 详细 介绍 了 这 三 类 方法 各自 具有 代表 性 的 工作 , 并 进 一 步 分析 了 各 方法 的 优劣 ; 然后 对 图像 文本 描述 方法 的 相关 数据 集 、 评测 标准 和 主要 开源 工具 包 进行 了 阐述 ; 最后 , 分析 了 图像 的 文本 描述 中 需要 解决 的 关键 技术 问题 。	该文 详细 介绍 了 这 三 类 方法 各自 具有 代表 性 的 工作 , 并 进 一 步 分析 了 各 方法 的 优劣 ; 然后 对 图像 文本 描述 方法 的 相关 数据 集 、 评测 标准 和 主要 开源 工具 包 进行 了 阐述 ; 最后 , 分析 了 图像 的 文本 描述 中 需要 解决 的 关键 技术 问题 。	1<2	progression	progression
nlpabs95_Chi	102-116	128-149	该文 详细 介绍 了 这 三 类 方法 各自 具有 代表 性 的 工作 ,	然后 对 图像 文本 描述 方法 的 相关 数据 集 、 评测 标准 和 主要 开源 工具 包 进行 了 阐述 ;	102-165	102-165	该文 详细 介绍 了 这 三 类 方法 各自 具有 代表 性 的 工作 , 并 进 一 步 分析 了 各 方法 的 优劣 ; 然后 对 图像 文本 描述 方法 的 相关 数据 集 、 评测 标准 和 主要 开源 工具 包 进行 了 阐述 ; 最后 , 分析 了 图像 的 文本 描述 中 需要 解决 的 关键 技术 问题 。	该文 详细 介绍 了 这 三 类 方法 各自 具有 代表 性 的 工作 , 并 进 一 步 分析 了 各 方法 的 优劣 ; 然后 对 图像 文本 描述 方法 的 相关 数据 集 、 评测 标准 和 主要 开源 工具 包 进行 了 阐述 ; 最后 , 分析 了 图像 的 文本 描述 中 需要 解决 的 关键 技术 问题 。	1<2	joint	joint
nlpabs95_Chi	102-116	150-165	该文 详细 介绍 了 这 三 类 方法 各自 具有 代表 性 的 工作 ,	最后 , 分析 了 图像 的 文本 描述 中 需要 解决 的 关键 技术 问题 。	102-165	102-165	该文 详细 介绍 了 这 三 类 方法 各自 具有 代表 性 的 工作 , 并 进 一 步 分析 了 各 方法 的 优劣 ; 然后 对 图像 文本 描述 方法 的 相关 数据 集 、 评测 标准 和 主要 开源 工具 包 进行 了 阐述 ; 最后 , 分析 了 图像 的 文本 描述 中 需要 解决 的 关键 技术 问题 。	该文 详细 介绍 了 这 三 类 方法 各自 具有 代表 性 的 工作 , 并 进 一 步 分析 了 各 方法 的 优劣 ; 然后 对 图像 文本 描述 方法 的 相关 数据 集 、 评测 标准 和 主要 开源 工具 包 进行 了 阐述 ; 最后 , 分析 了 图像 的 文本 描述 中 需要 解决 的 关键 技术 问题 。	1<2	joint	joint
nlpabs96_Chi	1-16	17-28	在 各类 在线 学习 系统 中 , 为了 给 学生 提供 优质 的 学习 服务 ,	一 个 基础 性 的 任务 是 试题 知识 点 预测 ,	1-42	1-42	在 各类 在线 学习 系统 中 , 为了 给 学生 提供 优质 的 学习 服务 , 一 个 基础 性 的 任务 是 试题 知识 点 预测 , 即 预测 一 道 试题 所 考察 的 知识 概念 、 能力 等 。	在 各类 在线 学习 系统 中 , 为了 给 学生 提供 优质 的 学习 服务 , 一 个 基础 性 的 任务 是 试题 知识 点 预测 , 即 预测 一 道 试题 所 考察 的 知识 概念 、 能力 等 。	1>2	enablement	enablement
nlpabs96_Chi	17-28	111-131	一 个 基础 性 的 任务 是 试题 知识 点 预测 ,	为 此 , 该文 提出 一 种 教研 知识 强化 的 卷积 神经 网络 方法 进行 试题 知识 点 预测 。	1-42	111-131	在 各类 在线 学习 系统 中 , 为了 给 学生 提供 优质 的 学习 服务 , 一 个 基础 性 的 任务 是 试题 知识 点 预测 , 即 预测 一 道 试题 所 考察 的 知识 概念 、 能力 等 。	为 此 , 该文 提出 一 种 教研 知识 强化 的 卷积 神经 网络 方法 进行 试题 知识 点 预测 。	1>2	bg-general	bg-general
nlpabs96_Chi	17-28	29-42	一 个 基础 性 的 任务 是 试题 知识 点 预测 ,	即 预测 一 道 试题 所 考察 的 知识 概念 、 能力 等 。	1-42	1-42	在 各类 在线 学习 系统 中 , 为了 给 学生 提供 优质 的 学习 服务 , 一 个 基础 性 的 任务 是 试题 知识 点 预测 , 即 预测 一 道 试题 所 考察 的 知识 概念 、 能力 等 。	在 各类 在线 学习 系统 中 , 为了 给 学生 提供 优质 的 学习 服务 , 一 个 基础 性 的 任务 是 试题 知识 点 预测 , 即 预测 一 道 试题 所 考察 的 知识 概念 、 能力 等 。	1<2	elab-addition	elab-addition
nlpabs96_Chi	17-28	43-63	一 个 基础 性 的 任务 是 试题 知识 点 预测 ,	在 这 个 任务 中 , 已 有 方法 通常 基 于 人工 专家 标注 或者 传统 机器 学习 方法 。	1-42	43-63	在 各类 在线 学习 系统 中 , 为了 给 学生 提供 优质 的 学习 服务 , 一 个 基础 性 的 任务 是 试题 知识 点 预测 , 即 预测 一 道 试题 所 考察 的 知识 概念 、 能力 等 。	在 这 个 任务 中 , 已 有 方法 通常 基 于 人工 专家 标注 或者 传统 机器 学习 方法 。	1<2	elab-addition	elab-addition
nlpabs96_Chi	43-63	64-72	在 这 个 任务 中 , 已 有 方法 通常 基 于 人工 专家 标注 或者 传统 机器 学习 方法 。	然而 , 这些 传统 方法 要么 耗时 耗力 ,	43-63	64-94	在 这 个 任务 中 , 已 有 方法 通常 基 于 人工 专家 标注 或者 传统 机器 学习 方法 。	然而 , 这些 传统 方法 要么 耗时 耗力 , 要么 仅 关注 试题 资源 的 浅层 特征 , 忽略 了 试题 文本 和 知识 点 之间 的 深层 语义 关联 。	1<2	elab-addition	elab-addition
nlpabs96_Chi	64-72	73-81	然而 , 这些 传统 方法 要么 耗时 耗力 ,	要么 仅 关注 试题 资源 的 浅层 特征 ,	64-94	64-94	然而 , 这些 传统 方法 要么 耗时 耗力 , 要么 仅 关注 试题 资源 的 浅层 特征 , 忽略 了 试题 文本 和 知识 点 之间 的 深层 语义 关联 。	然而 , 这些 传统 方法 要么 耗时 耗力 , 要么 仅 关注 试题 资源 的 浅层 特征 , 忽略 了 试题 文本 和 知识 点 之间 的 深层 语义 关联 。	1<2	joint	joint
nlpabs96_Chi	73-81	82-94	要么 仅 关注 试题 资源 的 浅层 特征 ,	忽略 了 试题 文本 和 知识 点 之间 的 深层 语义 关联 。	64-94	64-94	然而 , 这些 传统 方法 要么 耗时 耗力 , 要么 仅 关注 试题 资源 的 浅层 特征 , 忽略 了 试题 文本 和 知识 点 之间 的 深层 语义 关联 。	然而 , 这些 传统 方法 要么 耗时 耗力 , 要么 仅 关注 试题 资源 的 浅层 特征 , 忽略 了 试题 文本 和 知识 点 之间 的 深层 语义 关联 。	1<2	elab-addition	elab-addition
nlpabs96_Chi	64-72	95-110	然而 , 这些 传统 方法 要么 耗时 耗力 ,	因 此 , 这 两 类 方法 在 实际 应用 中 均 受到 了 限制 。	64-94	95-110	然而 , 这些 传统 方法 要么 耗时 耗力 , 要么 仅 关注 试题 资源 的 浅层 特征 , 忽略 了 试题 文本 和 知识 点 之间 的 深层 语义 关联 。	因 此 , 这 两 类 方法 在 实际 应用 中 均 受到 了 限制 。	1<2	result	result
nlpabs96_Chi	132-138	139-146	首先 , 结合 教育 学 经验 ,	定义 和 抽取 试题 的 浅层 特征 。	132-146	132-146	首先 , 结合 教育 学 经验 , 定义 和 抽取 试题 的 浅层 特征 。	首先 , 结合 教育 学 经验 , 定义 和 抽取 试题 的 浅层 特征 。	1>2	manner-means	manner-means
nlpabs96_Chi	111-131	139-146	为 此 , 该文 提出 一 种 教研 知识 强化 的 卷积 神经 网络 方法 进行 试题 知识 点 预测 。	定义 和 抽取 试题 的 浅层 特征 。	111-131	132-146	为 此 , 该文 提出 一 种 教研 知识 强化 的 卷积 神经 网络 方法 进行 试题 知识 点 预测 。	首先 , 结合 教育 学 经验 , 定义 和 抽取 试题 的 浅层 特征 。	1<2	elab-process_step	elab-process_step
nlpabs96_Chi	139-146	147-154	定义 和 抽取 试题 的 浅层 特征 。	然后 , 利用 一 个 卷积 神经 网络	132-146	147-164	首先 , 结合 教育 学 经验 , 定义 和 抽取 试题 的 浅层 特征 。	然后 , 利用 一 个 卷积 神经 网络 对 试题 的 深层 语义 进行 理解 和 表征 。	1<2	joint	joint
nlpabs96_Chi	147-154	155-164	然后 , 利用 一 个 卷积 神经 网络	对 试题 的 深层 语义 进行 理解 和 表征 。	147-164	147-164	然后 , 利用 一 个 卷积 神经 网络 对 试题 的 深层 语义 进行 理解 和 表征 。	然后 , 利用 一 个 卷积 神经 网络 对 试题 的 深层 语义 进行 理解 和 表征 。	1<2	enablement	enablement
nlpabs96_Chi	147-154	165-177	然后 , 利用 一 个 卷积 神经 网络	然后 , 考虑 到 教研 先验 与 试题 词句 之间 的 关联 ,	147-164	165-202	然后 , 利用 一 个 卷积 神经 网络 对 试题 的 深层 语义 进行 理解 和 表征 。	然后 , 考虑 到 教研 先验 与 试题 词句 之间 的 关联 , 提出 一 种 基 于 注意 力 机制 的 方法 能够 自动 识别 和 计算 不同 教研 先验 对 试题 的 重要 性 程度 。	1<2	joint	joint
nlpabs96_Chi	165-177	178-187	然后 , 考虑 到 教研 先验 与 试题 词句 之间 的 关联 ,	提出 一 种 基 于 注意 力 机制 的 方法	165-202	165-202	然后 , 考虑 到 教研 先验 与 试题 词句 之间 的 关联 , 提出 一 种 基 于 注意 力 机制 的 方法 能够 自动 识别 和 计算 不同 教研 先验 对 试题 的 重要 性 程度 。	然后 , 考虑 到 教研 先验 与 试题 词句 之间 的 关联 , 提出 一 种 基 于 注意 力 机制 的 方法 能够 自动 识别 和 计算 不同 教研 先验 对 试题 的 重要 性 程度 。	1<2	elab-addition	elab-addition
nlpabs96_Chi	178-187	188-202	提出 一 种 基 于 注意 力 机制 的 方法	能够 自动 识别 和 计算 不同 教研 先验 对 试题 的 重要 性 程度 。	165-202	165-202	然后 , 考虑 到 教研 先验 与 试题 词句 之间 的 关联 , 提出 一 种 基 于 注意 力 机制 的 方法 能够 自动 识别 和 计算 不同 教研 先验 对 试题 的 重要 性 程度 。	然后 , 考虑 到 教研 先验 与 试题 词句 之间 的 关联 , 提出 一 种 基 于 注意 力 机制 的 方法 能够 自动 识别 和 计算 不同 教研 先验 对 试题 的 重要 性 程度 。	1<2	elab-addition	elab-addition
nlpabs96_Chi	165-177	203-221	然后 , 考虑 到 教研 先验 与 试题 词句 之间 的 关联 ,	最后 , 设计 了 一 个 融合 知识 点 决策 和 试题 语义 约束 的 模型 训练 目标 。	165-202	203-221	然后 , 考虑 到 教研 先验 与 试题 词句 之间 的 关联 , 提出 一 种 基 于 注意 力 机制 的 方法 能够 自动 识别 和 计算 不同 教研 先验 对 试题 的 重要 性 程度 。	最后 , 设计 了 一 个 融合 知识 点 决策 和 试题 语义 约束 的 模型 训练 目标 。	1<2	joint	joint
nlpabs96_Chi	111-131	222-233	为 此 , 该文 提出 一 种 教研 知识 强化 的 卷积 神经 网络 方法 进行 试题 知识 点 预测 。	该文 在 大 规模 数据 上 进行 了 充分 的 实验 。	111-131	222-233	为 此 , 该文 提出 一 种 教研 知识 强化 的 卷积 神经 网络 方法 进行 试题 知识 点 预测 。	该文 在 大 规模 数据 上 进行 了 充分 的 实验 。	1<2	evaluation	evaluation
nlpabs96_Chi	234-237	238-250	实验 结果 表明 ,	所 提出 的 方法 能够 有效 地 进行 试题 知识 点 预测 ,	234-256	234-256	实验 结果 表明 , 所 提出 的 方法 能够 有效 地 进行 试题 知识 点 预测 , 具有 很好 的 应用 价值 。	实验 结果 表明 , 所 提出 的 方法 能够 有效 地 进行 试题 知识 点 预测 , 具有 很好 的 应用 价值 。	1>2	root	root
nlpabs96_Chi	222-233	238-250	该文 在 大 规模 数据 上 进行 了 充分 的 实验 。	所 提出 的 方法 能够 有效 地 进行 试题 知识 点 预测 ,	222-233	234-256	该文 在 大 规模 数据 上 进行 了 充分 的 实验 。	实验 结果 表明 , 所 提出 的 方法 能够 有效 地 进行 试题 知识 点 预测 , 具有 很好 的 应用 价值 。	1<2	elab-addition	elab-addition
nlpabs96_Chi	238-250	251-256	所 提出 的 方法 能够 有效 地 进行 试题 知识 点 预测 ,	具有 很好 的 应用 价值 。	234-256	234-256	实验 结果 表明 , 所 提出 的 方法 能够 有效 地 进行 试题 知识 点 预测 , 具有 很好 的 应用 价值 。	实验 结果 表明 , 所 提出 的 方法 能够 有效 地 进行 试题 知识 点 预测 , 具有 很好 的 应用 价值 。	1<2	progression	progression
nlpabs97_Chi	1-20	43-57	交互 式 问答 是 一 种 对话 式 的 、 连续 的 、 前后 关联 的 信息 交互 形式 ,	该文 归纳 分析 了 交互 式 问答 中 的 对话 行为 和 语句 关系 ,	1-42	43-136	交互 式 问答 是 一 种 对话 式 的 、 连续 的 、 前后 关联 的 信息 交互 形式 , 交互 式 问答 的 关系 结构 直接 体现 了 交互 式 场景 在 不同 语言 层面 上 的 上下 文 关联 。	该文 归纳 分析 了 交互 式 问答 中 的 对话 行为 和 语句 关系 , 在 此 基础 上 提出 了 对应 的 关系 结构 体系 ; 为了 验证 类别 体系 的 合理 性 , 对 真实 环境 中 的 交互 式 问答 语料 进行 了 对话 行为 标注 和 上下 文 语句 关系 标注 ; 并 针 对 交互 式 问答 的 关系 结构 , 采用 隐马尔可夫 模型 总结 分析 了 交互 式 问答 中 对话 行为 的 变化 规律 , 统计 分析 了 交互 式 问答 的 语句 关系 结构 特点 。	1>2	bg-general	bg-general
nlpabs97_Chi	1-20	21-42	交互 式 问答 是 一 种 对话 式 的 、 连续 的 、 前后 关联 的 信息 交互 形式 ,	交互 式 问答 的 关系 结构 直接 体现 了 交互 式 场景 在 不同 语言 层面 上 的 上下 文 关联 。	1-42	1-42	交互 式 问答 是 一 种 对话 式 的 、 连续 的 、 前后 关联 的 信息 交互 形式 , 交互 式 问答 的 关系 结构 直接 体现 了 交互 式 场景 在 不同 语言 层面 上 的 上下 文 关联 。	交互 式 问答 是 一 种 对话 式 的 、 连续 的 、 前后 关联 的 信息 交互 形式 , 交互 式 问答 的 关系 结构 直接 体现 了 交互 式 场景 在 不同 语言 层面 上 的 上下 文 关联 。	1<2	elab-addition	elab-addition
nlpabs97_Chi	43-57	58-69	该文 归纳 分析 了 交互 式 问答 中 的 对话 行为 和 语句 关系 ,	在 此 基础 上 提出 了 对应 的 关系 结构 体系 ;	43-136	43-136	该文 归纳 分析 了 交互 式 问答 中 的 对话 行为 和 语句 关系 , 在 此 基础 上 提出 了 对应 的 关系 结构 体系 ; 为了 验证 类别 体系 的 合理 性 , 对 真实 环境 中 的 交互 式 问答 语料 进行 了 对话 行为 标注 和 上下 文 语句 关系 标注 ; 并 针 对 交互 式 问答 的 关系 结构 , 采用 隐马尔可夫 模型 总结 分析 了 交互 式 问答 中 对话 行为 的 变化 规律 , 统计 分析 了 交互 式 问答 的 语句 关系 结构 特点 。	该文 归纳 分析 了 交互 式 问答 中 的 对话 行为 和 语句 关系 , 在 此 基础 上 提出 了 对应 的 关系 结构 体系 ; 为了 验证 类别 体系 的 合理 性 , 对 真实 环境 中 的 交互 式 问答 语料 进行 了 对话 行为 标注 和 上下 文 语句 关系 标注 ; 并 针 对 交互 式 问答 的 关系 结构 , 采用 隐马尔可夫 模型 总结 分析 了 交互 式 问答 中 对话 行为 的 变化 规律 , 统计 分析 了 交互 式 问答 的 语句 关系 结构 特点 。	1<2	progression	progression
nlpabs97_Chi	70-77	78-98	为了 验证 类别 体系 的 合理 性 ,	对 真实 环境 中 的 交互 式 问答 语料 进行 了 对话 行为 标注 和 上下 文 语句 关系 标注 ;	43-136	43-136	该文 归纳 分析 了 交互 式 问答 中 的 对话 行为 和 语句 关系 , 在 此 基础 上 提出 了 对应 的 关系 结构 体系 ; 为了 验证 类别 体系 的 合理 性 , 对 真实 环境 中 的 交互 式 问答 语料 进行 了 对话 行为 标注 和 上下 文 语句 关系 标注 ; 并 针 对 交互 式 问答 的 关系 结构 , 采用 隐马尔可夫 模型 总结 分析 了 交互 式 问答 中 对话 行为 的 变化 规律 , 统计 分析 了 交互 式 问答 的 语句 关系 结构 特点 。	该文 归纳 分析 了 交互 式 问答 中 的 对话 行为 和 语句 关系 , 在 此 基础 上 提出 了 对应 的 关系 结构 体系 ; 为了 验证 类别 体系 的 合理 性 , 对 真实 环境 中 的 交互 式 问答 语料 进行 了 对话 行为 标注 和 上下 文 语句 关系 标注 ; 并 针 对 交互 式 问答 的 关系 结构 , 采用 隐马尔可夫 模型 总结 分析 了 交互 式 问答 中 对话 行为 的 变化 规律 , 统计 分析 了 交互 式 问答 的 语句 关系 结构 特点 。	1>2	enablement	enablement
nlpabs97_Chi	43-57	78-98	该文 归纳 分析 了 交互 式 问答 中 的 对话 行为 和 语句 关系 ,	对 真实 环境 中 的 交互 式 问答 语料 进行 了 对话 行为 标注 和 上下 文 语句 关系 标注 ;	43-136	43-136	该文 归纳 分析 了 交互 式 问答 中 的 对话 行为 和 语句 关系 , 在 此 基础 上 提出 了 对应 的 关系 结构 体系 ; 为了 验证 类别 体系 的 合理 性 , 对 真实 环境 中 的 交互 式 问答 语料 进行 了 对话 行为 标注 和 上下 文 语句 关系 标注 ; 并 针 对 交互 式 问答 的 关系 结构 , 采用 隐马尔可夫 模型 总结 分析 了 交互 式 问答 中 对话 行为 的 变化 规律 , 统计 分析 了 交互 式 问答 的 语句 关系 结构 特点 。	该文 归纳 分析 了 交互 式 问答 中 的 对话 行为 和 语句 关系 , 在 此 基础 上 提出 了 对应 的 关系 结构 体系 ; 为了 验证 类别 体系 的 合理 性 , 对 真实 环境 中 的 交互 式 问答 语料 进行 了 对话 行为 标注 和 上下 文 语句 关系 标注 ; 并 针 对 交互 式 问答 的 关系 结构 , 采用 隐马尔可夫 模型 总结 分析 了 交互 式 问答 中 对话 行为 的 变化 规律 , 统计 分析 了 交互 式 问答 的 语句 关系 结构 特点 。	1<2	joint	joint
nlpabs97_Chi	99-108	112-124	并 针 对 交互 式 问答 的 关系 结构 ,	总结 分析 了 交互 式 问答 中 对话 行为 的 变化 规律 ,	43-136	43-136	该文 归纳 分析 了 交互 式 问答 中 的 对话 行为 和 语句 关系 , 在 此 基础 上 提出 了 对应 的 关系 结构 体系 ; 为了 验证 类别 体系 的 合理 性 , 对 真实 环境 中 的 交互 式 问答 语料 进行 了 对话 行为 标注 和 上下 文 语句 关系 标注 ; 并 针 对 交互 式 问答 的 关系 结构 , 采用 隐马尔可夫 模型 总结 分析 了 交互 式 问答 中 对话 行为 的 变化 规律 , 统计 分析 了 交互 式 问答 的 语句 关系 结构 特点 。	该文 归纳 分析 了 交互 式 问答 中 的 对话 行为 和 语句 关系 , 在 此 基础 上 提出 了 对应 的 关系 结构 体系 ; 为了 验证 类别 体系 的 合理 性 , 对 真实 环境 中 的 交互 式 问答 语料 进行 了 对话 行为 标注 和 上下 文 语句 关系 标注 ; 并 针 对 交互 式 问答 的 关系 结构 , 采用 隐马尔可夫 模型 总结 分析 了 交互 式 问答 中 对话 行为 的 变化 规律 , 统计 分析 了 交互 式 问答 的 语句 关系 结构 特点 。	1>2	bg-general	bg-general
nlpabs97_Chi	109-111	112-124	采用 隐马尔可夫 模型	总结 分析 了 交互 式 问答 中 对话 行为 的 变化 规律 ,	43-136	43-136	该文 归纳 分析 了 交互 式 问答 中 的 对话 行为 和 语句 关系 , 在 此 基础 上 提出 了 对应 的 关系 结构 体系 ; 为了 验证 类别 体系 的 合理 性 , 对 真实 环境 中 的 交互 式 问答 语料 进行 了 对话 行为 标注 和 上下 文 语句 关系 标注 ; 并 针 对 交互 式 问答 的 关系 结构 , 采用 隐马尔可夫 模型 总结 分析 了 交互 式 问答 中 对话 行为 的 变化 规律 , 统计 分析 了 交互 式 问答 的 语句 关系 结构 特点 。	该文 归纳 分析 了 交互 式 问答 中 的 对话 行为 和 语句 关系 , 在 此 基础 上 提出 了 对应 的 关系 结构 体系 ; 为了 验证 类别 体系 的 合理 性 , 对 真实 环境 中 的 交互 式 问答 语料 进行 了 对话 行为 标注 和 上下 文 语句 关系 标注 ; 并 针 对 交互 式 问答 的 关系 结构 , 采用 隐马尔可夫 模型 总结 分析 了 交互 式 问答 中 对话 行为 的 变化 规律 , 统计 分析 了 交互 式 问答 的 语句 关系 结构 特点 。	1>2	manner-means	manner-means
nlpabs97_Chi	43-57	112-124	该文 归纳 分析 了 交互 式 问答 中 的 对话 行为 和 语句 关系 ,	总结 分析 了 交互 式 问答 中 对话 行为 的 变化 规律 ,	43-136	43-136	该文 归纳 分析 了 交互 式 问答 中 的 对话 行为 和 语句 关系 , 在 此 基础 上 提出 了 对应 的 关系 结构 体系 ; 为了 验证 类别 体系 的 合理 性 , 对 真实 环境 中 的 交互 式 问答 语料 进行 了 对话 行为 标注 和 上下 文 语句 关系 标注 ; 并 针 对 交互 式 问答 的 关系 结构 , 采用 隐马尔可夫 模型 总结 分析 了 交互 式 问答 中 对话 行为 的 变化 规律 , 统计 分析 了 交互 式 问答 的 语句 关系 结构 特点 。	该文 归纳 分析 了 交互 式 问答 中 的 对话 行为 和 语句 关系 , 在 此 基础 上 提出 了 对应 的 关系 结构 体系 ; 为了 验证 类别 体系 的 合理 性 , 对 真实 环境 中 的 交互 式 问答 语料 进行 了 对话 行为 标注 和 上下 文 语句 关系 标注 ; 并 针 对 交互 式 问答 的 关系 结构 , 采用 隐马尔可夫 模型 总结 分析 了 交互 式 问答 中 对话 行为 的 变化 规律 , 统计 分析 了 交互 式 问答 的 语句 关系 结构 特点 。	1<2	joint	joint
nlpabs97_Chi	112-124	125-136	总结 分析 了 交互 式 问答 中 对话 行为 的 变化 规律 ,	统计 分析 了 交互 式 问答 的 语句 关系 结构 特点 。	43-136	43-136	该文 归纳 分析 了 交互 式 问答 中 的 对话 行为 和 语句 关系 , 在 此 基础 上 提出 了 对应 的 关系 结构 体系 ; 为了 验证 类别 体系 的 合理 性 , 对 真实 环境 中 的 交互 式 问答 语料 进行 了 对话 行为 标注 和 上下 文 语句 关系 标注 ; 并 针 对 交互 式 问答 的 关系 结构 , 采用 隐马尔可夫 模型 总结 分析 了 交互 式 问答 中 对话 行为 的 变化 规律 , 统计 分析 了 交互 式 问答 的 语句 关系 结构 特点 。	该文 归纳 分析 了 交互 式 问答 中 的 对话 行为 和 语句 关系 , 在 此 基础 上 提出 了 对应 的 关系 结构 体系 ; 为了 验证 类别 体系 的 合理 性 , 对 真实 环境 中 的 交互 式 问答 语料 进行 了 对话 行为 标注 和 上下 文 语句 关系 标注 ; 并 针 对 交互 式 问答 的 关系 结构 , 采用 隐马尔可夫 模型 总结 分析 了 交互 式 问答 中 对话 行为 的 变化 规律 , 统计 分析 了 交互 式 问答 的 语句 关系 结构 特点 。	1<2	joint	joint
nlpabs98_Chi	1-17	18-29	该文 提 出 面 向 文本 聚类 分析 的 实体 — 动作 关联 模 型 EARM ,	探讨 汉 语 语义 实体 及 其 行为 的 描述 方法 。	1-29	1-29	该文 提 出 面 向 文本 聚类 分析 的 实体 — 动作 关联 模 型 EARM , 探讨 汉 语 语义 实体 及 其 行为 的 描述 方法 。	该文 提 出 面 向 文本 聚类 分析 的 实体 — 动作 关联 模 型 EARM , 探讨 汉 语 语义 实体 及 其 行为 的 描述 方法 。	1<2	joint	joint
nlpabs98_Chi	30-37	60-68	汉 语 属 于 非 形态 语言 ,	该文 提出 一 种 句法 成分 识别 机制 ,	30-59	60-80	汉 语 属 于 非 形态 语言 , 语句 没有 时态 及 语态 的 变化 , 词类 跟 句法 成分 之间 也 不是 简单 的 一 一 对应 关系 。	该文 提出 一 种 句法 成分 识别 机制 , 根据 词汇 类别 特征 及 位置 特征 识别 实体 及 动作 。	1>2	bg-general	bg-general
nlpabs98_Chi	30-37	38-45	汉 语 属 于 非 形态 语言 ,	语句 没有 时态 及 语态 的 变化 ,	30-59	30-59	汉 语 属 于 非 形态 语言 , 语句 没有 时态 及 语态 的 变化 , 词类 跟 句法 成分 之间 也 不是 简单 的 一 一 对应 关系 。	汉 语 属 于 非 形态 语言 , 语句 没有 时态 及 语态 的 变化 , 词类 跟 句法 成分 之间 也 不是 简单 的 一 一 对应 关系 。	1<2	elab-addition	elab-addition
nlpabs98_Chi	38-45	46-59	语句 没有 时态 及 语态 的 变化 ,	词类 跟 句法 成分 之间 也 不是 简单 的 一 一 对应 关系 。	30-59	30-59	汉 语 属 于 非 形态 语言 , 语句 没有 时态 及 语态 的 变化 , 词类 跟 句法 成分 之间 也 不是 简单 的 一 一 对应 关系 。	汉 语 属 于 非 形态 语言 , 语句 没有 时态 及 语态 的 变化 , 词类 跟 句法 成分 之间 也 不是 简单 的 一 一 对应 关系 。	1<2	joint	joint
nlpabs98_Chi	1-17	60-68	该文 提 出 面 向 文本 聚类 分析 的 实体 — 动作 关联 模 型 EARM ,	该文 提出 一 种 句法 成分 识别 机制 ,	1-29	60-80	该文 提 出 面 向 文本 聚类 分析 的 实体 — 动作 关联 模 型 EARM , 探讨 汉 语 语义 实体 及 其 行为 的 描述 方法 。	该文 提出 一 种 句法 成分 识别 机制 , 根据 词汇 类别 特征 及 位置 特征 识别 实体 及 动作 。	1<2	elab-addition	elab-addition
nlpabs98_Chi	60-68	69-80	该文 提出 一 种 句法 成分 识别 机制 ,	根据 词汇 类别 特征 及 位置 特征 识别 实体 及 动作 。	60-80	60-80	该文 提出 一 种 句法 成分 识别 机制 , 根据 词汇 类别 特征 及 位置 特征 识别 实体 及 动作 。	该文 提出 一 种 句法 成分 识别 机制 , 根据 词汇 类别 特征 及 位置 特征 识别 实体 及 动作 。	1<2	elab-addition	elab-addition
nlpabs98_Chi	69-80	81-91	根据 词汇 类别 特征 及 位置 特征 识别 实体 及 动作 。	在 句法 成分 识别 的 基础 上 展开 句法 分析 ,	60-80	81-111	该文 提出 一 种 句法 成分 识别 机制 , 根据 词汇 类别 特征 及 位置 特征 识别 实体 及 动作 。	在 句法 成分 识别 的 基础 上 展开 句法 分析 , 通过 匹配 句型 特征 建立 实体 — 动作 关联 模 型 EARM , 描述 实体 的 行为 及 状态 。	1<2	elab-addition	elab-addition
nlpabs98_Chi	81-91	92-104	在 句法 成分 识别 的 基础 上 展开 句法 分析 ,	通过 匹配 句型 特征 建立 实体 — 动作 关联 模 型 EARM ,	81-111	81-111	在 句法 成分 识别 的 基础 上 展开 句法 分析 , 通过 匹配 句型 特征 建立 实体 — 动作 关联 模 型 EARM , 描述 实体 的 行为 及 状态 。	在 句法 成分 识别 的 基础 上 展开 句法 分析 , 通过 匹配 句型 特征 建立 实体 — 动作 关联 模 型 EARM , 描述 实体 的 行为 及 状态 。	1<2	elab-addition	elab-addition
nlpabs98_Chi	92-104	105-111	通过 匹配 句型 特征 建立 实体 — 动作 关联 模 型 EARM ,	描述 实体 的 行为 及 状态 。	81-111	81-111	在 句法 成分 识别 的 基础 上 展开 句法 分析 , 通过 匹配 句型 特征 建立 实体 — 动作 关联 模 型 EARM , 描述 实体 的 行为 及 状态 。	在 句法 成分 识别 的 基础 上 展开 句法 分析 , 通过 匹配 句型 特征 建立 实体 — 动作 关联 模 型 EARM , 描述 实体 的 行为 及 状态 。	1<2	enablement	enablement
nlpabs98_Chi	112-121	122-132	对于 嵌套 句型 等 较为 复杂 的 句型 结构 ,	需要 在 句法 分析 过程 中 实施 动作 层次 分解 ,	112-151	112-151	对于 嵌套 句型 等 较为 复杂 的 句型 结构 , 需要 在 句法 分析 过程 中 实施 动作 层次 分解 , 将 复杂 语句 分解 为 简单 的 基本 句型 , 以 便 于 挖掘 实体 — 动作 关联 。	对于 嵌套 句型 等 较为 复杂 的 句型 结构 , 需要 在 句法 分析 过程 中 实施 动作 层次 分解 , 将 复杂 语句 分解 为 简单 的 基本 句型 , 以 便 于 挖掘 实体 — 动作 关联 。	1>2	bg-general	bg-general
nlpabs98_Chi	81-91	122-132	在 句法 成分 识别 的 基础 上 展开 句法 分析 ,	需要 在 句法 分析 过程 中 实施 动作 层次 分解 ,	81-111	112-151	在 句法 成分 识别 的 基础 上 展开 句法 分析 , 通过 匹配 句型 特征 建立 实体 — 动作 关联 模 型 EARM , 描述 实体 的 行为 及 状态 。	对于 嵌套 句型 等 较为 复杂 的 句型 结构 , 需要 在 句法 分析 过程 中 实施 动作 层次 分解 , 将 复杂 语句 分解 为 简单 的 基本 句型 , 以 便 于 挖掘 实体 — 动作 关联 。	1<2	elab-addition	elab-addition
nlpabs98_Chi	122-132	133-142	需要 在 句法 分析 过程 中 实施 动作 层次 分解 ,	将 复杂 语句 分解 为 简单 的 基本 句型 ,	112-151	112-151	对于 嵌套 句型 等 较为 复杂 的 句型 结构 , 需要 在 句法 分析 过程 中 实施 动作 层次 分解 , 将 复杂 语句 分解 为 简单 的 基本 句型 , 以 便 于 挖掘 实体 — 动作 关联 。	对于 嵌套 句型 等 较为 复杂 的 句型 结构 , 需要 在 句法 分析 过程 中 实施 动作 层次 分解 , 将 复杂 语句 分解 为 简单 的 基本 句型 , 以 便 于 挖掘 实体 — 动作 关联 。	1<2	elab-addition	elab-addition
nlpabs98_Chi	133-142	143-151	将 复杂 语句 分解 为 简单 的 基本 句型 ,	以 便 于 挖掘 实体 — 动作 关联 。	112-151	112-151	对于 嵌套 句型 等 较为 复杂 的 句型 结构 , 需要 在 句法 分析 过程 中 实施 动作 层次 分解 , 将 复杂 语句 分解 为 简单 的 基本 句型 , 以 便 于 挖掘 实体 — 动作 关联 。	对于 嵌套 句型 等 较为 复杂 的 句型 结构 , 需要 在 句法 分析 过程 中 实施 动作 层次 分解 , 将 复杂 语句 分解 为 简单 的 基本 句型 , 以 便 于 挖掘 实体 — 动作 关联 。	1<2	enablement	enablement
nlpabs98_Chi	152-168	169-177	考虑 到 汉 语 语法 比较 灵活 , 语句 成分 缺省 和 倒装 现象 相对 普遍 ,	该文 提出 了 倒装 句 的 识别 机制 ,	152-189	152-189	考虑 到 汉 语 语法 比较 灵活 , 语句 成分 缺省 和 倒装 现象 相对 普遍 , 该文 提出 了 倒装 句 的 识别 机制 , 通过 匹配 接近 的 句型 进行 实体 移位 , 调整 语序 。	考虑 到 汉 语 语法 比较 灵活 , 语句 成分 缺省 和 倒装 现象 相对 普遍 , 该文 提出 了 倒装 句 的 识别 机制 , 通过 匹配 接近 的 句型 进行 实体 移位 , 调整 语序 。	1>2	exp-reason	exp-reason
nlpabs98_Chi	60-68	169-177	该文 提出 一 种 句法 成分 识别 机制 ,	该文 提出 了 倒装 句 的 识别 机制 ,	60-80	152-189	该文 提出 一 种 句法 成分 识别 机制 , 根据 词汇 类别 特征 及 位置 特征 识别 实体 及 动作 。	考虑 到 汉 语 语法 比较 灵活 , 语句 成分 缺省 和 倒装 现象 相对 普遍 , 该文 提出 了 倒装 句 的 识别 机制 , 通过 匹配 接近 的 句型 进行 实体 移位 , 调整 语序 。	1<2	joint	joint
nlpabs98_Chi	169-177	178-189	该文 提出 了 倒装 句 的 识别 机制 ,	通过 匹配 接近 的 句型 进行 实体 移位 , 调整 语序 。	152-189	152-189	考虑 到 汉 语 语法 比较 灵活 , 语句 成分 缺省 和 倒装 现象 相对 普遍 , 该文 提出 了 倒装 句 的 识别 机制 , 通过 匹配 接近 的 句型 进行 实体 移位 , 调整 语序 。	考虑 到 汉 语 语法 比较 灵活 , 语句 成分 缺省 和 倒装 现象 相对 普遍 , 该文 提出 了 倒装 句 的 识别 机制 , 通过 匹配 接近 的 句型 进行 实体 移位 , 调整 语序 。	1<2	elab-addition	elab-addition
nlpabs98_Chi	60-68	190-201	该文 提出 一 种 句法 成分 识别 机制 ,	论述 了 基 于 统计 模型 的 EARM 权重 量化 策略 ,	60-80	190-233	该文 提出 一 种 句法 成分 识别 机制 , 根据 词汇 类别 特征 及 位置 特征 识别 实体 及 动作 。	论述 了 基 于 统计 模型 的 EARM 权重 量化 策略 , 借助 语法 树 的 最大 公共 子 图 量化 文本 的 相似 度 并 实施 聚类 , 设计 并 开展 了 EARM 实体 — 动作 分析 实验 和 EARM 聚类 实验 。	1<2	joint	joint
nlpabs98_Chi	202-209	210-214	借助 语法 树 的 最大 公共 子 图	量化 文本 的 相似 度	190-233	190-233	论述 了 基 于 统计 模型 的 EARM 权重 量化 策略 , 借助 语法 树 的 最大 公共 子 图 量化 文本 的 相似 度 并 实施 聚类 , 设计 并 开展 了 EARM 实体 — 动作 分析 实验 和 EARM 聚类 实验 。	论述 了 基 于 统计 模型 的 EARM 权重 量化 策略 , 借助 语法 树 的 最大 公共 子 图 量化 文本 的 相似 度 并 实施 聚类 , 设计 并 开展 了 EARM 实体 — 动作 分析 实验 和 EARM 聚类 实验 。	1>2	manner-means	manner-means
nlpabs98_Chi	190-201	210-214	论述 了 基 于 统计 模型 的 EARM 权重 量化 策略 ,	量化 文本 的 相似 度	190-233	190-233	论述 了 基 于 统计 模型 的 EARM 权重 量化 策略 , 借助 语法 树 的 最大 公共 子 图 量化 文本 的 相似 度 并 实施 聚类 , 设计 并 开展 了 EARM 实体 — 动作 分析 实验 和 EARM 聚类 实验 。	论述 了 基 于 统计 模型 的 EARM 权重 量化 策略 , 借助 语法 树 的 最大 公共 子 图 量化 文本 的 相似 度 并 实施 聚类 , 设计 并 开展 了 EARM 实体 — 动作 分析 实验 和 EARM 聚类 实验 。	1<2	joint	joint
nlpabs98_Chi	210-214	215-218	量化 文本 的 相似 度	并 实施 聚类 ,	190-233	190-233	论述 了 基 于 统计 模型 的 EARM 权重 量化 策略 , 借助 语法 树 的 最大 公共 子 图 量化 文本 的 相似 度 并 实施 聚类 , 设计 并 开展 了 EARM 实体 — 动作 分析 实验 和 EARM 聚类 实验 。	论述 了 基 于 统计 模型 的 EARM 权重 量化 策略 , 借助 语法 树 的 最大 公共 子 图 量化 文本 的 相似 度 并 实施 聚类 , 设计 并 开展 了 EARM 实体 — 动作 分析 实验 和 EARM 聚类 实验 。	1<2	joint	joint
nlpabs98_Chi	190-201	219-233	论述 了 基 于 统计 模型 的 EARM 权重 量化 策略 ,	设计 并 开展 了 EARM 实体 — 动作 分析 实验 和 EARM 聚类 实验 。	190-233	190-233	论述 了 基 于 统计 模型 的 EARM 权重 量化 策略 , 借助 语法 树 的 最大 公共 子 图 量化 文本 的 相似 度 并 实施 聚类 , 设计 并 开展 了 EARM 实体 — 动作 分析 实验 和 EARM 聚类 实验 。	论述 了 基 于 统计 模型 的 EARM 权重 量化 策略 , 借助 语法 树 的 最大 公共 子 图 量化 文本 的 相似 度 并 实施 聚类 , 设计 并 开展 了 EARM 实体 — 动作 分析 实验 和 EARM 聚类 实验 。	1<2	joint	joint
nlpabs98_Chi	234-236	237-244	实验 结果 表明	EARM 的 分析 是 准确 有效 的 ,	234-250	234-250	实验 结果 表明 EARM 的 分析 是 准确 有效 的 , 聚类 结果 是 合理 的 。	实验 结果 表明 EARM 的 分析 是 准确 有效 的 , 聚类 结果 是 合理 的 。	1>2	attribution	attribution
nlpabs98_Chi	1-17	237-244	该文 提 出 面 向 文本 聚类 分析 的 实体 — 动作 关联 模 型 EARM ,	EARM 的 分析 是 准确 有效 的 ,	1-29	234-250	该文 提 出 面 向 文本 聚类 分析 的 实体 — 动作 关联 模 型 EARM , 探讨 汉 语 语义 实体 及 其 行为 的 描述 方法 。	实验 结果 表明 EARM 的 分析 是 准确 有效 的 , 聚类 结果 是 合理 的 。	1<2	evaluation	evaluation
nlpabs98_Chi	237-244	245-250	EARM 的 分析 是 准确 有效 的 ,	聚类 结果 是 合理 的 。	234-250	234-250	实验 结果 表明 EARM 的 分析 是 准确 有效 的 , 聚类 结果 是 合理 的 。	实验 结果 表明 EARM 的 分析 是 准确 有效 的 , 聚类 结果 是 合理 的 。	1<2	elab-addition	elab-addition
nlpabs99_Chi	1-28	29-56	该文 从 短语 结构 和 句式 结构 的 区别 与 联系 入手 , 设计 了 一 种 将 短语 结构 自动 转换 为 句式 结构 的 算法 。	并 以 清华 短语 结构 树库 ( TCT ) 为 测试 语料 , 实现 了 将 大 规模 短语 结构 语料 向 句式 结构 语料 的 转换 。	1-28	29-56	该文 从 短语 结构 和 句式 结构 的 区别 与 联系 入手 , 设计 了 一 种 将 短语 结构 自动 转换 为 句式 结构 的 算法 。	并 以 清华 短语 结构 树库 ( TCT ) 为 测试 语料 , 实现 了 将 大 规模 短语 结构 语料 向 句式 结构 语料 的 转换 。	1<2	joint	joint
nlpabs99_Chi	1-28	57-70	该文 从 短语 结构 和 句式 结构 的 区别 与 联系 入手 , 设计 了 一 种 将 短语 结构 自动 转换 为 句式 结构 的 算法 。	最后 , 搭建 了 一 套 可 扩展 的 可 视 化 系统 ,	1-28	57-82	该文 从 短语 结构 和 句式 结构 的 区别 与 联系 入手 , 设计 了 一 种 将 短语 结构 自动 转换 为 句式 结构 的 算法 。	最后 , 搭建 了 一 套 可 扩展 的 可 视 化 系统 , 用 于 不同 句法 结构 语料 的 可 视 化 查看 。	1<2	joint	joint
nlpabs99_Chi	57-70	71-82	最后 , 搭建 了 一 套 可 扩展 的 可 视 化 系统 ,	用 于 不同 句法 结构 语料 的 可 视 化 查看 。	57-82	57-82	最后 , 搭建 了 一 套 可 扩展 的 可 视 化 系统 , 用 于 不同 句法 结构 语料 的 可 视 化 查看 。	最后 , 搭建 了 一 套 可 扩展 的 可 视 化 系统 , 用 于 不同 句法 结构 语料 的 可 视 化 查看 。	1<2	elab-addition	elab-addition
nlpabs99_Chi	1-28	83-96	该文 从 短语 结构 和 句式 结构 的 区别 与 联系 入手 , 设计 了 一 种 将 短语 结构 自动 转换 为 句式 结构 的 算法 。	这 一 研究 不仅 实现 了 两 种 结构 之间 的 初步 转换 ,	1-28	83-126	该文 从 短语 结构 和 句式 结构 的 区别 与 联系 入手 , 设计 了 一 种 将 短语 结构 自动 转换 为 句式 结构 的 算法 。	这 一 研究 不仅 实现 了 两 种 结构 之间 的 初步 转换 , 而且 极大 地 丰富 了 汉 语句 本位 图解 树 库 的 语料 规模 , 并 为 汉 语句 本位 图解 树库 的 后续 应用 研究 奠定 了 基础 。	1<2	elab-addition	elab-addition
nlpabs99_Chi	83-96	97-111	这 一 研究 不仅 实现 了 两 种 结构 之间 的 初步 转换 ,	而且 极大 地 丰富 了 汉 语句 本位 图解 树 库 的 语料 规模 ,	83-126	83-126	这 一 研究 不仅 实现 了 两 种 结构 之间 的 初步 转换 , 而且 极大 地 丰富 了 汉 语句 本位 图解 树 库 的 语料 规模 , 并 为 汉 语句 本位 图解 树库 的 后续 应用 研究 奠定 了 基础 。	这 一 研究 不仅 实现 了 两 种 结构 之间 的 初步 转换 , 而且 极大 地 丰富 了 汉 语句 本位 图解 树 库 的 语料 规模 , 并 为 汉 语句 本位 图解 树库 的 后续 应用 研究 奠定 了 基础 。	1<2	joint	joint
nlpabs99_Chi	83-96	112-126	这 一 研究 不仅 实现 了 两 种 结构 之间 的 初步 转换 ,	并 为 汉 语句 本位 图解 树库 的 后续 应用 研究 奠定 了 基础 。	83-126	83-126	这 一 研究 不仅 实现 了 两 种 结构 之间 的 初步 转换 , 而且 极大 地 丰富 了 汉 语句 本位 图解 树 库 的 语料 规模 , 并 为 汉 语句 本位 图解 树库 的 后续 应用 研究 奠定 了 基础 。	这 一 研究 不仅 实现 了 两 种 结构 之间 的 初步 转换 , 而且 极大 地 丰富 了 汉 语句 本位 图解 树 库 的 语料 规模 , 并 为 汉 语句 本位 图解 树库 的 后续 应用 研究 奠定 了 基础 。	1<2	joint	joint
nlpabs9_Chi	1-10	11-27	﻿本文 依据 语言 测试 领域 的 作文 评分 要素 ,	对 国外 具有 代表 性 的 三 种 作文 自动 评分 系统 进行 评介 和 比较 ,	1-71	1-71	﻿本文 依据 语言 测试 领域 的 作文 评分 要素 , 对 国外 具有 代表 性 的 三 种 作文 自动 评分 系统 进行 评介 和 比较 , 指出 这些 评分 系统 在 训练 及 作文 的 人工 评分 方法 和 机器 评分 效度 等 方面 存在 的 问题 , 并 分析 这些 作文 自动 评分 系统 为 我国 自 主 开发 作文 自动 评分 系统 所 提供 的 借鉴 作用 。	﻿本文 依据 语言 测试 领域 的 作文 评分 要素 , 对 国外 具有 代表 性 的 三 种 作文 自动 评分 系统 进行 评介 和 比较 , 指出 这些 评分 系统 在 训练 及 作文 的 人工 评分 方法 和 机器 评分 效度 等 方面 存在 的 问题 , 并 分析 这些 作文 自动 评分 系统 为 我国 自 主 开发 作文 自动 评分 系统 所 提供 的 借鉴 作用 。	1>2	bg-general	bg-general
nlpabs9_Chi	11-27	28-49	对 国外 具有 代表 性 的 三 种 作文 自动 评分 系统 进行 评介 和 比较 ,	指出 这些 评分 系统 在 训练 及 作文 的 人工 评分 方法 和 机器 评分 效度 等 方面 存在 的 问题 ,	1-71	1-71	﻿本文 依据 语言 测试 领域 的 作文 评分 要素 , 对 国外 具有 代表 性 的 三 种 作文 自动 评分 系统 进行 评介 和 比较 , 指出 这些 评分 系统 在 训练 及 作文 的 人工 评分 方法 和 机器 评分 效度 等 方面 存在 的 问题 , 并 分析 这些 作文 自动 评分 系统 为 我国 自 主 开发 作文 自动 评分 系统 所 提供 的 借鉴 作用 。	﻿本文 依据 语言 测试 领域 的 作文 评分 要素 , 对 国外 具有 代表 性 的 三 种 作文 自动 评分 系统 进行 评介 和 比较 , 指出 这些 评分 系统 在 训练 及 作文 的 人工 评分 方法 和 机器 评分 效度 等 方面 存在 的 问题 , 并 分析 这些 作文 自动 评分 系统 为 我国 自 主 开发 作文 自动 评分 系统 所 提供 的 借鉴 作用 。	1<2	elab-addition	elab-addition
nlpabs9_Chi	28-49	50-71	指出 这些 评分 系统 在 训练 及 作文 的 人工 评分 方法 和 机器 评分 效度 等 方面 存在 的 问题 ,	并 分析 这些 作文 自动 评分 系统 为 我国 自 主 开发 作文 自动 评分 系统 所 提供 的 借鉴 作用 。	1-71	1-71	﻿本文 依据 语言 测试 领域 的 作文 评分 要素 , 对 国外 具有 代表 性 的 三 种 作文 自动 评分 系统 进行 评介 和 比较 , 指出 这些 评分 系统 在 训练 及 作文 的 人工 评分 方法 和 机器 评分 效度 等 方面 存在 的 问题 , 并 分析 这些 作文 自动 评分 系统 为 我国 自 主 开发 作文 自动 评分 系统 所 提供 的 借鉴 作用 。	﻿本文 依据 语言 测试 领域 的 作文 评分 要素 , 对 国外 具有 代表 性 的 三 种 作文 自动 评分 系统 进行 评介 和 比较 , 指出 这些 评分 系统 在 训练 及 作文 的 人工 评分 方法 和 机器 评分 效度 等 方面 存在 的 问题 , 并 分析 这些 作文 自动 评分 系统 为 我国 自 主 开发 作文 自动 评分 系统 所 提供 的 借鉴 作用 。	1<2	joint	joint
