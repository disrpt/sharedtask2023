doc	unit1_toks	unit2_toks	unit1_txt	unit2_txt	s1_toks	s2_toks	unit1_sent	unit2_sent	dir	orig_label	label
nlpabs100_Chi	1-30	99-120	随 着 科学 技术 的 发展 , 以 循 环 神经 网络 为 基础 的 机器 翻译 方法 由于 翻译 质量 更好 而 逐渐 取代 统计 机器 翻译 方法 ,	因此 该文 提出 一 种 基 于 卷积 神经 网络 CNN ( convolutional neural network ) 的 蒙汉 机器 翻译 方法 ,	1-61	62-168	随 着 科学 技术 的 发展 , 以 循 环 神经 网络 为 基础 的 机器 翻译 方法 由于 翻译 质量 更好 而 逐渐 取代 统计 机器 翻译 方法 , 特别 是 在 国际 大 语种 之间 的 互译 方面 , RNN 在 对 语料 编码 时 能够 提取 更好 的 特征 , 这 对 翻译 质量 好坏 至关 重要 。	然而 在 蒙古 语 这 类 小 语种 的 翻译 方面 , 由于 语料 不足 导致 的 数据 稀疏 和 RNN 模型 训练 梯度 消失 等 问题 , 很难 从 语料 中 充分 获取 语义 关系 , 因此 该文 提出 一 种 基 于 卷积 神经 网络 CNN ( convolutional neural network ) 的 蒙汉 机器 翻译 方法 , 在 对 源 语料 编码 时 利用 池化 层 获取 语义 关系 , 并 根据 蒙古 语构词 特点 得到 句子 的 语义 信息 , 再 通过 融合 全局 注意 力 机制 的 GRU 循环 神经 网络 将 编码 过 后 的 源 语言 解码 为 汉 语 。	1>2	bg-general	bg-general
nlpabs100_Chi	1-30	31-53	随 着 科学 技术 的 发展 , 以 循 环 神经 网络 为 基础 的 机器 翻译 方法 由于 翻译 质量 更好 而 逐渐 取代 统计 机器 翻译 方法 ,	特别 是 在 国际 大 语种 之间 的 互译 方面 , RNN 在 对 语料 编码 时 能够 提取 更好 的 特征 ,	1-61	1-61	随 着 科学 技术 的 发展 , 以 循 环 神经 网络 为 基础 的 机器 翻译 方法 由于 翻译 质量 更好 而 逐渐 取代 统计 机器 翻译 方法 , 特别 是 在 国际 大 语种 之间 的 互译 方面 , RNN 在 对 语料 编码 时 能够 提取 更好 的 特征 , 这 对 翻译 质量 好坏 至关 重要 。	随 着 科学 技术 的 发展 , 以 循 环 神经 网络 为 基础 的 机器 翻译 方法 由于 翻译 质量 更好 而 逐渐 取代 统计 机器 翻译 方法 , 特别 是 在 国际 大 语种 之间 的 互译 方面 , RNN 在 对 语料 编码 时 能够 提取 更好 的 特征 , 这 对 翻译 质量 好坏 至关 重要 。	1<2	elab-addition	elab-addition
nlpabs100_Chi	31-53	54-61	特别 是 在 国际 大 语种 之间 的 互译 方面 , RNN 在 对 语料 编码 时 能够 提取 更好 的 特征 ,	这 对 翻译 质量 好坏 至关 重要 。	1-61	1-61	随 着 科学 技术 的 发展 , 以 循 环 神经 网络 为 基础 的 机器 翻译 方法 由于 翻译 质量 更好 而 逐渐 取代 统计 机器 翻译 方法 , 特别 是 在 国际 大 语种 之间 的 互译 方面 , RNN 在 对 语料 编码 时 能够 提取 更好 的 特征 , 这 对 翻译 质量 好坏 至关 重要 。	随 着 科学 技术 的 发展 , 以 循 环 神经 网络 为 基础 的 机器 翻译 方法 由于 翻译 质量 更好 而 逐渐 取代 统计 机器 翻译 方法 , 特别 是 在 国际 大 语种 之间 的 互译 方面 , RNN 在 对 语料 编码 时 能够 提取 更好 的 特征 , 这 对 翻译 质量 好坏 至关 重要 。	1<2	elab-addition	elab-addition
nlpabs100_Chi	54-61	62-98	这 对 翻译 质量 好坏 至关 重要 。	然而 在 蒙古 语 这 类 小 语种 的 翻译 方面 , 由于 语料 不足 导致 的 数据 稀疏 和 RNN 模型 训练 梯度 消失 等 问题 , 很难 从 语料 中 充分 获取 语义 关系 ,	1-61	62-168	随 着 科学 技术 的 发展 , 以 循 环 神经 网络 为 基础 的 机器 翻译 方法 由于 翻译 质量 更好 而 逐渐 取代 统计 机器 翻译 方法 , 特别 是 在 国际 大 语种 之间 的 互译 方面 , RNN 在 对 语料 编码 时 能够 提取 更好 的 特征 , 这 对 翻译 质量 好坏 至关 重要 。	然而 在 蒙古 语 这 类 小 语种 的 翻译 方面 , 由于 语料 不足 导致 的 数据 稀疏 和 RNN 模型 训练 梯度 消失 等 问题 , 很难 从 语料 中 充分 获取 语义 关系 , 因此 该文 提出 一 种 基 于 卷积 神经 网络 CNN ( convolutional neural network ) 的 蒙汉 机器 翻译 方法 , 在 对 源 语料 编码 时 利用 池化 层 获取 语义 关系 , 并 根据 蒙古 语构词 特点 得到 句子 的 语义 信息 , 再 通过 融合 全局 注意 力 机制 的 GRU 循环 神经 网络 将 编码 过 后 的 源 语言 解码 为 汉 语 。	1<2	contrast	contrast
nlpabs100_Chi	99-120	121-168	因此 该文 提出 一 种 基 于 卷积 神经 网络 CNN ( convolutional neural network ) 的 蒙汉 机器 翻译 方法 ,	在 对 源 语料 编码 时 利用 池化 层 获取 语义 关系 , 并 根据 蒙古 语构词 特点 得到 句子 的 语义 信息 , 再 通过 融合 全局 注意 力 机制 的 GRU 循环 神经 网络 将 编码 过 后 的 源 语言 解码 为 汉 语 。	62-168	62-168	然而 在 蒙古 语 这 类 小 语种 的 翻译 方面 , 由于 语料 不足 导致 的 数据 稀疏 和 RNN 模型 训练 梯度 消失 等 问题 , 很难 从 语料 中 充分 获取 语义 关系 , 因此 该文 提出 一 种 基 于 卷积 神经 网络 CNN ( convolutional neural network ) 的 蒙汉 机器 翻译 方法 , 在 对 源 语料 编码 时 利用 池化 层 获取 语义 关系 , 并 根据 蒙古 语构词 特点 得到 句子 的 语义 信息 , 再 通过 融合 全局 注意 力 机制 的 GRU 循环 神经 网络 将 编码 过 后 的 源 语言 解码 为 汉 语 。	然而 在 蒙古 语 这 类 小 语种 的 翻译 方面 , 由于 语料 不足 导致 的 数据 稀疏 和 RNN 模型 训练 梯度 消失 等 问题 , 很难 从 语料 中 充分 获取 语义 关系 , 因此 该文 提出 一 种 基 于 卷积 神经 网络 CNN ( convolutional neural network ) 的 蒙汉 机器 翻译 方法 , 在 对 源 语料 编码 时 利用 池化 层 获取 语义 关系 , 并 根据 蒙古 语构词 特点 得到 句子 的 语义 信息 , 再 通过 融合 全局 注意 力 机制 的 GRU 循环 神经 网络 将 编码 过 后 的 源 语言 解码 为 汉 语 。	1<2	elab-addition	elab-addition
nlpabs100_Chi	169-172	173-192	实验 结果 表明 ,	该 方法 在 翻译 准确 率 和 训练 速度 两 方面 均 优 于 RNN 基准 机器 翻译 方法 。	169-192	169-192	实验 结果 表明 , 该 方法 在 翻译 准确 率 和 训练 速度 两 方面 均 优 于 RNN 基准 机器 翻译 方法 。	实验 结果 表明 , 该 方法 在 翻译 准确 率 和 训练 速度 两 方面 均 优 于 RNN 基准 机器 翻译 方法 。	1>2	attribution	attribution
nlpabs100_Chi	99-120	173-192	因此 该文 提出 一 种 基 于 卷积 神经 网络 CNN ( convolutional neural network ) 的 蒙汉 机器 翻译 方法 ,	该 方法 在 翻译 准确 率 和 训练 速度 两 方面 均 优 于 RNN 基准 机器 翻译 方法 。	62-168	169-192	然而 在 蒙古 语 这 类 小 语种 的 翻译 方面 , 由于 语料 不足 导致 的 数据 稀疏 和 RNN 模型 训练 梯度 消失 等 问题 , 很难 从 语料 中 充分 获取 语义 关系 , 因此 该文 提出 一 种 基 于 卷积 神经 网络 CNN ( convolutional neural network ) 的 蒙汉 机器 翻译 方法 , 在 对 源 语料 编码 时 利用 池化 层 获取 语义 关系 , 并 根据 蒙古 语构词 特点 得到 句子 的 语义 信息 , 再 通过 融合 全局 注意 力 机制 的 GRU 循环 神经 网络 将 编码 过 后 的 源 语言 解码 为 汉 语 。	实验 结果 表明 , 该 方法 在 翻译 准确 率 和 训练 速度 两 方面 均 优 于 RNN 基准 机器 翻译 方法 。	1<2	evaluation	evaluation
nlpabs101_Chi	1-19	20-25	探索 将 循环 神经 网络 和 连接 时序 分类 算法 应用 于 藏 语 语音 识别 声学 建模 ,	实现 端到端 的 模型 训练 。	1-25	1-25	探索 将 循环 神经 网络 和 连接 时序 分类 算法 应用 于 藏 语 语音 识别 声学 建模 , 实现 端到端 的 模型 训练 。	探索 将 循环 神经 网络 和 连接 时序 分类 算法 应用 于 藏 语 语音 识别 声学 建模 , 实现 端到端 的 模型 训练 。	1<2	enablement	enablement
nlpabs101_Chi	26-35	36-57	同时 根据 声学 模型 输入 与 输出 的 关系 ,	通过 在 隐含 层 输出 序列 上 引入 时域 卷积 操作 来 对 网络 隐含 层 时域 展开 步数 进行 约简 ,	26-67	26-67	同时 根据 声学 模型 输入 与 输出 的 关系 , 通过 在 隐含 层 输出 序列 上 引入 时域 卷积 操作 来 对 网络 隐含 层 时域 展开 步数 进行 约简 , 从而 有效 提升 模型 的 训练 与 解码 效率 。	同时 根据 声学 模型 输入 与 输出 的 关系 , 通过 在 隐含 层 输出 序列 上 引入 时域 卷积 操作 来 对 网络 隐含 层 时域 展开 步数 进行 约简 , 从而 有效 提升 模型 的 训练 与 解码 效率 。	1>2	bg-general	bg-general
nlpabs101_Chi	1-19	36-57	探索 将 循环 神经 网络 和 连接 时序 分类 算法 应用 于 藏 语 语音 识别 声学 建模 ,	通过 在 隐含 层 输出 序列 上 引入 时域 卷积 操作 来 对 网络 隐含 层 时域 展开 步数 进行 约简 ,	1-25	26-67	探索 将 循环 神经 网络 和 连接 时序 分类 算法 应用 于 藏 语 语音 识别 声学 建模 , 实现 端到端 的 模型 训练 。	同时 根据 声学 模型 输入 与 输出 的 关系 , 通过 在 隐含 层 输出 序列 上 引入 时域 卷积 操作 来 对 网络 隐含 层 时域 展开 步数 进行 约简 , 从而 有效 提升 模型 的 训练 与 解码 效率 。	1<2	elab-addition	elab-addition
nlpabs101_Chi	36-57	58-67	通过 在 隐含 层 输出 序列 上 引入 时域 卷积 操作 来 对 网络 隐含 层 时域 展开 步数 进行 约简 ,	从而 有效 提升 模型 的 训练 与 解码 效率 。	26-67	26-67	同时 根据 声学 模型 输入 与 输出 的 关系 , 通过 在 隐含 层 输出 序列 上 引入 时域 卷积 操作 来 对 网络 隐含 层 时域 展开 步数 进行 约简 , 从而 有效 提升 模型 的 训练 与 解码 效率 。	同时 根据 声学 模型 输入 与 输出 的 关系 , 通过 在 隐含 层 输出 序列 上 引入 时域 卷积 操作 来 对 网络 隐含 层 时域 展开 步数 进行 约简 , 从而 有效 提升 模型 的 训练 与 解码 效率 。	1<2	enablement	enablement
nlpabs101_Chi	68-71	84-101	实验 结果 显示 ,	循环 神经 网络 模型 在 藏 语 拉萨 话音素 识别 任务 上 具有 更好 的 识别 性能 ,	68-129	68-129	实验 结果 显示 , 与 传统 基 于 隐马尔可夫 模型 的 声学 建模 方法 相比 , 循环 神经 网络 模型 在 藏 语 拉萨 话音素 识别 任务 上 具有 更好 的 识别 性能 , 而 引入 时域 卷积 操作 的 循环 神经 网络 声学 模型 在 保持 同等 识别 性能 的 情况 下 , 拥有 更高 的 训练 和 解码 效率 。	实验 结果 显示 , 与 传统 基 于 隐马尔可夫 模型 的 声学 建模 方法 相比 , 循环 神经 网络 模型 在 藏 语 拉萨 话音素 识别 任务 上 具有 更好 的 识别 性能 , 而 引入 时域 卷积 操作 的 循环 神经 网络 声学 模型 在 保持 同等 识别 性能 的 情况 下 , 拥有 更高 的 训练 和 解码 效率 。	1>2	attribution	attribution
nlpabs101_Chi	72-83	84-101	与 传统 基 于 隐马尔可夫 模型 的 声学 建模 方法 相比 ,	循环 神经 网络 模型 在 藏 语 拉萨 话音素 识别 任务 上 具有 更好 的 识别 性能 ,	68-129	68-129	实验 结果 显示 , 与 传统 基 于 隐马尔可夫 模型 的 声学 建模 方法 相比 , 循环 神经 网络 模型 在 藏 语 拉萨 话音素 识别 任务 上 具有 更好 的 识别 性能 , 而 引入 时域 卷积 操作 的 循环 神经 网络 声学 模型 在 保持 同等 识别 性能 的 情况 下 , 拥有 更高 的 训练 和 解码 效率 。	实验 结果 显示 , 与 传统 基 于 隐马尔可夫 模型 的 声学 建模 方法 相比 , 循环 神经 网络 模型 在 藏 语 拉萨 话音素 识别 任务 上 具有 更好 的 识别 性能 , 而 引入 时域 卷积 操作 的 循环 神经 网络 声学 模型 在 保持 同等 识别 性能 的 情况 下 , 拥有 更高 的 训练 和 解码 效率 。	1>2	comparison	comparison
nlpabs101_Chi	1-19	84-101	探索 将 循环 神经 网络 和 连接 时序 分类 算法 应用 于 藏 语 语音 识别 声学 建模 ,	循环 神经 网络 模型 在 藏 语 拉萨 话音素 识别 任务 上 具有 更好 的 识别 性能 ,	1-25	68-129	探索 将 循环 神经 网络 和 连接 时序 分类 算法 应用 于 藏 语 语音 识别 声学 建模 , 实现 端到端 的 模型 训练 。	实验 结果 显示 , 与 传统 基 于 隐马尔可夫 模型 的 声学 建模 方法 相比 , 循环 神经 网络 模型 在 藏 语 拉萨 话音素 识别 任务 上 具有 更好 的 识别 性能 , 而 引入 时域 卷积 操作 的 循环 神经 网络 声学 模型 在 保持 同等 识别 性能 的 情况 下 , 拥有 更高 的 训练 和 解码 效率 。	1<2	evaluation	evaluation
nlpabs101_Chi	84-101	102-129	循环 神经 网络 模型 在 藏 语 拉萨 话音素 识别 任务 上 具有 更好 的 识别 性能 ,	而 引入 时域 卷积 操作 的 循环 神经 网络 声学 模型 在 保持 同等 识别 性能 的 情况 下 , 拥有 更高 的 训练 和 解码 效率 。	68-129	68-129	实验 结果 显示 , 与 传统 基 于 隐马尔可夫 模型 的 声学 建模 方法 相比 , 循环 神经 网络 模型 在 藏 语 拉萨 话音素 识别 任务 上 具有 更好 的 识别 性能 , 而 引入 时域 卷积 操作 的 循环 神经 网络 声学 模型 在 保持 同等 识别 性能 的 情况 下 , 拥有 更高 的 训练 和 解码 效率 。	实验 结果 显示 , 与 传统 基 于 隐马尔可夫 模型 的 声学 建模 方法 相比 , 循环 神经 网络 模型 在 藏 语 拉萨 话音素 识别 任务 上 具有 更好 的 识别 性能 , 而 引入 时域 卷积 操作 的 循环 神经 网络 声学 模型 在 保持 同等 识别 性能 的 情况 下 , 拥有 更高 的 训练 和 解码 效率 。	1<2	joint	joint
nlpabs103_Chi	1-18	28-45	维吾尔 语 事件 伴随 关系 是 维吾尔 语 语言 中 常见 且 重要 的 关系 之 一 。	该文 提出 一 种 基 于 深度 信念 网络 的 维吾尔 语 事件 伴随 关系 识别 方法 ,	1-18	19-99	维吾尔 语 事件 伴随 关系 是 维吾尔 语 语言 中 常见 且 重要 的 关系 之 一 。	结合 对 维吾尔 语 语言 特点 的 研究 , 该文 提出 一 种 基 于 深度 信念 网络 的 维吾尔 语 事件 伴随 关系 识别 方法 , 根据 维吾尔 语 语言 特性 和 事件 伴随 关系 的 特点 , 抽取 12 项 基 于 事件 结构 信息 的 特征 ; 同时 充分 利用 事件 对 所 对应 的 两 个 触发 词 之间 的 语义 信息 , 引入 Word Embedding 计算 两 个 触发 词 之间 的 语义 相似 度 。	1>2	bg-general	bg-general
nlpabs103_Chi	19-27	28-45	结合 对 维吾尔 语 语言 特点 的 研究 ,	该文 提出 一 种 基 于 深度 信念 网络 的 维吾尔 语 事件 伴随 关系 识别 方法 ,	19-99	19-99	结合 对 维吾尔 语 语言 特点 的 研究 , 该文 提出 一 种 基 于 深度 信念 网络 的 维吾尔 语 事件 伴随 关系 识别 方法 , 根据 维吾尔 语 语言 特性 和 事件 伴随 关系 的 特点 , 抽取 12 项 基 于 事件 结构 信息 的 特征 ; 同时 充分 利用 事件 对 所 对应 的 两 个 触发 词 之间 的 语义 信息 , 引入 Word Embedding 计算 两 个 触发 词 之间 的 语义 相似 度 。	结合 对 维吾尔 语 语言 特点 的 研究 , 该文 提出 一 种 基 于 深度 信念 网络 的 维吾尔 语 事件 伴随 关系 识别 方法 , 根据 维吾尔 语 语言 特性 和 事件 伴随 关系 的 特点 , 抽取 12 项 基 于 事件 结构 信息 的 特征 ; 同时 充分 利用 事件 对 所 对应 的 两 个 触发 词 之间 的 语义 信息 , 引入 Word Embedding 计算 两 个 触发 词 之间 的 语义 相似 度 。	1>2	bg-general	bg-general
nlpabs103_Chi	46-57	58-68	根据 维吾尔 语 语言 特性 和 事件 伴随 关系 的 特点 ,	抽取 12 项 基 于 事件 结构 信息 的 特征 ;	19-99	19-99	结合 对 维吾尔 语 语言 特点 的 研究 , 该文 提出 一 种 基 于 深度 信念 网络 的 维吾尔 语 事件 伴随 关系 识别 方法 , 根据 维吾尔 语 语言 特性 和 事件 伴随 关系 的 特点 , 抽取 12 项 基 于 事件 结构 信息 的 特征 ; 同时 充分 利用 事件 对 所 对应 的 两 个 触发 词 之间 的 语义 信息 , 引入 Word Embedding 计算 两 个 触发 词 之间 的 语义 相似 度 。	结合 对 维吾尔 语 语言 特点 的 研究 , 该文 提出 一 种 基 于 深度 信念 网络 的 维吾尔 语 事件 伴随 关系 识别 方法 , 根据 维吾尔 语 语言 特性 和 事件 伴随 关系 的 特点 , 抽取 12 项 基 于 事件 结构 信息 的 特征 ; 同时 充分 利用 事件 对 所 对应 的 两 个 触发 词 之间 的 语义 信息 , 引入 Word Embedding 计算 两 个 触发 词 之间 的 语义 相似 度 。	1>2	bg-general	bg-general
nlpabs103_Chi	28-45	58-68	该文 提出 一 种 基 于 深度 信念 网络 的 维吾尔 语 事件 伴随 关系 识别 方法 ,	抽取 12 项 基 于 事件 结构 信息 的 特征 ;	19-99	19-99	结合 对 维吾尔 语 语言 特点 的 研究 , 该文 提出 一 种 基 于 深度 信念 网络 的 维吾尔 语 事件 伴随 关系 识别 方法 , 根据 维吾尔 语 语言 特性 和 事件 伴随 关系 的 特点 , 抽取 12 项 基 于 事件 结构 信息 的 特征 ; 同时 充分 利用 事件 对 所 对应 的 两 个 触发 词 之间 的 语义 信息 , 引入 Word Embedding 计算 两 个 触发 词 之间 的 语义 相似 度 。	结合 对 维吾尔 语 语言 特点 的 研究 , 该文 提出 一 种 基 于 深度 信念 网络 的 维吾尔 语 事件 伴随 关系 识别 方法 , 根据 维吾尔 语 语言 特性 和 事件 伴随 关系 的 特点 , 抽取 12 项 基 于 事件 结构 信息 的 特征 ; 同时 充分 利用 事件 对 所 对应 的 两 个 触发 词 之间 的 语义 信息 , 引入 Word Embedding 计算 两 个 触发 词 之间 的 语义 相似 度 。	1<2	elab-process_step	elab-process_step
nlpabs103_Chi	58-68	69-85	抽取 12 项 基 于 事件 结构 信息 的 特征 ;	同时 充分 利用 事件 对 所 对应 的 两 个 触发 词 之间 的 语义 信息 ,	19-99	19-99	结合 对 维吾尔 语 语言 特点 的 研究 , 该文 提出 一 种 基 于 深度 信念 网络 的 维吾尔 语 事件 伴随 关系 识别 方法 , 根据 维吾尔 语 语言 特性 和 事件 伴随 关系 的 特点 , 抽取 12 项 基 于 事件 结构 信息 的 特征 ; 同时 充分 利用 事件 对 所 对应 的 两 个 触发 词 之间 的 语义 信息 , 引入 Word Embedding 计算 两 个 触发 词 之间 的 语义 相似 度 。	结合 对 维吾尔 语 语言 特点 的 研究 , 该文 提出 一 种 基 于 深度 信念 网络 的 维吾尔 语 事件 伴随 关系 识别 方法 , 根据 维吾尔 语 语言 特性 和 事件 伴随 关系 的 特点 , 抽取 12 项 基 于 事件 结构 信息 的 特征 ; 同时 充分 利用 事件 对 所 对应 的 两 个 触发 词 之间 的 语义 信息 , 引入 Word Embedding 计算 两 个 触发 词 之间 的 语义 相似 度 。	1<2	joint	joint
nlpabs103_Chi	69-85	86-99	同时 充分 利用 事件 对 所 对应 的 两 个 触发 词 之间 的 语义 信息 ,	引入 Word Embedding 计算 两 个 触发 词 之间 的 语义 相似 度 。	19-99	19-99	结合 对 维吾尔 语 语言 特点 的 研究 , 该文 提出 一 种 基 于 深度 信念 网络 的 维吾尔 语 事件 伴随 关系 识别 方法 , 根据 维吾尔 语 语言 特性 和 事件 伴随 关系 的 特点 , 抽取 12 项 基 于 事件 结构 信息 的 特征 ; 同时 充分 利用 事件 对 所 对应 的 两 个 触发 词 之间 的 语义 信息 , 引入 Word Embedding 计算 两 个 触发 词 之间 的 语义 相似 度 。	结合 对 维吾尔 语 语言 特点 的 研究 , 该文 提出 一 种 基 于 深度 信念 网络 的 维吾尔 语 事件 伴随 关系 识别 方法 , 根据 维吾尔 语 语言 特性 和 事件 伴随 关系 的 特点 , 抽取 12 项 基 于 事件 结构 信息 的 特征 ; 同时 充分 利用 事件 对 所 对应 的 两 个 触发 词 之间 的 语义 信息 , 引入 Word Embedding 计算 两 个 触发 词 之间 的 语义 相似 度 。	1<2	enablement	enablement
nlpabs103_Chi	58-68	100-114	抽取 12 项 基 于 事件 结构 信息 的 特征 ;	而 后 融合 两 类 特征 作 为 DBN 模型 的 输入 进行 训练 ,	19-99	100-133	结合 对 维吾尔 语 语言 特点 的 研究 , 该文 提出 一 种 基 于 深度 信念 网络 的 维吾尔 语 事件 伴随 关系 识别 方法 , 根据 维吾尔 语 语言 特性 和 事件 伴随 关系 的 特点 , 抽取 12 项 基 于 事件 结构 信息 的 特征 ; 同时 充分 利用 事件 对 所 对应 的 两 个 触发 词 之间 的 语义 信息 , 引入 Word Embedding 计算 两 个 触发 词 之间 的 语义 相似 度 。	而 后 融合 两 类 特征 作 为 DBN 模型 的 输入 进行 训练 , 最后 将 训练 结果 作 为 softmax 分类器 的 输入 实现 维吾尔 语 事件 伴随 关系 的 识别 。	1<2	joint	joint
nlpabs103_Chi	100-114	115-133	而 后 融合 两 类 特征 作 为 DBN 模型 的 输入 进行 训练 ,	最后 将 训练 结果 作 为 softmax 分类器 的 输入 实现 维吾尔 语 事件 伴随 关系 的 识别 。	100-133	100-133	而 后 融合 两 类 特征 作 为 DBN 模型 的 输入 进行 训练 , 最后 将 训练 结果 作 为 softmax 分类器 的 输入 实现 维吾尔 语 事件 伴随 关系 的 识别 。	而 后 融合 两 类 特征 作 为 DBN 模型 的 输入 进行 训练 , 最后 将 训练 结果 作 为 softmax 分类器 的 输入 实现 维吾尔 语 事件 伴随 关系 的 识别 。	1<2	joint	joint
nlpabs103_Chi	28-45	134-161	该文 提出 一 种 基 于 深度 信念 网络 的 维吾尔 语 事件 伴随 关系 识别 方法 ,	该 方法 用 于 维吾尔 语 事件 伴随 关系 的 识别 准确 率 P 为 81.89% 、 召回 率 R 为 84.32% 、 F1 值 为 82.48% 。	19-99	134-161	结合 对 维吾尔 语 语言 特点 的 研究 , 该文 提出 一 种 基 于 深度 信念 网络 的 维吾尔 语 事件 伴随 关系 识别 方法 , 根据 维吾尔 语 语言 特性 和 事件 伴随 关系 的 特点 , 抽取 12 项 基 于 事件 结构 信息 的 特征 ; 同时 充分 利用 事件 对 所 对应 的 两 个 触发 词 之间 的 语义 信息 , 引入 Word Embedding 计算 两 个 触发 词 之间 的 语义 相似 度 。	该 方法 用 于 维吾尔 语 事件 伴随 关系 的 识别 准确 率 P 为 81.89% 、 召回 率 R 为 84.32% 、 F1 值 为 82.48% 。	1<2	evaluation	evaluation
nlpabs103_Chi	162-165	173-185	实验 结果 表明 ,	基 于 DBN 模型 的 方法 取 得 更好 的 识别 效果 。	162-185	162-185	实验 结果 表明 , 与 支持 向量 机 方法 相比 , 基 于 DBN 模型 的 方法 取 得 更好 的 识别 效果 。	实验 结果 表明 , 与 支持 向量 机 方法 相比 , 基 于 DBN 模型 的 方法 取 得 更好 的 识别 效果 。	1>2	elab-addition	elab-addition
nlpabs103_Chi	166-172	173-185	与 支持 向量 机 方法 相比 ,	基 于 DBN 模型 的 方法 取 得 更好 的 识别 效果 。	162-185	162-185	实验 结果 表明 , 与 支持 向量 机 方法 相比 , 基 于 DBN 模型 的 方法 取 得 更好 的 识别 效果 。	实验 结果 表明 , 与 支持 向量 机 方法 相比 , 基 于 DBN 模型 的 方法 取 得 更好 的 识别 效果 。	1>2	contrast	contrast
nlpabs103_Chi	134-161	173-185	该 方法 用 于 维吾尔 语 事件 伴随 关系 的 识别 准确 率 P 为 81.89% 、 召回 率 R 为 84.32% 、 F1 值 为 82.48% 。	基 于 DBN 模型 的 方法 取 得 更好 的 识别 效果 。	134-161	162-185	该 方法 用 于 维吾尔 语 事件 伴随 关系 的 识别 准确 率 P 为 81.89% 、 召回 率 R 为 84.32% 、 F1 值 为 82.48% 。	实验 结果 表明 , 与 支持 向量 机 方法 相比 , 基 于 DBN 模型 的 方法 取 得 更好 的 识别 效果 。	1<2	elab-addition	elab-addition
nlpabs104_Chi	1-16	49-65	网络 化 大 数据 时代 的 到来 丰富 了 网络 空间 中 的 信息 资源 ,	该文 提出 了 一 种 基 于 潜 在 语义 分析 的 文本 指纹 提取 方法 ,	1-48	49-90	网络 化 大 数据 时代 的 到来 丰富 了 网络 空间 中 的 信息 资源 , 然而 由于 数据 资源 类型 的 多样 性 及 其 增长 的 快速 性 , 给 网络 空间 的 存储 和 信息 资源 的 有效 利用 带来 了 压力 和 挑战 。	该文 提出 了 一 种 基 于 潜 在 语义 分析 的 文本 指纹 提取 方法 , 该 方法 是 对 数据 信息 的 一 种 压缩 表示 , 是 针对 目前 指纹 提取 方法 语义 缺失 的 一 种 改进 。	1>2	bg-general	bg-general
nlpabs104_Chi	1-16	17-48	网络 化 大 数据 时代 的 到来 丰富 了 网络 空间 中 的 信息 资源 ,	然而 由于 数据 资源 类型 的 多样 性 及 其 增长 的 快速 性 , 给 网络 空间 的 存储 和 信息 资源 的 有效 利用 带来 了 压力 和 挑战 。	1-48	1-48	网络 化 大 数据 时代 的 到来 丰富 了 网络 空间 中 的 信息 资源 , 然而 由于 数据 资源 类型 的 多样 性 及 其 增长 的 快速 性 , 给 网络 空间 的 存储 和 信息 资源 的 有效 利用 带来 了 压力 和 挑战 。	网络 化 大 数据 时代 的 到来 丰富 了 网络 空间 中 的 信息 资源 , 然而 由于 数据 资源 类型 的 多样 性 及 其 增长 的 快速 性 , 给 网络 空间 的 存储 和 信息 资源 的 有效 利用 带来 了 压力 和 挑战 。	1<2	contrast	contrast
nlpabs104_Chi	49-65	66-77	该文 提出 了 一 种 基 于 潜 在 语义 分析 的 文本 指纹 提取 方法 ,	该 方法 是 对 数据 信息 的 一 种 压缩 表示 ,	49-90	49-90	该文 提出 了 一 种 基 于 潜 在 语义 分析 的 文本 指纹 提取 方法 , 该 方法 是 对 数据 信息 的 一 种 压缩 表示 , 是 针对 目前 指纹 提取 方法 语义 缺失 的 一 种 改进 。	该文 提出 了 一 种 基 于 潜 在 语义 分析 的 文本 指纹 提取 方法 , 该 方法 是 对 数据 信息 的 一 种 压缩 表示 , 是 针对 目前 指纹 提取 方法 语义 缺失 的 一 种 改进 。	1<2	elab-addition	elab-addition
nlpabs104_Chi	66-77	78-90	该 方法 是 对 数据 信息 的 一 种 压缩 表示 ,	是 针对 目前 指纹 提取 方法 语义 缺失 的 一 种 改进 。	49-90	49-90	该文 提出 了 一 种 基 于 潜 在 语义 分析 的 文本 指纹 提取 方法 , 该 方法 是 对 数据 信息 的 一 种 压缩 表示 , 是 针对 目前 指纹 提取 方法 语义 缺失 的 一 种 改进 。	该文 提出 了 一 种 基 于 潜 在 语义 分析 的 文本 指纹 提取 方法 , 该 方法 是 对 数据 信息 的 一 种 压缩 表示 , 是 针对 目前 指纹 提取 方法 语义 缺失 的 一 种 改进 。	1<2	elab-addition	elab-addition
nlpabs104_Chi	49-65	91-105	该文 提出 了 一 种 基 于 潜 在 语义 分析 的 文本 指纹 提取 方法 ,	该 方法 主要 通过 奇异 值 分解 获取 原始 文档 的 潜在 语义 特征 ,	49-90	91-152	该文 提出 了 一 种 基 于 潜 在 语义 分析 的 文本 指纹 提取 方法 , 该 方法 是 对 数据 信息 的 一 种 压缩 表示 , 是 针对 目前 指纹 提取 方法 语义 缺失 的 一 种 改进 。	该 方法 主要 通过 奇异 值 分解 获取 原始 文档 的 潜在 语义 特征 , 然后 将 原 文档 向量 空间 转换 到 与 其 对应 的 潜在 语义 空间 , 再 根据 随机 超 平面 原理 将 该 空间 的 文档 转换 成 二 进制 数字 指纹 , 最终 用 汉 明 距离 来 衡量 指纹 间 的 差异 程度 。	1<2	elab-process_step	elab-process_step
nlpabs104_Chi	91-105	106-121	该 方法 主要 通过 奇异 值 分解 获取 原始 文档 的 潜在 语义 特征 ,	然后 将 原 文档 向量 空间 转换 到 与 其 对应 的 潜在 语义 空间 ,	91-152	91-152	该 方法 主要 通过 奇异 值 分解 获取 原始 文档 的 潜在 语义 特征 , 然后 将 原 文档 向量 空间 转换 到 与 其 对应 的 潜在 语义 空间 , 再 根据 随机 超 平面 原理 将 该 空间 的 文档 转换 成 二 进制 数字 指纹 , 最终 用 汉 明 距离 来 衡量 指纹 间 的 差异 程度 。	该 方法 主要 通过 奇异 值 分解 获取 原始 文档 的 潜在 语义 特征 , 然后 将 原 文档 向量 空间 转换 到 与 其 对应 的 潜在 语义 空间 , 再 根据 随机 超 平面 原理 将 该 空间 的 文档 转换 成 二 进制 数字 指纹 , 最终 用 汉 明 距离 来 衡量 指纹 间 的 差异 程度 。	1<2	joint	joint
nlpabs104_Chi	106-121	122-127	然后 将 原 文档 向量 空间 转换 到 与 其 对应 的 潜在 语义 空间 ,	再 根据 随机 超 平面 原理	91-152	91-152	该 方法 主要 通过 奇异 值 分解 获取 原始 文档 的 潜在 语义 特征 , 然后 将 原 文档 向量 空间 转换 到 与 其 对应 的 潜在 语义 空间 , 再 根据 随机 超 平面 原理 将 该 空间 的 文档 转换 成 二 进制 数字 指纹 , 最终 用 汉 明 距离 来 衡量 指纹 间 的 差异 程度 。	该 方法 主要 通过 奇异 值 分解 获取 原始 文档 的 潜在 语义 特征 , 然后 将 原 文档 向量 空间 转换 到 与 其 对应 的 潜在 语义 空间 , 再 根据 随机 超 平面 原理 将 该 空间 的 文档 转换 成 二 进制 数字 指纹 , 最终 用 汉 明 距离 来 衡量 指纹 间 的 差异 程度 。	1<2	joint	joint
nlpabs104_Chi	122-127	128-139	再 根据 随机 超 平面 原理	将 该 空间 的 文档 转换 成 二 进制 数字 指纹 ,	91-152	91-152	该 方法 主要 通过 奇异 值 分解 获取 原始 文档 的 潜在 语义 特征 , 然后 将 原 文档 向量 空间 转换 到 与 其 对应 的 潜在 语义 空间 , 再 根据 随机 超 平面 原理 将 该 空间 的 文档 转换 成 二 进制 数字 指纹 , 最终 用 汉 明 距离 来 衡量 指纹 间 的 差异 程度 。	该 方法 主要 通过 奇异 值 分解 获取 原始 文档 的 潜在 语义 特征 , 然后 将 原 文档 向量 空间 转换 到 与 其 对应 的 潜在 语义 空间 , 再 根据 随机 超 平面 原理 将 该 空间 的 文档 转换 成 二 进制 数字 指纹 , 最终 用 汉 明 距离 来 衡量 指纹 间 的 差异 程度 。	1<2	elab-addition	elab-addition
nlpabs104_Chi	128-139	140-152	将 该 空间 的 文档 转换 成 二 进制 数字 指纹 ,	最终 用 汉 明 距离 来 衡量 指纹 间 的 差异 程度 。	91-152	91-152	该 方法 主要 通过 奇异 值 分解 获取 原始 文档 的 潜在 语义 特征 , 然后 将 原 文档 向量 空间 转换 到 与 其 对应 的 潜在 语义 空间 , 再 根据 随机 超 平面 原理 将 该 空间 的 文档 转换 成 二 进制 数字 指纹 , 最终 用 汉 明 距离 来 衡量 指纹 间 的 差异 程度 。	该 方法 主要 通过 奇异 值 分解 获取 原始 文档 的 潜在 语义 特征 , 然后 将 原 文档 向量 空间 转换 到 与 其 对应 的 潜在 语义 空间 , 再 根据 随机 超 平面 原理 将 该 空间 的 文档 转换 成 二 进制 数字 指纹 , 最终 用 汉 明 距离 来 衡量 指纹 间 的 差异 程度 。	1<2	joint	joint
nlpabs104_Chi	49-65	153-165	该文 提出 了 一 种 基 于 潜 在 语义 分析 的 文本 指纹 提取 方法 ,	实验 以 中国 知网 上 的 学术 论文 作 为 数据 对象 ,	49-90	153-185	该文 提出 了 一 种 基 于 潜 在 语义 分析 的 文本 指纹 提取 方法 , 该 方法 是 对 数据 信息 的 一 种 压缩 表示 , 是 针对 目前 指纹 提取 方法 语义 缺失 的 一 种 改进 。	实验 以 中国 知网 上 的 学术 论文 作 为 数据 对象 , 通过 对 论文 文本 进行 相似 度 实验 和 聚类 实验 对 该文 提出 的 方法 进行 实验 验证 。	1<2	evaluation	evaluation
nlpabs104_Chi	153-165	166-185	实验 以 中国 知网 上 的 学术 论文 作 为 数据 对象 ,	通过 对 论文 文本 进行 相似 度 实验 和 聚类 实验 对 该文 提出 的 方法 进行 实验 验证 。	153-185	153-185	实验 以 中国 知网 上 的 学术 论文 作 为 数据 对象 , 通过 对 论文 文本 进行 相似 度 实验 和 聚类 实验 对 该文 提出 的 方法 进行 实验 验证 。	实验 以 中国 知网 上 的 学术 论文 作 为 数据 对象 , 通过 对 论文 文本 进行 相似 度 实验 和 聚类 实验 对 该文 提出 的 方法 进行 实验 验证 。	1<2	elab-addition	elab-addition
nlpabs104_Chi	186-188	189-198	实验 结果 表明	该 方法 能够 较好 地 表征 文档 语义 信息 ,	186-212	186-212	实验 结果 表明 该 方法 能够 较好 地 表征 文档 语义 信息 , 进而 验证 了 文本 语义 压缩 表示 的 准确 性 和 有效 性 。	实验 结果 表明 该 方法 能够 较好 地 表征 文档 语义 信息 , 进而 验证 了 文本 语义 压缩 表示 的 准确 性 和 有效 性 。	1>2	attribution	attribution
nlpabs104_Chi	166-185	189-198	通过 对 论文 文本 进行 相似 度 实验 和 聚类 实验 对 该文 提出 的 方法 进行 实验 验证 。	该 方法 能够 较好 地 表征 文档 语义 信息 ,	153-185	186-212	实验 以 中国 知网 上 的 学术 论文 作 为 数据 对象 , 通过 对 论文 文本 进行 相似 度 实验 和 聚类 实验 对 该文 提出 的 方法 进行 实验 验证 。	实验 结果 表明 该 方法 能够 较好 地 表征 文档 语义 信息 , 进而 验证 了 文本 语义 压缩 表示 的 准确 性 和 有效 性 。	1<2	elab-addition	elab-addition
nlpabs104_Chi	189-198	199-212	该 方法 能够 较好 地 表征 文档 语义 信息 ,	进而 验证 了 文本 语义 压缩 表示 的 准确 性 和 有效 性 。	186-212	186-212	实验 结果 表明 该 方法 能够 较好 地 表征 文档 语义 信息 , 进而 验证 了 文本 语义 压缩 表示 的 准确 性 和 有效 性 。	实验 结果 表明 该 方法 能够 较好 地 表征 文档 语义 信息 , 进而 验证 了 文本 语义 压缩 表示 的 准确 性 和 有效 性 。	1<2	elab-addition	elab-addition
nlpabs105_Chi	1-11	57-76	文本 是 社交 媒体 用户 的 重要 信息 之 一 ,	为 此 该文 提出 一 种 融合 用户 信任 关系 及 词 相关 关系 的 词 特征 重建 方法 。	1-36	37-76	文本 是 社交 媒体 用户 的 重要 信息 之 一 , 从 文本 中 获取 用户 的 词 特征 是 实现 用户 主题 建模 、 兴趣 挖掘 及 个性 化 推荐 等 任务 的 基础 。	然而 社交 媒体 中 存在 许多 用户 ( 冷启 动用 户 ) 只 含有 少量 甚至 缺乏 文本 信息 , 为 此 该文 提出 一 种 融合 用户 信任 关系 及 词 相关 关系 的 词 特征 重建 方法 。	1>2	bg-general	bg-general
nlpabs105_Chi	1-11	12-36	文本 是 社交 媒体 用户 的 重要 信息 之 一 ,	从 文本 中 获取 用户 的 词 特征 是 实现 用户 主题 建模 、 兴趣 挖掘 及 个性 化 推荐 等 任务 的 基础 。	1-36	1-36	文本 是 社交 媒体 用户 的 重要 信息 之 一 , 从 文本 中 获取 用户 的 词 特征 是 实现 用户 主题 建模 、 兴趣 挖掘 及 个性 化 推荐 等 任务 的 基础 。	文本 是 社交 媒体 用户 的 重要 信息 之 一 , 从 文本 中 获取 用户 的 词 特征 是 实现 用户 主题 建模 、 兴趣 挖掘 及 个性 化 推荐 等 任务 的 基础 。	1<2	elab-addition	elab-addition
nlpabs105_Chi	12-36	37-56	从 文本 中 获取 用户 的 词 特征 是 实现 用户 主题 建模 、 兴趣 挖掘 及 个性 化 推荐 等 任务 的 基础 。	然而 社交 媒体 中 存在 许多 用户 ( 冷启 动用 户 ) 只 含有 少量 甚至 缺乏 文本 信息 ,	1-36	37-76	文本 是 社交 媒体 用户 的 重要 信息 之 一 , 从 文本 中 获取 用户 的 词 特征 是 实现 用户 主题 建模 、 兴趣 挖掘 及 个性 化 推荐 等 任务 的 基础 。	然而 社交 媒体 中 存在 许多 用户 ( 冷启 动用 户 ) 只 含有 少量 甚至 缺乏 文本 信息 , 为 此 该文 提出 一 种 融合 用户 信任 关系 及 词 相关 关系 的 词 特征 重建 方法 。	1<2	contrast	contrast
nlpabs105_Chi	57-76	77-99	为 此 该文 提出 一 种 融合 用户 信任 关系 及 词 相关 关系 的 词 特征 重建 方法 。	该 方法 通过 对 用户 信任 关系 矩阵 、 词相 关 关系 矩阵 和 用户 词 特征 矩阵 进行 联合 概率 矩阵 分解	37-76	77-109	然而 社交 媒体 中 存在 许多 用户 ( 冷启 动用 户 ) 只 含有 少量 甚至 缺乏 文本 信息 , 为 此 该文 提出 一 种 融合 用户 信任 关系 及 词 相关 关系 的 词 特征 重建 方法 。	该 方法 通过 对 用户 信任 关系 矩阵 、 词相 关 关系 矩阵 和 用户 词 特征 矩阵 进行 联合 概率 矩阵 分解 来 实现 对 冷启动 用户 的 词 特征 重建 。	1<2	elab-addition	elab-addition
nlpabs105_Chi	77-99	100-109	该 方法 通过 对 用户 信任 关系 矩阵 、 词相 关 关系 矩阵 和 用户 词 特征 矩阵 进行 联合 概率 矩阵 分解	来 实现 对 冷启动 用户 的 词 特征 重建 。	77-109	77-109	该 方法 通过 对 用户 信任 关系 矩阵 、 词相 关 关系 矩阵 和 用户 词 特征 矩阵 进行 联合 概率 矩阵 分解 来 实现 对 冷启动 用户 的 词 特征 重建 。	该 方法 通过 对 用户 信任 关系 矩阵 、 词相 关 关系 矩阵 和 用户 词 特征 矩阵 进行 联合 概率 矩阵 分解 来 实现 对 冷启动 用户 的 词 特征 重建 。	1<2	enablement	enablement
nlpabs105_Chi	110-124	125-144	在 新浪 微博 和 Twitter 的 四 组 数据 集上 的 实验 结果 表明 ,	该文 所 提出 的 冷启 动用 户 词 特征 重建 算法 能够 取得 较好 的 词 特征 重建 结果 。	110-144	110-144	在 新浪 微博 和 Twitter 的 四 组 数据 集上 的 实验 结果 表明 , 该文 所 提出 的 冷启 动用 户 词 特征 重建 算法 能够 取得 较好 的 词 特征 重建 结果 。	在 新浪 微博 和 Twitter 的 四 组 数据 集上 的 实验 结果 表明 , 该文 所 提出 的 冷启 动用 户 词 特征 重建 算法 能够 取得 较好 的 词 特征 重建 结果 。	1>2	attribution	attribution
nlpabs105_Chi	57-76	125-144	为 此 该文 提出 一 种 融合 用户 信任 关系 及 词 相关 关系 的 词 特征 重建 方法 。	该文 所 提出 的 冷启 动用 户 词 特征 重建 算法 能够 取得 较好 的 词 特征 重建 结果 。	37-76	110-144	然而 社交 媒体 中 存在 许多 用户 ( 冷启 动用 户 ) 只 含有 少量 甚至 缺乏 文本 信息 , 为 此 该文 提出 一 种 融合 用户 信任 关系 及 词 相关 关系 的 词 特征 重建 方法 。	在 新浪 微博 和 Twitter 的 四 组 数据 集上 的 实验 结果 表明 , 该文 所 提出 的 冷启 动用 户 词 特征 重建 算法 能够 取得 较好 的 词 特征 重建 结果 。	1<2	evaluation	evaluation
nlpabs106_Chi	1-29	112-136	实体 属性 挖掘 ( slot filling , SF ) 旨 在 从 大 规模 文档 集 中 挖掘 给定 实体 ( 称作 查询 ) 的 特定 属性 信息 。	该文 提出 一 种 基 于 跨 文档 实体 共指 消解 ( cross document coreferen ce resolution , CDCR ) 的 实体 搜索 模型 。	1-29	107-136	实体 属性 挖掘 ( slot filling , SF ) 旨 在 从 大 规模 文档 集 中 挖掘 给定 实体 ( 称作 查询 ) 的 特定 属性 信息 。	针对 这 一 问题 , 该文 提出 一 种 基 于 跨 文档 实体 共指 消解 ( cross document coreferen ce resolution , CDCR ) 的 实体 搜索 模型 。	1>2	bg-general	bg-general
nlpabs106_Chi	1-29	30-38	实体 属性 挖掘 ( slot filling , SF ) 旨 在 从 大 规模 文档 集 中 挖掘 给定 实体 ( 称作 查询 ) 的 特定 属性 信息 。	实体 搜索 是 SF 的 重要 组成 部分 ,	1-29	30-60	实体 属性 挖掘 ( slot filling , SF ) 旨 在 从 大 规模 文档 集 中 挖掘 给定 实体 ( 称作 查询 ) 的 特定 属性 信息 。	实体 搜索 是 SF 的 重要 组成 部分 , 负责 检索 包含 给定 查询 的 文档 ( 称 为 相关 文档 ) , 供 后续 模块 从中 抽取 属性 信息 。	1<2	elab-addition	elab-addition
nlpabs106_Chi	30-38	39-52	实体 搜索 是 SF 的 重要 组成 部分 ,	负责 检索 包含 给定 查询 的 文档 ( 称 为 相关 文档 ) ,	30-60	30-60	实体 搜索 是 SF 的 重要 组成 部分 , 负责 检索 包含 给定 查询 的 文档 ( 称 为 相关 文档 ) , 供 后续 模块 从中 抽取 属性 信息 。	实体 搜索 是 SF 的 重要 组成 部分 , 负责 检索 包含 给定 查询 的 文档 ( 称 为 相关 文档 ) , 供 后续 模块 从中 抽取 属性 信息 。	1<2	elab-addition	elab-addition
nlpabs106_Chi	39-52	53-60	负责 检索 包含 给定 查询 的 文档 ( 称 为 相关 文档 ) ,	供 后续 模块 从中 抽取 属性 信息 。	30-60	30-60	实体 搜索 是 SF 的 重要 组成 部分 , 负责 检索 包含 给定 查询 的 文档 ( 称 为 相关 文档 ) , 供 后续 模块 从中 抽取 属性 信息 。	实体 搜索 是 SF 的 重要 组成 部分 , 负责 检索 包含 给定 查询 的 文档 ( 称 为 相关 文档 ) , 供 后续 模块 从中 抽取 属性 信息 。	1<2	elab-addition	elab-addition
nlpabs106_Chi	30-38	61-71	实体 搜索 是 SF 的 重要 组成 部分 ,	目前 , SF 领域 关于 实体 搜索 的 研究 较少 ,	30-60	61-106	实体 搜索 是 SF 的 重要 组成 部分 , 负责 检索 包含 给定 查询 的 文档 ( 称 为 相关 文档 ) , 供 后续 模块 从中 抽取 属性 信息 。	目前 , SF 领域 关于 实体 搜索 的 研究 较少 , 使用 的 基 于 布尔 逻辑 的 检索 模型 忽略 了 实体 查询 的 特点 , 仅 使用 查询 的 词形 信息 , 受限 于 查询 歧义 性 , 检索 结果 准确 率 较低 。	1<2	elab-addition	elab-addition
nlpabs106_Chi	61-71	72-87	目前 , SF 领域 关于 实体 搜索 的 研究 较少 ,	使用 的 基 于 布尔 逻辑 的 检索 模型 忽略 了 实体 查询 的 特点 ,	61-106	61-106	目前 , SF 领域 关于 实体 搜索 的 研究 较少 , 使用 的 基 于 布尔 逻辑 的 检索 模型 忽略 了 实体 查询 的 特点 , 仅 使用 查询 的 词形 信息 , 受限 于 查询 歧义 性 , 检索 结果 准确 率 较低 。	目前 , SF 领域 关于 实体 搜索 的 研究 较少 , 使用 的 基 于 布尔 逻辑 的 检索 模型 忽略 了 实体 查询 的 特点 , 仅 使用 查询 的 词形 信息 , 受限 于 查询 歧义 性 , 检索 结果 准确 率 较低 。	1<2	elab-addition	elab-addition
nlpabs106_Chi	72-87	88-100	使用 的 基 于 布尔 逻辑 的 检索 模型 忽略 了 实体 查询 的 特点 ,	仅 使用 查询 的 词形 信息 , 受限 于 查询 歧义 性 ,	61-106	61-106	目前 , SF 领域 关于 实体 搜索 的 研究 较少 , 使用 的 基 于 布尔 逻辑 的 检索 模型 忽略 了 实体 查询 的 特点 , 仅 使用 查询 的 词形 信息 , 受限 于 查询 歧义 性 , 检索 结果 准确 率 较低 。	目前 , SF 领域 关于 实体 搜索 的 研究 较少 , 使用 的 基 于 布尔 逻辑 的 检索 模型 忽略 了 实体 查询 的 特点 , 仅 使用 查询 的 词形 信息 , 受限 于 查询 歧义 性 , 检索 结果 准确 率 较低 。	1<2	elab-addition	elab-addition
nlpabs106_Chi	88-100	101-106	仅 使用 查询 的 词形 信息 , 受限 于 查询 歧义 性 ,	检索 结果 准确 率 较低 。	61-106	61-106	目前 , SF 领域 关于 实体 搜索 的 研究 较少 , 使用 的 基 于 布尔 逻辑 的 检索 模型 忽略 了 实体 查询 的 特点 , 仅 使用 查询 的 词形 信息 , 受限 于 查询 歧义 性 , 检索 结果 准确 率 较低 。	目前 , SF 领域 关于 实体 搜索 的 研究 较少 , 使用 的 基 于 布尔 逻辑 的 检索 模型 忽略 了 实体 查询 的 特点 , 仅 使用 查询 的 词形 信息 , 受限 于 查询 歧义 性 , 检索 结果 准确 率 较低 。	1<2	result	result
nlpabs106_Chi	107-111	112-136	针对 这 一 问题 ,	该文 提出 一 种 基 于 跨 文档 实体 共指 消解 ( cross document coreferen ce resolution , CDCR ) 的 实体 搜索 模型 。	107-136	107-136	针对 这 一 问题 , 该文 提出 一 种 基 于 跨 文档 实体 共指 消解 ( cross document coreferen ce resolution , CDCR ) 的 实体 搜索 模型 。	针对 这 一 问题 , 该文 提出 一 种 基 于 跨 文档 实体 共指 消解 ( cross document coreferen ce resolution , CDCR ) 的 实体 搜索 模型 。	1>2	bg-general	bg-general
nlpabs106_Chi	112-136	137-153	该文 提出 一 种 基 于 跨 文档 实体 共指 消解 ( cross document coreferen ce resolution , CDCR ) 的 实体 搜索 模型 。	该 方法 通过 对 召回 率 较高 但 准确 率 较低 的 候选 结果 进行 CDCR ,	107-136	137-172	针对 这 一 问题 , 该文 提出 一 种 基 于 跨 文档 实体 共指 消解 ( cross document coreferen ce resolution , CDCR ) 的 实体 搜索 模型 。	该 方法 通过 对 召回 率 较高 但 准确 率 较低 的 候选 结果 进行 CDCR , 过滤 不 包含 与 给定 实体 共 指 实体 的 文档 , 提高 检索 结果 的 准确 率 。	1<2	elab-addition	elab-addition
nlpabs106_Chi	137-153	154-165	该 方法 通过 对 召回 率 较高 但 准确 率 较低 的 候选 结果 进行 CDCR ,	过滤 不 包含 与 给定 实体 共 指 实体 的 文档 ,	137-172	137-172	该 方法 通过 对 召回 率 较高 但 准确 率 较低 的 候选 结果 进行 CDCR , 过滤 不 包含 与 给定 实体 共 指 实体 的 文档 , 提高 检索 结果 的 准确 率 。	该 方法 通过 对 召回 率 较高 但 准确 率 较低 的 候选 结果 进行 CDCR , 过滤 不 包含 与 给定 实体 共 指 实体 的 文档 , 提高 检索 结果 的 准确 率 。	1<2	enablement	enablement
nlpabs106_Chi	154-165	166-172	过滤 不 包含 与 给定 实体 共 指 实体 的 文档 ,	提高 检索 结果 的 准确 率 。	137-172	137-172	该 方法 通过 对 召回 率 较高 但 准确 率 较低 的 候选 结果 进行 CDCR , 过滤 不 包含 与 给定 实体 共 指 实体 的 文档 , 提高 检索 结果 的 准确 率 。	该 方法 通过 对 召回 率 较高 但 准确 率 较低 的 候选 结果 进行 CDCR , 过滤 不 包含 与 给定 实体 共 指 实体 的 文档 , 提高 检索 结果 的 准确 率 。	1<2	enablement	enablement
nlpabs106_Chi	173-181	182-194	为了 降低 过滤 造成 的 召回 率 损失 ,	该文 使用 伪 相关 反馈 方法 扩充 查询 实体 的 描述 信息 。	173-194	173-194	为了 降低 过滤 造成 的 召回 率 损失 , 该文 使用 伪 相关 反馈 方法 扩充 查询 实体 的 描述 信息 。	为了 降低 过滤 造成 的 召回 率 损失 , 该文 使用 伪 相关 反馈 方法 扩充 查询 实体 的 描述 信息 。	1>2	enablement	enablement
nlpabs106_Chi	112-136	182-194	该文 提出 一 种 基 于 跨 文档 实体 共指 消解 ( cross document coreferen ce resolution , CDCR ) 的 实体 搜索 模型 。	该文 使用 伪 相关 反馈 方法 扩充 查询 实体 的 描述 信息 。	107-136	173-194	针对 这 一 问题 , 该文 提出 一 种 基 于 跨 文档 实体 共指 消解 ( cross document coreferen ce resolution , CDCR ) 的 实体 搜索 模型 。	为了 降低 过滤 造成 的 召回 率 损失 , 该文 使用 伪 相关 反馈 方法 扩充 查询 实体 的 描述 信息 。	1<2	elab-addition	elab-addition
nlpabs106_Chi	195-198	204-211	实验 结果 显示 ,	该 方法 能 有效 提升 检索 结果 ,	195-221	195-221	实验 结果 显示 , 相比 于 基准 系统 , 该 方法 能 有效 提升 检索 结果 , 准确 率 和 F1 分别 提升 5.63% 、 2.56% 。	实验 结果 显示 , 相比 于 基准 系统 , 该 方法 能 有效 提升 检索 结果 , 准确 率 和 F1 分别 提升 5.63% 、 2.56% 。	1>2	attribution	attribution
nlpabs106_Chi	199-203	204-211	相比 于 基准 系统 ,	该 方法 能 有效 提升 检索 结果 ,	195-221	195-221	实验 结果 显示 , 相比 于 基准 系统 , 该 方法 能 有效 提升 检索 结果 , 准确 率 和 F1 分别 提升 5.63% 、 2.56% 。	实验 结果 显示 , 相比 于 基准 系统 , 该 方法 能 有效 提升 检索 结果 , 准确 率 和 F1 分别 提升 5.63% 、 2.56% 。	1>2	comparison	comparison
nlpabs106_Chi	112-136	204-211	该文 提出 一 种 基 于 跨 文档 实体 共指 消解 ( cross document coreferen ce resolution , CDCR ) 的 实体 搜索 模型 。	该 方法 能 有效 提升 检索 结果 ,	107-136	195-221	针对 这 一 问题 , 该文 提出 一 种 基 于 跨 文档 实体 共指 消解 ( cross document coreferen ce resolution , CDCR ) 的 实体 搜索 模型 。	实验 结果 显示 , 相比 于 基准 系统 , 该 方法 能 有效 提升 检索 结果 , 准确 率 和 F1 分别 提升 5.63% 、 2.56% 。	1<2	evaluation	evaluation
nlpabs106_Chi	204-211	212-221	该 方法 能 有效 提升 检索 结果 ,	准确 率 和 F1 分别 提升 5.63% 、 2.56% 。	195-221	195-221	实验 结果 显示 , 相比 于 基准 系统 , 该 方法 能 有效 提升 检索 结果 , 准确 率 和 F1 分别 提升 5.63% 、 2.56% 。	实验 结果 显示 , 相比 于 基准 系统 , 该 方法 能 有效 提升 检索 结果 , 准确 率 和 F1 分别 提升 5.63% 、 2.56% 。	1<2	elab-addition	elab-addition
nlpabs107_Chi	1-21	75-92	在 文本 情感 分析 时 , 使用 无 监督 的 聚类 方法 , 可以 有效 节省 人力 和 数据 资源 ,	提出 一 种 基 于 子 空间 的 文本 语义 相似 度 计算 方法 ( RESS ) 。	1-31	32-92	在 文本 情感 分析 时 , 使用 无 监督 的 聚类 方法 , 可以 有效 节省 人力 和 数据 资源 , 但 同时 也 面临 聚类 精度 不高 的 问题 。	相似 性 是 文本 聚类 的 主要 依据 , 该文 从 文本 相似 度 计算 的 角度 , 针对 情感 聚类 中 文本 — 特征 向量 的 高维 和 稀疏 问题 , 以及 对 评论 文本 潜在 情感 因素 的 表示 问题 , 提出 一 种 基 于 子 空间 的 文本 语义 相似 度 计算 方法 ( RESS ) 。	1>2	bg-compare	bg-compare
nlpabs107_Chi	1-21	22-31	在 文本 情感 分析 时 , 使用 无 监督 的 聚类 方法 , 可以 有效 节省 人力 和 数据 资源 ,	但 同时 也 面临 聚类 精度 不高 的 问题 。	1-31	1-31	在 文本 情感 分析 时 , 使用 无 监督 的 聚类 方法 , 可以 有效 节省 人力 和 数据 资源 , 但 同时 也 面临 聚类 精度 不高 的 问题 。	在 文本 情感 分析 时 , 使用 无 监督 的 聚类 方法 , 可以 有效 节省 人力 和 数据 资源 , 但 同时 也 面临 聚类 精度 不高 的 问题 。	1<2	contrast	contrast
nlpabs107_Chi	32-40	75-92	相似 性 是 文本 聚类 的 主要 依据 ,	提出 一 种 基 于 子 空间 的 文本 语义 相似 度 计算 方法 ( RESS ) 。	32-92	32-92	相似 性 是 文本 聚类 的 主要 依据 , 该文 从 文本 相似 度 计算 的 角度 , 针对 情感 聚类 中 文本 — 特征 向量 的 高维 和 稀疏 问题 , 以及 对 评论 文本 潜在 情感 因素 的 表示 问题 , 提出 一 种 基 于 子 空间 的 文本 语义 相似 度 计算 方法 ( RESS ) 。	相似 性 是 文本 聚类 的 主要 依据 , 该文 从 文本 相似 度 计算 的 角度 , 针对 情感 聚类 中 文本 — 特征 向量 的 高维 和 稀疏 问题 , 以及 对 评论 文本 潜在 情感 因素 的 表示 问题 , 提出 一 种 基 于 子 空间 的 文本 语义 相似 度 计算 方法 ( RESS ) 。	1>2	exp-reason	exp-reason
nlpabs107_Chi	41-63	75-92	该文 从 文本 相似 度 计算 的 角度 , 针对 情感 聚类 中 文本 — 特征 向量 的 高维 和 稀疏 问题 ,	提出 一 种 基 于 子 空间 的 文本 语义 相似 度 计算 方法 ( RESS ) 。	32-92	32-92	相似 性 是 文本 聚类 的 主要 依据 , 该文 从 文本 相似 度 计算 的 角度 , 针对 情感 聚类 中 文本 — 特征 向量 的 高维 和 稀疏 问题 , 以及 对 评论 文本 潜在 情感 因素 的 表示 问题 , 提出 一 种 基 于 子 空间 的 文本 语义 相似 度 计算 方法 ( RESS ) 。	相似 性 是 文本 聚类 的 主要 依据 , 该文 从 文本 相似 度 计算 的 角度 , 针对 情感 聚类 中 文本 — 特征 向量 的 高维 和 稀疏 问题 , 以及 对 评论 文本 潜在 情感 因素 的 表示 问题 , 提出 一 种 基 于 子 空间 的 文本 语义 相似 度 计算 方法 ( RESS ) 。	1>2	bg-goal	bg-goal
nlpabs107_Chi	41-63	64-74	该文 从 文本 相似 度 计算 的 角度 , 针对 情感 聚类 中 文本 — 特征 向量 的 高维 和 稀疏 问题 ,	以及 对 评论 文本 潜在 情感 因素 的 表示 问题 ,	32-92	32-92	相似 性 是 文本 聚类 的 主要 依据 , 该文 从 文本 相似 度 计算 的 角度 , 针对 情感 聚类 中 文本 — 特征 向量 的 高维 和 稀疏 问题 , 以及 对 评论 文本 潜在 情感 因素 的 表示 问题 , 提出 一 种 基 于 子 空间 的 文本 语义 相似 度 计算 方法 ( RESS ) 。	相似 性 是 文本 聚类 的 主要 依据 , 该文 从 文本 相似 度 计算 的 角度 , 针对 情感 聚类 中 文本 — 特征 向量 的 高维 和 稀疏 问题 , 以及 对 评论 文本 潜在 情感 因素 的 表示 问题 , 提出 一 种 基 于 子 空间 的 文本 语义 相似 度 计算 方法 ( RESS ) 。	1<2	joint	joint
nlpabs107_Chi	93-96	97-115	实验 结果 表明 ,	基 于 RESS 的 文本 相似 度 计算 方法 , 有效 解决 了 文本 向量 的 高维 问题 ,	93-132	93-132	实验 结果 表明 , 基 于 RESS 的 文本 相似 度 计算 方法 , 有效 解决 了 文本 向量 的 高维 问题 , 更好 地 表达 了 文本 间 情感 相似 性 , 并 获得 较好 的 聚类 结果 。	实验 结果 表明 , 基 于 RESS 的 文本 相似 度 计算 方法 , 有效 解决 了 文本 向量 的 高维 问题 , 更好 地 表达 了 文本 间 情感 相似 性 , 并 获得 较好 的 聚类 结果 。	1>2	attribution	attribution
nlpabs107_Chi	75-92	97-115	提出 一 种 基 于 子 空间 的 文本 语义 相似 度 计算 方法 ( RESS ) 。	基 于 RESS 的 文本 相似 度 计算 方法 , 有效 解决 了 文本 向量 的 高维 问题 ,	32-92	93-132	相似 性 是 文本 聚类 的 主要 依据 , 该文 从 文本 相似 度 计算 的 角度 , 针对 情感 聚类 中 文本 — 特征 向量 的 高维 和 稀疏 问题 , 以及 对 评论 文本 潜在 情感 因素 的 表示 问题 , 提出 一 种 基 于 子 空间 的 文本 语义 相似 度 计算 方法 ( RESS ) 。	实验 结果 表明 , 基 于 RESS 的 文本 相似 度 计算 方法 , 有效 解决 了 文本 向量 的 高维 问题 , 更好 地 表达 了 文本 间 情感 相似 性 , 并 获得 较好 的 聚类 结果 。	1<2	evaluation	evaluation
nlpabs107_Chi	97-115	116-125	基 于 RESS 的 文本 相似 度 计算 方法 , 有效 解决 了 文本 向量 的 高维 问题 ,	更好 地 表达 了 文本 间 情感 相似 性 ,	93-132	93-132	实验 结果 表明 , 基 于 RESS 的 文本 相似 度 计算 方法 , 有效 解决 了 文本 向量 的 高维 问题 , 更好 地 表达 了 文本 间 情感 相似 性 , 并 获得 较好 的 聚类 结果 。	实验 结果 表明 , 基 于 RESS 的 文本 相似 度 计算 方法 , 有效 解决 了 文本 向量 的 高维 问题 , 更好 地 表达 了 文本 间 情感 相似 性 , 并 获得 较好 的 聚类 结果 。	1<2	elab-addition	elab-addition
nlpabs107_Chi	116-125	126-132	更好 地 表达 了 文本 间 情感 相似 性 ,	并 获得 较好 的 聚类 结果 。	93-132	93-132	实验 结果 表明 , 基 于 RESS 的 文本 相似 度 计算 方法 , 有效 解决 了 文本 向量 的 高维 问题 , 更好 地 表达 了 文本 间 情感 相似 性 , 并 获得 较好 的 聚类 结果 。	实验 结果 表明 , 基 于 RESS 的 文本 相似 度 计算 方法 , 有效 解决 了 文本 向量 的 高维 问题 , 更好 地 表达 了 文本 间 情感 相似 性 , 并 获得 较好 的 聚类 结果 。	1<2	elab-addition	elab-addition
nlpabs108_Chi	1-17	57-74	随 着 互联 网 的 飞速 发展 , 网络 舆情 引发 的 问题 也 越发 突出 。	该文 从 主题 热度 变化 、 内容 变化 及 关键 词 等 多 方面 进行 了 研究 。	1-17	36-74	随 着 互联 网 的 飞速 发展 , 网络 舆情 引发 的 问题 也 越发 突出 。	主题 演化 是 网络 舆情 分析 的 重要 内容 之 一 , 为了 把 握关 于 新疆 的 舆情 动态 , 该文 从 主题 热度 变化 、 内容 变化 及 关键 词 等 多 方面 进行 了 研究 。	1>2	bg-general	bg-general
nlpabs108_Chi	1-17	18-35	随 着 互联 网 的 飞速 发展 , 网络 舆情 引发 的 问题 也 越发 突出 。	尤其 是 近年 来 发生 的 新疆 暴恐 事件 , 已 成 为 公众 关注 的 焦点 。	1-17	18-35	随 着 互联 网 的 飞速 发展 , 网络 舆情 引发 的 问题 也 越发 突出 。	尤其 是 近年 来 发生 的 新疆 暴恐 事件 , 已 成 为 公众 关注 的 焦点 。	1<2	elab-addition	elab-addition
nlpabs108_Chi	36-47	57-74	主题 演化 是 网络 舆情 分析 的 重要 内容 之 一 ,	该文 从 主题 热度 变化 、 内容 变化 及 关键 词 等 多 方面 进行 了 研究 。	36-74	36-74	主题 演化 是 网络 舆情 分析 的 重要 内容 之 一 , 为了 把 握关 于 新疆 的 舆情 动态 , 该文 从 主题 热度 变化 、 内容 变化 及 关键 词 等 多 方面 进行 了 研究 。	主题 演化 是 网络 舆情 分析 的 重要 内容 之 一 , 为了 把 握关 于 新疆 的 舆情 动态 , 该文 从 主题 热度 变化 、 内容 变化 及 关键 词 等 多 方面 进行 了 研究 。	1>2	bg-general	bg-general
nlpabs108_Chi	48-56	57-74	为了 把 握关 于 新疆 的 舆情 动态 ,	该文 从 主题 热度 变化 、 内容 变化 及 关键 词 等 多 方面 进行 了 研究 。	36-74	36-74	主题 演化 是 网络 舆情 分析 的 重要 内容 之 一 , 为了 把 握关 于 新疆 的 舆情 动态 , 该文 从 主题 热度 变化 、 内容 变化 及 关键 词 等 多 方面 进行 了 研究 。	主题 演化 是 网络 舆情 分析 的 重要 内容 之 一 , 为了 把 握关 于 新疆 的 舆情 动态 , 该文 从 主题 热度 变化 、 内容 变化 及 关键 词 等 多 方面 进行 了 研究 。	1>2	enablement	enablement
nlpabs108_Chi	57-74	75-97	该文 从 主题 热度 变化 、 内容 变化 及 关键 词 等 多 方面 进行 了 研究 。	该文 首先 抓取 了 2013 年 1 月 到 2015 年 12 月 互联 网 中 关于 新疆 暴恐 事件 的 新闻 ,	36-74	75-117	主题 演化 是 网络 舆情 分析 的 重要 内容 之 一 , 为了 把 握关 于 新疆 的 舆情 动态 , 该文 从 主题 热度 变化 、 内容 变化 及 关键 词 等 多 方面 进行 了 研究 。	该文 首先 抓取 了 2013 年 1 月 到 2015 年 12 月 互联 网 中 关于 新疆 暴恐 事件 的 新闻 , 并 以 此作 为 数据 集 建立 了 动态 主题 模型 , 实现 对 新闻 的 主题 演化 分析 。	1<2	elab-addition	elab-addition
nlpabs108_Chi	75-97	98-109	该文 首先 抓取 了 2013 年 1 月 到 2015 年 12 月 互联 网 中 关于 新疆 暴恐 事件 的 新闻 ,	并 以 此作 为 数据 集 建立 了 动态 主题 模型 ,	75-117	75-117	该文 首先 抓取 了 2013 年 1 月 到 2015 年 12 月 互联 网 中 关于 新疆 暴恐 事件 的 新闻 , 并 以 此作 为 数据 集 建立 了 动态 主题 模型 , 实现 对 新闻 的 主题 演化 分析 。	该文 首先 抓取 了 2013 年 1 月 到 2015 年 12 月 互联 网 中 关于 新疆 暴恐 事件 的 新闻 , 并 以 此作 为 数据 集 建立 了 动态 主题 模型 , 实现 对 新闻 的 主题 演化 分析 。	1<2	joint	joint
nlpabs108_Chi	98-109	110-117	并 以 此作 为 数据 集 建立 了 动态 主题 模型 ,	实现 对 新闻 的 主题 演化 分析 。	75-117	75-117	该文 首先 抓取 了 2013 年 1 月 到 2015 年 12 月 互联 网 中 关于 新疆 暴恐 事件 的 新闻 , 并 以 此作 为 数据 集 建立 了 动态 主题 模型 , 实现 对 新闻 的 主题 演化 分析 。	该文 首先 抓取 了 2013 年 1 月 到 2015 年 12 月 互联 网 中 关于 新疆 暴恐 事件 的 新闻 , 并 以 此作 为 数据 集 建立 了 动态 主题 模型 , 实现 对 新闻 的 主题 演化 分析 。	1<2	enablement	enablement
nlpabs108_Chi	98-109	118-130	并 以 此作 为 数据 集 建立 了 动态 主题 模型 ,	该 模型 采用 两 次 非 负 矩阵 分解 来 生成 主题 ,	75-117	118-155	该文 首先 抓取 了 2013 年 1 月 到 2015 年 12 月 互联 网 中 关于 新疆 暴恐 事件 的 新闻 , 并 以 此作 为 数据 集 建立 了 动态 主题 模型 , 实现 对 新闻 的 主题 演化 分析 。	该 模型 采用 两 次 非 负 矩阵 分解 来 生成 主题 , 以 层级 式 狄利克雷 过程 为 对比 实验 , 通过 可 视 化 分析 与 比较 , 总结 出 新疆 暴恐 事件 的 一些 规律	1<2	elab-addition	elab-addition
nlpabs108_Chi	118-130	131-139	该 模型 采用 两 次 非 负 矩阵 分解 来 生成 主题 ,	以 层级 式 狄利克雷 过程 为 对比 实验 ,	118-155	118-155	该 模型 采用 两 次 非 负 矩阵 分解 来 生成 主题 , 以 层级 式 狄利克雷 过程 为 对比 实验 , 通过 可 视 化 分析 与 比较 , 总结 出 新疆 暴恐 事件 的 一些 规律	该 模型 采用 两 次 非 负 矩阵 分解 来 生成 主题 , 以 层级 式 狄利克雷 过程 为 对比 实验 , 通过 可 视 化 分析 与 比较 , 总结 出 新疆 暴恐 事件 的 一些 规律	1<2	elab-addition	elab-addition
nlpabs108_Chi	131-139	140-155	以 层级 式 狄利克雷 过程 为 对比 实验 ,	通过 可 视 化 分析 与 比较 , 总结 出 新疆 暴恐 事件 的 一些 规律	118-155	118-155	该 模型 采用 两 次 非 负 矩阵 分解 来 生成 主题 , 以 层级 式 狄利克雷 过程 为 对比 实验 , 通过 可 视 化 分析 与 比较 , 总结 出 新疆 暴恐 事件 的 一些 规律	该 模型 采用 两 次 非 负 矩阵 分解 来 生成 主题 , 以 层级 式 狄利克雷 过程 为 对比 实验 , 通过 可 视 化 分析 与 比较 , 总结 出 新疆 暴恐 事件 的 一些 规律	1<2	elab-addition	elab-addition
nlpabs10_Chi	1-29	100-121	﻿作 为 自然 语言 处理 一 个 新 的 研究 方向 , 话题 识别 与 跟踪 旨 在 发展 一 系列 基 于 事件 的 信息 组织 技术 ,	该文 介绍 了 话题 识别 与 跟踪 研究 的 发展 历史 、 研究 任务 、 主要 技术 及 评价 方法 等 ,	1-49	100-134	﻿作 为 自然 语言 处理 一 个 新 的 研究 方向 , 话题 识别 与 跟踪 旨 在 发展 一 系列 基 于 事件 的 信息 组织 技术 , 以 实现 对 新闻 媒体信 息流 中 新 话题 的 自动 识别 以及 对 已知 话题 的 动态 跟踪 。	该文 介绍 了 话题 识别 与 跟踪 研究 的 发展 历史 、 研究 任务 、 主要 技术 及 评价 方法 等 , 希望 能 引起 相关 研究 者 对 这 项 研究 的 关注 。	1>2	bg-general	bg-general
nlpabs10_Chi	1-29	30-49	﻿作 为 自然 语言 处理 一 个 新 的 研究 方向 , 话题 识别 与 跟踪 旨 在 发展 一 系列 基 于 事件 的 信息 组织 技术 ,	以 实现 对 新闻 媒体信 息流 中 新 话题 的 自动 识别 以及 对 已知 话题 的 动态 跟踪 。	1-49	1-49	﻿作 为 自然 语言 处理 一 个 新 的 研究 方向 , 话题 识别 与 跟踪 旨 在 发展 一 系列 基 于 事件 的 信息 组织 技术 , 以 实现 对 新闻 媒体信 息流 中 新 话题 的 自动 识别 以及 对 已知 话题 的 动态 跟踪 。	﻿作 为 自然 语言 处理 一 个 新 的 研究 方向 , 话题 识别 与 跟踪 旨 在 发展 一 系列 基 于 事件 的 信息 组织 技术 , 以 实现 对 新闻 媒体信 息流 中 新 话题 的 自动 识别 以及 对 已知 话题 的 动态 跟踪 。	1<2	enablement	enablement
nlpabs10_Chi	1-29	50-86	﻿作 为 自然 语言 处理 一 个 新 的 研究 方向 , 话题 识别 与 跟踪 旨 在 发展 一 系列 基 于 事件 的 信息 组织 技术 ,	自 1997 年 以来 连续 举行 的 多 次 大 规模 评测 使得 话题 识别 与 跟踪 研究 正 逐步 成 为 近来 自然 语言 处理 尤其 是 信息 检索 领域 的 一 个 研究 热点 ,	1-49	50-99	﻿作 为 自然 语言 处理 一 个 新 的 研究 方向 , 话题 识别 与 跟踪 旨 在 发展 一 系列 基 于 事件 的 信息 组织 技术 , 以 实现 对 新闻 媒体信 息流 中 新 话题 的 自动 识别 以及 对 已知 话题 的 动态 跟踪 。	自 1997 年 以来 连续 举行 的 多 次 大 规模 评测 使得 话题 识别 与 跟踪 研究 正 逐步 成 为 近来 自然 语言 处理 尤其 是 信息 检索 领域 的 一 个 研究 热点 , 目前 国内 在 这 方面 的 研究 尚 处 在 起步 阶段 。	1<2	elab-addition	elab-addition
nlpabs10_Chi	50-86	87-99	自 1997 年 以来 连续 举行 的 多 次 大 规模 评测 使得 话题 识别 与 跟踪 研究 正 逐步 成 为 近来 自然 语言 处理 尤其 是 信息 检索 领域 的 一 个 研究 热点 ,	目前 国内 在 这 方面 的 研究 尚 处 在 起步 阶段 。	50-99	50-99	自 1997 年 以来 连续 举行 的 多 次 大 规模 评测 使得 话题 识别 与 跟踪 研究 正 逐步 成 为 近来 自然 语言 处理 尤其 是 信息 检索 领域 的 一 个 研究 热点 , 目前 国内 在 这 方面 的 研究 尚 处 在 起步 阶段 。	自 1997 年 以来 连续 举行 的 多 次 大 规模 评测 使得 话题 识别 与 跟踪 研究 正 逐步 成 为 近来 自然 语言 处理 尤其 是 信息 检索 领域 的 一 个 研究 热点 , 目前 国内 在 这 方面 的 研究 尚 处 在 起步 阶段 。	1<2	elab-addition	elab-addition
nlpabs10_Chi	100-121	122-134	该文 介绍 了 话题 识别 与 跟踪 研究 的 发展 历史 、 研究 任务 、 主要 技术 及 评价 方法 等 ,	希望 能 引起 相关 研究 者 对 这 项 研究 的 关注 。	100-134	100-134	该文 介绍 了 话题 识别 与 跟踪 研究 的 发展 历史 、 研究 任务 、 主要 技术 及 评价 方法 等 , 希望 能 引起 相关 研究 者 对 这 项 研究 的 关注 。	该文 介绍 了 话题 识别 与 跟踪 研究 的 发展 历史 、 研究 任务 、 主要 技术 及 评价 方法 等 , 希望 能 引起 相关 研究 者 对 这 项 研究 的 关注 。	1<2	elab-addition	elab-addition
nlpabs11_Chi	1-10	66-76	自然 语言 是 人类 交流 最 自然 的 方式 。	受控 自然 语言 随 着 这些 需求 应运 而 生 。	1-10	26-76	自然 语言 是 人类 交流 最 自然 的 方式 。	现代 社会 尤其 是 当前 信息 时代 面对 大量 的 信息 数据 , 不少 工业 场景 和 科研 领域 以及 各种 人机 交互 的 应用 要求 清晰 精准 、 标准 化 而 又 较为 自然 的 表达 和 交流 , 受控 自然 语言 随 着 这些 需求 应运 而 生 。	1>2	bg-general	bg-general
nlpabs11_Chi	1-10	11-25	自然 语言 是 人类 交流 最 自然 的 方式 。	但 其 复杂 性 和 模糊 性 常常 给 有效 的 交流 带来 问题 。	1-10	11-25	自然 语言 是 人类 交流 最 自然 的 方式 。	但 其 复杂 性 和 模糊 性 常常 给 有效 的 交流 带来 问题 。	1<2	elab-addition	elab-addition
nlpabs11_Chi	26-38	77-99	现代 社会 尤其 是 当前 信息 时代 面对 大量 的 信息 数据 ,	该 文 讨论 受控 自然 语言 及 其 性质 、 分类 和 应用 , 以及 受控 自然 语言 的 计算 处理 方法 。	26-76	77-99	现代 社会 尤其 是 当前 信息 时代 面对 大量 的 信息 数据 , 不少 工业 场景 和 科研 领域 以及 各种 人机 交互 的 应用 要求 清晰 精准 、 标准 化 而 又 较为 自然 的 表达 和 交流 , 受控 自然 语言 随 着 这些 需求 应运 而 生 。	该 文 讨论 受控 自然 语言 及 其 性质 、 分类 和 应用 , 以及 受控 自然 语言 的 计算 处理 方法 。	1>2	bg-general	bg-general
nlpabs11_Chi	26-38	39-65	现代 社会 尤其 是 当前 信息 时代 面对 大量 的 信息 数据 ,	不少 工业 场景 和 科研 领域 以及 各种 人机 交互 的 应用 要求 清晰 精准 、 标准 化 而 又 较为 自然 的 表达 和 交流 ,	26-76	26-76	现代 社会 尤其 是 当前 信息 时代 面对 大量 的 信息 数据 , 不少 工业 场景 和 科研 领域 以及 各种 人机 交互 的 应用 要求 清晰 精准 、 标准 化 而 又 较为 自然 的 表达 和 交流 , 受控 自然 语言 随 着 这些 需求 应运 而 生 。	现代 社会 尤其 是 当前 信息 时代 面对 大量 的 信息 数据 , 不少 工业 场景 和 科研 领域 以及 各种 人机 交互 的 应用 要求 清晰 精准 、 标准 化 而 又 较为 自然 的 表达 和 交流 , 受控 自然 语言 随 着 这些 需求 应运 而 生 。	1<2	elab-addition	elab-addition
nlpabs11_Chi	39-65	66-76	不少 工业 场景 和 科研 领域 以及 各种 人机 交互 的 应用 要求 清晰 精准 、 标准 化 而 又 较为 自然 的 表达 和 交流 ,	受控 自然 语言 随 着 这些 需求 应运 而 生 。	26-76	26-76	现代 社会 尤其 是 当前 信息 时代 面对 大量 的 信息 数据 , 不少 工业 场景 和 科研 领域 以及 各种 人机 交互 的 应用 要求 清晰 精准 、 标准 化 而 又 较为 自然 的 表达 和 交流 , 受控 自然 语言 随 着 这些 需求 应运 而 生 。	现代 社会 尤其 是 当前 信息 时代 面对 大量 的 信息 数据 , 不少 工业 场景 和 科研 领域 以及 各种 人机 交互 的 应用 要求 清晰 精准 、 标准 化 而 又 较为 自然 的 表达 和 交流 , 受控 自然 语言 随 着 这些 需求 应运 而 生 。	1<2	elab-addition	elab-addition
nlpabs11_Chi	77-99	100-116	该 文 讨论 受控 自然 语言 及 其 性质 、 分类 和 应用 , 以及 受控 自然 语言 的 计算 处理 方法 。	该文 将 以 航空 工业 民 用 飞机 所 涉及 的 英 语 文本 数据 为 例	77-99	100-157	该 文 讨论 受控 自然 语言 及 其 性质 、 分类 和 应用 , 以及 受控 自然 语言 的 计算 处理 方法 。	该文 将 以 航空 工业 民 用 飞机 所 涉及 的 英 语 文本 数据 为 例 来 阐述 受控 自然 语言 在 工业 场景 中 的 作用 和 重要 性 , 并且 简要 讨论 受控 自然 语言 更为 广泛 的 意义 和 价值 , 涉及 其他 领域 包括 当前 热门 的 人工 智能 等 相关 的 课题	1<2	elab-addition	elab-addition
nlpabs11_Chi	100-116	117-131	该文 将 以 航空 工业 民 用 飞机 所 涉及 的 英 语 文本 数据 为 例	来 阐述 受控 自然 语言 在 工业 场景 中 的 作用 和 重要 性 ,	100-157	100-157	该文 将 以 航空 工业 民 用 飞机 所 涉及 的 英 语 文本 数据 为 例 来 阐述 受控 自然 语言 在 工业 场景 中 的 作用 和 重要 性 , 并且 简要 讨论 受控 自然 语言 更为 广泛 的 意义 和 价值 , 涉及 其他 领域 包括 当前 热门 的 人工 智能 等 相关 的 课题	该文 将 以 航空 工业 民 用 飞机 所 涉及 的 英 语 文本 数据 为 例 来 阐述 受控 自然 语言 在 工业 场景 中 的 作用 和 重要 性 , 并且 简要 讨论 受控 自然 语言 更为 广泛 的 意义 和 价值 , 涉及 其他 领域 包括 当前 热门 的 人工 智能 等 相关 的 课题	1<2	enablement	enablement
nlpabs11_Chi	117-131	132-144	来 阐述 受控 自然 语言 在 工业 场景 中 的 作用 和 重要 性 ,	并且 简要 讨论 受控 自然 语言 更为 广泛 的 意义 和 价值 ,	100-157	100-157	该文 将 以 航空 工业 民 用 飞机 所 涉及 的 英 语 文本 数据 为 例 来 阐述 受控 自然 语言 在 工业 场景 中 的 作用 和 重要 性 , 并且 简要 讨论 受控 自然 语言 更为 广泛 的 意义 和 价值 , 涉及 其他 领域 包括 当前 热门 的 人工 智能 等 相关 的 课题	该文 将 以 航空 工业 民 用 飞机 所 涉及 的 英 语 文本 数据 为 例 来 阐述 受控 自然 语言 在 工业 场景 中 的 作用 和 重要 性 , 并且 简要 讨论 受控 自然 语言 更为 广泛 的 意义 和 价值 , 涉及 其他 领域 包括 当前 热门 的 人工 智能 等 相关 的 课题	1<2	joint	joint
nlpabs11_Chi	132-144	145-157	并且 简要 讨论 受控 自然 语言 更为 广泛 的 意义 和 价值 ,	涉及 其他 领域 包括 当前 热门 的 人工 智能 等 相关 的 课题	100-157	100-157	该文 将 以 航空 工业 民 用 飞机 所 涉及 的 英 语 文本 数据 为 例 来 阐述 受控 自然 语言 在 工业 场景 中 的 作用 和 重要 性 , 并且 简要 讨论 受控 自然 语言 更为 广泛 的 意义 和 价值 , 涉及 其他 领域 包括 当前 热门 的 人工 智能 等 相关 的 课题	该文 将 以 航空 工业 民 用 飞机 所 涉及 的 英 语 文本 数据 为 例 来 阐述 受控 自然 语言 在 工业 场景 中 的 作用 和 重要 性 , 并且 简要 讨论 受控 自然 语言 更为 广泛 的 意义 和 价值 , 涉及 其他 领域 包括 当前 热门 的 人工 智能 等 相关 的 课题	1<2	elab-addition	elab-addition
nlpabs12_Chi	1-30	103-119	随 着 移动 互联 网 与 社会 网络 的 深度 融合 , 基 于 位置 服务 ( Location Based Service , LBS ) 的 社交 媒体 应用 更加 流行 ,	从 LBSN 时空 数据 抽取 、 海量 时空 数据 可 视 化 等 方面 进行 综述 ,	1-45	89-180	随 着 移动 互联 网 与 社会 网络 的 深度 融合 , 基 于 位置 服务 ( Location Based Service , LBS ) 的 社交 媒体 应用 更加 流行 , 成 为 地理 社会 网络 ( Geo-Social Networks , GSN ) 的 研究 重点 。	该文 以 GSN 中 抽取 出 的 海量 时空 数据 为 分析 对象 , 从 LBSN 时空 数据 抽取 、 海量 时空 数据 可 视 化 等 方面 进行 综述 , 对 地理 社会 网络 时空 数据 交互 可 视 化 分析 技术 开展 研究 , 以期 能够 实现 比较 方便 、 快速 、 直接 地 从 地理 社会 网络 的 海量 数据 中 提取 出 有用 、 可靠 、 可 知识 化 的 综合 信息 , 并 通过 信息 可 视 化 方式 进行 直观 表达 、 展示 与 分析 。	1>2	bg-general	bg-general
nlpabs12_Chi	1-30	31-45	随 着 移动 互联 网 与 社会 网络 的 深度 融合 , 基 于 位置 服务 ( Location Based Service , LBS ) 的 社交 媒体 应用 更加 流行 ,	成 为 地理 社会 网络 ( Geo-Social Networks , GSN ) 的 研究 重点 。	1-45	1-45	随 着 移动 互联 网 与 社会 网络 的 深度 融合 , 基 于 位置 服务 ( Location Based Service , LBS ) 的 社交 媒体 应用 更加 流行 , 成 为 地理 社会 网络 ( Geo-Social Networks , GSN ) 的 研究 重点 。	随 着 移动 互联 网 与 社会 网络 的 深度 融合 , 基 于 位置 服务 ( Location Based Service , LBS ) 的 社交 媒体 应用 更加 流行 , 成 为 地理 社会 网络 ( Geo-Social Networks , GSN ) 的 研究 重点 。	1<2	joint	joint
nlpabs12_Chi	1-30	46-65	随 着 移动 互联 网 与 社会 网络 的 深度 融合 , 基 于 位置 服务 ( Location Based Service , LBS ) 的 社交 媒体 应用 更加 流行 ,	基 于 位置 信息 的 社会 网络 ( Location Based Social Network , LBSN ) 由于 具有 时空 特性 ,	1-45	46-88	随 着 移动 互联 网 与 社会 网络 的 深度 融合 , 基 于 位置 服务 ( Location Based Service , LBS ) 的 社交 媒体 应用 更加 流行 , 成 为 地理 社会 网络 ( Geo-Social Networks , GSN ) 的 研究 重点 。	基 于 位置 信息 的 社会 网络 ( Location Based Social Network , LBSN ) 由于 具有 时空 特性 , 其 海量 数据 可 视 化 不同 于 传统 信息 可 视 化 , 必须 结合 其 地理 信息 特征 进行 表达 。	1<2	elab-addition	elab-addition
nlpabs12_Chi	46-65	66-79	基 于 位置 信息 的 社会 网络 ( Location Based Social Network , LBSN ) 由于 具有 时空 特性 ,	其 海量 数据 可 视 化 不同 于 传统 信息 可 视 化 ,	46-88	46-88	基 于 位置 信息 的 社会 网络 ( Location Based Social Network , LBSN ) 由于 具有 时空 特性 , 其 海量 数据 可 视 化 不同 于 传统 信息 可 视 化 , 必须 结合 其 地理 信息 特征 进行 表达 。	基 于 位置 信息 的 社会 网络 ( Location Based Social Network , LBSN ) 由于 具有 时空 特性 , 其 海量 数据 可 视 化 不同 于 传统 信息 可 视 化 , 必须 结合 其 地理 信息 特征 进行 表达 。	1<2	result	result
nlpabs12_Chi	66-79	80-88	其 海量 数据 可 视 化 不同 于 传统 信息 可 视 化 ,	必须 结合 其 地理 信息 特征 进行 表达 。	46-88	46-88	基 于 位置 信息 的 社会 网络 ( Location Based Social Network , LBSN ) 由于 具有 时空 特性 , 其 海量 数据 可 视 化 不同 于 传统 信息 可 视 化 , 必须 结合 其 地理 信息 特征 进行 表达 。	基 于 位置 信息 的 社会 网络 ( Location Based Social Network , LBSN ) 由于 具有 时空 特性 , 其 海量 数据 可 视 化 不同 于 传统 信息 可 视 化 , 必须 结合 其 地理 信息 特征 进行 表达 。	1<2	elab-addition	elab-addition
nlpabs12_Chi	89-102	103-119	该文 以 GSN 中 抽取 出 的 海量 时空 数据 为 分析 对象 ,	从 LBSN 时空 数据 抽取 、 海量 时空 数据 可 视 化 等 方面 进行 综述 ,	89-180	89-180	该文 以 GSN 中 抽取 出 的 海量 时空 数据 为 分析 对象 , 从 LBSN 时空 数据 抽取 、 海量 时空 数据 可 视 化 等 方面 进行 综述 , 对 地理 社会 网络 时空 数据 交互 可 视 化 分析 技术 开展 研究 , 以期 能够 实现 比较 方便 、 快速 、 直接 地 从 地理 社会 网络 的 海量 数据 中 提取 出 有用 、 可靠 、 可 知识 化 的 综合 信息 , 并 通过 信息 可 视 化 方式 进行 直观 表达 、 展示 与 分析 。	该文 以 GSN 中 抽取 出 的 海量 时空 数据 为 分析 对象 , 从 LBSN 时空 数据 抽取 、 海量 时空 数据 可 视 化 等 方面 进行 综述 , 对 地理 社会 网络 时空 数据 交互 可 视 化 分析 技术 开展 研究 , 以期 能够 实现 比较 方便 、 快速 、 直接 地 从 地理 社会 网络 的 海量 数据 中 提取 出 有用 、 可靠 、 可 知识 化 的 综合 信息 , 并 通过 信息 可 视 化 方式 进行 直观 表达 、 展示 与 分析 。	1>2	bg-general	bg-general
nlpabs12_Chi	103-119	120-134	从 LBSN 时空 数据 抽取 、 海量 时空 数据 可 视 化 等 方面 进行 综述 ,	对 地理 社会 网络 时空 数据 交互 可 视 化 分析 技术 开展 研究 ,	89-180	89-180	该文 以 GSN 中 抽取 出 的 海量 时空 数据 为 分析 对象 , 从 LBSN 时空 数据 抽取 、 海量 时空 数据 可 视 化 等 方面 进行 综述 , 对 地理 社会 网络 时空 数据 交互 可 视 化 分析 技术 开展 研究 , 以期 能够 实现 比较 方便 、 快速 、 直接 地 从 地理 社会 网络 的 海量 数据 中 提取 出 有用 、 可靠 、 可 知识 化 的 综合 信息 , 并 通过 信息 可 视 化 方式 进行 直观 表达 、 展示 与 分析 。	该文 以 GSN 中 抽取 出 的 海量 时空 数据 为 分析 对象 , 从 LBSN 时空 数据 抽取 、 海量 时空 数据 可 视 化 等 方面 进行 综述 , 对 地理 社会 网络 时空 数据 交互 可 视 化 分析 技术 开展 研究 , 以期 能够 实现 比较 方便 、 快速 、 直接 地 从 地理 社会 网络 的 海量 数据 中 提取 出 有用 、 可靠 、 可 知识 化 的 综合 信息 , 并 通过 信息 可 视 化 方式 进行 直观 表达 、 展示 与 分析 。	1<2	joint	joint
nlpabs12_Chi	103-119	135-165	从 LBSN 时空 数据 抽取 、 海量 时空 数据 可 视 化 等 方面 进行 综述 ,	以期 能够 实现 比较 方便 、 快速 、 直接 地 从 地理 社会 网络 的 海量 数据 中 提取 出 有用 、 可靠 、 可 知识 化 的 综合 信息 ,	89-180	89-180	该文 以 GSN 中 抽取 出 的 海量 时空 数据 为 分析 对象 , 从 LBSN 时空 数据 抽取 、 海量 时空 数据 可 视 化 等 方面 进行 综述 , 对 地理 社会 网络 时空 数据 交互 可 视 化 分析 技术 开展 研究 , 以期 能够 实现 比较 方便 、 快速 、 直接 地 从 地理 社会 网络 的 海量 数据 中 提取 出 有用 、 可靠 、 可 知识 化 的 综合 信息 , 并 通过 信息 可 视 化 方式 进行 直观 表达 、 展示 与 分析 。	该文 以 GSN 中 抽取 出 的 海量 时空 数据 为 分析 对象 , 从 LBSN 时空 数据 抽取 、 海量 时空 数据 可 视 化 等 方面 进行 综述 , 对 地理 社会 网络 时空 数据 交互 可 视 化 分析 技术 开展 研究 , 以期 能够 实现 比较 方便 、 快速 、 直接 地 从 地理 社会 网络 的 海量 数据 中 提取 出 有用 、 可靠 、 可 知识 化 的 综合 信息 , 并 通过 信息 可 视 化 方式 进行 直观 表达 、 展示 与 分析 。	1<2	enablement	enablement
nlpabs12_Chi	135-165	166-180	以期 能够 实现 比较 方便 、 快速 、 直接 地 从 地理 社会 网络 的 海量 数据 中 提取 出 有用 、 可靠 、 可 知识 化 的 综合 信息 ,	并 通过 信息 可 视 化 方式 进行 直观 表达 、 展示 与 分析 。	89-180	89-180	该文 以 GSN 中 抽取 出 的 海量 时空 数据 为 分析 对象 , 从 LBSN 时空 数据 抽取 、 海量 时空 数据 可 视 化 等 方面 进行 综述 , 对 地理 社会 网络 时空 数据 交互 可 视 化 分析 技术 开展 研究 , 以期 能够 实现 比较 方便 、 快速 、 直接 地 从 地理 社会 网络 的 海量 数据 中 提取 出 有用 、 可靠 、 可 知识 化 的 综合 信息 , 并 通过 信息 可 视 化 方式 进行 直观 表达 、 展示 与 分析 。	该文 以 GSN 中 抽取 出 的 海量 时空 数据 为 分析 对象 , 从 LBSN 时空 数据 抽取 、 海量 时空 数据 可 视 化 等 方面 进行 综述 , 对 地理 社会 网络 时空 数据 交互 可 视 化 分析 技术 开展 研究 , 以期 能够 实现 比较 方便 、 快速 、 直接 地 从 地理 社会 网络 的 海量 数据 中 提取 出 有用 、 可靠 、 可 知识 化 的 综合 信息 , 并 通过 信息 可 视 化 方式 进行 直观 表达 、 展示 与 分析 。	1<2	joint	joint
nlpabs13_Chi	1-10	11-23	该文 吸收 已 有 动词 研究 的 相关 成果 ,	提出 了 动词 语义 词典 开发 的 相关 原则 和 研制 思路 ,	1-55	1-55	该文 吸收 已 有 动词 研究 的 相关 成果 , 提出 了 动词 语义 词典 开发 的 相关 原则 和 研制 思路 , 界定 并 描写 了 词典 中 所 涉及 的 相关 属性 信息 , 并 对 词典 的 总体 文件 结构 及 其 各个 库 的 信息 进行 了 描写 和 说明 。	该文 吸收 已 有 动词 研究 的 相关 成果 , 提出 了 动词 语义 词典 开发 的 相关 原则 和 研制 思路 , 界定 并 描写 了 词典 中 所 涉及 的 相关 属性 信息 , 并 对 词典 的 总体 文件 结构 及 其 各个 库 的 信息 进行 了 描写 和 说明 。	1>2	bg-general	bg-general
nlpabs13_Chi	11-23	24-36	提出 了 动词 语义 词典 开发 的 相关 原则 和 研制 思路 ,	界定 并 描写 了 词典 中 所 涉及 的 相关 属性 信息 ,	1-55	1-55	该文 吸收 已 有 动词 研究 的 相关 成果 , 提出 了 动词 语义 词典 开发 的 相关 原则 和 研制 思路 , 界定 并 描写 了 词典 中 所 涉及 的 相关 属性 信息 , 并 对 词典 的 总体 文件 结构 及 其 各个 库 的 信息 进行 了 描写 和 说明 。	该文 吸收 已 有 动词 研究 的 相关 成果 , 提出 了 动词 语义 词典 开发 的 相关 原则 和 研制 思路 , 界定 并 描写 了 词典 中 所 涉及 的 相关 属性 信息 , 并 对 词典 的 总体 文件 结构 及 其 各个 库 的 信息 进行 了 描写 和 说明 。	1<2	elab-addition	elab-addition
nlpabs13_Chi	24-36	37-55	界定 并 描写 了 词典 中 所 涉及 的 相关 属性 信息 ,	并 对 词典 的 总体 文件 结构 及 其 各个 库 的 信息 进行 了 描写 和 说明 。	1-55	1-55	该文 吸收 已 有 动词 研究 的 相关 成果 , 提出 了 动词 语义 词典 开发 的 相关 原则 和 研制 思路 , 界定 并 描写 了 词典 中 所 涉及 的 相关 属性 信息 , 并 对 词典 的 总体 文件 结构 及 其 各个 库 的 信息 进行 了 描写 和 说明 。	该文 吸收 已 有 动词 研究 的 相关 成果 , 提出 了 动词 语义 词典 开发 的 相关 原则 和 研制 思路 , 界定 并 描写 了 词典 中 所 涉及 的 相关 属性 信息 , 并 对 词典 的 总体 文件 结构 及 其 各个 库 的 信息 进行 了 描写 和 说明 。	1<2	joint	joint
nlpabs13_Chi	11-23	56-100	提出 了 动词 语义 词典 开发 的 相关 原则 和 研制 思路 ,	最终 开发 了 融合 词汇 语义 和 句法 语义 , 涵盖 词形 、 词性 、 释义 、 义类 、 义场 、 句法 范畴 信息 、 语义 范畴 信息 、 语义 句模 等 多 种 信息 参数 的 开放 性 的 动词 语义 知识 词典 。	1-55	56-100	该文 吸收 已 有 动词 研究 的 相关 成果 , 提出 了 动词 语义 词典 开发 的 相关 原则 和 研制 思路 , 界定 并 描写 了 词典 中 所 涉及 的 相关 属性 信息 , 并 对 词典 的 总体 文件 结构 及 其 各个 库 的 信息 进行 了 描写 和 说明 。	最终 开发 了 融合 词汇 语义 和 句法 语义 , 涵盖 词形 、 词性 、 释义 、 义类 、 义场 、 句法 范畴 信息 、 语义 范畴 信息 、 语义 句模 等 多 种 信息 参数 的 开放 性 的 动词 语义 知识 词典 。	1<2	enablement	enablement
nlpabs13_Chi	56-100	101-123	最终 开发 了 融合 词汇 语义 和 句法 语义 , 涵盖 词形 、 词性 、 释义 、 义类 、 义场 、 句法 范畴 信息 、 语义 范畴 信息 、 语义 句模 等 多 种 信息 参数 的 开放 性 的 动词 语义 知识 词典 。	该 词典 可以 在 歧义 分化 、 词义 关系 考察 、 句法 — 语义 接口 、 句模 抽取 等 方面 提供 支持 。	56-100	101-123	最终 开发 了 融合 词汇 语义 和 句法 语义 , 涵盖 词形 、 词性 、 释义 、 义类 、 义场 、 句法 范畴 信息 、 语义 范畴 信息 、 语义 句模 等 多 种 信息 参数 的 开放 性 的 动词 语义 知识 词典 。	该 词典 可以 在 歧义 分化 、 词义 关系 考察 、 句法 — 语义 接口 、 句模 抽取 等 方面 提供 支持 。	1<2	elab-addition	elab-addition
nlpabs14_Chi	1-29	90-102	近 十 年 来 , 依存 句法 分析 由于 具有 表示 形式 简单 、 灵活 、 分析 效率 高 等 特点 , 得到 了 学术 界 广泛 关注 。	为 此 , 该文 充分 参考 了 已有 的 数据 标注 工作 ,	1-29	90-132	近 十 年 来 , 依存 句法 分析 由于 具有 表示 形式 简单 、 灵活 、 分析 效率 高 等 特点 , 得到 了 学术 界 广泛 关注 。	为 此 , 该文 充分 参考 了 已有 的 数据 标注 工作 , 同时 结合 实际 标注 中 遇到 的 问题 , 制定 了 一 个 新 的 适应 多 领域 多来源 文本 的 汉 语 依 存句 法 数据 标注 规范 。	1>2	bg-general	bg-general
nlpabs14_Chi	1-29	30-51	近 十 年 来 , 依存 句法 分析 由于 具有 表示 形式 简单 、 灵活 、 分析 效率 高 等 特点 , 得到 了 学术 界 广泛 关注 。	为了 支持 汉 语 依存 句法 分析 研究 , 国内 同行 分别 标注 了 几 个 汉 语 依存 句法 树库 。	1-29	30-51	近 十 年 来 , 依存 句法 分析 由于 具有 表示 形式 简单 、 灵活 、 分析 效率 高 等 特点 , 得到 了 学术 界 广泛 关注 。	为了 支持 汉 语 依存 句法 分析 研究 , 国内 同行 分别 标注 了 几 个 汉 语 依存 句法 树库 。	1<2	elab-addition	elab-addition
nlpabs14_Chi	30-51	52-72	为了 支持 汉 语 依存 句法 分析 研究 , 国内 同行 分别 标注 了 几 个 汉 语 依存 句法 树库 。	然而 , 目前 还 没有 一 个 公开 、 完整 、 系统 的 汉 语 依 存句法 数据 标注 规范 ,	30-51	52-89	为了 支持 汉 语 依存 句法 分析 研究 , 国内 同行 分别 标注 了 几 个 汉 语 依存 句法 树库 。	然而 , 目前 还 没有 一 个 公开 、 完整 、 系统 的 汉 语 依 存句法 数据 标注 规范 , 并且 已有 的 树库 标注 工作 对 网络 文本 中 的 特殊 语言 现象 考虑 较少 。	1<2	contrast	contrast
nlpabs14_Chi	52-72	73-89	然而 , 目前 还 没有 一 个 公开 、 完整 、 系统 的 汉 语 依 存句法 数据 标注 规范 ,	并且 已有 的 树库 标注 工作 对 网络 文本 中 的 特殊 语言 现象 考虑 较少 。	52-89	52-89	然而 , 目前 还 没有 一 个 公开 、 完整 、 系统 的 汉 语 依 存句法 数据 标注 规范 , 并且 已有 的 树库 标注 工作 对 网络 文本 中 的 特殊 语言 现象 考虑 较少 。	然而 , 目前 还 没有 一 个 公开 、 完整 、 系统 的 汉 语 依 存句法 数据 标注 规范 , 并且 已有 的 树库 标注 工作 对 网络 文本 中 的 特殊 语言 现象 考虑 较少 。	1<2	joint	joint
nlpabs14_Chi	90-102	112-132	为 此 , 该文 充分 参考 了 已有 的 数据 标注 工作 ,	制定 了 一 个 新 的 适应 多 领域 多来源 文本 的 汉 语 依 存句 法 数据 标注 规范 。	90-132	90-132	为 此 , 该文 充分 参考 了 已有 的 数据 标注 工作 , 同时 结合 实际 标注 中 遇到 的 问题 , 制定 了 一 个 新 的 适应 多 领域 多来源 文本 的 汉 语 依 存句 法 数据 标注 规范 。	为 此 , 该文 充分 参考 了 已有 的 数据 标注 工作 , 同时 结合 实际 标注 中 遇到 的 问题 , 制定 了 一 个 新 的 适应 多 领域 多来源 文本 的 汉 语 依 存句 法 数据 标注 规范 。	1>2	manner-means	manner-means
nlpabs14_Chi	90-102	103-111	为 此 , 该文 充分 参考 了 已有 的 数据 标注 工作 ,	同时 结合 实际 标注 中 遇到 的 问题 ,	90-132	90-132	为 此 , 该文 充分 参考 了 已有 的 数据 标注 工作 , 同时 结合 实际 标注 中 遇到 的 问题 , 制定 了 一 个 新 的 适应 多 领域 多来源 文本 的 汉 语 依 存句 法 数据 标注 规范 。	为 此 , 该文 充分 参考 了 已有 的 数据 标注 工作 , 同时 结合 实际 标注 中 遇到 的 问题 , 制定 了 一 个 新 的 适应 多 领域 多来源 文本 的 汉 语 依 存句 法 数据 标注 规范 。	1<2	joint	joint
nlpabs14_Chi	112-132	133-153	制定 了 一 个 新 的 适应 多 领域 多来源 文本 的 汉 语 依 存句 法 数据 标注 规范 。	我们 制定 规范 的 目标 是 准确 刻画 各种 语言 现象 的 句法 结构 , 同时 保证 标注 一致 性 。	90-132	133-153	为 此 , 该文 充分 参考 了 已有 的 数据 标注 工作 , 同时 结合 实际 标注 中 遇到 的 问题 , 制定 了 一 个 新 的 适应 多 领域 多来源 文本 的 汉 语 依 存句 法 数据 标注 规范 。	我们 制定 规范 的 目标 是 准确 刻画 各种 语言 现象 的 句法 结构 , 同时 保证 标注 一致 性 。	1<2	bg-goal	bg-goal
nlpabs14_Chi	154-157	158-171	利用 此 规范 ,	我们 已经 标注 了 约 3万 句 汉 语 依存 句法 树 库 。	154-171	154-171	利用 此 规范 , 我们 已经 标注 了 约 3万 句 汉 语 依存 句法 树 库 。	利用 此 规范 , 我们 已经 标注 了 约 3万 句 汉 语 依存 句法 树 库 。	1>2	manner-means	manner-means
nlpabs14_Chi	112-132	158-171	制定 了 一 个 新 的 适应 多 领域 多来源 文本 的 汉 语 依 存句 法 数据 标注 规范 。	我们 已经 标注 了 约 3万 句 汉 语 依存 句法 树 库 。	90-132	154-171	为 此 , 该文 充分 参考 了 已有 的 数据 标注 工作 , 同时 结合 实际 标注 中 遇到 的 问题 , 制定 了 一 个 新 的 适应 多 领域 多来源 文本 的 汉 语 依 存句 法 数据 标注 规范 。	利用 此 规范 , 我们 已经 标注 了 约 3万 句 汉 语 依存 句法 树 库 。	1<2	elab-addition	elab-addition
nlpabs15_Chi	1-21	126-145	基 于 注意 力 机 制 的 神经 网络 机器 翻译 模型 已经 成 为 目前 主流 的 翻译 模型 ,	该文 使用 了 一 种 简单 循环 单元 ( sim ple recurrent unit , SRU ) 代替 GRU 单元 ,	1-50	126-168	基 于 注意 力 机 制 的 神经 网络 机器 翻译 模型 已经 成 为 目前 主流 的 翻译 模型 , 在 许多 翻译 方向 上 均 超过 了 统计 机器 翻译 模型 , 尤其 是 在 训练 语料 规模 比 较大 的 情况 下 , 优势 更加 明显 。	该文 使用 了 一 种 简单 循环 单元 ( sim ple recurrent unit , SRU ) 代替 GRU 单元 , 通过 堆叠 网络 层数 加深 编码 器 和 解码 器 的 结构 , 提高 了 神经 网络 机器 翻译 模型 的 性能 。	1>2	bg-compare	bg-compare
nlpabs15_Chi	1-21	22-50	基 于 注意 力 机 制 的 神经 网络 机器 翻译 模型 已经 成 为 目前 主流 的 翻译 模型 ,	在 许多 翻译 方向 上 均 超过 了 统计 机器 翻译 模型 , 尤其 是 在 训练 语料 规模 比 较大 的 情况 下 , 优势 更加 明显 。	1-50	1-50	基 于 注意 力 机 制 的 神经 网络 机器 翻译 模型 已经 成 为 目前 主流 的 翻译 模型 , 在 许多 翻译 方向 上 均 超过 了 统计 机器 翻译 模型 , 尤其 是 在 训练 语料 规模 比 较大 的 情况 下 , 优势 更加 明显 。	基 于 注意 力 机 制 的 神经 网络 机器 翻译 模型 已经 成 为 目前 主流 的 翻译 模型 , 在 许多 翻译 方向 上 均 超过 了 统计 机器 翻译 模型 , 尤其 是 在 训练 语料 规模 比 较大 的 情况 下 , 优势 更加 明显 。	1<2	elab-addition	elab-addition
nlpabs15_Chi	1-21	51-60	基 于 注意 力 机 制 的 神经 网络 机器 翻译 模型 已经 成 为 目前 主流 的 翻译 模型 ,	该 模型 使用 编码 器 — 解码 器 框架 ,	1-50	51-72	基 于 注意 力 机 制 的 神经 网络 机器 翻译 模型 已经 成 为 目前 主流 的 翻译 模型 , 在 许多 翻译 方向 上 均 超过 了 统计 机器 翻译 模型 , 尤其 是 在 训练 语料 规模 比 较大 的 情况 下 , 优势 更加 明显 。	该 模型 使用 编码 器 — 解码 器 框架 , 将 翻译 任务 建模 成 序 列 到 序列 的 问题 。	1<2	elab-addition	elab-addition
nlpabs15_Chi	51-60	61-72	该 模型 使用 编码 器 — 解码 器 框架 ,	将 翻译 任务 建模 成 序 列 到 序列 的 问题 。	51-72	51-72	该 模型 使用 编码 器 — 解码 器 框架 , 将 翻译 任务 建模 成 序 列 到 序列 的 问题 。	该 模型 使用 编码 器 — 解码 器 框架 , 将 翻译 任务 建模 成 序 列 到 序列 的 问题 。	1<2	enablement	enablement
nlpabs15_Chi	1-21	73-114	基 于 注意 力 机 制 的 神经 网络 机器 翻译 模型 已经 成 为 目前 主流 的 翻译 模型 ,	然而 , 在 基 于 门 控 循环 单元 ( gated recurren t unit , GRU ) 的 编码 器 — 解码 器 模型 中 , 随 着 模型 层数 的 增加 , 梯度 消失 的 问题 使 模型 难 以 收敛	1-50	73-125	基 于 注意 力 机 制 的 神经 网络 机器 翻译 模型 已经 成 为 目前 主流 的 翻译 模型 , 在 许多 翻译 方向 上 均 超过 了 统计 机器 翻译 模型 , 尤其 是 在 训练 语料 规模 比 较大 的 情况 下 , 优势 更加 明显 。	然而 , 在 基 于 门 控 循环 单元 ( gated recurren t unit , GRU ) 的 编码 器 — 解码 器 模型 中 , 随 着 模型 层数 的 增加 , 梯度 消失 的 问题 使 模型 难 以 收敛 并且 严重 退化 , 进而 使 翻译 性 能 下降 。	1<2	elab-addition	elab-addition
nlpabs15_Chi	73-114	115-118	然而 , 在 基 于 门 控 循环 单元 ( gated recurren t unit , GRU ) 的 编码 器 — 解码 器 模型 中 , 随 着 模型 层数 的 增加 , 梯度 消失 的 问题 使 模型 难 以 收敛	并且 严重 退化 ,	73-125	73-125	然而 , 在 基 于 门 控 循环 单元 ( gated recurren t unit , GRU ) 的 编码 器 — 解码 器 模型 中 , 随 着 模型 层数 的 增加 , 梯度 消失 的 问题 使 模型 难 以 收敛 并且 严重 退化 , 进而 使 翻译 性 能 下降 。	然而 , 在 基 于 门 控 循环 单元 ( gated recurren t unit , GRU ) 的 编码 器 — 解码 器 模型 中 , 随 着 模型 层数 的 增加 , 梯度 消失 的 问题 使 模型 难 以 收敛 并且 严重 退化 , 进而 使 翻译 性 能 下降 。	1<2	joint	joint
nlpabs15_Chi	73-114	119-125	然而 , 在 基 于 门 控 循环 单元 ( gated recurren t unit , GRU ) 的 编码 器 — 解码 器 模型 中 , 随 着 模型 层数 的 增加 , 梯度 消失 的 问题 使 模型 难 以 收敛	进而 使 翻译 性 能 下降 。	73-125	73-125	然而 , 在 基 于 门 控 循环 单元 ( gated recurren t unit , GRU ) 的 编码 器 — 解码 器 模型 中 , 随 着 模型 层数 的 增加 , 梯度 消失 的 问题 使 模型 难 以 收敛 并且 严重 退化 , 进而 使 翻译 性 能 下降 。	然而 , 在 基 于 门 控 循环 单元 ( gated recurren t unit , GRU ) 的 编码 器 — 解码 器 模型 中 , 随 着 模型 层数 的 增加 , 梯度 消失 的 问题 使 模型 难 以 收敛 并且 严重 退化 , 进而 使 翻译 性 能 下降 。	1<2	elab-addition	elab-addition
nlpabs15_Chi	126-145	146-168	该文 使用 了 一 种 简单 循环 单元 ( sim ple recurrent unit , SRU ) 代替 GRU 单元 ,	通过 堆叠 网络 层数 加深 编码 器 和 解码 器 的 结构 , 提高 了 神经 网络 机器 翻译 模型 的 性能 。	126-168	126-168	该文 使用 了 一 种 简单 循环 单元 ( sim ple recurrent unit , SRU ) 代替 GRU 单元 , 通过 堆叠 网络 层数 加深 编码 器 和 解码 器 的 结构 , 提高 了 神经 网络 机器 翻译 模型 的 性能 。	该文 使用 了 一 种 简单 循环 单元 ( sim ple recurrent unit , SRU ) 代替 GRU 单元 , 通过 堆叠 网络 层数 加深 编码 器 和 解码 器 的 结构 , 提高 了 神经 网络 机器 翻译 模型 的 性能 。	1<2	elab-addition	elab-addition
nlpabs15_Chi	126-145	169-188	该文 使用 了 一 种 简单 循环 单元 ( sim ple recurrent unit , SRU ) 代替 GRU 单元 ,	我们 在 德 语 — 英 语 和 维 语 — 汉 语 翻译 任务 上 进行 了 实验 ,	126-168	169-237	该文 使用 了 一 种 简单 循环 单元 ( sim ple recurrent unit , SRU ) 代替 GRU 单元 , 通过 堆叠 网络 层数 加深 编码 器 和 解码 器 的 结构 , 提高 了 神经 网络 机器 翻译 模型 的 性能 。	我们 在 德 语 — 英 语 和 维 语 — 汉 语 翻译 任务 上 进行 了 实验 , 实验 结果 表明 , 在 神经 网络 机器 翻译 模型 中 使用 SRU 单元 , 可以 有效 地 解决 梯度 消失 带来 的 模型 难 以 训练 的 问题 ; 通过 加深 模型 能够 显著 地 提升 系统 的 翻译 性能 , 同时 保证 训练 速度 基本 不变 。	1<2	evaluation	evaluation
nlpabs15_Chi	189-192	193-218	实验 结果 表明 ,	在 神经 网络 机器 翻译 模型 中 使用 SRU 单元 , 可以 有效 地 解决 梯度 消失 带来 的 模型 难 以 训练 的 问题 ;	169-237	169-237	我们 在 德 语 — 英 语 和 维 语 — 汉 语 翻译 任务 上 进行 了 实验 , 实验 结果 表明 , 在 神经 网络 机器 翻译 模型 中 使用 SRU 单元 , 可以 有效 地 解决 梯度 消失 带来 的 模型 难 以 训练 的 问题 ; 通过 加深 模型 能够 显著 地 提升 系统 的 翻译 性能 , 同时 保证 训练 速度 基本 不变 。	我们 在 德 语 — 英 语 和 维 语 — 汉 语 翻译 任务 上 进行 了 实验 , 实验 结果 表明 , 在 神经 网络 机器 翻译 模型 中 使用 SRU 单元 , 可以 有效 地 解决 梯度 消失 带来 的 模型 难 以 训练 的 问题 ; 通过 加深 模型 能够 显著 地 提升 系统 的 翻译 性能 , 同时 保证 训练 速度 基本 不变 。	1>2	attribution	attribution
nlpabs15_Chi	169-188	193-218	我们 在 德 语 — 英 语 和 维 语 — 汉 语 翻译 任务 上 进行 了 实验 ,	在 神经 网络 机器 翻译 模型 中 使用 SRU 单元 , 可以 有效 地 解决 梯度 消失 带来 的 模型 难 以 训练 的 问题 ;	169-237	169-237	我们 在 德 语 — 英 语 和 维 语 — 汉 语 翻译 任务 上 进行 了 实验 , 实验 结果 表明 , 在 神经 网络 机器 翻译 模型 中 使用 SRU 单元 , 可以 有效 地 解决 梯度 消失 带来 的 模型 难 以 训练 的 问题 ; 通过 加深 模型 能够 显著 地 提升 系统 的 翻译 性能 , 同时 保证 训练 速度 基本 不变 。	我们 在 德 语 — 英 语 和 维 语 — 汉 语 翻译 任务 上 进行 了 实验 , 实验 结果 表明 , 在 神经 网络 机器 翻译 模型 中 使用 SRU 单元 , 可以 有效 地 解决 梯度 消失 带来 的 模型 难 以 训练 的 问题 ; 通过 加深 模型 能够 显著 地 提升 系统 的 翻译 性能 , 同时 保证 训练 速度 基本 不变 。	1<2	progression	progression
nlpabs15_Chi	193-218	219-230	在 神经 网络 机器 翻译 模型 中 使用 SRU 单元 , 可以 有效 地 解决 梯度 消失 带来 的 模型 难 以 训练 的 问题 ;	通过 加深 模型 能够 显著 地 提升 系统 的 翻译 性能 ,	169-237	169-237	我们 在 德 语 — 英 语 和 维 语 — 汉 语 翻译 任务 上 进行 了 实验 , 实验 结果 表明 , 在 神经 网络 机器 翻译 模型 中 使用 SRU 单元 , 可以 有效 地 解决 梯度 消失 带来 的 模型 难 以 训练 的 问题 ; 通过 加深 模型 能够 显著 地 提升 系统 的 翻译 性能 , 同时 保证 训练 速度 基本 不变 。	我们 在 德 语 — 英 语 和 维 语 — 汉 语 翻译 任务 上 进行 了 实验 , 实验 结果 表明 , 在 神经 网络 机器 翻译 模型 中 使用 SRU 单元 , 可以 有效 地 解决 梯度 消失 带来 的 模型 难 以 训练 的 问题 ; 通过 加深 模型 能够 显著 地 提升 系统 的 翻译 性能 , 同时 保证 训练 速度 基本 不变 。	1<2	joint	joint
nlpabs15_Chi	219-230	231-237	通过 加深 模型 能够 显著 地 提升 系统 的 翻译 性能 ,	同时 保证 训练 速度 基本 不变 。	169-237	169-237	我们 在 德 语 — 英 语 和 维 语 — 汉 语 翻译 任务 上 进行 了 实验 , 实验 结果 表明 , 在 神经 网络 机器 翻译 模型 中 使用 SRU 单元 , 可以 有效 地 解决 梯度 消失 带来 的 模型 难 以 训练 的 问题 ; 通过 加深 模型 能够 显著 地 提升 系统 的 翻译 性能 , 同时 保证 训练 速度 基本 不变 。	我们 在 德 语 — 英 语 和 维 语 — 汉 语 翻译 任务 上 进行 了 实验 , 实验 结果 表明 , 在 神经 网络 机器 翻译 模型 中 使用 SRU 单元 , 可以 有效 地 解决 梯度 消失 带来 的 模型 难 以 训练 的 问题 ; 通过 加深 模型 能够 显著 地 提升 系统 的 翻译 性能 , 同时 保证 训练 速度 基本 不变 。	1<2	joint	joint
nlpabs15_Chi	169-188	238-261	我们 在 德 语 — 英 语 和 维 语 — 汉 语 翻译 任务 上 进行 了 实验 ,	此外 , 我们 还 与 基 于 残差 连接 ( residual connections ) 的 神经 网络 机器 翻译 模型 进行 了 实验 对比 ,	169-237	238-273	我们 在 德 语 — 英 语 和 维 语 — 汉 语 翻译 任务 上 进行 了 实验 , 实验 结果 表明 , 在 神经 网络 机器 翻译 模型 中 使用 SRU 单元 , 可以 有效 地 解决 梯度 消失 带来 的 模型 难 以 训练 的 问题 ; 通过 加深 模型 能够 显著 地 提升 系统 的 翻译 性能 , 同时 保证 训练 速度 基本 不变 。	此外 , 我们 还 与 基 于 残差 连接 ( residual connections ) 的 神经 网络 机器 翻译 模型 进行 了 实验 对比 , 实验 结果 表明 , 我们 的 模型 有 显著 性 优势 。	1<2	progression	progression
nlpabs15_Chi	262-265	266-273	实验 结果 表明 ,	我们 的 模型 有 显著 性 优势 。	238-273	238-273	此外 , 我们 还 与 基 于 残差 连接 ( residual connections ) 的 神经 网络 机器 翻译 模型 进行 了 实验 对比 , 实验 结果 表明 , 我们 的 模型 有 显著 性 优势 。	此外 , 我们 还 与 基 于 残差 连接 ( residual connections ) 的 神经 网络 机器 翻译 模型 进行 了 实验 对比 , 实验 结果 表明 , 我们 的 模型 有 显著 性 优势 。	1>2	attribution	attribution
nlpabs15_Chi	238-261	266-273	此外 , 我们 还 与 基 于 残差 连接 ( residual connections ) 的 神经 网络 机器 翻译 模型 进行 了 实验 对比 ,	我们 的 模型 有 显著 性 优势 。	238-273	238-273	此外 , 我们 还 与 基 于 残差 连接 ( residual connections ) 的 神经 网络 机器 翻译 模型 进行 了 实验 对比 , 实验 结果 表明 , 我们 的 模型 有 显著 性 优势 。	此外 , 我们 还 与 基 于 残差 连接 ( residual connections ) 的 神经 网络 机器 翻译 模型 进行 了 实验 对比 , 实验 结果 表明 , 我们 的 模型 有 显著 性 优势 。	1<2	evaluation	evaluation
nlpabs16_Chi	1-22	87-105	复杂 网络 具有 自 组织 、 自 相似 、 吸引子 、 小 世界 、 无 标度 中 部分 或 全部 性质 ,	分析 了 藏 文 字 同 现 网络 的 最短 路径 长度 、 聚类 系数 和 度 分布 ,	1-43	44-142	复杂 网络 具有 自 组织 、 自 相似 、 吸引子 、 小 世界 、 无 标度 中 部分 或 全部 性质 , 而 语言 文字 作 为 人类 智慧 和 文明 的 结晶 , 是 经过 漫长 演化 形成 的 复杂 网络 。	该文 对 藏 语 诗歌 、 散文 、 政治 、 佛教 、 教材 和 口语 等 六 类 具有 代表 性 的 体裁 语料 , 每类 各 取 15 篇 共 90 篇 文章 构建 了 97 个 藏 文 字同现 网络 , 分析 了 藏 文 字 同 现 网络 的 最短 路径 长度 、 聚类 系数 和 度 分布 , 实验 数据 显示 97 个 藏 文字 同 现 网络 都 具有 小 世界 效应 和 无 标度 特性 , 表明 藏 文 字 同 现 网络 都 具有 小 世界 效应 和 无 标度 特性 。	1>2	bg-general	bg-general
nlpabs16_Chi	1-22	23-34	复杂 网络 具有 自 组织 、 自 相似 、 吸引子 、 小 世界 、 无 标度 中 部分 或 全部 性质 ,	而 语言 文字 作 为 人类 智慧 和 文明 的 结晶 ,	1-43	1-43	复杂 网络 具有 自 组织 、 自 相似 、 吸引子 、 小 世界 、 无 标度 中 部分 或 全部 性质 , 而 语言 文字 作 为 人类 智慧 和 文明 的 结晶 , 是 经过 漫长 演化 形成 的 复杂 网络 。	复杂 网络 具有 自 组织 、 自 相似 、 吸引子 、 小 世界 、 无 标度 中 部分 或 全部 性质 , 而 语言 文字 作 为 人类 智慧 和 文明 的 结晶 , 是 经过 漫长 演化 形成 的 复杂 网络 。	1<2	elab-addition	elab-addition
nlpabs16_Chi	23-34	35-43	而 语言 文字 作 为 人类 智慧 和 文明 的 结晶 ,	是 经过 漫长 演化 形成 的 复杂 网络 。	1-43	1-43	复杂 网络 具有 自 组织 、 自 相似 、 吸引子 、 小 世界 、 无 标度 中 部分 或 全部 性质 , 而 语言 文字 作 为 人类 智慧 和 文明 的 结晶 , 是 经过 漫长 演化 形成 的 复杂 网络 。	复杂 网络 具有 自 组织 、 自 相似 、 吸引子 、 小 世界 、 无 标度 中 部分 或 全部 性质 , 而 语言 文字 作 为 人类 智慧 和 文明 的 结晶 , 是 经过 漫长 演化 形成 的 复杂 网络 。	1<2	elab-addition	elab-addition
nlpabs16_Chi	44-86	87-105	该文 对 藏 语 诗歌 、 散文 、 政治 、 佛教 、 教材 和 口语 等 六 类 具有 代表 性 的 体裁 语料 , 每类 各 取 15 篇 共 90 篇 文章 构建 了 97 个 藏 文 字同现 网络 ,	分析 了 藏 文 字 同 现 网络 的 最短 路径 长度 、 聚类 系数 和 度 分布 ,	44-142	44-142	该文 对 藏 语 诗歌 、 散文 、 政治 、 佛教 、 教材 和 口语 等 六 类 具有 代表 性 的 体裁 语料 , 每类 各 取 15 篇 共 90 篇 文章 构建 了 97 个 藏 文 字同现 网络 , 分析 了 藏 文 字 同 现 网络 的 最短 路径 长度 、 聚类 系数 和 度 分布 , 实验 数据 显示 97 个 藏 文字 同 现 网络 都 具有 小 世界 效应 和 无 标度 特性 , 表明 藏 文 字 同 现 网络 都 具有 小 世界 效应 和 无 标度 特性 。	该文 对 藏 语 诗歌 、 散文 、 政治 、 佛教 、 教材 和 口语 等 六 类 具有 代表 性 的 体裁 语料 , 每类 各 取 15 篇 共 90 篇 文章 构建 了 97 个 藏 文 字同现 网络 , 分析 了 藏 文 字 同 现 网络 的 最短 路径 长度 、 聚类 系数 和 度 分布 , 实验 数据 显示 97 个 藏 文字 同 现 网络 都 具有 小 世界 效应 和 无 标度 特性 , 表明 藏 文 字 同 现 网络 都 具有 小 世界 效应 和 无 标度 特性 。	1>2	manner-means	manner-means
nlpabs16_Chi	106-108	109-125	实验 数据 显示	97 个 藏 文字 同 现 网络 都 具有 小 世界 效应 和 无 标度 特性 ,	44-142	44-142	该文 对 藏 语 诗歌 、 散文 、 政治 、 佛教 、 教材 和 口语 等 六 类 具有 代表 性 的 体裁 语料 , 每类 各 取 15 篇 共 90 篇 文章 构建 了 97 个 藏 文 字同现 网络 , 分析 了 藏 文 字 同 现 网络 的 最短 路径 长度 、 聚类 系数 和 度 分布 , 实验 数据 显示 97 个 藏 文字 同 现 网络 都 具有 小 世界 效应 和 无 标度 特性 , 表明 藏 文 字 同 现 网络 都 具有 小 世界 效应 和 无 标度 特性 。	该文 对 藏 语 诗歌 、 散文 、 政治 、 佛教 、 教材 和 口语 等 六 类 具有 代表 性 的 体裁 语料 , 每类 各 取 15 篇 共 90 篇 文章 构建 了 97 个 藏 文 字同现 网络 , 分析 了 藏 文 字 同 现 网络 的 最短 路径 长度 、 聚类 系数 和 度 分布 , 实验 数据 显示 97 个 藏 文字 同 现 网络 都 具有 小 世界 效应 和 无 标度 特性 , 表明 藏 文 字 同 现 网络 都 具有 小 世界 效应 和 无 标度 特性 。	1>2	attribution	attribution
nlpabs16_Chi	87-105	109-125	分析 了 藏 文 字 同 现 网络 的 最短 路径 长度 、 聚类 系数 和 度 分布 ,	97 个 藏 文字 同 现 网络 都 具有 小 世界 效应 和 无 标度 特性 ,	44-142	44-142	该文 对 藏 语 诗歌 、 散文 、 政治 、 佛教 、 教材 和 口语 等 六 类 具有 代表 性 的 体裁 语料 , 每类 各 取 15 篇 共 90 篇 文章 构建 了 97 个 藏 文 字同现 网络 , 分析 了 藏 文 字 同 现 网络 的 最短 路径 长度 、 聚类 系数 和 度 分布 , 实验 数据 显示 97 个 藏 文字 同 现 网络 都 具有 小 世界 效应 和 无 标度 特性 , 表明 藏 文 字 同 现 网络 都 具有 小 世界 效应 和 无 标度 特性 。	该文 对 藏 语 诗歌 、 散文 、 政治 、 佛教 、 教材 和 口语 等 六 类 具有 代表 性 的 体裁 语料 , 每类 各 取 15 篇 共 90 篇 文章 构建 了 97 个 藏 文 字同现 网络 , 分析 了 藏 文 字 同 现 网络 的 最短 路径 长度 、 聚类 系数 和 度 分布 , 实验 数据 显示 97 个 藏 文字 同 现 网络 都 具有 小 世界 效应 和 无 标度 特性 , 表明 藏 文 字 同 现 网络 都 具有 小 世界 效应 和 无 标度 特性 。	1<2	elab-addition	elab-addition
nlpabs16_Chi	126	127-142	表明	藏 文 字 同 现 网络 都 具有 小 世界 效应 和 无 标度 特性 。	44-142	44-142	该文 对 藏 语 诗歌 、 散文 、 政治 、 佛教 、 教材 和 口语 等 六 类 具有 代表 性 的 体裁 语料 , 每类 各 取 15 篇 共 90 篇 文章 构建 了 97 个 藏 文 字同现 网络 , 分析 了 藏 文 字 同 现 网络 的 最短 路径 长度 、 聚类 系数 和 度 分布 , 实验 数据 显示 97 个 藏 文字 同 现 网络 都 具有 小 世界 效应 和 无 标度 特性 , 表明 藏 文 字 同 现 网络 都 具有 小 世界 效应 和 无 标度 特性 。	该文 对 藏 语 诗歌 、 散文 、 政治 、 佛教 、 教材 和 口语 等 六 类 具有 代表 性 的 体裁 语料 , 每类 各 取 15 篇 共 90 篇 文章 构建 了 97 个 藏 文 字同现 网络 , 分析 了 藏 文 字 同 现 网络 的 最短 路径 长度 、 聚类 系数 和 度 分布 , 实验 数据 显示 97 个 藏 文字 同 现 网络 都 具有 小 世界 效应 和 无 标度 特性 , 表明 藏 文 字 同 现 网络 都 具有 小 世界 效应 和 无 标度 特性 。	1>2	attribution	attribution
nlpabs16_Chi	109-125	127-142	97 个 藏 文字 同 现 网络 都 具有 小 世界 效应 和 无 标度 特性 ,	藏 文 字 同 现 网络 都 具有 小 世界 效应 和 无 标度 特性 。	44-142	44-142	该文 对 藏 语 诗歌 、 散文 、 政治 、 佛教 、 教材 和 口语 等 六 类 具有 代表 性 的 体裁 语料 , 每类 各 取 15 篇 共 90 篇 文章 构建 了 97 个 藏 文 字同现 网络 , 分析 了 藏 文 字 同 现 网络 的 最短 路径 长度 、 聚类 系数 和 度 分布 , 实验 数据 显示 97 个 藏 文字 同 现 网络 都 具有 小 世界 效应 和 无 标度 特性 , 表明 藏 文 字 同 现 网络 都 具有 小 世界 效应 和 无 标度 特性 。	该文 对 藏 语 诗歌 、 散文 、 政治 、 佛教 、 教材 和 口语 等 六 类 具有 代表 性 的 体裁 语料 , 每类 各 取 15 篇 共 90 篇 文章 构建 了 97 个 藏 文 字同现 网络 , 分析 了 藏 文 字 同 现 网络 的 最短 路径 长度 、 聚类 系数 和 度 分布 , 实验 数据 显示 97 个 藏 文字 同 现 网络 都 具有 小 世界 效应 和 无 标度 特性 , 表明 藏 文 字 同 现 网络 都 具有 小 世界 效应 和 无 标度 特性 。	1<2	elab-addition	elab-addition
nlpabs18_Chi	1-10	11-20	不 平衡 数据 广泛 存在 于 现实 生活 中 ,	代价 敏感 学习 能 有效 解决 这 一 问题 。	1-20	1-20	不 平衡 数据 广泛 存在 于 现实 生活 中 , 代价 敏感 学习 能 有效 解决 这 一 问题 。	不 平衡 数据 广泛 存在 于 现实 生活 中 , 代价 敏感 学习 能 有效 解决 这 一 问题 。	1>2	bg-general	bg-general
nlpabs18_Chi	11-20	21-32	代价 敏感 学习 能 有效 解决 这 一 问题 。	然而 , 当 数据 的 标记 信息 有限 或 不足 时 ,	1-20	21-50	不 平衡 数据 广泛 存在 于 现实 生活 中 , 代价 敏感 学习 能 有效 解决 这 一 问题 。	然而 , 当 数据 的 标记 信息 有限 或 不足 时 , 代价 敏感 学习分 类器 的 分类 精度 大大 下降 , 分类 性 能 得 不 到 保证 。	1>2	bg-general	bg-general
nlpabs18_Chi	21-32	33-42	然而 , 当 数据 的 标记 信息 有限 或 不足 时 ,	代价 敏感 学习分 类器 的 分类 精度 大大 下降 ,	21-50	21-50	然而 , 当 数据 的 标记 信息 有限 或 不足 时 , 代价 敏感 学习分 类器 的 分类 精度 大大 下降 , 分类 性 能 得 不 到 保证 。	然而 , 当 数据 的 标记 信息 有限 或 不足 时 , 代价 敏感 学习分 类器 的 分类 精度 大大 下降 , 分类 性 能 得 不 到 保证 。	1>2	condition	condition
nlpabs18_Chi	33-42	51-55	代价 敏感 学习分 类器 的 分类 精度 大大 下降 ,	针对 这 一 情况 ,	21-50	51-134	然而 , 当 数据 的 标记 信息 有限 或 不足 时 , 代价 敏感 学习分 类器 的 分类 精度 大大 下降 , 分类 性 能 得 不 到 保证 。	针对 这 一 情况 , 该文 提出 了 一 种 局部 几何 保持 的 Laplacian 代价 敏感 支持 向量 机 ( LPCS-Lap SVM ) , 该 模型 基 于 半 监督 学习 框 架 , 将 代价 敏感 学习 和 类内 局部 保持 散度 的 思想 引入 其中 , 从 考虑 内 在 可 分辨 信息 和 样本 的 局部 几何 分布 两 方面 来 提 高 代价 敏感 支持 向 量 机 在 标记 信息 有限 的 场景 中 的 分类 性能 。	1>2	elab-addition	elab-addition
nlpabs18_Chi	33-42	43-50	代价 敏感 学习分 类器 的 分类 精度 大大 下降 ,	分类 性 能 得 不 到 保证 。	21-50	21-50	然而 , 当 数据 的 标记 信息 有限 或 不足 时 , 代价 敏感 学习分 类器 的 分类 精度 大大 下降 , 分类 性 能 得 不 到 保证 。	然而 , 当 数据 的 标记 信息 有限 或 不足 时 , 代价 敏感 学习分 类器 的 分类 精度 大大 下降 , 分类 性 能 得 不 到 保证 。	1<2	result	result
nlpabs18_Chi	51-55	56-75	针对 这 一 情况 ,	该文 提出 了 一 种 局部 几何 保持 的 Laplacian 代价 敏感 支持 向量 机 ( LPCS-Lap SVM ) ,	51-134	51-134	针对 这 一 情况 , 该文 提出 了 一 种 局部 几何 保持 的 Laplacian 代价 敏感 支持 向量 机 ( LPCS-Lap SVM ) , 该 模型 基 于 半 监督 学习 框 架 , 将 代价 敏感 学习 和 类内 局部 保持 散度 的 思想 引入 其中 , 从 考虑 内 在 可 分辨 信息 和 样本 的 局部 几何 分布 两 方面 来 提 高 代价 敏感 支持 向 量 机 在 标记 信息 有限 的 场景 中 的 分类 性能 。	针对 这 一 情况 , 该文 提出 了 一 种 局部 几何 保持 的 Laplacian 代价 敏感 支持 向量 机 ( LPCS-Lap SVM ) , 该 模型 基 于 半 监督 学习 框 架 , 将 代价 敏感 学习 和 类内 局部 保持 散度 的 思想 引入 其中 , 从 考虑 内 在 可 分辨 信息 和 样本 的 局部 几何 分布 两 方面 来 提 高 代价 敏感 支持 向 量 机 在 标记 信息 有限 的 场景 中 的 分类 性能 。	1>2	bg-general	bg-general
nlpabs18_Chi	56-75	76-85	该文 提出 了 一 种 局部 几何 保持 的 Laplacian 代价 敏感 支持 向量 机 ( LPCS-Lap SVM ) ,	该 模型 基 于 半 监督 学习 框 架 ,	51-134	51-134	针对 这 一 情况 , 该文 提出 了 一 种 局部 几何 保持 的 Laplacian 代价 敏感 支持 向量 机 ( LPCS-Lap SVM ) , 该 模型 基 于 半 监督 学习 框 架 , 将 代价 敏感 学习 和 类内 局部 保持 散度 的 思想 引入 其中 , 从 考虑 内 在 可 分辨 信息 和 样本 的 局部 几何 分布 两 方面 来 提 高 代价 敏感 支持 向 量 机 在 标记 信息 有限 的 场景 中 的 分类 性能 。	针对 这 一 情况 , 该文 提出 了 一 种 局部 几何 保持 的 Laplacian 代价 敏感 支持 向量 机 ( LPCS-Lap SVM ) , 该 模型 基 于 半 监督 学习 框 架 , 将 代价 敏感 学习 和 类内 局部 保持 散度 的 思想 引入 其中 , 从 考虑 内 在 可 分辨 信息 和 样本 的 局部 几何 分布 两 方面 来 提 高 代价 敏感 支持 向 量 机 在 标记 信息 有限 的 场景 中 的 分类 性能 。	1<2	elab-addition	elab-addition
nlpabs18_Chi	76-85	86-99	该 模型 基 于 半 监督 学习 框 架 ,	将 代价 敏感 学习 和 类内 局部 保持 散度 的 思想 引入 其中 ,	51-134	51-134	针对 这 一 情况 , 该文 提出 了 一 种 局部 几何 保持 的 Laplacian 代价 敏感 支持 向量 机 ( LPCS-Lap SVM ) , 该 模型 基 于 半 监督 学习 框 架 , 将 代价 敏感 学习 和 类内 局部 保持 散度 的 思想 引入 其中 , 从 考虑 内 在 可 分辨 信息 和 样本 的 局部 几何 分布 两 方面 来 提 高 代价 敏感 支持 向 量 机 在 标记 信息 有限 的 场景 中 的 分类 性能 。	针对 这 一 情况 , 该文 提出 了 一 种 局部 几何 保持 的 Laplacian 代价 敏感 支持 向量 机 ( LPCS-Lap SVM ) , 该 模型 基 于 半 监督 学习 框 架 , 将 代价 敏感 学习 和 类内 局部 保持 散度 的 思想 引入 其中 , 从 考虑 内 在 可 分辨 信息 和 样本 的 局部 几何 分布 两 方面 来 提 高 代价 敏感 支持 向 量 机 在 标记 信息 有限 的 场景 中 的 分类 性能 。	1<2	elab-addition	elab-addition
nlpabs18_Chi	86-99	100-134	将 代价 敏感 学习 和 类内 局部 保持 散度 的 思想 引入 其中 ,	从 考虑 内 在 可 分辨 信息 和 样本 的 局部 几何 分布 两 方面 来 提 高 代价 敏感 支持 向 量 机 在 标记 信息 有限 的 场景 中 的 分类 性能 。	51-134	51-134	针对 这 一 情况 , 该文 提出 了 一 种 局部 几何 保持 的 Laplacian 代价 敏感 支持 向量 机 ( LPCS-Lap SVM ) , 该 模型 基 于 半 监督 学习 框 架 , 将 代价 敏感 学习 和 类内 局部 保持 散度 的 思想 引入 其中 , 从 考虑 内 在 可 分辨 信息 和 样本 的 局部 几何 分布 两 方面 来 提 高 代价 敏感 支持 向 量 机 在 标记 信息 有限 的 场景 中 的 分类 性能 。	针对 这 一 情况 , 该文 提出 了 一 种 局部 几何 保持 的 Laplacian 代价 敏感 支持 向量 机 ( LPCS-Lap SVM ) , 该 模型 基 于 半 监督 学习 框 架 , 将 代价 敏感 学习 和 类内 局部 保持 散度 的 思想 引入 其中 , 从 考虑 内 在 可 分辨 信息 和 样本 的 局部 几何 分布 两 方面 来 提 高 代价 敏感 支持 向 量 机 在 标记 信息 有限 的 场景 中 的 分类 性能 。	1<2	elab-addition	elab-addition
nlpabs18_Chi	56-75	135-148	该文 提出 了 一 种 局部 几何 保持 的 Laplacian 代价 敏感 支持 向量 机 ( LPCS-Lap SVM ) ,	UCI 数据 集上 的 实验 结果 表明 了 该 算法 的 有效 性 。	51-134	135-148	针对 这 一 情况 , 该文 提出 了 一 种 局部 几何 保持 的 Laplacian 代价 敏感 支持 向量 机 ( LPCS-Lap SVM ) , 该 模型 基 于 半 监督 学习 框 架 , 将 代价 敏感 学习 和 类内 局部 保持 散度 的 思想 引入 其中 , 从 考虑 内 在 可 分辨 信息 和 样本 的 局部 几何 分布 两 方面 来 提 高 代价 敏感 支持 向 量 机 在 标记 信息 有限 的 场景 中 的 分类 性能 。	UCI 数据 集上 的 实验 结果 表明 了 该 算法 的 有效 性 。	1<2	evaluation	evaluation
nlpabs20_Chi	1-16	17-43	为 从 大量 的 复杂 非 规范 网页 结构 中 自动 抽取 出 新闻 标题 ,	该文 提出 一 种 基 于 密度 和 文本 特征 的 新闻 标题 抽取 算法 ( title extraction with den sity and text-features , TEDT ) 。	1-43	1-43	为 从 大量 的 复杂 非 规范 网页 结构 中 自动 抽取 出 新闻 标题 , 该文 提出 一 种 基 于 密度 和 文本 特征 的 新闻 标题 抽取 算法 ( title extraction with den sity and text-features , TEDT ) 。	为 从 大量 的 复杂 非 规范 网页 结构 中 自动 抽取 出 新闻 标题 , 该文 提出 一 种 基 于 密度 和 文本 特征 的 新闻 标题 抽取 算法 ( title extraction with den sity and text-features , TEDT ) 。	1>2	bg-goal	bg-goal
nlpabs20_Chi	17-43	44-58	该文 提出 一 种 基 于 密度 和 文本 特征 的 新闻 标题 抽取 算法 ( title extraction with den sity and text-features , TEDT ) 。	主要 通过 融合 网页 文本 密度 分布 和 语言 特征 的 语料 判定 模型 ,	1-43	44-98	为 从 大量 的 复杂 非 规范 网页 结构 中 自动 抽取 出 新闻 标题 , 该文 提出 一 种 基 于 密度 和 文本 特征 的 新闻 标题 抽取 算法 ( title extraction with den sity and text-features , TEDT ) 。	主要 通过 融合 网页 文本 密度 分布 和 语言 特征 的 语料 判定 模型 , 将 网页 划分 为 语料 区 和 标题 候选 区 , 选取 语料后 通过 Text Rank 算法 计算 对应 的 key-value 权重 集合 , 最后 采用 改进 的 相似 度 计算 方法 从 标题 候选 区 抽取 新闻 标题 。	1<2	elab-process_step	elab-process_step
nlpabs20_Chi	44-58	59-69	主要 通过 融合 网页 文本 密度 分布 和 语言 特征 的 语料 判定 模型 ,	将 网页 划分 为 语料 区 和 标题 候选 区 ,	44-98	44-98	主要 通过 融合 网页 文本 密度 分布 和 语言 特征 的 语料 判定 模型 , 将 网页 划分 为 语料 区 和 标题 候选 区 , 选取 语料后 通过 Text Rank 算法 计算 对应 的 key-value 权重 集合 , 最后 采用 改进 的 相似 度 计算 方法 从 标题 候选 区 抽取 新闻 标题 。	主要 通过 融合 网页 文本 密度 分布 和 语言 特征 的 语料 判定 模型 , 将 网页 划分 为 语料 区 和 标题 候选 区 , 选取 语料后 通过 Text Rank 算法 计算 对应 的 key-value 权重 集合 , 最后 采用 改进 的 相似 度 计算 方法 从 标题 候选 区 抽取 新闻 标题 。	1<2	enablement	enablement
nlpabs20_Chi	70-71	72-75	选取 语料后	通过 Text Rank 算法	44-98	44-98	主要 通过 融合 网页 文本 密度 分布 和 语言 特征 的 语料 判定 模型 , 将 网页 划分 为 语料 区 和 标题 候选 区 , 选取 语料后 通过 Text Rank 算法 计算 对应 的 key-value 权重 集合 , 最后 采用 改进 的 相似 度 计算 方法 从 标题 候选 区 抽取 新闻 标题 。	主要 通过 融合 网页 文本 密度 分布 和 语言 特征 的 语料 判定 模型 , 将 网页 划分 为 语料 区 和 标题 候选 区 , 选取 语料后 通过 Text Rank 算法 计算 对应 的 key-value 权重 集合 , 最后 采用 改进 的 相似 度 计算 方法 从 标题 候选 区 抽取 新闻 标题 。	1>2	temporal	temporal
nlpabs20_Chi	17-43	72-75	该文 提出 一 种 基 于 密度 和 文本 特征 的 新闻 标题 抽取 算法 ( title extraction with den sity and text-features , TEDT ) 。	通过 Text Rank 算法	1-43	44-98	为 从 大量 的 复杂 非 规范 网页 结构 中 自动 抽取 出 新闻 标题 , 该文 提出 一 种 基 于 密度 和 文本 特征 的 新闻 标题 抽取 算法 ( title extraction with den sity and text-features , TEDT ) 。	主要 通过 融合 网页 文本 密度 分布 和 语言 特征 的 语料 判定 模型 , 将 网页 划分 为 语料 区 和 标题 候选 区 , 选取 语料后 通过 Text Rank 算法 计算 对应 的 key-value 权重 集合 , 最后 采用 改进 的 相似 度 计算 方法 从 标题 候选 区 抽取 新闻 标题 。	1<2	elab-process_step	elab-process_step
nlpabs20_Chi	72-75	76-82	通过 Text Rank 算法	计算 对应 的 key-value 权重 集合 ,	44-98	44-98	主要 通过 融合 网页 文本 密度 分布 和 语言 特征 的 语料 判定 模型 , 将 网页 划分 为 语料 区 和 标题 候选 区 , 选取 语料后 通过 Text Rank 算法 计算 对应 的 key-value 权重 集合 , 最后 采用 改进 的 相似 度 计算 方法 从 标题 候选 区 抽取 新闻 标题 。	主要 通过 融合 网页 文本 密度 分布 和 语言 特征 的 语料 判定 模型 , 将 网页 划分 为 语料 区 和 标题 候选 区 , 选取 语料后 通过 Text Rank 算法 计算 对应 的 key-value 权重 集合 , 最后 采用 改进 的 相似 度 计算 方法 从 标题 候选 区 抽取 新闻 标题 。	1<2	enablement	enablement
nlpabs20_Chi	17-43	83-90	该文 提出 一 种 基 于 密度 和 文本 特征 的 新闻 标题 抽取 算法 ( title extraction with den sity and text-features , TEDT ) 。	最后 采用 改进 的 相似 度 计算 方法	1-43	44-98	为 从 大量 的 复杂 非 规范 网页 结构 中 自动 抽取 出 新闻 标题 , 该文 提出 一 种 基 于 密度 和 文本 特征 的 新闻 标题 抽取 算法 ( title extraction with den sity and text-features , TEDT ) 。	主要 通过 融合 网页 文本 密度 分布 和 语言 特征 的 语料 判定 模型 , 将 网页 划分 为 语料 区 和 标题 候选 区 , 选取 语料后 通过 Text Rank 算法 计算 对应 的 key-value 权重 集合 , 最后 采用 改进 的 相似 度 计算 方法 从 标题 候选 区 抽取 新闻 标题 。	1<2	elab-process_step	elab-process_step
nlpabs20_Chi	83-90	91-98	最后 采用 改进 的 相似 度 计算 方法	从 标题 候选 区 抽取 新闻 标题 。	44-98	44-98	主要 通过 融合 网页 文本 密度 分布 和 语言 特征 的 语料 判定 模型 , 将 网页 划分 为 语料 区 和 标题 候选 区 , 选取 语料后 通过 Text Rank 算法 计算 对应 的 key-value 权重 集合 , 最后 采用 改进 的 相似 度 计算 方法 从 标题 候选 区 抽取 新闻 标题 。	主要 通过 融合 网页 文本 密度 分布 和 语言 特征 的 语料 判定 模型 , 将 网页 划分 为 语料 区 和 标题 候选 区 , 选取 语料后 通过 Text Rank 算法 计算 对应 的 key-value 权重 集合 , 最后 采用 改进 的 相似 度 计算 方法 从 标题 候选 区 抽取 新闻 标题 。	1<2	enablement	enablement
nlpabs20_Chi	17-43	99-109	该文 提出 一 种 基 于 密度 和 文本 特征 的 新闻 标题 抽取 算法 ( title extraction with den sity and text-features , TEDT ) 。	该 算法 能 有 效 划分 语料 和 标题 区域 ,	1-43	99-120	为 从 大量 的 复杂 非 规范 网页 结构 中 自动 抽取 出 新闻 标题 , 该文 提出 一 种 基 于 密度 和 文本 特征 的 新闻 标题 抽取 算法 ( title extraction with den sity and text-features , TEDT ) 。	该 算法 能 有 效 划分 语料 和 标题 区域 , 降低 网页 噪声 干扰 , 准确 抽取 出 新闻 标题 。	1<2	evaluation	evaluation
nlpabs20_Chi	99-109	110-114	该 算法 能 有 效 划分 语料 和 标题 区域 ,	降低 网页 噪声 干扰 ,	99-120	99-120	该 算法 能 有 效 划分 语料 和 标题 区域 , 降低 网页 噪声 干扰 , 准确 抽取 出 新闻 标题 。	该 算法 能 有 效 划分 语料 和 标题 区域 , 降低 网页 噪声 干扰 , 准确 抽取 出 新闻 标题 。	1<2	joint	joint
nlpabs20_Chi	99-109	115-120	该 算法 能 有 效 划分 语料 和 标题 区域 ,	准确 抽取 出 新闻 标题 。	99-120	99-120	该 算法 能 有 效 划分 语料 和 标题 区域 , 降低 网页 噪声 干扰 , 准确 抽取 出 新闻 标题 。	该 算法 能 有 效 划分 语料 和 标题 区域 , 降低 网页 噪声 干扰 , 准确 抽取 出 新闻 标题 。	1<2	result	result
nlpabs20_Chi	121-124	125-148	实验 结果 表明 ,	TEDT 的 准确 率 和 召回 率 均 优 于 传统 的 基 于 规则 和 相似 度 的 新闻 标题 抽取 算法 ,	121-168	121-168	实验 结果 表明 , TEDT 的 准确 率 和 召回 率 均 优 于 传统 的 基 于 规则 和 相似 度 的 新闻 标题 抽取 算法 , 证明 了 TEDT 不仅 对 主流 新闻 网站 有效 , 而且 对 复杂 非 规范 网页 也 广泛 适用 。	实验 结果 表明 , TEDT 的 准确 率 和 召回 率 均 优 于 传统 的 基 于 规则 和 相似 度 的 新闻 标题 抽取 算法 , 证明 了 TEDT 不仅 对 主流 新闻 网站 有效 , 而且 对 复杂 非 规范 网页 也 广泛 适用 。	1>2	attribution	attribution
nlpabs20_Chi	99-109	125-148	该 算法 能 有 效 划分 语料 和 标题 区域 ,	TEDT 的 准确 率 和 召回 率 均 优 于 传统 的 基 于 规则 和 相似 度 的 新闻 标题 抽取 算法 ,	99-120	121-168	该 算法 能 有 效 划分 语料 和 标题 区域 , 降低 网页 噪声 干扰 , 准确 抽取 出 新闻 标题 。	实验 结果 表明 , TEDT 的 准确 率 和 召回 率 均 优 于 传统 的 基 于 规则 和 相似 度 的 新闻 标题 抽取 算法 , 证明 了 TEDT 不仅 对 主流 新闻 网站 有效 , 而且 对 复杂 非 规范 网页 也 广泛 适用 。	1<2	elab-addition	elab-addition
nlpabs20_Chi	125-148	149-158	TEDT 的 准确 率 和 召回 率 均 优 于 传统 的 基 于 规则 和 相似 度 的 新闻 标题 抽取 算法 ,	证明 了 TEDT 不仅 对 主流 新闻 网站 有效 ,	121-168	121-168	实验 结果 表明 , TEDT 的 准确 率 和 召回 率 均 优 于 传统 的 基 于 规则 和 相似 度 的 新闻 标题 抽取 算法 , 证明 了 TEDT 不仅 对 主流 新闻 网站 有效 , 而且 对 复杂 非 规范 网页 也 广泛 适用 。	实验 结果 表明 , TEDT 的 准确 率 和 召回 率 均 优 于 传统 的 基 于 规则 和 相似 度 的 新闻 标题 抽取 算法 , 证明 了 TEDT 不仅 对 主流 新闻 网站 有效 , 而且 对 复杂 非 规范 网页 也 广泛 适用 。	1<2	elab-addition	elab-addition
nlpabs20_Chi	149-158	159-168	证明 了 TEDT 不仅 对 主流 新闻 网站 有效 ,	而且 对 复杂 非 规范 网页 也 广泛 适用 。	121-168	121-168	实验 结果 表明 , TEDT 的 准确 率 和 召回 率 均 优 于 传统 的 基 于 规则 和 相似 度 的 新闻 标题 抽取 算法 , 证明 了 TEDT 不仅 对 主流 新闻 网站 有效 , 而且 对 复杂 非 规范 网页 也 广泛 适用 。	实验 结果 表明 , TEDT 的 准确 率 和 召回 率 均 优 于 传统 的 基 于 规则 和 相似 度 的 新闻 标题 抽取 算法 , 证明 了 TEDT 不仅 对 主流 新闻 网站 有效 , 而且 对 复杂 非 规范 网页 也 广泛 适用 。	1<2	progression	progression
nlpabs53_Chi	1-25	80-94	大 数据 时代 , 文本 数据 量 的 爆炸 式 增长 使得 特征 选择 成 为 文本 挖掘 领域 最关键 的 任务 之 一 。	该文 提出 基 于 包含 度 和 频繁 模式 的 文本 特征 选择 方法 :	1-25	80-94	大 数据 时代 , 文本 数据 量 的 爆炸 式 增长 使得 特征 选择 成 为 文本 挖掘 领域 最关键 的 任务 之 一 。	该文 提出 基 于 包含 度 和 频繁 模式 的 文本 特征 选择 方法 :	1>2	bg-general	bg-general
nlpabs53_Chi	1-25	26-34	大 数据 时代 , 文本 数据 量 的 爆炸 式 增长 使得 特征 选择 成 为 文本 挖掘 领域 最关键 的 任务 之 一 。	文档 中 的 词语 和 模式 规模 庞杂 ,	1-25	26-45	大 数据 时代 , 文本 数据 量 的 爆炸 式 增长 使得 特征 选择 成 为 文本 挖掘 领域 最关键 的 任务 之 一 。	文档 中 的 词语 和 模式 规模 庞杂 , 故 需 保证 所 挖掘 特征 的 质量 充满 挑战 。	1<2	elab-addition	elab-addition
nlpabs53_Chi	26-34	35-45	文档 中 的 词语 和 模式 规模 庞杂 ,	故 需 保证 所 挖掘 特征 的 质量 充满 挑战 。	26-45	26-45	文档 中 的 词语 和 模式 规模 庞杂 , 故 需 保证 所 挖掘 特征 的 质量 充满 挑战 。	文档 中 的 词语 和 模式 规模 庞杂 , 故 需 保证 所 挖掘 特征 的 质量 充满 挑战 。	1<2	result	result
nlpabs53_Chi	26-34	46-67	文档 中 的 词语 和 模式 规模 庞杂 ,	“ 基 于 模式 ” 特征 选择 方法 具有 传统 “ 基 于 词语 ” 方法 所 没有 的 优越 特性 ,	26-45	46-79	文档 中 的 词语 和 模式 规模 庞杂 , 故 需 保证 所 挖掘 特征 的 质量 充满 挑战 。	“ 基 于 模式 ” 特征 选择 方法 具有 传统 “ 基 于 词语 ” 方法 所 没有 的 优越 特性 , 可以 进行 有效 地 信息 去噪 , 提升 文本 挖掘 性能 。	1<2	joint	joint
nlpabs53_Chi	46-67	68-74	“ 基 于 模式 ” 特征 选择 方法 具有 传统 “ 基 于 词语 ” 方法 所 没有 的 优越 特性 ,	可以 进行 有效 地 信息 去噪 ,	46-79	46-79	“ 基 于 模式 ” 特征 选择 方法 具有 传统 “ 基 于 词语 ” 方法 所 没有 的 优越 特性 , 可以 进行 有效 地 信息 去噪 , 提升 文本 挖掘 性能 。	“ 基 于 模式 ” 特征 选择 方法 具有 传统 “ 基 于 词语 ” 方法 所 没有 的 优越 特性 , 可以 进行 有效 地 信息 去噪 , 提升 文本 挖掘 性能 。	1<2	elab-addition	elab-addition
nlpabs53_Chi	68-74	75-79	可以 进行 有效 地 信息 去噪 ,	提升 文本 挖掘 性能 。	46-79	46-79	“ 基 于 模式 ” 特征 选择 方法 具有 传统 “ 基 于 词语 ” 方法 所 没有 的 优越 特性 , 可以 进行 有效 地 信息 去噪 , 提升 文本 挖掘 性能 。	“ 基 于 模式 ” 特征 选择 方法 具有 传统 “ 基 于 词语 ” 方法 所 没有 的 优越 特性 , 可以 进行 有效 地 信息 去噪 , 提升 文本 挖掘 性能 。	1<2	enablement	enablement
nlpabs53_Chi	80-94	95-107	该文 提出 基 于 包含 度 和 频繁 模式 的 文本 特征 选择 方法 :	首先 , 定义 基 于 包含 度 的 相似 性 度量 原理 ;	80-94	95-123	该文 提出 基 于 包含 度 和 频繁 模式 的 文本 特征 选择 方法 :	首先 , 定义 基 于 包含 度 的 相似 性 度量 原理 ; 然后 , 提出 基 于 包含 度 的 冗余 文本 频繁 模 式 过滤 方法 。	1<2	elab-process_step	elab-process_step
nlpabs53_Chi	95-107	108-123	首先 , 定义 基 于 包含 度 的 相似 性 度量 原理 ;	然后 , 提出 基 于 包含 度 的 冗余 文本 频繁 模 式 过滤 方法 。	95-123	95-123	首先 , 定义 基 于 包含 度 的 相似 性 度量 原理 ; 然后 , 提出 基 于 包含 度 的 冗余 文本 频繁 模 式 过滤 方法 。	首先 , 定义 基 于 包含 度 的 相似 性 度量 原理 ; 然后 , 提出 基 于 包含 度 的 冗余 文本 频繁 模 式 过滤 方法 。	1<2	joint	joint
nlpabs53_Chi	108-123	124-135	然后 , 提出 基 于 包含 度 的 冗余 文本 频繁 模 式 过滤 方法 。	基 于 包含 度 度量 文本 频繁 模式 间 相似 性 ,	95-123	124-148	首先 , 定义 基 于 包含 度 的 相似 性 度量 原理 ; 然后 , 提出 基 于 包含 度 的 冗余 文本 频繁 模 式 过滤 方法 。	基 于 包含 度 度量 文本 频繁 模式 间 相似 性 , 以 此 去除 子 模式 及 相似 度 较高 的 交叉 模式 。	1<2	elab-addition	elab-addition
nlpabs53_Chi	124-135	136-148	基 于 包含 度 度量 文本 频繁 模式 间 相似 性 ,	以 此 去除 子 模式 及 相似 度 较高 的 交叉 模式 。	124-148	124-148	基 于 包含 度 度量 文本 频繁 模式 间 相似 性 , 以 此 去除 子 模式 及 相似 度 较高 的 交叉 模式 。	基 于 包含 度 度量 文本 频繁 模式 间 相似 性 , 以 此 去除 子 模式 及 相似 度 较高 的 交叉 模式 。	1<2	enablement	enablement
nlpabs53_Chi	108-123	149-154	然后 , 提出 基 于 包含 度 的 冗余 文本 频繁 模 式 过滤 方法 。	再 通过 冗余 模式 去噪 ,	95-123	149-173	首先 , 定义 基 于 包含 度 的 相似 性 度量 原理 ; 然后 , 提出 基 于 包含 度 的 冗余 文本 频繁 模 式 过滤 方法 。	再 通过 冗余 模式 去噪 , 提升 文本 频繁 模 式 挖掘 性能 ; 提出 基 于 关联 度 的 文本 特征 选择 方法 。	1<2	joint	joint
nlpabs53_Chi	149-154	155-162	再 通过 冗余 模式 去噪 ,	提升 文本 频繁 模 式 挖掘 性能 ;	149-173	149-173	再 通过 冗余 模式 去噪 , 提升 文本 频繁 模 式 挖掘 性能 ; 提出 基 于 关联 度 的 文本 特征 选择 方法 。	再 通过 冗余 模式 去噪 , 提升 文本 频繁 模 式 挖掘 性能 ; 提出 基 于 关联 度 的 文本 特征 选择 方法 。	1<2	enablement	enablement
nlpabs53_Chi	149-154	163-173	再 通过 冗余 模式 去噪 ,	提出 基 于 关联 度 的 文本 特征 选择 方法 。	149-173	149-173	再 通过 冗余 模式 去噪 , 提升 文本 频繁 模 式 挖掘 性能 ; 提出 基 于 关联 度 的 文本 特征 选择 方法 。	再 通过 冗余 模式 去噪 , 提升 文本 频繁 模 式 挖掘 性能 ; 提出 基 于 关联 度 的 文本 特征 选择 方法 。	1<2	joint	joint
nlpabs53_Chi	174-188	189-193	以 经过 过滤 处理 后 的 非 冗余 文本 频繁 模 式 为 基础 ,	进行 文本 特征 选择 ,	174-209	174-209	以 经过 过滤 处理 后 的 非 冗余 文本 频繁 模 式 为 基础 , 进行 文本 特征 选择 , 并 利用 词语 与 文档 的 关联 度 进行 词语 类别 划分 及 权重 分配 。	以 经过 过滤 处理 后 的 非 冗余 文本 频繁 模 式 为 基础 , 进行 文本 特征 选择 , 并 利用 词语 与 文档 的 关联 度 进行 词语 类别 划分 及 权重 分配 。	1>2	bg-goal	bg-goal
nlpabs53_Chi	149-154	189-193	再 通过 冗余 模式 去噪 ,	进行 文本 特征 选择 ,	149-173	174-209	再 通过 冗余 模式 去噪 , 提升 文本 频繁 模 式 挖掘 性能 ; 提出 基 于 关联 度 的 文本 特征 选择 方法 。	以 经过 过滤 处理 后 的 非 冗余 文本 频繁 模 式 为 基础 , 进行 文本 特征 选择 , 并 利用 词语 与 文档 的 关联 度 进行 词语 类别 划分 及 权重 分配 。	1<2	joint	joint
nlpabs53_Chi	189-193	194-209	进行 文本 特征 选择 ,	并 利用 词语 与 文档 的 关联 度 进行 词语 类别 划分 及 权重 分配 。	174-209	174-209	以 经过 过滤 处理 后 的 非 冗余 文本 频繁 模 式 为 基础 , 进行 文本 特征 选择 , 并 利用 词语 与 文档 的 关联 度 进行 词语 类别 划分 及 权重 分配 。	以 经过 过滤 处理 后 的 非 冗余 文本 频繁 模 式 为 基础 , 进行 文本 特征 选择 , 并 利用 词语 与 文档 的 关联 度 进行 词语 类别 划分 及 权重 分配 。	1<2	joint	joint
nlpabs53_Chi	194-209	210-220	并 利用 词语 与 文档 的 关联 度 进行 词语 类别 划分 及 权重 分配 。	使 所 选 特征 与 文档 关联 度 更加 清晰 ,	174-209	210-224	以 经过 过滤 处理 后 的 非 冗余 文本 频繁 模 式 为 基础 , 进行 文本 特征 选择 , 并 利用 词语 与 文档 的 关联 度 进行 词语 类别 划分 及 权重 分配 。	使 所 选 特征 与 文档 关联 度 更加 清晰 , 分类 效果 更好 。	1<2	enablement	enablement
nlpabs53_Chi	210-220	221-224	使 所 选 特征 与 文档 关联 度 更加 清晰 ,	分类 效果 更好 。	210-224	210-224	使 所 选 特征 与 文档 关联 度 更加 清晰 , 分类 效果 更好 。	使 所 选 特征 与 文档 关联 度 更加 清晰 , 分类 效果 更好 。	1<2	elab-addition	elab-addition
nlpabs53_Chi	225-235	236-270	通过 在 数据 集 Reuters -21578 上 的 实验 得知 ,	基 于 包含 度 和 频繁 模式 的 文本 特征 选择 算法 性能 , 优 于 当前 普遍 应用 的 传统 文本 特征 选择 方法 和 新 的 特征 选择 及 特征 抽取 方法 。	225-270	225-270	通过 在 数据 集 Reuters -21578 上 的 实验 得知 , 基 于 包含 度 和 频繁 模式 的 文本 特征 选择 算法 性能 , 优 于 当前 普遍 应用 的 传统 文本 特征 选择 方法 和 新 的 特征 选择 及 特征 抽取 方法 。	通过 在 数据 集 Reuters -21578 上 的 实验 得知 , 基 于 包含 度 和 频繁 模式 的 文本 特征 选择 算法 性能 , 优 于 当前 普遍 应用 的 传统 文本 特征 选择 方法 和 新 的 特征 选择 及 特征 抽取 方法 。	1>2	attribution	attribution
nlpabs53_Chi	80-94	236-270	该文 提出 基 于 包含 度 和 频繁 模式 的 文本 特征 选择 方法 :	基 于 包含 度 和 频繁 模式 的 文本 特征 选择 算法 性能 , 优 于 当前 普遍 应用 的 传统 文本 特征 选择 方法 和 新 的 特征 选择 及 特征 抽取 方法 。	80-94	225-270	该文 提出 基 于 包含 度 和 频繁 模式 的 文本 特征 选择 方法 :	通过 在 数据 集 Reuters -21578 上 的 实验 得知 , 基 于 包含 度 和 频繁 模式 的 文本 特征 选择 算法 性能 , 优 于 当前 普遍 应用 的 传统 文本 特征 选择 方法 和 新 的 特征 选择 及 特征 抽取 方法 。	1<2	evaluation	evaluation
nlpabs59_Chi	1-18	78-101	现有 的 将 词 映射 为 单 一 向量 的 方法 没有 考虑 词 的 多义 性 ,	该文 提出 了 一 种 基 于 非 残差 块 封装 的 门控 卷积 机制 加 以 层次 注意 力 机制 的 方法 ,	1-70	71-154	现有 的 将 词 映射 为 单 一 向量 的 方法 没有 考虑 词 的 多义 性 , 从而 会 引发 歧义 问题 ; 映射 为 多 个 向量 或 高斯 分布 的 方法 虽然 考虑 了 词 的 多义 性 , 但 或多 或少 没能 有 效 利用 词序 、 句法 结构 和 词间 距离 等 信息 对 词 在 某一 固定 语境 中 语义 表达 的 影响 。	综合 考虑 以上 存在 的 问题 , 该文 提出 了 一 种 基 于 非 残差 块 封装 的 门控 卷积 机制 加 以 层次 注意 力 机制 的 方法 , 分别 在 所 选取 语境 窗口 中 词 的 子 语义 层 、 合成 语义 层 获得 非 对称 语境 窗 口 下 目标 单 词 的 合成 语义 向量 以 预测 目标 单词 , 并 按 此法 在 给定 语料 上 学习 得到 多 语 义 词 向量 的 计算 方法 。	1>2	bg-compare	bg-compare
nlpabs59_Chi	1-18	19-24	现有 的 将 词 映射 为 单 一 向量 的 方法 没有 考虑 词 的 多义 性 ,	从而 会 引发 歧义 问题 ;	1-70	1-70	现有 的 将 词 映射 为 单 一 向量 的 方法 没有 考虑 词 的 多义 性 , 从而 会 引发 歧义 问题 ; 映射 为 多 个 向量 或 高斯 分布 的 方法 虽然 考虑 了 词 的 多义 性 , 但 或多 或少 没能 有 效 利用 词序 、 句法 结构 和 词间 距离 等 信息 对 词 在 某一 固定 语境 中 语义 表达 的 影响 。	现有 的 将 词 映射 为 单 一 向量 的 方法 没有 考虑 词 的 多义 性 , 从而 会 引发 歧义 问题 ; 映射 为 多 个 向量 或 高斯 分布 的 方法 虽然 考虑 了 词 的 多义 性 , 但 或多 或少 没能 有 效 利用 词序 、 句法 结构 和 词间 距离 等 信息 对 词 在 某一 固定 语境 中 语义 表达 的 影响 。	1<2	result	result
nlpabs59_Chi	1-18	25-42	现有 的 将 词 映射 为 单 一 向量 的 方法 没有 考虑 词 的 多义 性 ,	映射 为 多 个 向量 或 高斯 分布 的 方法 虽然 考虑 了 词 的 多义 性 ,	1-70	1-70	现有 的 将 词 映射 为 单 一 向量 的 方法 没有 考虑 词 的 多义 性 , 从而 会 引发 歧义 问题 ; 映射 为 多 个 向量 或 高斯 分布 的 方法 虽然 考虑 了 词 的 多义 性 , 但 或多 或少 没能 有 效 利用 词序 、 句法 结构 和 词间 距离 等 信息 对 词 在 某一 固定 语境 中 语义 表达 的 影响 。	现有 的 将 词 映射 为 单 一 向量 的 方法 没有 考虑 词 的 多义 性 , 从而 会 引发 歧义 问题 ; 映射 为 多 个 向量 或 高斯 分布 的 方法 虽然 考虑 了 词 的 多义 性 , 但 或多 或少 没能 有 效 利用 词序 、 句法 结构 和 词间 距离 等 信息 对 词 在 某一 固定 语境 中 语义 表达 的 影响 。	1<2	elab-addition	elab-addition
nlpabs59_Chi	25-42	43-70	映射 为 多 个 向量 或 高斯 分布 的 方法 虽然 考虑 了 词 的 多义 性 ,	但 或多 或少 没能 有 效 利用 词序 、 句法 结构 和 词间 距离 等 信息 对 词 在 某一 固定 语境 中 语义 表达 的 影响 。	1-70	1-70	现有 的 将 词 映射 为 单 一 向量 的 方法 没有 考虑 词 的 多义 性 , 从而 会 引发 歧义 问题 ; 映射 为 多 个 向量 或 高斯 分布 的 方法 虽然 考虑 了 词 的 多义 性 , 但 或多 或少 没能 有 效 利用 词序 、 句法 结构 和 词间 距离 等 信息 对 词 在 某一 固定 语境 中 语义 表达 的 影响 。	现有 的 将 词 映射 为 单 一 向量 的 方法 没有 考虑 词 的 多义 性 , 从而 会 引发 歧义 问题 ; 映射 为 多 个 向量 或 高斯 分布 的 方法 虽然 考虑 了 词 的 多义 性 , 但 或多 或少 没能 有 效 利用 词序 、 句法 结构 和 词间 距离 等 信息 对 词 在 某一 固定 语境 中 语义 表达 的 影响 。	1<2	contrast	contrast
nlpabs59_Chi	71-77	78-101	综合 考虑 以上 存在 的 问题 ,	该文 提出 了 一 种 基 于 非 残差 块 封装 的 门控 卷积 机制 加 以 层次 注意 力 机制 的 方法 ,	71-154	71-154	综合 考虑 以上 存在 的 问题 , 该文 提出 了 一 种 基 于 非 残差 块 封装 的 门控 卷积 机制 加 以 层次 注意 力 机制 的 方法 , 分别 在 所 选取 语境 窗口 中 词 的 子 语义 层 、 合成 语义 层 获得 非 对称 语境 窗 口 下 目标 单 词 的 合成 语义 向量 以 预测 目标 单词 , 并 按 此法 在 给定 语料 上 学习 得到 多 语 义 词 向量 的 计算 方法 。	综合 考虑 以上 存在 的 问题 , 该文 提出 了 一 种 基 于 非 残差 块 封装 的 门控 卷积 机制 加 以 层次 注意 力 机制 的 方法 , 分别 在 所 选取 语境 窗口 中 词 的 子 语义 层 、 合成 语义 层 获得 非 对称 语境 窗 口 下 目标 单 词 的 合成 语义 向量 以 预测 目标 单词 , 并 按 此法 在 给定 语料 上 学习 得到 多 语 义 词 向量 的 计算 方法 。	1>2	elab-addition	elab-addition
nlpabs59_Chi	78-101	102-131	该文 提出 了 一 种 基 于 非 残差 块 封装 的 门控 卷积 机制 加 以 层次 注意 力 机制 的 方法 ,	分别 在 所 选取 语境 窗口 中 词 的 子 语义 层 、 合成 语义 层 获得 非 对称 语境 窗 口 下 目标 单 词 的 合成 语义 向量	71-154	71-154	综合 考虑 以上 存在 的 问题 , 该文 提出 了 一 种 基 于 非 残差 块 封装 的 门控 卷积 机制 加 以 层次 注意 力 机制 的 方法 , 分别 在 所 选取 语境 窗口 中 词 的 子 语义 层 、 合成 语义 层 获得 非 对称 语境 窗 口 下 目标 单 词 的 合成 语义 向量 以 预测 目标 单词 , 并 按 此法 在 给定 语料 上 学习 得到 多 语 义 词 向量 的 计算 方法 。	综合 考虑 以上 存在 的 问题 , 该文 提出 了 一 种 基 于 非 残差 块 封装 的 门控 卷积 机制 加 以 层次 注意 力 机制 的 方法 , 分别 在 所 选取 语境 窗口 中 词 的 子 语义 层 、 合成 语义 层 获得 非 对称 语境 窗 口 下 目标 单 词 的 合成 语义 向量 以 预测 目标 单词 , 并 按 此法 在 给定 语料 上 学习 得到 多 语 义 词 向量 的 计算 方法 。	1<2	elab-addition	elab-addition
nlpabs59_Chi	102-131	132-136	分别 在 所 选取 语境 窗口 中 词 的 子 语义 层 、 合成 语义 层 获得 非 对称 语境 窗 口 下 目标 单 词 的 合成 语义 向量	以 预测 目标 单词 ,	71-154	71-154	综合 考虑 以上 存在 的 问题 , 该文 提出 了 一 种 基 于 非 残差 块 封装 的 门控 卷积 机制 加 以 层次 注意 力 机制 的 方法 , 分别 在 所 选取 语境 窗口 中 词 的 子 语义 层 、 合成 语义 层 获得 非 对称 语境 窗 口 下 目标 单 词 的 合成 语义 向量 以 预测 目标 单词 , 并 按 此法 在 给定 语料 上 学习 得到 多 语 义 词 向量 的 计算 方法 。	综合 考虑 以上 存在 的 问题 , 该文 提出 了 一 种 基 于 非 残差 块 封装 的 门控 卷积 机制 加 以 层次 注意 力 机制 的 方法 , 分别 在 所 选取 语境 窗口 中 词 的 子 语义 层 、 合成 语义 层 获得 非 对称 语境 窗 口 下 目标 单 词 的 合成 语义 向量 以 预测 目标 单词 , 并 按 此法 在 给定 语料 上 学习 得到 多 语 义 词 向量 的 计算 方法 。	1<2	enablement	enablement
nlpabs59_Chi	102-131	137-154	分别 在 所 选取 语境 窗口 中 词 的 子 语义 层 、 合成 语义 层 获得 非 对称 语境 窗 口 下 目标 单 词 的 合成 语义 向量	并 按 此法 在 给定 语料 上 学习 得到 多 语 义 词 向量 的 计算 方法 。	71-154	71-154	综合 考虑 以上 存在 的 问题 , 该文 提出 了 一 种 基 于 非 残差 块 封装 的 门控 卷积 机制 加 以 层次 注意 力 机制 的 方法 , 分别 在 所 选取 语境 窗口 中 词 的 子 语义 层 、 合成 语义 层 获得 非 对称 语境 窗 口 下 目标 单 词 的 合成 语义 向量 以 预测 目标 单词 , 并 按 此法 在 给定 语料 上 学习 得到 多 语 义 词 向量 的 计算 方法 。	综合 考虑 以上 存在 的 问题 , 该文 提出 了 一 种 基 于 非 残差 块 封装 的 门控 卷积 机制 加 以 层次 注意 力 机制 的 方法 , 分别 在 所 选取 语境 窗口 中 词 的 子 语义 层 、 合成 语义 层 获得 非 对称 语境 窗 口 下 目标 单 词 的 合成 语义 向量 以 预测 目标 单词 , 并 按 此法 在 给定 语料 上 学习 得到 多 语 义 词 向量 的 计算 方法 。	1<2	elab-addition	elab-addition
nlpabs59_Chi	102-131	155-187	分别 在 所 选取 语境 窗口 中 词 的 子 语义 层 、 合成 语义 层 获得 非 对称 语境 窗 口 下 目标 单 词 的 合成 语义 向量	小 规模 语料 上 用 该 方法 得到 的 多 语义 词 向量 , 在 词类 比 任务 的 语义 类比 上 相比 于 基线 方法 准确 率 最高 可 提升 1.42% ;	71-154	155-221	综合 考虑 以上 存在 的 问题 , 该文 提出 了 一 种 基 于 非 残差 块 封装 的 门控 卷积 机制 加 以 层次 注意 力 机制 的 方法 , 分别 在 所 选取 语境 窗口 中 词 的 子 语义 层 、 合成 语义 层 获得 非 对称 语境 窗 口 下 目标 单 词 的 合成 语义 向量 以 预测 目标 单词 , 并 按 此法 在 给定 语料 上 学习 得到 多 语 义 词 向量 的 计算 方法 。	小 规模 语料 上 用 该 方法 得到 的 多 语义 词 向量 , 在 词类 比 任务 的 语义 类比 上 相比 于 基线 方法 准确 率 最高 可 提升 1.42% ; 在 Word Sim353 、 MC 、 RG 、 RW 等 计算 单词 相似 度 任务 的 数据 集上 相比 于 基线 方法 能够 达到 平均 2.11 的 性能 提升 , 最高 可到 5.47 。	1<2	evaluation	evaluation
nlpabs59_Chi	155-187	188-221	小 规模 语料 上 用 该 方法 得到 的 多 语义 词 向量 , 在 词类 比 任务 的 语义 类比 上 相比 于 基线 方法 准确 率 最高 可 提升 1.42% ;	在 Word Sim353 、 MC 、 RG 、 RW 等 计算 单词 相似 度 任务 的 数据 集上 相比 于 基线 方法 能够 达到 平均 2.11 的 性能 提升 , 最高 可到 5.47 。	155-221	155-221	小 规模 语料 上 用 该 方法 得到 的 多 语义 词 向量 , 在 词类 比 任务 的 语义 类比 上 相比 于 基线 方法 准确 率 最高 可 提升 1.42% ; 在 Word Sim353 、 MC 、 RG 、 RW 等 计算 单词 相似 度 任务 的 数据 集上 相比 于 基线 方法 能够 达到 平均 2.11 的 性能 提升 , 最高 可到 5.47 。	小 规模 语料 上 用 该 方法 得到 的 多 语义 词 向量 , 在 词类 比 任务 的 语义 类比 上 相比 于 基线 方法 准确 率 最高 可 提升 1.42% ; 在 Word Sim353 、 MC 、 RG 、 RW 等 计算 单词 相似 度 任务 的 数据 集上 相比 于 基线 方法 能够 达到 平均 2.11 的 性能 提升 , 最高 可到 5.47 。	1<2	joint	joint
nlpabs59_Chi	155-187	222-246	小 规模 语料 上 用 该 方法 得到 的 多 语义 词 向量 , 在 词类 比 任务 的 语义 类比 上 相比 于 基线 方法 准确 率 最高 可 提升 1.42% ;	在 语言 建模 实验 上 , 该 方法 的 语言 模型 性能 相比 于 其他 预测 目标 单词 的 方法 也 有 显著 提升 。	155-221	222-246	小 规模 语料 上 用 该 方法 得到 的 多 语义 词 向量 , 在 词类 比 任务 的 语义 类比 上 相比 于 基线 方法 准确 率 最高 可 提升 1.42% ; 在 Word Sim353 、 MC 、 RG 、 RW 等 计算 单词 相似 度 任务 的 数据 集上 相比 于 基线 方法 能够 达到 平均 2.11 的 性能 提升 , 最高 可到 5.47 。	在 语言 建模 实验 上 , 该 方法 的 语言 模型 性能 相比 于 其他 预测 目标 单词 的 方法 也 有 显著 提升 。	1<2	joint	joint
nlpabs91_Chi	1-12	78-91	古代 汉 语 是 中国 语言 文学 专业 的 核心 课程 ,	提出 了 古代 汉 语 教材 词汇 教学 预期 成效 的 计算 方法 ,	1-40	41-174	古代 汉 语 是 中国 语言 文学 专业 的 核心 课程 , 然而 现有 教材 编写 在 篇章 选择 、 内容 编排 和 知识 点 取舍 上 多 基 于 主观 经验 , 教学 成 效难 以 量化 评估 。	该 文 基 于 先秦 典型 文献 的 词汇 现象 的 频率 、 重要 程度 以及 古今 词义 的 差异 , 讨论 了 面向 古代 汉 语 教学 的 词汇 知识 点 语料 库 的 建设 , 提出 了 古代 汉 语 教材 词汇 教学 预期 成效 的 计算 方法 , 并 以 王 力 主编 《 古代 汉 语 》 和 王 硕 编著 《 汉 语 古文 读本 》 两 种 性质 不同 、 文选 编排 顺序 不同 的 教材 作 为 个案 , 对比 分析 了 两 部 教材 的 篇幅 、 知识 点 分布 和 学习 曲线 , 从 量化 数据 上 佐证 了 学界 对 两 种 不同 性质 教材 的 定性 认识 , 同时 也 证明 所 提出 的 教材 预期 成效 评估 方法 的 合理 性 。	1>2	bg-general	bg-general
nlpabs91_Chi	1-12	13-33	古代 汉 语 是 中国 语言 文学 专业 的 核心 课程 ,	然而 现有 教材 编写 在 篇章 选择 、 内容 编排 和 知识 点 取舍 上 多 基 于 主观 经验 ,	1-40	1-40	古代 汉 语 是 中国 语言 文学 专业 的 核心 课程 , 然而 现有 教材 编写 在 篇章 选择 、 内容 编排 和 知识 点 取舍 上 多 基 于 主观 经验 , 教学 成 效难 以 量化 评估 。	古代 汉 语 是 中国 语言 文学 专业 的 核心 课程 , 然而 现有 教材 编写 在 篇章 选择 、 内容 编排 和 知识 点 取舍 上 多 基 于 主观 经验 , 教学 成 效难 以 量化 评估 。	1<2	elab-addition	elab-addition
nlpabs91_Chi	13-33	34-40	然而 现有 教材 编写 在 篇章 选择 、 内容 编排 和 知识 点 取舍 上 多 基 于 主观 经验 ,	教学 成 效难 以 量化 评估 。	1-40	1-40	古代 汉 语 是 中国 语言 文学 专业 的 核心 课程 , 然而 现有 教材 编写 在 篇章 选择 、 内容 编排 和 知识 点 取舍 上 多 基 于 主观 经验 , 教学 成 效难 以 量化 评估 。	古代 汉 语 是 中国 语言 文学 专业 的 核心 课程 , 然而 现有 教材 编写 在 篇章 选择 、 内容 编排 和 知识 点 取舍 上 多 基 于 主观 经验 , 教学 成 效难 以 量化 评估 。	1<2	elab-addition	elab-addition
nlpabs91_Chi	41-61	78-91	该 文 基 于 先秦 典型 文献 的 词汇 现象 的 频率 、 重要 程度 以及 古今 词义 的 差异 ,	提出 了 古代 汉 语 教材 词汇 教学 预期 成效 的 计算 方法 ,	41-174	41-174	该 文 基 于 先秦 典型 文献 的 词汇 现象 的 频率 、 重要 程度 以及 古今 词义 的 差异 , 讨论 了 面向 古代 汉 语 教学 的 词汇 知识 点 语料 库 的 建设 , 提出 了 古代 汉 语 教材 词汇 教学 预期 成效 的 计算 方法 , 并 以 王 力 主编 《 古代 汉 语 》 和 王 硕 编著 《 汉 语 古文 读本 》 两 种 性质 不同 、 文选 编排 顺序 不同 的 教材 作 为 个案 , 对比 分析 了 两 部 教材 的 篇幅 、 知识 点 分布 和 学习 曲线 , 从 量化 数据 上 佐证 了 学界 对 两 种 不同 性质 教材 的 定性 认识 , 同时 也 证明 所 提出 的 教材 预期 成效 评估 方法 的 合理 性 。	该 文 基 于 先秦 典型 文献 的 词汇 现象 的 频率 、 重要 程度 以及 古今 词义 的 差异 , 讨论 了 面向 古代 汉 语 教学 的 词汇 知识 点 语料 库 的 建设 , 提出 了 古代 汉 语 教材 词汇 教学 预期 成效 的 计算 方法 , 并 以 王 力 主编 《 古代 汉 语 》 和 王 硕 编著 《 汉 语 古文 读本 》 两 种 性质 不同 、 文选 编排 顺序 不同 的 教材 作 为 个案 , 对比 分析 了 两 部 教材 的 篇幅 、 知识 点 分布 和 学习 曲线 , 从 量化 数据 上 佐证 了 学界 对 两 种 不同 性质 教材 的 定性 认识 , 同时 也 证明 所 提出 的 教材 预期 成效 评估 方法 的 合理 性 。	1>2	manner-means	manner-means
nlpabs91_Chi	41-61	62-77	该 文 基 于 先秦 典型 文献 的 词汇 现象 的 频率 、 重要 程度 以及 古今 词义 的 差异 ,	讨论 了 面向 古代 汉 语 教学 的 词汇 知识 点 语料 库 的 建设 ,	41-174	41-174	该 文 基 于 先秦 典型 文献 的 词汇 现象 的 频率 、 重要 程度 以及 古今 词义 的 差异 , 讨论 了 面向 古代 汉 语 教学 的 词汇 知识 点 语料 库 的 建设 , 提出 了 古代 汉 语 教材 词汇 教学 预期 成效 的 计算 方法 , 并 以 王 力 主编 《 古代 汉 语 》 和 王 硕 编著 《 汉 语 古文 读本 》 两 种 性质 不同 、 文选 编排 顺序 不同 的 教材 作 为 个案 , 对比 分析 了 两 部 教材 的 篇幅 、 知识 点 分布 和 学习 曲线 , 从 量化 数据 上 佐证 了 学界 对 两 种 不同 性质 教材 的 定性 认识 , 同时 也 证明 所 提出 的 教材 预期 成效 评估 方法 的 合理 性 。	该 文 基 于 先秦 典型 文献 的 词汇 现象 的 频率 、 重要 程度 以及 古今 词义 的 差异 , 讨论 了 面向 古代 汉 语 教学 的 词汇 知识 点 语料 库 的 建设 , 提出 了 古代 汉 语 教材 词汇 教学 预期 成效 的 计算 方法 , 并 以 王 力 主编 《 古代 汉 语 》 和 王 硕 编著 《 汉 语 古文 读本 》 两 种 性质 不同 、 文选 编排 顺序 不同 的 教材 作 为 个案 , 对比 分析 了 两 部 教材 的 篇幅 、 知识 点 分布 和 学习 曲线 , 从 量化 数据 上 佐证 了 学界 对 两 种 不同 性质 教材 的 定性 认识 , 同时 也 证明 所 提出 的 教材 预期 成效 评估 方法 的 合理 性 。	1<2	joint	joint
nlpabs91_Chi	78-91	92-126	提出 了 古代 汉 语 教材 词汇 教学 预期 成效 的 计算 方法 ,	并 以 王 力 主编 《 古代 汉 语 》 和 王 硕 编著 《 汉 语 古文 读本 》 两 种 性质 不同 、 文选 编排 顺序 不同 的 教材 作 为 个案 ,	41-174	41-174	该 文 基 于 先秦 典型 文献 的 词汇 现象 的 频率 、 重要 程度 以及 古今 词义 的 差异 , 讨论 了 面向 古代 汉 语 教学 的 词汇 知识 点 语料 库 的 建设 , 提出 了 古代 汉 语 教材 词汇 教学 预期 成效 的 计算 方法 , 并 以 王 力 主编 《 古代 汉 语 》 和 王 硕 编著 《 汉 语 古文 读本 》 两 种 性质 不同 、 文选 编排 顺序 不同 的 教材 作 为 个案 , 对比 分析 了 两 部 教材 的 篇幅 、 知识 点 分布 和 学习 曲线 , 从 量化 数据 上 佐证 了 学界 对 两 种 不同 性质 教材 的 定性 认识 , 同时 也 证明 所 提出 的 教材 预期 成效 评估 方法 的 合理 性 。	该 文 基 于 先秦 典型 文献 的 词汇 现象 的 频率 、 重要 程度 以及 古今 词义 的 差异 , 讨论 了 面向 古代 汉 语 教学 的 词汇 知识 点 语料 库 的 建设 , 提出 了 古代 汉 语 教材 词汇 教学 预期 成效 的 计算 方法 , 并 以 王 力 主编 《 古代 汉 语 》 和 王 硕 编著 《 汉 语 古文 读本 》 两 种 性质 不同 、 文选 编排 顺序 不同 的 教材 作 为 个案 , 对比 分析 了 两 部 教材 的 篇幅 、 知识 点 分布 和 学习 曲线 , 从 量化 数据 上 佐证 了 学界 对 两 种 不同 性质 教材 的 定性 认识 , 同时 也 证明 所 提出 的 教材 预期 成效 评估 方法 的 合理 性 。	1<2	joint	joint
nlpabs91_Chi	92-126	127-142	并 以 王 力 主编 《 古代 汉 语 》 和 王 硕 编著 《 汉 语 古文 读本 》 两 种 性质 不同 、 文选 编排 顺序 不同 的 教材 作 为 个案 ,	对比 分析 了 两 部 教材 的 篇幅 、 知识 点 分布 和 学习 曲线 ,	41-174	41-174	该 文 基 于 先秦 典型 文献 的 词汇 现象 的 频率 、 重要 程度 以及 古今 词义 的 差异 , 讨论 了 面向 古代 汉 语 教学 的 词汇 知识 点 语料 库 的 建设 , 提出 了 古代 汉 语 教材 词汇 教学 预期 成效 的 计算 方法 , 并 以 王 力 主编 《 古代 汉 语 》 和 王 硕 编著 《 汉 语 古文 读本 》 两 种 性质 不同 、 文选 编排 顺序 不同 的 教材 作 为 个案 , 对比 分析 了 两 部 教材 的 篇幅 、 知识 点 分布 和 学习 曲线 , 从 量化 数据 上 佐证 了 学界 对 两 种 不同 性质 教材 的 定性 认识 , 同时 也 证明 所 提出 的 教材 预期 成效 评估 方法 的 合理 性 。	该 文 基 于 先秦 典型 文献 的 词汇 现象 的 频率 、 重要 程度 以及 古今 词义 的 差异 , 讨论 了 面向 古代 汉 语 教学 的 词汇 知识 点 语料 库 的 建设 , 提出 了 古代 汉 语 教材 词汇 教学 预期 成效 的 计算 方法 , 并 以 王 力 主编 《 古代 汉 语 》 和 王 硕 编著 《 汉 语 古文 读本 》 两 种 性质 不同 、 文选 编排 顺序 不同 的 教材 作 为 个案 , 对比 分析 了 两 部 教材 的 篇幅 、 知识 点 分布 和 学习 曲线 , 从 量化 数据 上 佐证 了 学界 对 两 种 不同 性质 教材 的 定性 认识 , 同时 也 证明 所 提出 的 教材 预期 成效 评估 方法 的 合理 性 。	1<2	elab-addition	elab-addition
nlpabs91_Chi	127-142	143-159	对比 分析 了 两 部 教材 的 篇幅 、 知识 点 分布 和 学习 曲线 ,	从 量化 数据 上 佐证 了 学界 对 两 种 不同 性质 教材 的 定性 认识 ,	41-174	41-174	该 文 基 于 先秦 典型 文献 的 词汇 现象 的 频率 、 重要 程度 以及 古今 词义 的 差异 , 讨论 了 面向 古代 汉 语 教学 的 词汇 知识 点 语料 库 的 建设 , 提出 了 古代 汉 语 教材 词汇 教学 预期 成效 的 计算 方法 , 并 以 王 力 主编 《 古代 汉 语 》 和 王 硕 编著 《 汉 语 古文 读本 》 两 种 性质 不同 、 文选 编排 顺序 不同 的 教材 作 为 个案 , 对比 分析 了 两 部 教材 的 篇幅 、 知识 点 分布 和 学习 曲线 , 从 量化 数据 上 佐证 了 学界 对 两 种 不同 性质 教材 的 定性 认识 , 同时 也 证明 所 提出 的 教材 预期 成效 评估 方法 的 合理 性 。	该 文 基 于 先秦 典型 文献 的 词汇 现象 的 频率 、 重要 程度 以及 古今 词义 的 差异 , 讨论 了 面向 古代 汉 语 教学 的 词汇 知识 点 语料 库 的 建设 , 提出 了 古代 汉 语 教材 词汇 教学 预期 成效 的 计算 方法 , 并 以 王 力 主编 《 古代 汉 语 》 和 王 硕 编著 《 汉 语 古文 读本 》 两 种 性质 不同 、 文选 编排 顺序 不同 的 教材 作 为 个案 , 对比 分析 了 两 部 教材 的 篇幅 、 知识 点 分布 和 学习 曲线 , 从 量化 数据 上 佐证 了 学界 对 两 种 不同 性质 教材 的 定性 认识 , 同时 也 证明 所 提出 的 教材 预期 成效 评估 方法 的 合理 性 。	1<2	elab-addition	elab-addition
nlpabs91_Chi	143-159	160-174	从 量化 数据 上 佐证 了 学界 对 两 种 不同 性质 教材 的 定性 认识 ,	同时 也 证明 所 提出 的 教材 预期 成效 评估 方法 的 合理 性 。	41-174	41-174	该 文 基 于 先秦 典型 文献 的 词汇 现象 的 频率 、 重要 程度 以及 古今 词义 的 差异 , 讨论 了 面向 古代 汉 语 教学 的 词汇 知识 点 语料 库 的 建设 , 提出 了 古代 汉 语 教材 词汇 教学 预期 成效 的 计算 方法 , 并 以 王 力 主编 《 古代 汉 语 》 和 王 硕 编著 《 汉 语 古文 读本 》 两 种 性质 不同 、 文选 编排 顺序 不同 的 教材 作 为 个案 , 对比 分析 了 两 部 教材 的 篇幅 、 知识 点 分布 和 学习 曲线 , 从 量化 数据 上 佐证 了 学界 对 两 种 不同 性质 教材 的 定性 认识 , 同时 也 证明 所 提出 的 教材 预期 成效 评估 方法 的 合理 性 。	该 文 基 于 先秦 典型 文献 的 词汇 现象 的 频率 、 重要 程度 以及 古今 词义 的 差异 , 讨论 了 面向 古代 汉 语 教学 的 词汇 知识 点 语料 库 的 建设 , 提出 了 古代 汉 语 教材 词汇 教学 预期 成效 的 计算 方法 , 并 以 王 力 主编 《 古代 汉 语 》 和 王 硕 编著 《 汉 语 古文 读本 》 两 种 性质 不同 、 文选 编排 顺序 不同 的 教材 作 为 个案 , 对比 分析 了 两 部 教材 的 篇幅 、 知识 点 分布 和 学习 曲线 , 从 量化 数据 上 佐证 了 学界 对 两 种 不同 性质 教材 的 定性 认识 , 同时 也 证明 所 提出 的 教材 预期 成效 评估 方法 的 合理 性 。	1<2	joint	joint
nlpabs91_Chi	127-142	175-184	对比 分析 了 两 部 教材 的 篇幅 、 知识 点 分布 和 学习 曲线 ,	进 一 步 讨论 了 文选 的 重新 排序 ,	41-174	175-195	该 文 基 于 先秦 典型 文献 的 词汇 现象 的 频率 、 重要 程度 以及 古今 词义 的 差异 , 讨论 了 面向 古代 汉 语 教学 的 词汇 知识 点 语料 库 的 建设 , 提出 了 古代 汉 语 教材 词汇 教学 预期 成效 的 计算 方法 , 并 以 王 力 主编 《 古代 汉 语 》 和 王 硕 编著 《 汉 语 古文 读本 》 两 种 性质 不同 、 文选 编排 顺序 不同 的 教材 作 为 个案 , 对比 分析 了 两 部 教材 的 篇幅 、 知识 点 分布 和 学习 曲线 , 从 量化 数据 上 佐证 了 学界 对 两 种 不同 性质 教材 的 定性 认识 , 同时 也 证明 所 提出 的 教材 预期 成效 评估 方法 的 合理 性 。	进 一 步 讨论 了 文选 的 重新 排序 , 获得 了 更加 符合 循序渐进 教学 过程 的 学习 曲线 。	1<2	progression	progression
nlpabs91_Chi	175-184	185-195	进 一 步 讨论 了 文选 的 重新 排序 ,	获得 了 更加 符合 循序渐进 教学 过程 的 学习 曲线 。	175-195	175-195	进 一 步 讨论 了 文选 的 重新 排序 , 获得 了 更加 符合 循序渐进 教学 过程 的 学习 曲线 。	进 一 步 讨论 了 文选 的 重新 排序 , 获得 了 更加 符合 循序渐进 教学 过程 的 学习 曲线 。	1<2	enablement	enablement
nlpabs91_Chi	78-91	196-217	提出 了 古代 汉 语 教材 词汇 教学 预期 成效 的 计算 方法 ,	基 于 语料 库 的 古代 汉 语 教材 预期 成效 评估 方法 不仅 为 教材 评估 提供 了 量化 方法 ,	41-174	196-239	该 文 基 于 先秦 典型 文献 的 词汇 现象 的 频率 、 重要 程度 以及 古今 词义 的 差异 , 讨论 了 面向 古代 汉 语 教学 的 词汇 知识 点 语料 库 的 建设 , 提出 了 古代 汉 语 教材 词汇 教学 预期 成效 的 计算 方法 , 并 以 王 力 主编 《 古代 汉 语 》 和 王 硕 编著 《 汉 语 古文 读本 》 两 种 性质 不同 、 文选 编排 顺序 不同 的 教材 作 为 个案 , 对比 分析 了 两 部 教材 的 篇幅 、 知识 点 分布 和 学习 曲线 , 从 量化 数据 上 佐证 了 学界 对 两 种 不同 性质 教材 的 定性 认识 , 同时 也 证明 所 提出 的 教材 预期 成效 评估 方法 的 合理 性 。	基 于 语料 库 的 古代 汉 语 教材 预期 成效 评估 方法 不仅 为 教材 评估 提供 了 量化 方法 , 也 为 成效 导向 教学 在 古代 汉 语 课程 的 应用 提供 了 探索 性 的 思路 和 基础 数据 。	1<2	elab-addition	elab-addition
nlpabs91_Chi	196-217	218-239	基 于 语料 库 的 古代 汉 语 教材 预期 成效 评估 方法 不仅 为 教材 评估 提供 了 量化 方法 ,	也 为 成效 导向 教学 在 古代 汉 语 课程 的 应用 提供 了 探索 性 的 思路 和 基础 数据 。	196-239	196-239	基 于 语料 库 的 古代 汉 语 教材 预期 成效 评估 方法 不仅 为 教材 评估 提供 了 量化 方法 , 也 为 成效 导向 教学 在 古代 汉 语 课程 的 应用 提供 了 探索 性 的 思路 和 基础 数据 。	基 于 语料 库 的 古代 汉 语 教材 预期 成效 评估 方法 不仅 为 教材 评估 提供 了 量化 方法 , 也 为 成效 导向 教学 在 古代 汉 语 课程 的 应用 提供 了 探索 性 的 思路 和 基础 数据 。	1<2	joint	joint
